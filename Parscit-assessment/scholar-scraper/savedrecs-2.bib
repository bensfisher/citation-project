
@article{ ISI:000184256300004,
Author = {Smith, G and Coulston, J and Jepsen, E and Prichard, T},
Title = {{A national ozone biomonitoring program - Results from field surveys of
   ozone sensitive plants in northeastern forests (1994-2000)}},
Journal = {{ENVIRONMENTAL MONITORING AND ASSESSMENT}},
Year = {{2003}},
Volume = {{87}},
Number = {{3}},
Pages = {{271-291}},
Month = {{SEP}},
Abstract = {{Ozone biomonitoring is a detection and monitoring technique that
   involves documenting ozone-induced visible injury to known
   ozone-sensitive species under conditions of ambient exposure. The USDA
   Forest Service administers a long-term, nationwide ozone biomonitoring
   program to address public and scientific concerns about ozone impacts on
   forest health. A systematic grid is used as the basis for biomonitoring
   site locations. At each site, trained field crews evaluate a maximum of
   thirty plants of up to six species and record the amount and severity of
   leaf-injury on individual plants. Injury from ozone was found more often
   on biomonitoring sites in the eastern Unites States than in the interior
   or west-coast areas. Further results from the northeast reveal that in
   any year, there is a higher percentage of ozone-injured plants with more
   severe symptoms in areas with relatively high ozone concentrations than
   in areas with relatively low ozone. In very dry years ( e. g., 1999) the
   percentage of injured plants and injury severity estimates are both
   sharply reduced even though ambient ozone exposures are high. These
   findings demonstrate that biomonitoring data provide meaningful evidence
   of when high ozone concentrations during the growing season have
   biological significance. Any assessment of ozone stress in the forest
   environment must include both biomonitoring (i. e., plant response) and
   air quality data to be complete.}},
DOI = {{10.1023/A:1024879527764}},
ISSN = {{0167-6369}},
Unique-ID = {{ISI:000184256300004}},
}

@article{ ISI:000270142700009,
Author = {Borland, R. and Wilson, N. and Fong, G. T. and Hammond, D. and Cummings,
   K. M. and Yong, H-H and Hosking, W. and Hastings, G. and Thrasher, J.
   and McNeill, A.},
Title = {{Impact of graphic and text warnings on cigarette packs: findings from
   four countries over five years}},
Journal = {{TOBACCO CONTROL}},
Year = {{2009}},
Volume = {{18}},
Number = {{5}},
Pages = {{358-364}},
Month = {{OCT}},
Abstract = {{Objectives: To examine the impact of health warnings on smokers by
   comparing the short-term impact of new graphic (2006) Australian
   warnings with: (i) earlier (2003) United Kingdom larger text-based
   warnings; (ii) and Canadian graphic warnings (late 2000); and also to
   extend our understanding of warning wear-out.
   Methods: The International Tobacco Control Policy Evaluation Survey (ITC
   Project) follows prospective cohorts (with replenishment) of adult
   smokers annually (five waves: 2002-2006), in Canada, United States, UK
   and Australia (around 2000 per country per wave; total n = 17 773).
   Measures were of pack warning salience (reading and noticing); cognitive
   responses (thoughts of harm and quitting); and two behavioural
   responses: forgoing cigarettes and avoiding the warnings.
   Results: All four indicators of impact increased markedly among
   Australian smokers following the introduction of graphic warnings.
   Controlling for date of introduction, they stimulated more cognitive
   responses than the UK (text-only) changes, and were avoided more, did
   not significantly increase forgoing cigarettes, but were read and
   noticed less. The findings also extend previous work showing partial
   wear-out of both graphic and text-only warnings, but the Canadian
   warnings have more sustained effects than UK ones.
   Conclusions: Australia's new health warnings increased reactions that
   are prospectively predictive of cessation activity. Warning size
   increases warning effectiveness and graphic warnings may be superior to
   text-based warnings. While there is partial wear-out in the initial
   impact associated with all warnings, stronger warnings tend to sustain
   their effects for longer. These findings support arguments for
   governments to exceed minimum FCTC requirements on warnings.}},
DOI = {{10.1136/tc.2008.028043}},
ISSN = {{0964-4563}},
ResearcherID-Numbers = {{Fong, Geoffrey/H-2810-2014}},
ORCID-Numbers = {{Fong, Geoffrey/0000-0001-9098-6472}},
Unique-ID = {{ISI:000270142700009}},
}

@article{ ISI:000272179400021,
Author = {Miller, Caroline L. and Hill, David J. and Quester, Pascale G. and
   Hiller, Janet E.},
Title = {{Response of mass media, tobacco industry and smokers to the introduction
   of graphic cigarette pack warnings in Australia}},
Journal = {{EUROPEAN JOURNAL OF PUBLIC HEALTH}},
Year = {{2009}},
Volume = {{19}},
Number = {{6}},
Pages = {{644-649}},
Month = {{DEC}},
Abstract = {{Background: In the year 2006, Australia introduced graphic cigarette
   packet warnings. Previous warnings were text only. New warnings include
   one of 14 pictures, many depicting tobacco-related pathology. Methods:
   This study monitored the roll-out of the health policy initiative using
   multiple methodologies. Print media coverage of new pack warnings was
   observed over 3 years. Story content was coded as positive (supportive
   of pack warnings), neutral or negative. An observational study of small
   random sample of metropolitan stores (n = 16) over 7 months measured the
   pace of the roll-out in shops. Once new packs were readily available in
   stores, smokers (n = 152) were intercepted in city streets and asked
   about their reactions. Results: Of the 67 media stories, 85\% were
   positive or neutral about the new warnings and 15\% were negative.
   Supportive content presented health benefits. Unsupportive content
   presented industry arguments. After the legislative change, it took 2
   months before any new packs appeared in stores. After 6 months, the
   majority carried them. Newest images had highest recall among smokers.
   About 60\% said new warnings detracted from the look of their brand.
   About 51\% felt the increased risk of dying from smoking-related
   illness. About 38\% felt motivated to quit. Conclusion: Plans by
   government to introduce graphic warnings were delayed up to 2 years,
   apparently by heavy industry lobbying. Actual widespread appearance in
   shops occurred several months after the implementation date. While media
   coverage of the new warnings reported the industry arguments against
   them, the balance of coverage was overwhelmingly positive. Smokers'
   initial reactions were in line with tobacco control objectives.}},
DOI = {{10.1093/eurpub/ckp089}},
ISSN = {{1101-1262}},
ResearcherID-Numbers = {{Hiller, Janet/A-5633-2008}},
ORCID-Numbers = {{Hiller, Janet/0000-0002-8532-4033}},
Unique-ID = {{ISI:000272179400021}},
}

@article{ ISI:000287620100006,
Author = {Boldo, Elena and Linares, Cristina and Lumbreras, Julio and Borge,
   Rafael and Narros, Adolfo and Garcia-Perez, Javier and
   Fernandez-Navarro, Pablo and Perez-Gomez, Beatriz and Aragones, Nuria
   and Ramis, Rebeca and Pollan, Marina and Moreno, Teresa and Karanasiou,
   Angeliki and Lopez-Abente, Gonzalo},
Title = {{Health impact assessment of a reduction in ambient PM2.5 levels in Spain}},
Journal = {{ENVIRONMENT INTERNATIONAL}},
Year = {{2011}},
Volume = {{37}},
Number = {{2}},
Pages = {{342-348}},
Month = {{FEB}},
Abstract = {{Background: Health effects linked to exposure to high air pollutant
   levels have been described in depth, and many recent epidemiologic
   studies have also consistently reported positive associations between
   exposure to air pollutants at low concentrations (particularly PM2.5)
   and adverse health outcomes.
   Objective: To estimate the number of avoidable deaths associated with
   reducing PM2.5 levels in Spain.
   Materials and methods: For exposure assessment, we used the US
   Environmental Protection Agency's Community Multiscale Air Quality model
   to simulate air pollution levels with a spatial resolution of 18 x 18
   km(2). Two different scenarios were compared, namely, a baseline 2004
   scenario based on Spain's National Emissions Inventory and a projected
   2011 scenario in which a reduction in PM2.5 was estimated on the basis
   of the benefits that might be attained if specific air quality policies
   were implemented. Using an 18 x 18 km2 grid, air pollution data were
   estimated for the entire Iberian Peninsula, the Balearic Islands, Ceuta
   and Melilla. For these strata, crude all-cause mortality rates (ICD-10:
   A00-Y98) were then calculated for the over-30 and 25-74 age groups,
   taking into account the 2004 population figures corresponding to these
   same age groups, selected in accordance with the concentration-response
   functions (Pope CA 3rd, Burnett RT,Thun MJ, Calle EE, Krewski D, Ito K
   et al. Lung cancer, cardiopulmonary mortality, and long-term exposure to
   fine particulate air pollution. JAMA 2002; 287:1132-41; Laden F.
   Schwartz J, Speizer FE, Dockery DW. Reduction in fine particulate air
   pollution and mortality: extended follow-up of the Harvard Six Cities
   study. Am J Respir Crit Care Med 2006; 173:667-72.). Health impacts were
   assessed using the Environmental Benefits Mapping and Analysis Program
   (BenMAP).
   Results: Air quality improvement was defined as an average annual
   reduction of 0.7 mu g/m(3) in PM2.5 levels. Using long-term health
   impact assessment analysis, we estimated that 1720 (673-2760) all-cause
   deaths (6 per 100,000 population) in the over-30 age group and
   1450(780-2108) all-cause deaths (5 per 100,000 population) in the 25-74
   age group could be prevented annually.
   Conclusions: The results showed the potential benefits in general
   mortality which could be expected if pollution control policies were
   successfully implemented by 2011. A specifically adapted BenMAP could be
   used as a tool for estimating health impacts associated with changes in
   air pollution in Spain. (c) 2010 Elsevier Ltd. All rights reserved.}},
DOI = {{10.1016/j.envint.2010.10.004}},
ISSN = {{0160-4120}},
ResearcherID-Numbers = {{Moreno, Teresa/C-9349-2009
   Lopez-Abente, Gonzalo/E-5221-2010
   Pollan, Marina/
   Boldo, Elena/L-6610-2014
   Pollan, Marina/M-3259-2014
   Wang, Linden/M-6617-2014
   Ramis, Rebeca/E-1743-2015
   Perez-Gomez, Beatriz/C-4715-2012
   Aragones, Nuria/O-5962-2015
   Garcia-Perez, Javier/}},
ORCID-Numbers = {{Moreno, Teresa/0000-0003-3235-1027
   Lopez-Abente, Gonzalo/0000-0003-2423-8075
   Pollan, Marina/0000-0002-4328-1565
   Boldo, Elena/0000-0003-0027-1989
   Ramis, Rebeca/0000-0001-6154-9142
   Perez-Gomez, Beatriz/0000-0002-4299-8214
   Aragones, Nuria/0000-0003-0983-2156
   Garcia-Perez, Javier/0000-0003-0300-1810}},
Unique-ID = {{ISI:000287620100006}},
}

@article{ ISI:A1993KM02400005,
Author = {DIETRICH, KN and BERGER, OG and SUCCOP, PA and HAMMOND, PB and
   BORNSCHEIN, RL},
Title = {{THE DEVELOPMENTAL CONSEQUENCES OF LOW TO MODERATE PRENATAL AND POSTNATAL
   LEAD-EXPOSURE - INTELLECTUAL ATTAINMENT IN THE CINCINNATI LEAD STUDY
   COHORT FOLLOWING SCHOOL ENTRY}},
Journal = {{NEUROTOXICOLOGY AND TERATOLOGY}},
Year = {{1993}},
Volume = {{15}},
Number = {{1}},
Pages = {{37-44}},
Month = {{JAN-FEB}},
Abstract = {{In a further follow-up study of the Cincinnati Lead Study Cohort, 253
   children were administered the Wechsler Intelligence Scale for
   Children-Revised (WISC-R) at approximately 6.5 years of age. Postnatal
   blood lead concentrations were inversely associated with Full-Scale
   (FSIQ) and Performance IQ (PIQ). Following statistical adjustment for
   developmental co-factors such as maternal IQ and an assessment of the
   quality of caretaking in the home environment, a statistically
   significant relationship remained between postnatal blood lead
   concentrations and PIQ. Further statistical analyses suggested that
   averaged lifetime blood lead concentrations in excess of 20 mug/dL were
   associated with deficits in PIQ on the order of approximately 7 points
   when compared to children with mean concentrations less or equal to 10
   mug/dL. These results are discussed in terms of their consistency with
   other similar studies as well as their internal consistency with earlier
   reports on this cohort. The findings of this investigation support
   recent initiatives in the United States to reduce the exposure of
   children to environmental lead.}},
DOI = {{10.1016/0892-0362(93)90043-N}},
ISSN = {{0892-0362}},
Unique-ID = {{ISI:A1993KM02400005}},
}

@article{ ISI:000080987100006,
Author = {Sorensen, N and Murata, K and Budtz-Jorgensen, E and Weihe, P and
   Grandjean, P},
Title = {{Prenatal methylmercury exposure as a cardiovascular risk factor at seven
   years of age}},
Journal = {{EPIDEMIOLOGY}},
Year = {{1999}},
Volume = {{10}},
Number = {{4}},
Pages = {{370-375}},
Month = {{JUL}},
Abstract = {{Blood pressure in childhood is an important determinant of hypertension
   risk later in life, and methylmercury exposure is a potential
   environmental risk factor. A birth cohort of 1,000 children from the
   Faroe Islands was examined for prenatal exposure to methylmercury, and
   at age 1 years, blood pressure, heart rate, and heart rate variability
   were determined. After adjustment for body weight, diastolic and
   systolic blood pressure increased by 13.9 mmHg {[}95\% confidence limits
   (CL) = 7.4, 20.4] and 14.6 mmHg (95\% CL = 8.3, 20.8), respectively,
   when cord blood mercury concentrations increased from 1 to 10 mu g/liter
   cord blood. Above this level, which corresponds to a current exposure
   limit, no further increase was seen. Birth weight acted as a modifier,
   with, the mercury effect bring stronger in children with lower birth
   weights. In boys, heart rate variability decreased with increasing
   mercury exposures, particularly from 1 to 10 mu g/liter cord blood, at
   which the variability was reduced by 47\%, (95\% CL = 14\%, 68\%). These
   findings suggest that prenatal exposure to methylmercury may affect the
   development of cardiovascular homeostasis.}},
ISSN = {{1044-3983}},
Unique-ID = {{ISI:000080987100006}},
}

@article{ ISI:000232412000008,
Author = {Koval, JJ and Aubut, JAL and Pederson, LL and O'Hegarty, M and Chan, SSH},
Title = {{The potential effectiveness of warning labels on cigarette packages -
   The perceptions of young adult Canadians}},
Journal = {{CANADIAN JOURNAL OF PUBLIC HEALTH-REVUE CANADIENNE DE SANTE PUBLIQUE}},
Year = {{2005}},
Volume = {{96}},
Number = {{5}},
Pages = {{353-356}},
Month = {{SEP-OCT}},
Abstract = {{Background: Since 1989 when health warning labels appeared on Canadian
   cigarette packages, the labels have changed from text only covering less
   than one quarter of the package to text and graphics covering over half
   the package. This study examines how Canadians in their 20s feel about
   the current graphic warning labels and their potential to prevent
   smoking and encourage quitting.
   Methods: Participants between 20 and 24 years of age were part of a
   10-year cohort study begun when the group was in Grade 6, with the
   purpose of examining factors that may affect smoking. Five questions
   about warning labels were added to the 2002 questionnaire requesting
   information on perceptions of the labels and their potential impact on
   smoking behaviours of young adults. One item had been included in
   previous questionnaires.
   Results: 32.8\% (n=1267) of the respondents were smokers, with males
   (35.6\%) being more likely to smoke than females (30.4\%). Current
   smokers were less likely than experimental/ex-smokers to believe that
   warning labels with stronger messages would make people their age less
   likely to smoke. Female current smokers were more likely to think about
   quitting.
   Conclusion: Despite the efforts taken in developing the labels, some
   young adults are skeptical about their effects. Warning labels may have
   to be modified to target issues that are relevant to young adults;
   gender differences are important in this modification. Warning labels
   can offer an additional component to a comprehensive tobacco control
   program, in that they provide health information.}},
ISSN = {{0008-4263}},
Unique-ID = {{ISI:000232412000008}},
}

@article{ ISI:000223047600040,
Author = {Hammond, D and Fong, GT and McDonald, PW and Brown, KS and Cameron, R},
Title = {{Graphic Canadian cigarette warning labels and adverse outcomes: Evidence
   from Canadian smokers}},
Journal = {{AMERICAN JOURNAL OF PUBLIC HEALTH}},
Year = {{2004}},
Volume = {{94}},
Number = {{8}},
Pages = {{1442-1445}},
Month = {{AUG}},
Abstract = {{Objectives. We assessed the impact of graphic Canadian cigarette warning
   labels.
   Methods. We used a longitudinal telephone survey of 616 adult smokers.
   Results. Approximately one fifth of participants reported smoking less
   as a result of the labels; only 1\% reported smoking more. Although
   participants reported negative emotional responses to the warnings
   including fear (44\%) and disgust (58\%), smokers who reported greater
   negative emotion were more likely to have quit, attempted to quit, or
   reduced their smoking 3 months later. Participants who attempted to
   avoid the warnings (30\%) were no less likely to think about the
   warnings or engage in cessation behavior at follow-up.
   Conclusions. Policynnakers should not be reluctant to introduce vivid or
   graphic warnings for fear of adverse outcomes.}},
DOI = {{10.2105/AJPH.94.8.1442}},
ISSN = {{0090-0036}},
ResearcherID-Numbers = {{Fong, Geoffrey/H-2810-2014}},
ORCID-Numbers = {{Fong, Geoffrey/0000-0001-9098-6472}},
Unique-ID = {{ISI:000223047600040}},
}

@article{ ISI:000236182100014,
Author = {Laden, F and Schwartz, J and Speizer, FE and Dockery, DW},
Title = {{Reduction in fine particulate air pollution and mortality - Extended
   follow-up of the Harvard six cities study}},
Journal = {{AMERICAN JOURNAL OF RESPIRATORY AND CRITICAL CARE MEDICINE}},
Year = {{2006}},
Volume = {{173}},
Number = {{6}},
Pages = {{667-672}},
Month = {{MAR 15}},
Abstract = {{Rationale: A large body of epidemiologic literature has found an
   association of increased fine particulate air pollution (PM2.5) with
   acute and chronic mortality. The effect of improvements in particle
   exposure is less clear.
   Objectives: Earlier analysis of the Harvard Six Cities adult cohort
   study showed an association between long-term ambient PM2.5 and
   mortality between enrollment in the mid-1970s and follow-up until 1990.
   We extended mortality follow-up for 8 yr in a period of reduced air
   pollution concentrations.
   Methods: Annual city-specific PM2.5 concentrations were measured between
   1979 and 1988, and estimated for later years from publicly available
   data. Exposure was defined as (1) city-specific mean PM2.5 during the
   two follow-up periods, (2) mean PM2.5 in the first period and change
   between these periods, (3) overall mean PM2.5 across the entire
   follow-up, and (4) year-specific mean PM2.5. Mortality rate ratios were
   estimated with Cox proportional hazards regression controlling for
   individual risk factors.
   Measurements and Main Results: We found an increase in overall mortality
   associated with each 10 mu g/m(3) increase in PM2.5 modeled either as
   the overall mean (rate ratio {[}RR], 1.16; 95\% confidence interval
   {[}CI], 1.07-1.26) or as exposure in the year of death (IRR, 1.14; 95\%
   Cl, 1.06-1.22). PM2.5 exposure was associated with lung cancer (1111,
   1.27; 95\% Cl, 0.96-1.69) and cardiovascular deaths (RR, 1.28;95\% Cl,
   1.13-1.44). Improved overall mortality was associated with decreased
   mean PM2.5 (10 mu g/m(3)) between periods (RR, 0.73; 95\% Cl,
   0.57-0.95).
   Conclusion: Total, cardiovascular, and lung cancer mortality were each
   positively associated with ambient PM2.5 concentrations. Reduced PM2.5
   concentrations were associated with reduced mortality risk.}},
DOI = {{10.1164/rccm.200503-443OC}},
ISSN = {{1073-449X}},
ResearcherID-Numbers = {{Wang, Linden/M-6617-2014}},
Unique-ID = {{ISI:000236182100014}},
}

@article{ ISI:A1996VV27400029,
Author = {Tsuji, H and Larson, MG and Venditti, FJ and Manders, ES and Evans, JC
   and Feldman, CL and Levy, D},
Title = {{Impact of reduced heart rate variability on risk for cardiac events -
   The Framingham Heart Study}},
Journal = {{CIRCULATION}},
Year = {{1996}},
Volume = {{94}},
Number = {{11}},
Pages = {{2850-2855}},
Month = {{DEC 1}},
Abstract = {{Background Although heart rate variability (HRV) is altered in a variety
   of pathological conditions, the association of reduced HRV with risk for
   new cardiac events has not been studied in a Large community-based
   population.
   Methods and Results The first 2 hours of ambulatory ECG recordings
   obtained on subjects of the Framingham Heart Study who were free of
   clinically apparent coronary heart disease or congestive heart failure
   were reprocessed to assess HRV. Five frequency-domain measures and three
   time-domain measures were obtained. The associations between HRV
   measures and the incidence of new cardiac events (angina pectoris,
   myocardial infarction, coronary heart disease death, or congestive heart
   failure) were assessed with proportional hazards regression analyses.
   There were 2501 eligible subjects with a mean age of 53 years. During a
   mean follow-up of 3.5 years, cardiac events occurred in 58 subjects.
   After adjustment for age, sex, cigarette smoking, diabetes, left
   ventricular hypertrophy, and other relevant risk factors, all HRV
   measures except the ratio of low-frequency to high-frequency power were
   significantly associated with risk for a cardiac event (P=.0016 to
   .0496). A one-standard deviation decrement in the standard deviation of
   total normal RR intervals (natural log transformed) was associated with
   a hazard ratio of 1.47 for new cardiac events (95\% confidence interval
   of 1.16 to 1.86).
   Conclusions The estimation of HRV by ambulatory monitoring offers
   prognostic information beyond that provided by the evaluation of
   traditional cardiovascular disease risk factors.}},
ISSN = {{0009-7322}},
Unique-ID = {{ISI:A1996VV27400029}},
}

@article{ ISI:A1996UF47800027,
Author = {Warner, KE and Fulton, GA and Nicolas, P and Grimes, DR},
Title = {{Employment implications of declining tobacco product sales for the
   regional economies of the United States}},
Journal = {{JAMA-JOURNAL OF THE AMERICAN MEDICAL ASSOCIATION}},
Year = {{1996}},
Volume = {{275}},
Number = {{16}},
Pages = {{1241-1246}},
Month = {{APR 24}},
Abstract = {{Objective.-To determine whether declines in tobacco product sales
   significantly reduce employment in the United States, as the tobacco
   industry claims.
   Design.-Computer simulation of the economies of the Southeast Tobacco
   region and 8 nontobacco regions of the United States, with domestic
   tobacco expenditures eliminated or reduced and the equivalent spending
   redistributed, according to consumers' normal spending patterns, We
   compared these results with baseline forecasts of the regional economies
   that include normal tobacco expenditures.
   Main Outcome Measure.-Number of jobs.
   Results.-Had there been no spending on tobacco products in the United
   States in 1993, the Southeast Tobacco region would have had 303 000
   fewer jobs. Collectively, however, the 8 nontobacco regions would have
   gained enough employment to completely offset losses in the Southeast
   Tobacco region, with every nontobacco region gaining jobs. By the year
   2000, the absence of tobacco spending would mean a loss of 222 000 jobs
   in the Southeast Tobacco region, but a gain of 355 000 throughout the
   rest of the country. In the more realistic scenario of doubling the
   downward trend in tobacco consumption, the Southeast Tobacco region
   would lose 6300 jobs in 1993 (0.03\% of regional employment) and 36 600
   jobs by 2000 (0.2\%). The 8 nontobacco regions would gain 6400 jobs in
   1993 and 56 300 jobs in 2000, with each of the nontobacco regions
   gaining employment in every year.
   Conclusions.-Contrary to the tobacco industry's claims, reductions in
   spending on tobacco products will boost employment in every one of the 8
   nontobacco regions and will not diminish employment in the Southeast
   Tobacco region by as much as the industry estimates. The primary concern
   about tobacco should be the enormity of its toll on health and not its
   impact on employment.}},
DOI = {{10.1001/jama.275.16.1241}},
ISSN = {{0098-7484}},
Unique-ID = {{ISI:A1996UF47800027}},
}

@article{ ISI:A1993KK57800005,
Author = {DIETRICH, KN and BERGER, OG and SUCCOP, PA},
Title = {{LEAD-EXPOSURE AND THE MOTOR DEVELOPMENTAL STATUS OF URBAN 6-YEAR-OLD
   CHILDREN IN THE CINCINNATI PROSPECTIVE-STUDY}},
Journal = {{PEDIATRICS}},
Year = {{1993}},
Volume = {{91}},
Number = {{2}},
Pages = {{301-307}},
Month = {{FEB}},
Abstract = {{The relationship between asymptomatic lead exposure and subtle deficits
   in intellectual attainment has been relatively well established by
   modern studies. However, neuromotor performance has rarely been the
   focus of these investigations. It was postulated that motor
   developmental outcomes may be more sensitive indicators of lead's
   adverse effects on the central nervous system as they are probably less
   confounded with social factors than cognitive and academic outcomes. A
   comprehensive neuromotor assessment battery was administered to 245
   six-year-old urban inner-city children enrolled in the Cincinnati Lead
   Study. These children have been followed since birth with quarterly
   assessments of blood lead concentrations, medical status, and
   neurobehavioral development. Prior to covariate adjustment, neonatal,
   but not prenatal blood lead levels were associated with poorer scores on
   assessments of bilateral coordination, upper-limb speed and dexterity,
   and a composite index of fine-motor coordination. Averaged postnatal
   blood lead levels were also associated with lower scores on the
   aforementioned subtests as well as a measure of visual-motor control.
   Following statistical adjustment for covariates, neonatal blood lead
   levels were associated with poorer performance on a measure of
   upper-limb speed and dexterity and the fine-motor composite. Postnatal
   blood lead levels remained significantly associated with poorer scores
   on measures of bilateral coordination, visual-motor control, upper-limb
   speed and dexterity, and the fine-motor composite. Low to moderate lead
   exposure is associated with moderate deficits in gross and especially
   fine-motor developmental status. Results of this study provide support
   for recent initiatives to reduce the exposure of children to sources of
   environmental lead.}},
ISSN = {{0031-4005}},
Unique-ID = {{ISI:A1993KK57800005}},
}

@article{ ISI:000174186000028,
Author = {Pope, CA and Burnett, RT and Thun, MJ and Calle, EE and Krewski, D and
   Ito, K and Thurston, GD},
Title = {{Lung cancer, cardiopulmonary mortality, and long-term exposure to fine
   particulate air pollution}},
Journal = {{JAMA-JOURNAL OF THE AMERICAN MEDICAL ASSOCIATION}},
Year = {{2002}},
Volume = {{287}},
Number = {{9}},
Pages = {{1132-1141}},
Month = {{MAR 6}},
Abstract = {{Context Associations have been found between day-to-day particulate air
   pollution and increased risk of various adverse health outcomes,
   including cardiopulmonary mortality, However, studies of health effects
   of long-term particulate air pollution have been less conclusive.
   Objective To assess the relationship between long-term exposure to fine
   particulate air pollution and all-cause, lung cancer, and
   cardiopulmonary mortality.
   Design, Setting, and Participants Vital status and cause of death data
   were collected by the American Cancer Society as part of the Cancer
   Prevention II study, an ongoing prospective mortality study, which
   enrolled approximately 1.2 million adults in 1982. Participants
   completed a questionnaire detailing individual risk factor data (age,
   sex, race, weight, height, smoking history, education, marital status,
   diet, alcohol consumption, and occupational exposures). The risk factor
   data for approximately 500000 adults were linked with air pollution data
   for metropolitan areas throughout the United States and combined with
   vital status and cause of death data through December 31, 1998.
   Main Outcome Measure All-cause, lung cancer, and cardiopulmonary
   mortality.
   Results Fine particulate and sulfur oxide-related pollution were
   associated with all-cause, lung cancer, and cardiopulmonary mortality.
   Each 10-mug/m(3) elevation in fine particulate air pollution was
   associated with approximately a 4\%, 6\%, and 8\% increased risk of
   all-cause, cardiopulmonary, and lung cancer mortality, respectively,
   Measures of coarse particle fraction and total suspended particles were
   not consistently associated with mortality.
   Conclusion Long-term exposure to combustion-related fine particulate air
   pollution is an important environmental risk factor for cardiopulmonary
   and lung cancer mortality.}},
DOI = {{10.1001/jama.287.9.1132}},
ISSN = {{0098-7484}},
Unique-ID = {{ISI:000174186000028}},
}

@article{ ISI:000266214800010,
Author = {Danaei, Goodarz and Ding, Eric L. and Mozaffarian, Dariush and Taylor,
   Ben and Rehm, Juergen and Murray, Christopher J. L. and Ezzati, Majid},
Title = {{The Preventable Causes of Death in the United States: Comparative Risk
   Assessment of Dietary, Lifestyle, and Metabolic Risk Factors}},
Journal = {{PLOS MEDICINE}},
Year = {{2009}},
Volume = {{6}},
Number = {{4}},
Month = {{APR}},
Abstract = {{Background: Knowledge of the number of deaths caused by risk factors is
   needed for health policy and priority setting. Our aim was to estimate
   the mortality effects of the following 12 modifiable dietary, lifestyle,
   and metabolic risk factors in the United States (US) using consistent
   and comparable methods: high blood glucose, low-density lipoprotein
   (LDL) cholesterol, and blood pressure; overweight-obesity; high dietary
   trans fatty acids and salt; low dietary polyunsaturated fatty acids,
   omega-3 fatty acids (seafood), and fruits and vegetables; physical
   inactivity; alcohol use; and tobacco smoking.
   Methods and Findings: We used data on risk factor exposures in the US
   population from nationally representative health surveys and
   disease-specific mortality statistics from the National Center for
   Health Statistics. We obtained the etiological effects of risk factors
   on disease-specific mortality, by age, from systematic reviews and
   meta-analyses of epidemiological studies that had adjusted (i) for major
   potential confounders, and (ii) where possible for regression dilution
   bias. We estimated the number of disease-specific deaths attributable to
   all non-optimal levels of each risk factor exposure, by age and sex. In
   2005, tobacco smoking and high blood pressure were responsible for an
   estimated 467,000 (95\% confidence interval {[}CI] 436,000-500,000) and
   395,000 (372,000-414,000) deaths, accounting for about one in five or
   six deaths in US adults. Overweight-obesity (216,000; 188,000-237,000)
   and physical inactivity (191,000; 164,000-222,000) were each responsible
   for nearly 1 in 10 deaths. High dietary salt (102,000; 97,000-107,000),
   low dietary omega-3 fatty acids (84,000; 72,000-96,000), and high
   dietary trans fatty acids (82,000; 63,000-97,000) were the dietary risks
   with the largest mortality effects. Although 26,000 (23,000-40,000)
   deaths from ischemic heart disease, ischemic stroke, and diabetes were
   averted by current alcohol use, they were outweighed by 90,000
   (88,000-94,000) deaths from other cardiovascular diseases, cancers,
   liver cirrhosis, pancreatitis, alcohol use disorders, road traffic and
   other injuries, and violence.
   Conclusions: Smoking and high blood pressure, which both have effective
   interventions, are responsible for the largest number of deaths in the
   US. Other dietary, lifestyle, and metabolic risk factors for chronic
   diseases also cause a substantial number of deaths in the US.}},
DOI = {{10.1371/journal.pmed.1000058}},
Article-Number = {{e1000058}},
ISSN = {{1549-1277}},
ORCID-Numbers = {{Ding, Eric/0000-0002-5881-8097}},
Unique-ID = {{ISI:000266214800010}},
}

@article{ ISI:000264653300020,
Author = {Vardavas, Constantine I. and Connolly, Gregory and Karamanolis, Kostas
   and Kafatos, Anthony},
Title = {{Adolescents perceived effectiveness of the proposed European graphic
   tobacco warning labels}},
Journal = {{EUROPEAN JOURNAL OF PUBLIC HEALTH}},
Year = {{2009}},
Volume = {{19}},
Number = {{2}},
Pages = {{212-217}},
Month = {{APR}},
Abstract = {{Background: Graphical tobacco product labelling is a prominent source of
   health information and has an important position among tobacco control
   initiatives. However, little is known about its effectiveness among
   adolescents. With this above in mind, we aimed to research into how
   adolescents perceive the proposed EU graphic tobacco product warning
   labels as an effective means of preventing smoking initiation in
   comparison to the current EU text-only warning labels. Methods: Five
   hundred seventy four adolescents (1318, 54 male) from Greece were
   privately interviewed, with the use of a digital questionnaire and
   randomly shown seven existing EU text-only and proposed EU graphic
   warning labels. Non-smoking respondents were asked to compare and rate
   the warnings effectiveness in regard to preventing them from smoking on
   a 15 Likert type scale. Results: Irrespective of the warning category
   shown, on all occasions, non-smoking adolescents rated the suggested EU
   graphic labels as more effective in preventing them from smoking in
   comparison to the existing EU text-only warnings. Controlling for
   gender, age, current smoking status and number of cigarettes smoked per
   month, younger adolescents were found to opt for graphic warnings more
   often, and also perceive graphic warning labels as a more effective
   means of preventing them from smoking, in comparison to their elder
   peers (P 0.001). Conclusions: The proposed EU graphic warning labels may
   play an important role in preventing of smoking initiation during the
   crucial years of early adolescence when smoking experimentation and
   early addiction usually take place.}},
DOI = {{10.1093/eurpub/ckp015}},
ISSN = {{1101-1262}},
Unique-ID = {{ISI:000264653300020}},
}

@article{ ISI:000294105900006,
Author = {Thrasher, James F. and Rousu, Matthew C. and Hammond, David and Navarro,
   Ashley and Corrigan, Jay R.},
Title = {{Estimating the impact of pictorial health warnings and ``plain{''}
   cigarette packaging: Evidence from experimental auctions among adult
   smokers in the United States}},
Journal = {{HEALTH POLICY}},
Year = {{2011}},
Volume = {{102}},
Number = {{1}},
Pages = {{41-48}},
Month = {{SEP}},
Abstract = {{Objective: To estimate differences in demand for cigarette packages with
   different packaging and health warning label formats.
   Methods: Adult smokers (n = 404) in four states participated in
   experimental auctions. Participants bid on two of four experimental
   conditions, each involving a different health warning label format but
   with the same warning message: (1) text on 50\% of pack side: (2) text
   on 50\% of the pack front and back; (3) text with a graphic picture on
   50\% of the pack front and back; and (4) same as previous format, but
   without brand imagery.
   Results: Mean bids decreased across conditions (1: \$3.52; 2: \$3.43; 3:
   \$3.11; 4: \$2.93). Bivariate and multivariate random effects models
   indicated that there was no statistically significant difference in
   demand for packs with either of the two text only warnings; however,
   demand was significantly lower for both packs with prominent pictorial
   warnings, with the lowest demand associated with the plain, unbranded
   pack.
   Conclusions: Results suggest that prominent health warnings with graphic
   pictures will reduce demand for cigarettes. Regulators should not only
   consider this type of warning label, but also plain packaging policies
   for tobacco products. (C) 2011 Elsevier Ireland Ltd. All rights
   reserved.}},
DOI = {{10.1016/j.healthpol.2011.06.003}},
ISSN = {{0168-8510}},
EISSN = {{1872-6054}},
Unique-ID = {{ISI:000294105900006}},
}

@article{ ISI:000250982200017,
Author = {Thrasher, James F. and Rousu, Matthew C. and Anaya-Ocampo, Rafael and
   Reynales-Shigematsu, Luz Myniarn and Anillo-Santillan, Edna and
   Hernandez-Avila, Mauncio},
Title = {{Estimating the impact of different cigarette package warning label
   policies: The auction method}},
Journal = {{ADDICTIVE BEHAVIORS}},
Year = {{2007}},
Volume = {{32}},
Number = {{12}},
Pages = {{2916-2925}},
Month = {{DEC}},
Abstract = {{The study estimated the reduction in demand associated with implementing
   cigarette package warning labels that contain imagery illustrating the
   consequences of smoking. The experimental auction method was used,
   wherein adult smokers in Mexico (n = 89) placed separate bids on two
   packs of cigarettes: one with a text-only warning label and the other
   with a warning label that included text and a graphic image. Differences
   in the values attributed to each pack were assessed using t-tests and
   multivariate regression. The pack with the graphic image had a mean
   attributed value which was 17\% lower (S3.21 pesos) than the pack with
   the text-only warning, and this difference remained statistically
   significant within subgroups defined by sociodemographics, amount of
   smoking, number of quit attempts, and levels of perceived smoking risks.
   In the multivariate model, the difference in attributed values was
   greater among females than males, but no such differences were found for
   other sociodemographic or smoking-related variables. The consistently
   lower value that smokers attributed to cigarette packages with the
   graphic warning label indicates that these labels are likely to reduce
   cigarette demand. (C) 2007 Elsevier Ltd. All rights reserved.}},
DOI = {{10.1016/j.addbeh.2007.05.018}},
ISSN = {{0306-4603}},
Unique-ID = {{ISI:000250982200017}},
}

@article{ ISI:000230250800038,
Author = {Lanphear, BP and Hornung, R and Khoury, J and Yolton, K and Baghurstl, P
   and Bellinger, DC and Canfield, RL and Dietrich, KN and Bornschein, R
   and Greene, T and Rothenberg, SJ and Needleman, HL and Schnaas, L and
   Wasserman, G and Graziano, J and Roberts, R},
Title = {{Low-level environmental lead exposure and children's intellectual
   function: An international pooled analysis}},
Journal = {{ENVIRONMENTAL HEALTH PERSPECTIVES}},
Year = {{2005}},
Volume = {{113}},
Number = {{7}},
Pages = {{894-899}},
Month = {{JUL}},
Abstract = {{Lead is a confirmed neurotoxin, but questions remain about
   lead-associated intellectual deficits at blood lead levels < 10 pg/dL
   and whether lower exposures are, for a given change in exposure,
   associated with greater deficits. The objective of this study was to
   examine the association of intelligence test scores and blood lead
   concentration, especially for children who had maximal measured blood
   lead levels < 10 mu g/dL. We examined data collected from 1,333 children
   who participated in seven international population-based longitudinal
   cohort studies, followed from birth or infancy until 5-10 years of age.
   The full-scale IQ score was the primary outcome measure. The geometric
   mean blood lead concentration of the children peaked at 17.8 mu g/dL and
   declined to 9.4 mu g/dL by 5-7 years of age; 244 (18\%) children had a
   maximal blood lead concentration < 10 mu g/dL, and 103 (8\%) had a
   maximal blood lead concentration < 7.5 pg/dL. After adjustment for
   covariates, we found an inverse relationship between blood lead
   concentration and IQ score. Using a log-linear model, we found a 6.9 IQ
   point decrement {[}95\% confidence interval (CI), 4.2-9.4] associated
   with an increase in concurrent blood lead levels from 2.4 to 30 mu g/dL.
   The estimated IQ point decrements associated with an increase in blood
   lead from 2.4 to 10 pg/dL, 10 to 20 pg/dL, and 20 to 30 pg/dL were 3.9
   (95\% Cl, 2.4-5-3), 1.9 (95\% Cl, 1.2-2.6), and 1.1 (95\% Cl, 0.7-1.5),
   respectively. For a given increase in blood lead, the lead-associated
   intellectual decrement for children with a maximal blood lead level <
   7.5 pg/dL was significantly greater than that observed for those with a
   maximal blood lead level >= 7.5 pg/dL (p = 0.015). We conclude that
   environmental lead exposure in children who have maximal blood lead
   levels < 7.5 Pg/dL is associated with intellectual deficits.}},
DOI = {{10.1289/ehp.7688}},
ISSN = {{0091-6765}},
ResearcherID-Numbers = {{Rothenberg, Stephen/A-1313-2008
   Rothenberg, Stephen/A-2147-2009
   Khoury, Jane/O-2068-2015}},
Unique-ID = {{ISI:000230250800038}},
}

@article{ ISI:000254492800012,
Author = {Roman, Henry A. . and Walker, Katherine D. and Walsh, Tyra L. and
   Conner, Lisa and Richmond, Harvey M. and Hubbell, Bryan J. and Kinney,
   Patrick L.},
Title = {{Expert judgment assessment of the mortality impact of changes in ambient
   fine particulate matter in the US}},
Journal = {{ENVIRONMENTAL SCIENCE \& TECHNOLOGY}},
Year = {{2008}},
Volume = {{42}},
Number = {{7}},
Pages = {{2268-2274}},
Month = {{APR 1}},
Abstract = {{In this paper, we present findings from a multiyear expert judgment
   study that comprehensively characterizes uncertainty in estimates of
   mortality reductions associated with decreases in tine particulate
   matter (PM2.5) in the U.S. Appropriate characterization of uncertainty
   is critical because mortality-related benefits represent up to 90\% of
   the monetized benefits reported in the Environmental Protection Agency's
   (EPA's) analyses of proposed air regulations. Numerous epidemiological
   and toxicological studies have evaluated the PM2.5-mortality association
   and investigated issues that may contribute to uncertainty in the
   concentration-response (C-R) function, such as exposure
   misclassification and potential confounding from other pollutant
   exposures. EPA's current uncertainty analysis methods rely largely on
   standard errors in published studies. However, no one study tan capture
   the full suite of issues that arise in quantifying the C-R relationship.
   Therefore, EPA has applied state-of-the-art expert judgment elicitation
   techniques to develop probabilistic uncertainty distributions that
   reflect the broader array of uncertainties in the C-R relationship.
   These distributions, elicited from 12 of the world's leading experts on
   this issue, suggest both potentially larger central estimates of
   mortality reductions for decreases in long-term PM2.5 exposure in the
   U.S. and a wider distribution of uncertainty than currently employed in
   EPA analyses.}},
DOI = {{10.1021/es0713882}},
ISSN = {{0013-936X}},
ResearcherID-Numbers = {{Kinney, Patrick/H-7914-2012}},
Unique-ID = {{ISI:000254492800012}},
}

@article{ ISI:A1989U491800010,
Author = {ERNHART, CB and MORROWTLUCAK, M and WOLF, AW and SUPER, D and DROTAR, D},
Title = {{LOW-LEVEL LEAD-EXPOSURE IN THE PRENATAL AND EARLY PRESCHOOL PERIODS -
   INTELLIGENCE PRIOR TO SCHOOL ENTRY}},
Journal = {{NEUROTOXICOLOGY AND TERATOLOGY}},
Year = {{1989}},
Volume = {{11}},
Number = {{2}},
Pages = {{161-170}},
Month = {{MAR-APR}},
DOI = {{10.1016/0892-0362(89)90055-X}},
ISSN = {{0892-0362}},
Unique-ID = {{ISI:A1989U491800010}},
}

@article{ ISI:000181482700005,
Author = {Hilts, SR},
Title = {{Effect of smelter emission reductions on children's blood lead levels}},
Journal = {{SCIENCE OF THE TOTAL ENVIRONMENT}},
Year = {{2003}},
Volume = {{303}},
Number = {{1-2}},
Pages = {{51-58}},
Month = {{FEB 15}},
Abstract = {{Trail, British Columbia has been the site of an active lead-zinc smelter
   for approximately 95 years. Since 1989, the community has been
   monitoring blood lead levels in children, studying exposure pathways and
   conducting comprehensive education and case management programs. From
   1989 through 1996, mean blood lead levels of preschool children declined
   at an average rate of 0.6 mug/dl per year. From 1996 to 1999, mean blood
   lead levels fell at an average rate of 1.8 mug/dl per year, from 11.5 in
   1996 to 5.9 in 1999. The recent rapid decline appears to be mainly
   attributable to the start-up of a new lead smelter using modern
   flash-smelting technology in May of 1997. In 1998, the annual arithmetic
   mean air lead level in Trail was 0.28 mug/m(3), compared with 1.1
   mug/m(3) in 1996. Reductions of approximately 50\% were observed in lead
   loadings and concentrations in outdoor dustfall, street dust and indoor
   dustfall after smelter emissions were reduced. Slight reductions
   (statistically insignificant) have been observed in carpet dust and soil
   lead concentrations. During the summer of 2001, the smelting and
   refining operations at Trail were shut down completely for 3 months.
   During this period, average air lead levels in Trail dropped to 0.03
   mug/m(3). The average blood lead level in Trail pre-school children at
   the end of the shutdown was 4.7 mug/dl. These results challenge
   prevailing theories about the relative importance of various
   environmental lead sources. For example, the US EPA Integrated
   Biokinetic Uptake Model for Lead(IEUBK), with its emphasis on soil
   concentrations, would not have predicted the dramatic decline in
   children's blood lead levels seen in Trail following the reductions in
   air lead levels. The Trail experience suggests that increased attention
   should be paid to the importance of active sources of highly
   bioavailable and mobile lead bearing dusts. (C) 2002 Elsevier Science
   B.V. All rights reserved.}},
DOI = {{10.1016/S0048-9697(02)00357-1}},
Article-Number = {{PII S0048-9697(02)00357-1}},
ISSN = {{0048-9697}},
Unique-ID = {{ISI:000181482700005}},
}

@article{ ISI:000282687000011,
Author = {Fong, Geoffrey T. and Hammond, David and Jiang, Yuan and Li, Qiang and
   Quah, Anne C. K. and Driezen, Pete and Yan, Mi and ITC China Project
   Team},
Title = {{Perceptions of tobacco health warnings in China compared with picture
   and text-only health warnings from other countries: an experimental
   study}},
Journal = {{TOBACCO CONTROL}},
Year = {{2010}},
Volume = {{19}},
Number = {{2}},
Month = {{OCT}},
Abstract = {{Objective To assess the perceived effectiveness of cigarette health
   warnings in China, compared with picture and text-only warnings from
   other countries.
   Method 1169 individuals ( adult smokers, adult nonsmokers and youth)
   from four Chinese cities ( Beijing, Shanghai, Kunming and Yinchuan)
   viewed 10 health warnings on cigarette packages, which included ( a) the
   current Chinese text warnings covering 30\% of the front/back of the
   pack ( introduced October 2008); (b) the former Chinese text warning
   located on the side of the pack; ( c) four picture warnings covering
   50\% of the front/back of the pack from Canada ( lung cancer), Singapore
   ( mouth disease), Hong Kong ( gangrene) and European Union ( clogged
   arteries); and ( d) the same four warnings without the picture.
   Participants rated and ranked the 10 warnings on dimensions including
   how effective each would be in motivating smokers to quit and in
   convincing youth not to start smoking.
   Results Both Chinese warnings were consistently rated as least
   effective, with the new Chinese warning rated only slightly higher than
   the old warning. The picture warnings were consistently ranked or rated
   as most effective, with the text-only versions in the middle. Results
   were consistent across subject group, city and sex.
   Conclusions ( 1) Picture warnings are rated as much more effective than
   the same warnings without pictures. ( 2) The revised health warnings in
   China, introduced in October 2008, are only marginally more effective
   than the previous warning and far less effective than even text warnings
   from other countries. These results, coupled with population-based
   evaluation studies, suggest that pictorial warnings would significantly
   increase the impact of health warnings in China.}},
DOI = {{10.1136/tc.2010.036483}},
Article-Number = {{i69}},
ISSN = {{0964-4563}},
ResearcherID-Numbers = {{Fong, Geoffrey/H-2810-2014}},
ORCID-Numbers = {{Fong, Geoffrey/0000-0001-9098-6472}},
Unique-ID = {{ISI:000282687000011}},
}

@article{ ISI:000221448300003,
Author = {Neuberger, M and Moshammer, H},
Title = {{Suspended particulates and lung health}},
Journal = {{WIENER KLINISCHE WOCHENSCHRIFT}},
Year = {{2004}},
Volume = {{116}},
Number = {{1}},
Pages = {{8-12}},
Abstract = {{Based on several severe air pollution episodes, a temporal correlation
   between high concentrations of particulate matter (PM) and SO2 pollution
   and acute increases in respiratory and cardiopulmonary mortality had
   been established in Vienna for the 1970's. After air pollution had
   decreased in Austria in the 1980's - as documented by data on SO2, and
   total suspended particles (TSP) - no such associations between
   day-to-day changes of SO2 and TSP and mortality have been documented any
   more, however, traffic related pollutants like fine particles and NO2
   remained a problem. Therefore, short term effects of PM on lung
   function, morbidity and mortality were investigated in Vienna, Linz,
   Graz and a rural control area. Long-term exposure and chronic disease -
   even more important for public health - were studied in repeated
   cross-sectional, a mixed longitudinal and a birth cohort study on school
   children in the city of Linz. Lung function growth was found impaired
   from long-term exposure to air pollutants and improved in districts
   where ambient air pollution had decreased. Where only TSP and SO2 had
   decreased, no continuous improvement of small airway function was found
   and end-expiratory flow rates stayed impaired where NO2-reduction from
   technical improvements of cars and industry was counterbalanced by
   increase of motorized (diesel) traffic. Remaining acute effects of
   ambient air pollution in 2001 from PM, NO2 and co-pollutants found in a
   time series study also show that continuing efforts are necessary.
   Active surface of particles inhaled several hours to days before
   spirometry was found related to short-term reductions in forced vital
   capacity-FVC (p < 0.01), forced expiratory volume in one second-FEV, (p
   < 0.01) and maximal expiratory flow rate at 50\% of vital capacity-MEF50
   (p < 0.05). In pupils with asthma or previous airway obstruction
   4-week-diaries proved that the following symptoms increased with acute
   exposure to higher active surface of particles: wheezing (p < 0.01),
   dyspnea, cough when going to sleep, cough at night (p < 0.05). Efforts
   to reduce exposure to fine particles from motor traffic and passive
   smoking have to be increased if we want to achieve full recovery of
   children from air pollution effects and best respiratory performance in
   adulthood. Surveillance seems to be necessary not only for particle mass
   but also for particle number and surface. Little is known on the
   mechanisms of irreversible long-term effects of PM such as myocardial
   infarction and cancer. In a prospective cohort study on 1630
   dust-exposed and 1630 non dust-exposed workers matched for smoking we
   found an increase of lung cancer related to nonfibrous insoluble PM.
   Other studies were able to relate lung cancer to specific particles like
   those from diesel engines, and a large prospective study of the American
   Cancer Society was able to link lung cancer in the general population
   with long-term exposure to fine particles from combustion processes. All
   these recent epidemiological findings will have consequences for
   occupational and ambient air PM standards.}},
ISSN = {{0043-5325}},
Unique-ID = {{ISI:000221448300003}},
}

@article{ ISI:000315406100018,
Author = {Fang, Y. and Naik, V. and Horowitz, L. W. and Mauzerall, D. L.},
Title = {{Air pollution and associated human mortality: the role of air pollutant
   emissions, climate change and methane concentration increases from the
   preindustrial period to present}},
Journal = {{ATMOSPHERIC CHEMISTRY AND PHYSICS}},
Year = {{2013}},
Volume = {{13}},
Number = {{3}},
Pages = {{1377-1394}},
Abstract = {{Increases in surface ozone (O-3) and fine particulate matter (<= 2.5 mu
   m aerodynamic diameter, PM2.5) are associated with excess premature
   human mortalities. We estimate changes in surface O-3 and PM2.5 from
   pre-industrial (1860) to present (2000) and the global present-day
   (2000) premature human mortalities associated with these changes. We
   extend previous work to differentiate the contribution of changes in
   three factors: emissions of short-lived air pollutants, climate change,
   and increased methane (CH4) concentrations, to air pollution levels and
   associated premature mortalities. We use a coupled chemistry-climate
   model in conjunction with global population distributions in 2000 to
   estimate exposure attributable to concentration changes since 1860 from
   each factor. Attributable mortalities are estimated using health impact
   functions of long-term relative risk estimates for O-3 and PM2.5 from
   the epidemiology literature. We find global mean surface PM2.5 and
   health-relevant O-3 (defined as the maximum 6-month mean of 1-h daily
   maximum O-3 in a year) have increased by 8+/-0.16 mu gm(-3) and
   30+/-0.16 ppbv (results reported as annual average +/-standard deviation
   of 10-yr model simulations), respectively, over this industrial period
   as a result of combined changes in emissions of air pollutants (EMIS),
   climate (CLIM) and CH4 concentrations (TCH4). EMIS, CLIM and TCH4 cause
   global population-weighted average PM2.5 (O-3) to change by +7.5+/-0.19
   mu gm(-3) (+25+/-0.30 ppbv), +0.4+/-0.17 mu gm(-3) (+0.5+/-0.28 ppbv),
   and 0.04+/-0.24 mu gm(-3) (+4.3+/-0.33 ppbv), respectively. Total global
   changes in PM2.5 are associated with 1.5 (95\% confidence interval, CI,
   1.2-1.8) million cardiopulmonary mortalities and 95 (95\% CI, 44-144)
   thousand lung cancer mortalities annually and changes in O-3 are
   associated with 375 (95\% CI, 129-592) thousand respiratory mortalities
   annually. Most air pollution mortality is driven by changes in emissions
   of short-lived air pollutants and their precursors (95\% and 85\% of
   mortalities from PM2.5 and O-3 respectively). However, changing climate
   and increasing CH4 concentrations also contribute to premature mortality
   associated with air pollution globally (by up to 5\% and 15 \%,
   respectively). In some regions, the contribution of climate change and
   increased CH4 together are responsible for more than 20\% of the
   respiratory mortality associated with O-3 exposure. We find the
   interaction between climate change and atmospheric chemistry has
   influenced atmospheric composition and human mortality associated with
   industrial air pollution. Our study highlights the benefits to air
   quality and human health of CH4 mitigation as a component of future air
   pollution control policy.}},
DOI = {{10.5194/acp-13-1377-2013}},
ISSN = {{1680-7316}},
ResearcherID-Numbers = {{Fang, Yuanyuan/F-1308-2011
   Mauzerall, Denise/I-5977-2013
   Horowitz, Larry/D-8048-2014
   Naik, Vaishali/A-4938-2013}},
ORCID-Numbers = {{Fang, Yuanyuan/0000-0001-7067-7103
   Mauzerall, Denise/0000-0003-3479-1798
   }},
Unique-ID = {{ISI:000315406100018}},
}

@article{ ISI:000298134500014,
Author = {Turner, Michelle C. and Krewski, Daniel and Pope, III, C. Arden and
   Chen, Yue and Gapstur, Susan M. and Thun, Michael J.},
Title = {{Long-term Ambient Fine Particulate Matter Air Pollution and Lung Cancer
   in a Large Cohort of Never-Smokers}},
Journal = {{AMERICAN JOURNAL OF RESPIRATORY AND CRITICAL CARE MEDICINE}},
Year = {{2011}},
Volume = {{184}},
Number = {{12}},
Pages = {{1374-1381}},
Month = {{DEC 15}},
Abstract = {{Rationale: There is compelling evidence that acute and chronic exposure
   to ambient fine particulate matter (PM2.5) air pollution increases
   cardiopulmonary mortality. However, the role of PM2.5 in the etiology of
   lung cancer is less clear, particularly at concentrations that prevail
   in developed countries and in never-smokers.
   Objectives: This study examined the association between mean long-term
   ambient PM2.5 concentrations and lung cancer mortality among 188,699
   lifelong never-smokers drawn from the nearly 1.2 million Cancer
   Prevention Study-II participants enrolled by the American Cancer Society
   in 1982 and followed prospectively through 2008.
   Methods: Mean metropolitan statistical area PM2.5 concentrations were
   determined for each participant based on central monitoring data. Cox
   proportional hazards regression models were used to estimate
   multivariate adjusted hazard ratios and 95\% confidence intervals for
   lung cancer mortality in relation to PM2.5.
   Measurements and Main Results: A total of 1,100 lung cancer deaths were
   observed during the 26-year follow-up period. Each 10 mu g/m(3) increase
   in PM2.5 concentrations was associated with a 15-27\% increase in lung
   cancer mortality. The association between PM2.5 and lung cancer
   mortality was similar in men and women and across categories of attained
   age and educational attainment, but was stronger in those with a normal
   body mass index and a history of chronic lung disease at enrollment (P <
   0.05).
   Conclusions: The present findings strengthen the evidence that ambient
   concentrations of PM2.5 measured in recent decades are associated with
   small but measurable increases in lung cancer mortality.}},
DOI = {{10.1164/rccm.201106-1011OC}},
ISSN = {{1073-449X}},
Unique-ID = {{ISI:000298134500014}},
}

@article{ ISI:000251925500005,
Author = {Lewtas, Joellen},
Title = {{Air pollution combustion emissions: Characterization of causative agents
   and mechanisms associated with cancer, reproductive, and cardiovascular
   effects}},
Journal = {{MUTATION RESEARCH-REVIEWS IN MUTATION RESEARCH}},
Year = {{2007}},
Volume = {{636}},
Number = {{1-3}},
Pages = {{95-133}},
Month = {{NOV-DEC}},
Abstract = {{Combustion emissions account for over half of the fine particle (PM2.5)
   air pollution and most of the primary particulate organic matter. Human
   exposure to combustion emissions including the associated airborne fine
   particles and mutagenic and carcinogenic constituents (e.g., polycyclic
   aromatic compounds (PAC), nitro-PAC) have been studied in populations in
   Europe, America, Asia, and increasingly in third-world counties.
   Bioassay-directed fractionation studies of particulate organic air
   pollution have identified mutagenic and carcinogenic polycyclic aromatic
   hydrocarbons (PAH), nitrated PAH, nitro-lactones, and lower molecular
   weight compounds from cooking. A number of these components are
   significant sources of human exposure to mutagenic and carcinogenic
   chemicals that may also cause oxidative and DNA damage that can lead to
   reproductive and cardiovascular effects. Chemical and physical tracers
   have been used to apportion outdoor and indoor and personal exposures to
   airborne particles between various combustion emissions and other
   sources. These sources include vehicles (e.g., diesel and gasoline
   vehicles), heating and power sources (e.g., including coal, oil, and
   biomass), indoor sources (e.g., cooking, heating, and tobacco smoke), as
   well as secondary organic aerosols and pollutants derived from
   long-range transport.
   Biomarkers of exposure, dose and susceptibility have been measured in
   populations exposed to air pollution combustion emissions. Biomarkers
   have included metabolic genotype, DNA adducts, PAH metabolites, and
   urinary mutagenic activity. A number of studies have shown a significant
   correlation of exposure to PM2.5 with these biomarkers. In addition,
   stratification by genotype increased this correlation. New multivariate
   receptor models, recently used to determine the sources of ambient
   particles, are now being explored in the analysis of human exposure and
   biomarker data.
   Human studies of both short- and long-term exposures to combustion
   emissions and ambient fine particulate air pollution have been
   associated with measures of genetic damage. Long-term epidemiologic
   studies have reported an increased risk of all causes of mortality,
   cardiopulmonary mortality, and lung cancer mortality associated with
   increasing exposures to air pollution. Adverse reproductive effects
   (e.g., risk for low birth weight) have also recently been reported in
   Eastern Europe and North America. Although there is substantial evidence
   that PAH or substituted PAH may be causative agents in cancer and
   reproductive effects, an increasing number of studies investigating
   cardiopulmonary and cardiovascular effects are investigating these and
   other potential causative agents from air pollution combustion sources.
   (C) 2007 Elsevier B.V. All rights reserved.}},
DOI = {{10.1016/j.mrrev.2007.08.003}},
ISSN = {{1383-5742}},
EISSN = {{1388-2139}},
ResearcherID-Numbers = {{Wang, Linden/M-6617-2014}},
Unique-ID = {{ISI:000251925500005}},
}

@incollection{ ISI:000271165000010,
Author = {Iwai, Kazuro and Uchimura, Kazuhiro and Mizuno, Shouichi and Miyasaka,
   Yoji},
Editor = {{Cheng, M and Liu, W}},
Title = {{CORRELATIONS BETWEEN DISEASE-SPECIFIC MORTALITIES WITH PARTICULATE AND
   GASEOUS AIR POLLUTANTS: RISKS FOR CARDIOPULMONARY DISEASE AND FEMALE
   REPRODUCTIVE ORGAN CANCERS}},
Booktitle = {{AIRBORNE PARTICULATES}},
Year = {{2009}},
Pages = {{273-287}},
Abstract = {{Suspended particles, particularly fine particles of less than 2.5 mu m
   in aerodynamic diameter (PM(2.5)) in the ambient air, has been reported
   to increase risks of cardiopulmonary diseases on daily death as well as
   deaths in long-term followed-up cohort studies. We conducted a
   cross-sectional study in which vital statistics in Japan were used to
   correlate disease-specific mortalities with air pollution data,
   including suspended particulate matter (SPM, less than 10 mu m in
   aerodynamic diameter), nitrogen dioxide (NO(2)), nitrogen oxide (NO),
   sulfur dioxide (SO(2)) and photochemical oxidants (Ox). A
   single-pollutant regression analysis revealed a strong correlation of
   SPM with ischemic heart disease, hypertensive heart disease in both
   genders, and pneumonia, asthma, chronic bronchitis / emphysema, lung
   cancer and also breast, uterine and ovarian cancers in females.
   Cerebrovascular disease, lung infarction and most of cancers did not
   show any correlation in either gender. NO(2) also showed a high
   statistically significant correlation with these diseases in a similar
   manner to SPM, whereas Ox had no association with any of these diseases.
   Results from the multi-pollutant Poisson regression analysis showed that
   cardiac diseases remained to correlate with SPM as well as NO(2), while
   pulmonary diseases correlated only with SPM. The unexpected correlation
   of female reproductive organ cancer, observed with SPM or NO(2) should
   further be studied in the future as possible endocrine disrupting-like
   effects.}},
ISBN = {{978-1-60692-907-0}},
Unique-ID = {{ISI:000271165000010}},
}

@article{ ISI:000230582500005,
Author = {Krewski, D and Burnett, R and Jerrett, M and Pope, CA and Rainham, D and
   Calle, E and Thurston, G and Thun, M},
Title = {{Mortality and long-term exposure to ambient air pollution: Ongoing
   analyses based on the American Cancer Society cohort}},
Journal = {{JOURNAL OF TOXICOLOGY AND ENVIRONMENTAL HEALTH-PART A-CURRENT ISSUES}},
Year = {{2005}},
Volume = {{68}},
Number = {{13-14}},
Pages = {{1093-1109}},
Month = {{JUL 9}},
Abstract = {{This article provides an overview of previous analysis and reanalysis of
   the American Cancer Society (ACS) cohort, along with an indication of
   current ongoing analyses of the cohort with additional follow-up
   information through to 2000. Results of the first analysis conducted by
   Pope et al. (1995) showed that higher average sulfate levels were
   associated with increased mortality, particularly from cardiopulmonary
   disease. A reanalysis of the ACS cohort, undertaken by Krewski et al.
   (2000), found the original risk estimates for fine-particle and sulfate
   air pollution to he highly robust against alternative statistical
   techniques and spatial modeling approaches. A detailed investigation of
   covariate effects found a significant modifying effect of education with
   risk of mortality associated with fine particles declining with
   increasing educational attainment. Pope et al. (2002) subsequently
   reported results of a subsequent study using an additional 10 yr of
   follow-up of the ACS cohort. This updated analysis included gaseous
   copollutant and new fine-particle measurements, more comprehensive
   information on occupational exposures, dietary variables, and the most
   recent developments in statistical modeling integrating random effects
   and nonparametric spatial smoothing into the Cox proportional hazards
   model. Robust associations between ambient fine particulate air
   pollution and elevated risks of cardiopulmonary and lung cancer
   mortality were clearly evident, providing the strongest evidence to date
   that long-term exposure to fine particles is an important health risk.
   Current ongoing analysis using the extended follow-up information will
   explore the role of ecologic, economic, and, demographic covariates in
   the particulate air pollution and mortality association. This analysis
   will also provide insight into the role of spatial autocorrelation at
   multiple geographic scales, and whether critical instances in time of
   exposure to fine particles influence the risk of mortality from
   cardiopulmonary and lung cancer. Information on the influence of
   covariates at multiple scales and of critical exposure time windows can
   assist policymakers in establishing timelines for regulatory
   interventions that maximize population health benefits.}},
DOI = {{10.1080/15287390590935941}},
ISSN = {{1528-7394}},
ResearcherID-Numbers = {{Rainham, Daniel/C-4800-2009}},
Unique-ID = {{ISI:000230582500005}},
}

@article{ ISI:000281621500002,
Author = {Anenberg, Susan C. and Horowitz, Larry W. and Tong, Daniel Q. and West,
   J. Jason},
Title = {{An Estimate of the Global Burden of Anthropogenic Ozone and Fine
   Particulate Matter on Premature Human Mortality Using Atmospheric
   Modeling}},
Journal = {{ENVIRONMENTAL HEALTH PERSPECTIVES}},
Year = {{2010}},
Volume = {{118}},
Number = {{9}},
Pages = {{1189-1195}},
Month = {{SEP}},
Abstract = {{BACKGROUND: Ground-level concentrations of ozone (O-3) and fine
   particulate matter {[}<= 2.5 mu m in aerodynamic diameter (PM2.5)] have
   increased since preindustrial times in urban and rural regions and are
   associated with cardiovascular and respiratory mortality.
   OBJECTIVES: We estimated the global burden of mortality due to O-3 and
   PM2.5 from anthropogenic emissions using global atmospheric chemical
   transport model simulations of preindustrial and present-day (2000)
   concentrations to derive exposure estimates.
   METHODS: Attributable mortalities were estimated using health impact
   functions based on long-term relative risk estimates for O-3 and PM2.5
   from the epidemiology literature. Using simulated concentrations rather
   than previous methods based on measurements allows the inclusion of
   rural areas where measurements are often unavailable and avoids making
   assumptions for background air pollution.
   RESULTS: Anthropogenic O-3 was associated with an estimated 0.7 +/- 0.3
   million respiratory mortalities (6.3 +/- 3.0 million years of life lost)
   annually. Anthropogenic PM2.5 was associated with 3.5 +/- 0.9 million
   cardiopulmonary and 220,000 +/- 80,000 lung cancer mortalities (30 +/-
   7.6 million years of life lost) annually. Mortality estimates were
   reduced approximately 30\% when we assumed low-concentration thresholds
   of 33.3 ppb for O-3 and 5.8 mu g/m(3) for PM2.5. These estimates were
   sensitive to concentration thresholds and concentration-mortality
   relationships, often by > 50\%.
   CONCLUSIONS: Anthropogenic O-3 and PM2.5 contribute substantially to
   global premature mortality. PM2.5 mortality estimates are about 50\%
   higher than previous measurement-based estimates based on common
   assumptions, mainly because of methodologic differences. Specifically,
   we included rural populations, suggesting higher estimates; however, the
   coarse resolution of the global atmospheric model may underestimate
   urban PM2.5 exposures.}},
DOI = {{10.1289/ehp.0901220}},
ISSN = {{0091-6765}},
EISSN = {{1552-9924}},
ResearcherID-Numbers = {{Tong, Daniel/A-8255-2008
   West, Jason/J-2322-2015}},
ORCID-Numbers = {{Tong, Daniel/0000-0002-4255-4568
   West, Jason/0000-0001-5652-4987}},
Unique-ID = {{ISI:000281621500002}},
}

@article{ ISI:000268644700025,
Author = {Fong, Geoffrey T. and Hammond, David and Hitchman, Sara C.},
Title = {{The impact of pictures on the effectiveness of tobacco warnings}},
Journal = {{BULLETIN OF THE WORLD HEALTH ORGANIZATION}},
Year = {{2009}},
Volume = {{87}},
Number = {{8}},
Pages = {{640-643}},
Month = {{AUG}},
DOI = {{10.2471/BLT.09.069575}},
ISSN = {{0042-9686}},
ResearcherID-Numbers = {{Fong, Geoffrey/H-2810-2014}},
ORCID-Numbers = {{Fong, Geoffrey/0000-0001-9098-6472}},
Unique-ID = {{ISI:000268644700025}},
}

@article{ ISI:000313606400005,
Author = {Evans, Jessica and van Donkelaar, Aaron and Martin, Randall V. and
   Burnett, Richard and Rainham, Daniel G. and Birkett, Nicholas J. and
   Krewski, Daniel},
Title = {{Estimates of global mortality attributable to particulate air pollution
   using satellite imagery}},
Journal = {{ENVIRONMENTAL RESEARCH}},
Year = {{2013}},
Volume = {{120}},
Pages = {{33-42}},
Month = {{JAN}},
Abstract = {{Background: Epidemiological studies of the health effects of air
   pollution have traditionally relied upon ground-monitoring stations to
   measure ambient concentrations. Satellite derived air pollution measures
   offer the advantage of providing global coverage.
   Objective: To undertake a global assessment of mortality associated with
   long-term exposure to fine particulate air pollution using remote
   sensing data.
   Methods: Global PM2.5 exposure levels were derived from the MODIS and
   MISR satellite instruments. Relative risks and attributable fractions of
   mortality were modeled using previously developed concentration-response
   functions for the association between PM2.5 and mortality.
   Results: The global fraction of adult mortality attributable to the
   anthropogenic component of PM2.5 (95\% CI) was 8.0\% (5.3-10.5) for
   cardiopulmonary disease, 12.8\% (5.9-18.5) for lung cancer, and 9.4\%
   (6.6-11.8) for ischemic heart disease.
   Conclusion: This study demonstrates the feasibility of using satellite
   derived pollution concentrations in assessing the population health
   impacts of air pollution at the global scale. This approach leads to
   global estimates of mortality attributable to PM2.5 that are greater
   than those based on fixed site ground-level measures of urban PM2.5, but
   more similar to estimates based on global chemical transport model
   simulations of anthropogenic PM2.5. (c) 2012 Elsevier Inc. All rights
   reserved.}},
DOI = {{10.1016/j.envres.2012.08.005}},
ISSN = {{0013-9351}},
EISSN = {{1096-0953}},
ResearcherID-Numbers = {{Martin, Randall/C-1205-2014}},
ORCID-Numbers = {{Martin, Randall/0000-0003-2632-8402}},
Unique-ID = {{ISI:000313606400005}},
}

@article{ ISI:000262862600002,
Author = {Valavanidis, Athanasios and Fiotakis, Konstantinos and Vlachogianni,
   Thomais},
Title = {{Airborne Particulate Matter and Human Health: Toxicological Assessment
   and Importance of Size and Composition of Particles for Oxidative Damage
   and Carcinogenic Mechanisms}},
Journal = {{JOURNAL OF ENVIRONMENTAL SCIENCE AND HEALTH PART C-ENVIRONMENTAL
   CARCINOGENESIS \& ECOTOXICOLOGY REVIEWS}},
Year = {{2008}},
Volume = {{26}},
Number = {{4}},
Pages = {{339-362}},
Abstract = {{Air pollution has been considered a hazard to human health. In the past
   decades, many studies highlighted the role of ambient airborne
   particulate matter (PM) as an important environmental pollutant for many
   different cardiopulmonary diseases and lung cancer. Numerous
   epidemiological studies in the past 30 years found a strong
   exposure-response relationship between PM for short-term effects
   premature mortality, hospital admissions) and long-term or cumulative
   health effects (morbidity, lung cancer, cardiovascular and
   cardiopulmonary diseases, etc). Current research on airborne
   particle-induced health effects investigates the critical
   characteristics of particulate matter that determine their biological
   effects. Several independent groups of investigators have shown that the
   size of the airborne particles and their surface area determine the
   potential to elicit inflammatory injury, oxidative damage, and other
   biological effects. These effects are stronger for fine and ultrafine
   particles because they can penetrate deeper into the airways of the
   respiratory tract and can reach the alveoli in which 50\% are retained
   in the lung parenchyma. Composition of the PM varies greatly and depends
   on many factors. The major components of PM are transition metals, ions
   (sulfate, nitrate), organic compound, quinoid stable radicals of
   carbonaceous material, minerals, reactive gases, and materials of
   biologic origin. Results from toxicological research have shown that PM
   have several mechanisms of adverse cellular effects, such as
   cytotoxicity through oxidative stress mechanisms, oxygen-free
   radical-generating activity, DNA oxidative damage, mutagenicity, and
   stimulation of proinflammatory factors. In this review, the results of
   the most recent epidemiological and toxicological studies are
   summarized. In general, the evaluation of most of these studies shows
   that the smaller the size of PM the higher the toxicity through
   mechanisms of oxidative stress and inflammation. Some studies showed
   that the extractable organic compounds (a variety of chemicals with
   mutagenic and cytotoxic properties) contribute to various mechanisms of
   cytotoxicity; in addition, the water-soluble faction (mainly transition
   metals with redox potential) play an important role in the initiation of
   oxidative DNA damage and membrane lipid peroxidation. Associations
   between chemical compositions and particle toxicity tend to be stronger
   for the fine and ultrafine PM size fractions. Vehicular exhaust
   particles are found to be most responsible for small-sized airborne PM
   air pollution in urban areas. With these aspects in mind, future
   research should aim at establishing a cleared picture of the cytotoxic
   and carcinogenic mechanisms of PM in the lungs, as well as mechanisms of
   formation during internal engine combustion processes and other sources
   of airborne fine particles of air pollution.}},
DOI = {{10.1080/10590500802494538}},
ISSN = {{1059-0501}},
EISSN = {{1532-4095}},
ORCID-Numbers = {{Valavanidis, Athanasios/0000-0003-2449-6939}},
Unique-ID = {{ISI:000262862600002}},
}

@article{ ISI:000268765500003,
Author = {Stroh, Emilie and Lundh, Thomas and Oudin, Anna and Skerfving, Staffan
   and Stromberg, Ulf},
Title = {{Geographical patterns in blood lead in relation to industrial emissions
   and traffic in Swedish children, 1978-2007}},
Journal = {{BMC PUBLIC HEALTH}},
Year = {{2009}},
Volume = {{9}},
Month = {{JUL 10}},
Abstract = {{Background: Blood lead concentrations (B-Pb) were measured in 3 879
   Swedish school children during the period 1978-2007. The objective was
   to study the effect of the proximity to lead sources based on the
   children's home and school location.
   Methods: The children's home address and school location were geocoded
   and their proximity to a lead smelter and major roads was calculated
   using geographical information system (GIS) software. All the
   statistical analyses were carried out using means of generalized
   log-linear modelling, with natural-logarithm-transformed B-Pb, adjusted
   for sex, school year, lead-exposing hobby, country of birth and, in the
   periods 1988-1994 and 1995-2007, parents' smoking habits.
   Results: The GIS analysis revealed that although the emission from the
   smelter and children's BPb levels had decreased considerably since 1978,
   proximity to the lead smelter continued to affect levels of B-Pb, even
   in recent years (geometric mean: near smelter: 22.90 mu g/l; far from
   smelter 19.75 mu g/l; p = 0.001). The analysis also revealed that
   proximity to major roads noticeably affected the children's B-Pb levels
   during the period 1978-1987 (geometric mean near major roads: 44.26 mu
   g/l; far from roads: 38.32 mu g/l; p = 0.056), due to the considerable
   amount of lead in petrol. This effect was, however, not visible after
   1987 due to prohibition of lead in petrol.
   Conclusion: The results show that proximity to the lead smelter still
   has an impact on the children's B-Pb levels. This is alarming since it
   could imply that living or working in the vicinity of a former lead
   source could pose a threat years after reduction of the emission. The
   analysis also revealed that urban children exposed to lead from traffic
   were only affected during the early period, when there were considerable
   amounts of lead in petrol, and that the prohibition of lead in petrol in
   later years led to reduced levels of lead in the blood of urban
   children.}},
DOI = {{10.1186/1471-2458-9-225}},
Article-Number = {{225}},
ISSN = {{1471-2458}},
ResearcherID-Numbers = {{Oudin, Anna/A-5446-2013}},
ORCID-Numbers = {{Oudin, Anna/0000-0002-9876-0627}},
Unique-ID = {{ISI:000268765500003}},
}

@article{ ISI:000292491500012,
Author = {Tredaniel, J. and Durand, C. and Teixeira, L. and Staudacher, L. and
   Beuzelin, C. and Jagot, J. -L. and Stucker, I. and Robert, J. and
   Salmeron, S.},
Title = {{Air pollution, a cause of lung cancer?}},
Journal = {{ARCHIVES DES MALADIES PROFESSIONNELLES ET DE L ENVIRONNEMENT}},
Year = {{2011}},
Volume = {{72}},
Number = {{3}},
Pages = {{290-296}},
Month = {{JUN}},
Abstract = {{Much has been written about the short-term effects of air pollution on
   health. In contrast, long-term effects, which are potentially very
   important such as lung cancer, have been addressed in only a few cohort
   studies. Long-term effects of air pollution on mortality have been
   evaluated in three American and four European prospective cohort
   studies. These studies consistently demonstrate associations between
   ambient fine particulate air pollution and elevated risks of both
   cardiopulmonary and lung cancer mortality. These studies indicate that
   diesel exhaust especially contributes to the human lung cancer burden,
   with a relative risk estimated to be about 1.5 in most situations.
   Although individual health risks of air pollution are relatively small,
   the public-health consequences of such exposure are nevertheless
   important. (C) 2011 Elsevier Masson SAS. All rights reserved.}},
DOI = {{10.1016/j.admp.2011.02.010}},
ISSN = {{1775-8785}},
Unique-ID = {{ISI:000292491500012}},
}

@article{ ISI:000336291500001,
Author = {Mannocci, Alice and Colamesta, Vittoria and Conti, Vittoria and
   Cattaruzza, Maria Sofia and Paone, Gregorino and Cafolla, Maria and
   Saulle, Rosella and Bulzomi, Vincenzo and Antici, Daniele and
   Cuccurullo, Pasquale and Boccia, Antonio and La Torre, Giuseppe and
   Terzano, Claudio},
Title = {{Demographic Characteristics, Nicotine Dependence, and Motivation to Quit
   as Possible Determinants of Smoking Behaviors and Acceptability of
   Shocking Warnings in Italy}},
Journal = {{BIOMED RESEARCH INTERNATIONAL}},
Year = {{2014}},
Abstract = {{Introduction. This paper presents the final results of a cross-sectional
   study started in 2010. It compares the perceived efficacy of different
   types of tobacco health warning (texts versus shocking pictures) to quit
   or reduce tobacco use. Methods. The study conducted between 2010 and
   2012 in Italy enrolled adults smokers. Administering a questionnaire
   demographic data, smokers behaviors were collected. Showing text and
   graphic warnings (the corpse of a smoker, diseased lungs, etc.) the most
   perceived efficacy to reduce tobacco consumption or to encourage was
   quit. Results. 666 subjects were interviewed; 6\% of responders referred
   that they stopped smoking at least one month due to the textual
   warnings. The 81\% of the smokers perceived that the warnings with
   shocking pictures are more effective in reducing/quitting tobacco
   consumption than text-only warnings. The younger group (<45 years), who
   are more motivated to quit (Mondor's score >= 12), and females showed a
   higher effectiveness of shocking warnings to reduce tobacco consumption
   of, 76\%, 78\%, and 43\%, respectively with P < 0.05. Conclusions. This
   study suggests that pictorial warnings on cigarette packages are more
   likely to be noticed and rated as effective by Italian smokers. Female
   and younger smokers appear to be more involved by shock images. The
   jarring warnings also appear to be supporting those who want to quit
   smoking. This type of supportive information in Italy may become
   increasingly important for helping smokers to change their behavior.}},
DOI = {{10.1155/2014/723035}},
Article-Number = {{723035}},
ISSN = {{2314-6133}},
EISSN = {{2314-6141}},
ORCID-Numbers = {{TERZANO, CLAUDIO/0000-0002-9851-7731}},
Unique-ID = {{ISI:000336291500001}},
}

@article{ ISI:000266401400008,
Author = {Tredaniel, J. and Aarab-Terrisse, S. and Teixeira, L. and Savinelli, F.
   and Fraboulet, S. and Gossot, D. and Hennequin, C.},
Title = {{Atmospheric air pollution and lung cancer: epidemiologic data}},
Journal = {{REVUE DES MALADIES RESPIRATOIRES}},
Year = {{2009}},
Volume = {{26}},
Number = {{4}},
Pages = {{437-445}},
Month = {{APR}},
Abstract = {{Introduction Much has been written about the short term effects of air
   pollution on health. In contrast, long term effects, which may be highly
   significant such as lung cancer, have been addressed in only a few
   cohort studies.
   State of the art Long term effects of air pollution on mortality have
   been evaluated in three American and three European prospective cohort
   studies. These studies consistently demonstrate associations between
   ambient fine particulate air pollution and elevated risks of both
   cardiopulmonary and lung cancer mortality. They indicate that diesel
   exhaust especially contributes to the human lung cancer burden.
   Perspectives and conclusions Although long-term health effects of air
   pollution are of relatively small magnitude at the individual level when
   compared to that of tobacco smoking, their consequences are considerable
   in terms of public health.}},
DOI = {{10.1019/20094070}},
ISSN = {{0761-8425}},
ResearcherID-Numbers = {{Teixeira, Luis/C-3694-2013}},
Unique-ID = {{ISI:000266401400008}},
}

@article{ ISI:000315357800012,
Author = {Allen, Ryan W. and Gombojav, Enkhjargal and Barkhasragchaa, Baldorj and
   Byambaa, Tsogtbaatar and Lkhasuren, Oyuntogos and Amram, Ofer and
   Takaro, Tim K. and Janes, Craig R.},
Title = {{An assessment of air pollution and its attributable mortality in
   Ulaanbaatar, Mongolia}},
Journal = {{AIR QUALITY ATMOSPHERE AND HEALTH}},
Year = {{2013}},
Volume = {{6}},
Number = {{1}},
Pages = {{137-150}},
Month = {{MAR}},
Abstract = {{Epidemiologic studies have consistently reported associations between
   outdoor fine particulate matter (PM2.5) air pollution and adverse health
   effects. Although Asia bears the majority of the public health burden
   from air pollution, few epidemiologic studies have been conducted
   outside of North America and Europe due in part to challenges in
   population exposure assessment. We assessed the feasibility of two
   current exposure assessment techniques, land use regression (LUR)
   modeling and mobile monitoring, and estimated the mortality attributable
   to air pollution in Ulaanbaatar, Mongolia. We developed LUR models for
   predicting wintertime spatial patterns of NO2 and SO2 based on 2-week
   passive Ogawa measurements at 37 locations and freely available
   geographic predictors. The models explained 74\% and 78\% of the
   variance in NO2 and SO2, respectively. Land cover characteristics
   derived from satellite images were useful predictors of both pollutants.
   Mobile PM2.5 monitoring with an integrating nephelometer also showed
   promise, capturing substantial spatial variation in PM2.5
   concentrations. The spatial patterns in SO2 and PM, seasonal and diurnal
   patterns in PM2.5, and high wintertime PM2.5/PM10 ratios were consistent
   with a major impact from coal and wood combustion in the city's
   low-income traditional housing (ger) areas. The annual average
   concentration of PM2.5 measured at a centrally located government
   monitoring site was 75 mu g/m(3) or more than seven times the World
   Health Organization's PM2.5 air quality guideline, driven by a
   wintertime average concentration of 148 mu g/m(3). PM2.5 concentrations
   measured in a traditional housing area were higher, with a wintertime
   mean PM2.5 concentration of 250 mu g/m(3). We conservatively estimated
   that 29\% (95\% CI, 12-43\%) of cardiopulmonary deaths and 40\% (95\%
   CI, 17-56\%) of lung cancer deaths in the city are attributable to
   outdoor air pollution. These deaths correspond to nearly 10\% of the
   city's total mortality, with estimates ranging to more than 13\% of
   mortality under less conservative model assumptions. LUR models and
   mobile monitoring can be successfully implemented in developing country
   cities, thus cost-effectively improving exposure assessment for
   epidemiology and risk assessment. Air pollution represents a major
   threat to public health in Ulaanbaatar, Mongolia, and reducing home
   heating emissions in traditional housing areas should be the primary
   focus of air pollution control efforts.}},
DOI = {{10.1007/s11869-011-0154-3}},
ISSN = {{1873-9318}},
Unique-ID = {{ISI:000315357800012}},
}

@article{ ISI:000306035300020,
Author = {Lepeule, Johanna and Laden, Francine and Dockery, Douglas and Schwartz,
   Joel},
Title = {{Chronic Exposure to Fine Particles and Mortality: An Extended Follow-up
   of the Harvard Six Cities Study from 1974 to 2009}},
Journal = {{ENVIRONMENTAL HEALTH PERSPECTIVES}},
Year = {{2012}},
Volume = {{120}},
Number = {{7}},
Pages = {{965-970}},
Month = {{JUL}},
Abstract = {{BACKGROUND: Epidemiologic studies have reported associations between
   fine particles (aerodynamic diameter >= 5 2.5 mu m; PM2.5) and
   mortality. However, concerns have been raised regarding the sensitivity
   of the results to model specifications, lower exposures, and averaging
   time.
   OBJECTIVE: We addressed these issues using 11 additional years of
   follow-up of the Harvard Six Cities study, incorporating recent lower
   exposures.
   METHODS: We replicated the previously applied Cox regression, and
   examined different time lags, the shape of the concentration response
   relationship using penalized splines, and changes in the slope of the
   relation over time. We then conducted Poisson survival analysis with
   time-varying effects for smoking, sex, and education.
   RESULTS: Since 2001, average PM2.5 levels, for all six cities, were < 18
   mu g/m(3). Each increase in PM2.5 (10 mu g/m(3)) was associated with an
   adjusted increased risk of all-cause mortality (PM2.5 average on
   previous year) of 14\% {[}95\% confidence interval (CI): 7, 22], and
   with 26\% (95\% CI: 14, 40) and 37\% (95\% CI: 7, 75) increases in
   cardiovascular and lung-cancer mortality (PM2.5 average of three
   previous years), respectively. The concentration response relationship
   was linear down to PM2.5 concentrations of 8 mu g/m(3). Mortality rate
   ratios for PM2.5 fluctuated over time, but without clear trends despite
   a substantial drop in the sulfate fraction. Poisson models produced
   similar results.
   CONCLUSIONS: These results suggest that further public policy efforts
   that reduce fine particulate matter air pollution are likely to have
   continuing public health benefits.}},
DOI = {{10.1289/ehp.1104660}},
ISSN = {{0091-6765}},
ResearcherID-Numbers = {{lepeule, johanna/N-2579-2013}},
Unique-ID = {{ISI:000306035300020}},
}

@article{ ISI:000284182800009,
Author = {Kees, Jeremy and Burton, Scot and Andrews, J. Craig and Kozup, John},
Title = {{Understanding How Graphic Pictorial Warnings Work on Cigarette Packaging}},
Journal = {{JOURNAL OF PUBLIC POLICY \& MARKETING}},
Year = {{2010}},
Volume = {{29}},
Number = {{2}},
Pages = {{265-276}},
Month = {{FAL}},
Abstract = {{The 2009 Family Smoking Prevention and Tobacco Control Act requires
   cigarette packages to contain stronger warnings in the form of color,
   graphic pictures depicting the negative health consequences of smoking.
   The authors present results from a between-subjects experiment with more
   than 500 smokers that test (1) the effectiveness of pictorial warnings
   that vary in their graphic depiction of the warning and (2) an
   underlying mechanism proposed to drive potential effects of the
   manipulation of the graphic depiction. The findings indicate that more
   graphic pictorial warning depictions strengthen smokers' intentions to
   quit smoking. Recall of warning message statements is reduced by
   moderately or highly graphic pictures compared with a no-picture control
   or less graphic pictures. The results also show that the graphic
   warnings affect evoked fear, and in turn, fear mediates the effects of
   the graphic warning depiction on intentions to quit for the sample of
   smokers. This pattern of results indicates that though highly graphic
   pictures may reduce specific message recall and limit the direct effect
   of recall on intentions to quit, highly graphic pictures increase
   intentions to quit smoking through evoked fear (i.e., fear fully
   mediates the effect of the graphic depiction level). The authors discuss
   implications for consumer health and policy decisions.}},
ISSN = {{0743-9156}},
Unique-ID = {{ISI:000284182800009}},
}

@article{ ISI:000312539600004,
Author = {Franchini, M. and Guida, A. and Tufano, A. and Coppola, A.},
Title = {{Air pollution, vascular disease and thrombosis: linking clinical data
   and pathogenic mechanisms}},
Journal = {{JOURNAL OF THROMBOSIS AND HAEMOSTASIS}},
Year = {{2012}},
Volume = {{10}},
Number = {{12}},
Pages = {{2438-2451}},
Month = {{DEC}},
Abstract = {{. The public health burden of air pollution has been increasingly
   recognized over the last decades. Following the first assessed adverse
   effects on respiratory diseases and lung cancer, a large body of
   epidemiologic and clinical studies definitely documented an even
   stronger association of air pollution exposure with cardiovascular
   mortality and morbidity, particularly related to atherothrombotic
   (coronary and cerebrovascular) disease. Particulate matter (PM), mainly
   that with lower aerodynamic diameter (fine and ultrafine PM), is
   responsible for the most severe effects, due to its capacity to
   transport toxic substances deep into the lower airways. These effects
   have been shown to occur not only after short-term exposure to elevated
   concentrations of pollutants, but even after long-term relatively low
   levels of exposure. Vulnerable subjects (elderly persons and those with
   preexisting cardiopulmonary diseases) show the highest impact. Fewer and
   conflicting data also suggest an association with venous
   thromboembolism. Although not completely elucidated, a series of
   mechanisms have been hypothesized and tested in experimental settings.
   These phenomena, including vasomotor and cardiac autonomic dysfunction,
   hemostatic unbalance, oxidative stress and inflammatory response, have
   been shown to change over time and differently contribute to the
   short-term and long-term adverse effects of pollution exposure. Beyond
   environmental health policies, crucial for improving air quality and
   reducing the impact of such an elusive threat to public health, the
   recognition and assessment of the individual risk, together with
   specific advice, should be routinely implemented in the strategies of
   primary and secondary cardiovascular prevention.}},
DOI = {{10.1111/jth.12006}},
ISSN = {{1538-7933}},
Unique-ID = {{ISI:000312539600004}},
}

@article{ ISI:000323703500023,
Author = {Cesaroni, Giulia and Badaloni, Chiara and Gariazzo, Claudio and
   Stafoggia, Massimo and Sozzi, Roberto and Davoli, Marina and Forastiere,
   Francesco},
Title = {{Long-Term Exposure to Urban Air Pollution and Mortality in a Cohort of
   More than a Million Adults in Rome}},
Journal = {{ENVIRONMENTAL HEALTH PERSPECTIVES}},
Year = {{2013}},
Volume = {{121}},
Number = {{3}},
Pages = {{324-331}},
Month = {{MAR}},
Abstract = {{BACKGROUND: Few European studies have investigated the effects of
   long-term exposure to both fine particulate matter (<= 2.5 mu m; PM2.5)
   and nitrogen dioxide (NO2) on mortality.
   OBJECTIVES: We studied the association of exposure to NO2, PM2.5, and
   traffic indicators on cause-specific mortality to evaluate the form of
   the concentration-response relationship.
   METHODS: We analyzed a population-based cohort enrolled at the 2001
   Italian census with 9 years of follow-up. We selected all 1,265,058
   subjects >= 30 years of age who had been living in Rome for at least 5
   years at baseline. Residential exposures included annual NO2 (from a
   land use regression model) and annual PM2.5 (from a Eulerian dispersion
   model), as well as distance to roads with > 10,000 vehicles/day and
   traffic intensity. We used Cox regression models to estimate
   associations with cause-specific mortality adjusted for individual (sex,
   age, place of birth, residential history, marital status, education,
   occupation) and area (socio-economic status, clustering)
   characteristics.
   RESULTS: Long-term exposures to both NO2 and PM2.5 were associated with
   an increase in non-accidental mortality {[}hazard ratio (HR) = 1.03
   (95\% CI: 1.02, 1.03) per 10-mu g/m(3) NO2; HR = 1.04 (95\% CI: 1.03,
   1.05) per 10-mu g/m(3) PM2.5]. The strongest association was found for
   ischemic heart diseases (IHD) {[}HR = 1.10 (95\% CI: 1.06, 1.13) per
   10-mu g/m(3) PM2.5], followed by cardio-vascular diseases and lung
   cancer. The only association showing some deviation from linearity was
   that between NO2 and IHD. In a bi-pollutant model, the estimated effect
   of NO2 on mortality was independent of PM2.5.
   CONCLUSIONS: This large study strongly supports an effect of long-term
   exposure to NO2 and PM2.5 on mortality, especially from cardio-vascular
   causes. The results are relevant for the next European policy decisions
   regarding air quality.}},
DOI = {{10.1289/ehp.1205862}},
ISSN = {{0091-6765}},
ORCID-Numbers = {{Gariazzo, Claudio/0000-0003-2287-6364}},
Unique-ID = {{ISI:000323703500023}},
}

@article{ ISI:000330853800026,
Author = {Giannadaki, D. and Pozzer, A. and Lelieveld, J.},
Title = {{Modeled global effects of airborne desert dust on air quality and
   premature mortality}},
Journal = {{ATMOSPHERIC CHEMISTRY AND PHYSICS}},
Year = {{2014}},
Volume = {{14}},
Number = {{2}},
Pages = {{957-968}},
Abstract = {{Fine particulate matter is one of the most important factors
   contributing to air pollution. Epidemiological studies have related
   increased levels of atmospheric particulate matter to premature human
   mortality caused by cardiopulmonary disease and lung cancer. However, a
   limited number of investigations have focused on the contribution of
   airborne desert dust particles. Here we assess the effects of dust
   particles with an aerodynamic diameter smaller than 2.5 mu m (DU2.5) on
   human mortality for the year 2005. We used the EMAC
   atmospheric-chemistry general circulation model at high resolution to
   simulate global atmospheric dust concentrations. We applied a health
   impact function to estimate premature mortality for the global
   population of 30 yr and older, using parameters from epidemiological
   studies. We estimate a global cardiopulmonary mortality of about 402 000
   in 2005. The associated years of life lost are about 3.47 million per
   year. We estimate the global fraction of the cardiopulmonary deaths
   caused by atmospheric desert dust to be about 1.8 \%, though in the 20
   countries most affected by dust this is much higher, about 15-50 \%.
   These countries are primarily found in the so-called ``dust belt{''}
   from North Africa across the Middle East and South Asia to East Asia}},
DOI = {{10.5194/acp-14-957-2014}},
ISSN = {{1680-7316}},
EISSN = {{1680-7324}},
ResearcherID-Numbers = {{Lelieveld, Johannes/A-1986-2013
   Pozzer,  Andrea/L-4872-2013}},
ORCID-Numbers = {{Pozzer,  Andrea/0000-0003-2440-6104}},
Unique-ID = {{ISI:000330853800026}},
}

@article{ ISI:A1990CH03100003,
Author = {NEEDLEMAN, HL and SCHELL, A and BELLINGER, D and LEVITON, A and ALLRED,
   EN},
Title = {{THE LONG-TERM EFFECTS OF EXPOSURE TO LOW-DOSES OF LEAD IN CHILDHOOD - AN
   11-YEAR FOLLOW-UP REPORT}},
Journal = {{NEW ENGLAND JOURNAL OF MEDICINE}},
Year = {{1990}},
Volume = {{322}},
Number = {{2}},
Pages = {{83-88}},
Month = {{JAN 11}},
DOI = {{10.1056/NEJM199001113220203}},
ISSN = {{0028-4793}},
Unique-ID = {{ISI:A1990CH03100003}},
}

@article{ ISI:000264051000006,
Author = {Jerrett, Michael and Burnett, Richard T. and Pope, II, C. Arden and Ito,
   Kazuhiko and Thurston, George and Krewski, Daniel and Shi, Yuanli and
   Calle, Eugenia and Thun, Michael},
Title = {{Long-Term Ozone Exposure and Mortality.}},
Journal = {{NEW ENGLAND JOURNAL OF MEDICINE}},
Year = {{2009}},
Volume = {{360}},
Number = {{11}},
Pages = {{1085-1095}},
Month = {{MAR 12}},
Abstract = {{Background: Although many studies have linked elevations in tropospheric
   ozone to adverse health outcomes, the effect of long-term exposure to
   ozone on air pollution-related mortality remains uncertain. We examined
   the potential contribution of exposure to ozone to the risk of death
   from cardiopulmonary causes and specifically to death from respiratory
   causes.
   Methods: Data from the study cohort of the American Cancer Society
   Cancer Prevention Study II were correlated with air-pollution data from
   96 metropolitan statistical areas in the United States. Data were
   analyzed from 448,850 subjects, with 118,777 deaths in an 18-year
   follow-up period. Data on daily maximum ozone concentrations were
   obtained from April 1 to September 30 for the years 1977 through 2000.
   Data on concentrations of fine particulate matter (particles that are
   lessthan/equal 2.5 microm in aerodynamic diameter {[}PM(sub 2.5)]) were
   obtained for the years 1999 and 2000. Associations between ozone
   concentrations and the risk of death were evaluated with the use of
   standard and multilevel Cox regression models.
   Results: In single-pollutant models, increased concentrations of either
   PM(sub 2.5) or ozone were significantly associated with an increased
   risk of death from cardiopulmonary causes. In two-pollutant models,
   PM(sub 2.5) was associated with the risk of death from cardiovascular
   causes, whereas ozone was associated with the risk of death from
   respiratory causes. The estimated relative risk of death from
   respiratory causes that was associated with an increment in ozone
   concentration of 10 ppb was 1.040 (95\% confidence interval, 1.010 to
   1.067). The association of ozone with the risk of death from respiratory
   causes was insensitive to adjustment for confounders and to the type of
   statistical model used.
   Conclusions: In this large study, we were not able to detect an effect
   of ozone on the risk of death from cardiovascular causes when the
   concentration of PM(sub 2.5) was taken into account. We did, however,
   demonstrate a significant increase in the risk of death from respiratory
   causes in association with an increase in ozone concentration.
   N Engl J Med 2009;360:1085-95.}},
DOI = {{10.1056/NEJMoa0803894}},
ISSN = {{0028-4793}},
Unique-ID = {{ISI:000264051000006}},
}

@article{ ISI:000249785500004,
Author = {Watterson, Todd L. and Sorensen, Jared and Martin, Randy and Coulombe,
   Jr., Roger A.},
Title = {{Effects of PM2.5 collected from Cache Valley Utah on genes associated
   with the inflammatory response in human lung cells}},
Journal = {{JOURNAL OF TOXICOLOGY AND ENVIRONMENTAL HEALTH-PART A-CURRENT ISSUES}},
Year = {{2007}},
Volume = {{70}},
Number = {{20}},
Pages = {{1731-1744}},
Abstract = {{In January 2004, the normally picturesque Cache Valley in northern Utah
   made national headlines with the highest PM2.5 levels in the nation.
   Epidemiological studies linked exposure to particulate air pollution in
   other locations with stroke and Alzheimer's disease and to early
   mortality from all causes, cancer, and cardiopulmonary diseases. To
   determine potential effects of these particles on human health, human
   bronchial epithelial cells (BEAS- 2B) were cultured with PM2.5 collected
   from various locations in the Cache Valley. These particles were
   slightly cytotoxic, but more potent than NH4NO3, the major chemical
   component of Cache Valley PM2.5. Gene expression analysis of
   PM2.5-exposed cells was performed using microarray and quantitative
   reverse-transcription polymerase chain reaction (RT-PCR.) Among other
   genes, PM2.5 exposure induced genes and proteins involved in the
   inflammatory response. Most notably, PM2.5-exposed cells showed
   significant gene level upregulation of activating receptors to
   interleukins 1 and 6 (IL-1R1 and IL-6R), as well as concomitant
   increases in protein. Increases in IL-1 receptor associated kinase-1
   (IRAK) protein were observed. PM2.5 exposure resulted in release of
   IL-6, as well phosphorylated STAT3 protein, providing evidence that PM
   activates the IL-6/gp130/STAT3 signaling pathway in BEAS-2B cells. IL-20
   and major histocompatibility complex peptide class-1 (MICA) were
   upregulated and cleavage of caspase- 12 was detected. In total, our
   results indicate that Cache Valley PM2.5 produces the upregulation of
   important cytokine receptors and is able to activate both IL-1R-and
   IL-6R-mediated signaling pathways in human lung cells. These
   observations are generally consistent with the adverse effects
   associated with inhalation of fine particulate matter like PM2.5.}},
DOI = {{10.1080/15287390701457746}},
ISSN = {{1528-7394}},
Unique-ID = {{ISI:000249785500004}},
}

@article{ ISI:000261221800015,
Author = {Nascimento, B. E. M. and Oliveira, L. and Vieira, A. S. and Joffily, M.
   and Gleiser, S. and Pereira, M. G. and Cavalcante, T. and Volchan, E.},
Title = {{Avoidance of smoking: the impact of warning labels in Brazil}},
Journal = {{TOBACCO CONTROL}},
Year = {{2008}},
Volume = {{17}},
Number = {{6}},
Pages = {{405-409}},
Month = {{DEC}},
Abstract = {{Background: Research on human emotion shows that pictures drive the
   activity of specialised brain networks affecting attitude and behaviour.
   Pictorial warnings on cigarette packages are considered one of the most
   effective ways to convey information on the health consequences of
   smoking. However, few studies have evaluated the effectiveness of
   warning labels to elicit avoidance of smoking.
   Objectives: To investigate the impact of pictorial health warnings
   conveyed by the Brazilian tobacco control programme through a
   well-established psychometric tool designed for studies on emotion and
   behaviour.
   Methods: Graphic Brazilian cigarette warnings labels were evaluated.
   They consisted of the two sets of warning pictures displayed in 2002-4
   (n = 9) and 2004-8 (n = 10). Pleasant, unpleasant and neutral pictures
   selected from a standard catalogue were used as controls. Undergraduate
   students (n = 212, 18\% smokers) evaluated the emotional content of each
   picture in two affective dimensions: hedonic valence and arousal.
   Participants were not provided with the sources of distinction between
   control and warning pictures.
   Results: The judgements of hedonic content of the warning pictures
   ranged from neutral to very unpleasant. None was classified as highly
   arousing. Smokers judged warning pictures representing people smoking
   significantly more pleasant than pictures without smoking scenes, and
   significantly more so than non-smokers. No significant differences
   between smokers and non-smokers were found for warning pictures without
   these smoking scenes.
   Conclusion: Previous studies have shown that the most threatening and
   arousing pictures prompt the greatest evidence of defensive activation.
   Emotional ratings of Brazilian warning pictures described them as
   unpleasant but moderately arousing. To intensify avoidance of the
   packages, future graphic warnings should therefore generate more
   arousal. The ratings for the Brazilian warning pictures indicated that,
   except for those depicting people smoking, judgements by smokers and
   non-smokers were similar, suggesting a potential applicability in both
   prevention and cessation. Smoking cues, however, should be avoided.}},
DOI = {{10.1136/tc.2008.025643}},
ISSN = {{0964-4563}},
ResearcherID-Numbers = {{Volchan, Eliane/C-5792-2013}},
Unique-ID = {{ISI:000261221800015}},
}

@article{ ISI:000364774900011,
Author = {Coletti, Daniel J. and Brunette, Mary and John, Majnu and Kane, John M.
   and Malhotra, Anil K. and Robinson, Delbert G.},
Title = {{Responses to Tobacco Smoking-Related Health Messages in Young People
   With Recent-Onset Schizophrenia}},
Journal = {{SCHIZOPHRENIA BULLETIN}},
Year = {{2015}},
Volume = {{41}},
Number = {{6}},
Pages = {{1256-1265}},
Month = {{NOV}},
Abstract = {{Virtually no research has examined the responses of youth with
   recent-onset psychosis (ROP) to smoking-related health warnings. We
   examined predictors of response and tested hypotheses that participants
   with ROP would (a) assess warnings as less effective than a healthy
   comparison (HC) group, and (b) assess video warnings as more effective
   than pictures. ROP participants (n = 69) had < 2 years of prior
   antipsychotic treatment; the HC group (n = 79) had no major mental
   illness. Participants viewed 10 pictorial warnings, 8 videos depicting
   similar messages, and were interviewed regarding tobacco use, health
   literacy, and smoking knowledge. We assessed response at baseline and at
   4-week follow-up. ROP participants were more likely than HC to smoke
   tobacco (49.3\% vs 10.1\%) and had lower levels of health literacy and
   smoking-related knowledge. Cannabis was used by 46.4\% of ROP
   participants. Effectiveness ratings were high for both picture and video
   warnings with no differences between media. ROP participants compared to
   HC and nonsmokers compared to smokers were more likely to perceive
   warnings as effective. Effectiveness was associated with negative affect
   and greater emotional arousal. We assessed 33 smokers at follow-up; 5
   (15\%) identified as nonsmokers, 15 (45\%) made a quit attempt, and 16
   (49\%) reported that the warnings influenced their smoking. Results
   indicate that young people with psychotic disorders respond favorably to
   health warnings. Effective messages depict health consequences clearly,
   elicit negative emotions, and may impact smoking behavior. Future
   research is needed to understand the effects of mode of presentation and
   message comprehension on smoking behavior.}},
DOI = {{10.1093/schbul/sbv122}},
ISSN = {{0586-7614}},
EISSN = {{1745-1701}},
Unique-ID = {{ISI:000364774900011}},
}

@article{ ISI:000323378000078,
Author = {Volchan, Eliane and David, Isabel A. and Tavares, Gisella and
   Nascimento, Billy M. and Oliveira, Jose M. and Gleiser, Sonia and Szklo,
   Andre and Perez, Cristina and Cavalcante, Tania and Pereira, Mirtes G.
   and Oliveira, Leticia},
Title = {{Implicit Motivational Impact of Pictorial Health Warning on Cigarette
   Packs}},
Journal = {{PLOS ONE}},
Year = {{2013}},
Volume = {{8}},
Number = {{8}},
Month = {{AUG 15}},
Abstract = {{Objective: The use of pictorial warning labels on cigarette packages is
   one of the provisions included in the first ever global health treaty by
   the World Health Organization against the tobacco epidemic. There is
   substantial evidence demonstrating the effectiveness of graphic health
   warning labels on intention to quit, thoughts about health risks and
   engaging in cessation behaviors. However, studies that address the
   implicit emotional drives evoked by such warnings are still
   underexplored. Here, we provide experimental data for the use of
   pictorial health warnings as a reliable strategy for tobacco control.
   Methods: Experiment 1 pre-tested nineteen prototypes of pictorial
   warnings to screen for their emotional impact. Participants (n = 338)
   were young adults balanced in gender, smoking status and education.
   Experiment 2 (n = 63) tested pictorial warnings (ten) that were stamped
   on packs. We employed an innovative set-up to investigate the impact of
   the warnings on the ordinary attitude of packs' manipulation, and
   quantified judgments of warnings' emotional strength and efficacy
   against smoking.
   Findings: Experiment 1 revealed that women judged the warning prototypes
   as more aversive than men, and smokers judged them more aversive than
   non-smokers. Participants with lower education judged the prototypes
   more aversive than participants with higher education. Experiment 2
   showed that stamped warnings antagonized the appeal of the brands by
   imposing a cost to manipulate the cigarette packs, especially for
   smokers. Additionally, participants' judgments revealed that the more
   aversive a warning, the more it is perceived as effective against
   smoking.
   Conclusions: Health warning labels are one of the key components of the
   integrated approach to control the global tobacco epidemic. The evidence
   presented in this study adds to the understanding of how implicit
   responses to pictorial warnings may contribute to behavioral change.}},
DOI = {{10.1371/journal.pone.0072117}},
Article-Number = {{e72117}},
ISSN = {{1932-6203}},
ResearcherID-Numbers = {{Volchan, Eliane/C-5792-2013}},
Unique-ID = {{ISI:000323378000078}},
}

@article{ ISI:000319860400014,
Author = {Carey, Iain M. and Atkinson, Richard W. and Kent, Andrew J. and van
   Staa, Tjeerd and Cook, Derek G. and Anderson, H. Ross},
Title = {{Mortality Associations with Long-Term Exposure to Outdoor Air Pollution
   in a National English Cohort}},
Journal = {{AMERICAN JOURNAL OF RESPIRATORY AND CRITICAL CARE MEDICINE}},
Year = {{2013}},
Volume = {{187}},
Number = {{11}},
Pages = {{1226-1233}},
Month = {{JUN 1}},
Abstract = {{Rationale: Cohort evidence linking long-term exposure to outdoor
   particulate air pollution and mortality has come largely from the United
   States. There is relatively little evidence from nationally
   representative cohorts in other countries.
   Objectives: To investigate the relationship between long-term exposure
   to a range of pollutants and causes of death in a national English
   cohort.
   Methods: A total of 835,607 patients aged 40-89 years registered with
   205 general practices were followed from 2003-2007. Annual average
   concentrations in 2002 for particulate matter with a median aerodynamic
   diameter less than 10 (PM10) and less than 2.5 mu m (PM2.5), nitrogen
   dioxide (NO2), ozone, and sulfur dioxide (SO2) at 1 km(2) resolution,
   estimated from emission-based models, were linked to residential
   postcode. Deaths (n = 83,103) were ascertained from linkage to death
   certificates, and hazard ratios (HRs) for all- and cause-specific
   mortality for pollutants were estimated for interquartile pollutant
   changes from Cox models adjusting for age, sex, smoking, body mass
   index, and area-level socioeconomic status markers.
   Measurements and Main Results: Residential concentrations of all
   pollutants except ozone were positively associated with all-cause
   mortality (HR, 1.02, 1.03, and 1.04 for PM2.5, NO2, and SO2,
   respectively). Associations for PM2.5, NO2, and SO2 were larger for
   respiratory deaths (HR, 1.09 each) and lung cancer (HR, 1.02, 1.06, and
   1.05) but nearer unity for cardiovascular deaths (1.00, 1.00, and 1.04).
   Conclusions: These results strengthen the evidence linking long-term
   ambient air pollution exposure to increased all-cause mortality.
   However, the stronger associations with respiratory mortality are not
   consistent with most US studies in which associations with
   cardiovascular causes of death tend to predominate.}},
DOI = {{10.1164/rccm.201210-1758OC}},
ISSN = {{1073-449X}},
ResearcherID-Numbers = {{Cook, Derek/C-3271-2008
   Carey, Iain/O-6973-2014
   van Staa, Tjeerd/}},
ORCID-Numbers = {{Carey, Iain/0000-0003-1099-8460
   van Staa, Tjeerd/0000-0001-9363-742X}},
Unique-ID = {{ISI:000319860400014}},
}

@article{ ISI:000313614900002,
Author = {Yang, Chia-Ming and Kao, Kai},
Title = {{Reducing Fine Particulate to Improve Health: A Health Impact Assessment
   for Taiwan}},
Journal = {{ARCHIVES OF ENVIRONMENTAL \& OCCUPATIONAL HEALTH}},
Year = {{2013}},
Volume = {{68}},
Number = {{1}},
Pages = {{3-12}},
Month = {{JAN 1}},
Abstract = {{Recently various countries have adopted the new standards for PM2.5
   (particulate matter <2.5 mu m in aerodynamic diameter), but Taiwan still
   maintains an old set of air quality guidelines for particulate matter;
   therefore, the authors quantified the public health impact of long-term
   exposure to PM2.5 in terms of attributable number of deaths and the
   potential gain in life expectancy by reducing PM2.5 annual levels to 25,
   20, 15, and 10 mu g/m3. When the guideline for PM2.5 long-term exposure
   was set at 25 mu g/m3, 3.3\% of all-cause mortality or 4,500 deaths in
   2009 could be prevented. The potential gain in life expectancy at age 30
   of this reduction would increase by a range between 1 and 7 months in
   Taiwan. This study shows that guidelines for PM2.5, especially for
   long-term exposure, should be adopted in Taiwan as soon as possible to
   protect public health.}},
DOI = {{10.1080/19338244.2011.619216}},
ISSN = {{1933-8244}},
EISSN = {{2154-4700}},
Unique-ID = {{ISI:000313614900002}},
}

@article{ ISI:A1994PQ66200018,
Author = {POCOCK, SJ and SMITH, M and BAGHURST, P},
Title = {{ENVIRONMENTAL LEAD AND CHILDRENS INTELLIGENCE - A SYSTEMATIC REVIEW OF
   THE EPIDEMIOLOGIC EVIDENCE}},
Journal = {{BRITISH MEDICAL JOURNAL}},
Year = {{1994}},
Volume = {{309}},
Number = {{6963}},
Pages = {{1189-1197}},
Month = {{NOV 5}},
Abstract = {{Objective-To quantify the magnitude of the relation between full scale
   IQ in children aged 5 or more and their body burden of lead.
   Design-A systematic review of 26 epidemiological studies since 1979:
   prospective studies of birth cohorts, cross sectional studies of blood
   lead, and cross sectional studies of tooth lead.
   Setting-General populations of children greater than or equal to 5
   years.
   Main outcome measures-For each study, the regression coefficient of IQ
   on lead, after adjustment for confounders when possible, was used to
   derive the estimated change in IQ for a specific doubling of either
   blood or tooth lead.
   Results-The five prospective studies with over 1100 children showed no
   association of cord blood lead or antenatal maternal blood lead with
   subsequent IQ. Blood lead at around age 2 had a small and significant
   inverse association with IQ, somewhat greater than that for mean blood
   lead over the preschool years. The 14 cross sectional studies of blood
   lead with 3499 children showed a significant inverse association
   overall, but showed more variation in their results and their ability to
   allow for confounders. The seven cross sectional studies of tooth lead
   with 2095 children were more consistent in finding an inverse
   association, although the estimated:magnitude was somewhat smaller.
   Overall synthesis of this evidence, including a meta-analysis, indicates
   that a typical doubling of body lead burden (from 10 to 20 mu g/dl (0.48
   to 0.97 mu mol/l) blood lead or from 5 to 10 mu g/g tooth lead) is
   associated with a mean deficit in full scale IQ of around 1-2 IQ points.
   Conclusion-While low level lead exposure may cause a small IQ deficit,
   other explanations need considering: are the published studies
   representative; is there inadequate allowance for confounders; are there
   selection biases in recruiting and following children; and do children
   of lower IQ adopt behaviour which makes them more prone to lead uptake
   (reverse causality)? Even if moderate increases in body lead burden
   adversely affect IQ, a threshold below which there is negligible
   influence cannot currently be determined. Because of these
   uncertainties, the degree of public health priority that should be
   devoted to detecting and reducing moderate increases in children's blood
   lead, compared with other important social detriments that impede
   children's development, needs careful consideration.}},
ISSN = {{0959-8138}},
Unique-ID = {{ISI:A1994PQ66200018}},
}

@article{ ISI:000269298600001,
Author = {Knol, Anne B. and de Hartog, Jeroen J. and Boogaard, Hanna and Slottje,
   Pauline and van der Sluijs, Jeroen P. and Lebret, Erik and Cassee,
   Flemming R. and Wardekker, Arjan and Ayres, Jon G. and Borm, Paul J. and
   Brunekreef, Bert and Donaldson, Kenneth and Forastiere, Francesco and
   Holgate, Stephen T. and Kreyling, Wolfgang G. and Nemery, Benoit and
   Pekkanen, Juha and Stone, Vicky and Wichmann, H-Erich and Hoek, Gerard},
Title = {{Expert elicitation on ultrafine particles: likelihood of health effects
   and causal pathways}},
Journal = {{PARTICLE AND FIBRE TOXICOLOGY}},
Year = {{2009}},
Volume = {{6}},
Month = {{JUL 24}},
Abstract = {{Background: Exposure to fine ambient particulate matter (PM) has
   consistently been associated with increased morbidity and mortality. The
   relationship between exposure to ultrafine particles (UFP) and health
   effects is less firmly established. If UFP cause health effects
   independently from coarser fractions, this could affect health impact
   assessment of air pollution, which would possibly lead to alternative
   policy options to be considered to reduce the disease burden of PM.
   Therefore, we organized an expert elicitation workshop to assess the
   evidence for a causal relationship between exposure to UFP and health
   endpoints.
   Methods: An expert elicitation on the health effects of ambient
   ultrafine particle exposure was carried out, focusing on: 1) the
   likelihood of causal relationships with key health endpoints, and 2) the
   likelihood of potential causal pathways for cardiac events. Based on a
   systematic peernomination procedure, fourteen European experts
   (epidemiologists, toxicologists and clinicians) were selected, of whom
   twelve attended. They were provided with a briefing book containing key
   literature. After a group discussion, individual expert judgments in the
   form of ratings of the likelihood of causal relationships and pathways
   were obtained using a confidence scheme adapted from the one used by the
   Intergovernmental Panel on Climate Change.
   Results: The likelihood of an independent causal relationship between
   increased short-term UFP exposure and increased all-cause mortality,
   hospital admissions for cardiovascular and respiratory diseases,
   aggravation of asthma symptoms and lung function decrements was rated
   medium to high by most experts. The likelihood for long-term UFP
   exposure to be causally related to all cause mortality, cardiovascular
   and respiratory morbidity and lung cancer was rated slightly lower,
   mostly medium. The experts rated the likelihood of each of the six
   identified possible causal pathways separately. Out of these six, the
   highest likelihood was rated for the pathway involving respiratory
   inflammation and subsequent thrombotic effects.
   Conclusion: The overall medium to high likelihood rating of causality of
   health effects of UFP exposure and the high likelihood rating of at
   least one of the proposed causal mechanisms explaining associations
   between UFP and cardiac events, stresses the importance of considering
   UFP in future health impact assessments of (transport-related) air
   pollution, and the need for further research on UFP exposure and health
   effects.}},
DOI = {{10.1186/1743-8977-6-19}},
Article-Number = {{19}},
ISSN = {{1743-8977}},
ResearcherID-Numbers = {{van der Sluijs, Jeroen/B-6302-2008
   Nemery, Benoit/D-1224-2013
   brunekreef, bert/}},
ORCID-Numbers = {{van der Sluijs, Jeroen/0000-0002-1346-5953
   brunekreef, bert/0000-0001-9908-0060}},
Unique-ID = {{ISI:000269298600001}},
}

@article{ ISI:000238889500009,
Author = {Bowers, Teresa S. and Beck, Barbara D.},
Title = {{What is the meaning of non-linear dose-response relationships between
   blood lead concentrations and IQ?}},
Journal = {{NEUROTOXICOLOGY}},
Year = {{2006}},
Volume = {{27}},
Number = {{4}},
Pages = {{520-524}},
Month = {{JUL}},
Abstract = {{Recent literature {[}e.g. Canfield RL, Henderson CR, Cory-Slechta DA,
   Cox C, Jusko TA, Lanphear BP Intellectual impairment in children with
   blood lead concentrations below 10 mg per deciliter. New Engl J Med
   2003;348(16):1517-1526; Lanphear BP, Hornung R, Khoury J, Yolton K,
   Baghurst P, Bellinger DC, Canfield RL, Dietrich KN, Bornschein R, Greene
   T, Rothenberg SJ, Needleman HL, Schnaas L, Wasserman G, Graziano J,
   Roberts R. Low-level environmental lead exposure and children's
   intellectual function: an international pooled analysis. Environ Health
   Perspect 2005; 113(7):894-899] has suggested the existence of a
   supra-linear dose-response relationship between environmental measures
   such as blood lead concentrations and IQ. This communication explores
   the mathematical requirements placed on such dose-response relationships
   when the environmental measure, or independent variable, is lognormally
   distributed and the effect, or dependent variable, is normally
   distributed. Results of the analyses show that a supra-linear slope is a
   required outcome of correlations between data distributions where one is
   lognormally distributed and the other is normally distributed. The
   analysis shows that caution should be taken in assigning biological
   significance to supra-linear dose-response relationships in these
   instances. Detailed analyses of such data sets should be conducted to
   determine if the magnitude of supra-linear slopes are more or less than
   mathematically required, and from there to consider biological
   significance. (c) 2006 Elsevier Inc. All rights reserved.}},
DOI = {{10.1016/j.neuro.2006.02.001}},
ISSN = {{0161-813X}},
Unique-ID = {{ISI:000238889500009}},
}

@article{ ISI:000250028100001,
Author = {Tainio, Marko and Tuomisto, Jouni T. and Hanninen, Otto and Ruuskanen,
   Juhani and Jantunen, Matti J. and Pekkanen, Juha},
Title = {{Parameter and model uncertainty in a life-table model for fine particles
   (PM(2.5)): a statistical modeling study}},
Journal = {{ENVIRONMENTAL HEALTH}},
Year = {{2007}},
Volume = {{6}},
Month = {{AUG 23}},
Abstract = {{Background: The estimation of health impacts involves often uncertain
   input variables and assumptions which have to be incorporated into the
   model structure. These uncertainties may have significant effects on the
   results obtained with model, and, thus, on decision making. Fine
   particles ( PM(2.5)) are believed to cause major health impacts, and,
   consequently, uncertainties in their health impact assessment have clear
   relevance to policy- making. We studied the effects of various uncertain
   input variables by building a life- table model for fine particles.
   Methods: Life- expectancy of the Helsinki metropolitan area population
   and the change in lifeexpectancy due to fine particle exposures were
   predicted using a life- table model. A number of parameter and model
   uncertainties were estimated. Sensitivity analysis for input variables
   was performed by calculating rank- order correlations between input and
   output variables. The studied model uncertainties were ( i) plausibility
   of mortality outcomes and ( ii) lag, and parameter uncertainties ( iii)
   exposure- response coefficients for different mortality outcomes, and (
   iv) exposure estimates for different age groups. The monetary value of
   the years- of- life- lost and the relative importance of the
   uncertainties related to monetary valuation were predicted to compare
   the relative importance of the monetary valuation on the health effect
   uncertainties.
   Results: The magnitude of the health effects costs depended mostly on
   discount rate, exposure-response coefficient, and plausibility of the
   cardiopulmonary mortality. Other mortality outcomes ( lung cancer, other
   non- accidental and infant mortality) and lag had only minor impact on
   the output. The results highlight the importance of the uncertainties
   associated with cardiopulmonary mortality in the fine particle impact
   assessment when compared with other uncertainties.
   Conclusion: When estimating life- expectancy, the estimates used for
   cardiopulmonary exposure-response coefficient, discount rate, and
   plausibility require careful assessment, while complicated lag estimates
   can be omitted without this having any major effect on the results.}},
DOI = {{10.1186/1476-069X-6-24}},
Article-Number = {{24}},
ISSN = {{1476-069X}},
ORCID-Numbers = {{Tainio, Marko/0000-0002-0973-2342}},
Unique-ID = {{ISI:000250028100001}},
}

@article{ ISI:000073530600009,
Author = {Russell, MW and Huse, DM and Drowns, S and Hamel, EC and Hartz, SC},
Title = {{Direct medical costs of coronary artery disease in the United States}},
Journal = {{AMERICAN JOURNAL OF CARDIOLOGY}},
Year = {{1998}},
Volume = {{81}},
Number = {{9}},
Pages = {{1110-1115}},
Month = {{MAY 1}},
Abstract = {{To generate current incidence-based estimates of the direct medical
   costs of coronary artery disease (CAD) in the United States, a Markov
   model of the economic costs of CAD-related medical care was developed.
   Risks of initial and subsequent CAD events (sudden CAD death,
   fatal/nonfatal acute myocardial infarction {[}AMI], unstable angina, and
   stable angina) were estimated using new Framingham Heart Study risk
   equations and population risk profiles derived from national survey
   data. Costs were assumed to be those related to treatment of initial and
   subsequent CAD events ({''}event-related{''}) and follow-up care
   ({''}nonevent-related{''}), respectively. Cost estimates were derived
   primarily from national public-use databases. First-year direct medical
   costs of treating CAD events are estimated to be \$17,532 for fatal AMI,
   \$15,540 for nonfatal AMI, \$2,569 for stable angina, \$12,058 for
   unstable angina, and \$713 for sudden CAD death. Nonevent-related direct
   costs of CAD treatment are estimated to be \$1,051 annually. The annual
   incidence of CAD in the United States is estimated at 616,900 cases,
   with first-year costs of treatment totaling \$5.54 billion. Five- and
   10-year cumulative costs in 1995 dollars for patients who are initially
   free of CAD are estimated at \$9.2 billion and \$16.5 billion,
   respectively; for all patients with CAD, these costs are estimated to be
   \$71.5 billion and \$126.6 billion, respectively. The direct medical
   costs of CAD create a large economic burden for the United States
   health-care system. (C) 1998 by Excerpta Medica, Inc.}},
DOI = {{10.1016/S0002-9149(98)00136-2}},
ISSN = {{0002-9149}},
Unique-ID = {{ISI:000073530600009}},
}

@article{ ISI:000262611100012,
Author = {Song, Howard K. and Diggs, Brian S. and Slater, Matthew S. and Guyton,
   Steven W. and Ungerleider, Ross M. and Welke, Karl F.},
Title = {{Improved quality and cost-effectiveness of coronary artery bypass
   grafting in the United States from 1988 to 2005}},
Journal = {{JOURNAL OF THORACIC AND CARDIOVASCULAR SURGERY}},
Year = {{2009}},
Volume = {{137}},
Number = {{1}},
Pages = {{65-69}},
Month = {{JAN}},
Abstract = {{Objective: This study was undertaken to assess the impact of increasing
   patient complexity and health care cost on coronary artery bypass
   grafting quality and cost-effectiveness in the United States over an 18-
   year period.
   Methods: A retrospective study was carried out utilizing the Nationwide
   Inpatient Sample to track the characteristics and outcomes of 5,549,700
   patients having isolated coronary artery bypass grafting in the United
   States from 1988 to 2005. Expected mortality, risk-adjusted mortality,
   and hospital charges were tracked over this period.
   Results: The prevalence of congestive heart failure, pulmonary disease,
   diabetes, and acute myocardial infarction increased significantly over
   the study period. Expected mortality increased from 2.57\% to 3.66\%,
   reflecting the increasing patient comorbidity burden (P<.0001). Despite
   this, coronary artery bypass grafting outcomes improved, leading to a
   decrease in risk-adjusted mortality from 6.20\% to 2.12\% (P<.0001).
   Furthermore, when hospital charges were corrected for medical care
   inflation, hospital charges declined significantly, from \$ 26,210 in
   1988 to \$ 19,196 in 2005 (1988 dollars, P<.0001).
   Conclusions: Coronary artery bypass grafting surgery is being performed
   on an increasingly complex, high-risk patient population in the United
   States. Despite this challenge, risk-adjusted operative mortality has
   progressively declined. Moreover, hospital charges for coronary artery
   bypass grafting in relation to other medical care services have been
   reduced. These findings reflect improved quality and cost-effectiveness
   of coronary artery bypass grafting in the United States. Ongoing efforts
   directed at quality improvement should address the risks associated with
   comorbidities that increasingly accompany the diagnosis of coronary
   artery disease in patients having coronary artery bypass grafting.}},
DOI = {{10.1016/j.jtcvs.2008.09.053}},
ISSN = {{0022-5223}},
ResearcherID-Numbers = {{Diggs, Brian/C-3568-2008}},
ORCID-Numbers = {{Diggs, Brian/0000-0003-3586-3757}},
Unique-ID = {{ISI:000262611100012}},
}

@article{ ISI:000288221800002,
Author = {Zaidi, Syed M. A. and Bikak, Abdul L. and Shaheryar, Ayesha and Imam,
   Syed H. and Khan, Javaid A.},
Title = {{Perceptions of anti-smoking messages amongst high school students in
   Pakistan}},
Journal = {{BMC PUBLIC HEALTH}},
Year = {{2011}},
Volume = {{11}},
Month = {{FEB 18}},
Abstract = {{Background: Surveys have provided evidence that tobacco use is widely
   prevalent amongst the youth in Pakistan. Several reviews have evaluated
   the effectiveness of various tobacco control programs, however, few have
   taken into account the perceptions of students themselves regarding
   these measures. The aim of this study was to determine the most
   effective anti-smoking messages that can be delivered to high-school
   students in Pakistan, based on their self-rated perceptions. It also
   aimed to assess the impact of pictorial/multi-media messages compared
   with written health warnings and to discover differences in perceptions
   of smokers to those of non-smokers to health warning messages.
   Methods: This study was carried out in five major cities of Pakistan in
   private English-medium schools. A presentation was delivered at each
   school that highlighted the well-established health consequences of
   smoking using both written health warnings and pictorial/multi-media
   health messages. Following the presentation, the participants filled out
   a graded questionnaire form, using which they rated the risk-factors and
   messages that they thought were most effective in stopping or preventing
   them from smoking. The Friedman test was used to rank responses to each
   of the questions in the form. The Wilcoxon Signed Rank test used to
   analyze the impact of pictorial/multi-media messages over written
   statements. The Mann Whitney U test was used to compare responses of
   smokers with those of non-smokers.
   Results: Picture of an oral cavity cancer, videos of a cancer patient
   using an electronic voice box and a patient on a ventilator, were
   perceived to be the most effective anti-smoking messages by students.
   Addiction, harming others through passive smoking and impact of smoking
   on disposable incomes were perceived to be less effective messages.
   Pictorial/multi-media messages were perceived to be more effective than
   written health warnings. Health warnings were perceived as less
   effective amongst smokers compared to non-smokers.
   Conclusion: Graphic pictorial/multi-media health warnings that depict
   cosmetic and functional distortions were perceived as effective
   anti-smoking messages by English-medium high school students in
   Pakistan. Smokers demonstrated greater resistance to health promotion
   messages compared with non-smokers. Targeted interventions for high
   school students may be beneficial.}},
DOI = {{10.1186/1471-2458-11-117}},
Article-Number = {{117}},
ISSN = {{1471-2458}},
Unique-ID = {{ISI:000288221800002}},
}

@article{ ISI:000241356000002,
Author = {Gandra, Shravanthi R. and Lawrence, Lesa W. and Parasuraman, Bhash M.
   and Darin, Robert M. and Sherman, Justin J. and Wall, Jerry L.},
Title = {{Total and component health care costs in a non-medicare HMO population
   of patients with and without type 2 diabetes and with and without
   macrovascular disease}},
Journal = {{JOURNAL OF MANAGED CARE PHARMACY}},
Year = {{2006}},
Volume = {{12}},
Number = {{7}},
Pages = {{546-554}},
Month = {{SEP}},
Abstract = {{BACKGROUND: Type 2 diabetes (T2DM) is one of the most prevalent and
   costly chronic conditions in the United States. Macrovascular disease
   (MVD) remains a common and costly comorbidity in T2DM. Understanding the
   impact of MVD on total health care costs in patients with T2DM is of
   great importance to managed care organizations (MCOs).
   OBJECTIVE: To examine from the perspective of an MCO the impact of MVD
   on health care costs in patients with T2DM and in a matched comparison
   group of patients without diabetes.
   METHODS: This study involved retrospective analysis of administrative
   claims (eligibility, pharmacy, and medical) using data from a commercial
   health maintenance organization population of approximately 700,000
   members in an East Coast health plan. Patients were included in this
   study if they (a) had 2 or more claims for T2DM (international
   Classification of Diseases, Ninth Revision, Clinical Modification
   {[}ICD-9-CM] codes 250.X0 or 250.X2), or (b) had a prescription drug
   claim for insulin and a diagnosis of T2DM, or (c) had at least I
   pharmacy claim for an oral glycemic-modifying agent during the 12-month
   period from January 1, 2003, through December 31, 2003. Patients with 2
   or more medical claims for type 1 diabetes (ICD-9-CM codes 25011 or
   25013) were excluded from the study. A random group of comparison
   patients without diabetes (ICD-9 code 250.xx) were matched on age group
   and sex. Study patients in these 2 groups were subdivided into 4 groups
   based on the presence of medical claims with diagnosis codes for MVD
   (acute myocardial infarction, other ischemic heart disease, coronary
   artery bypass surgery percutaneous transluminal angioplasty, congestive
   heart failure, cerebrovascular accident, peripheral vascular disease,
   cerebrovascular disease, and peripheral vascular disease). Direct
   medical costs were aggregated for 12 months after the index date for
   patients in all 4 groups. Bootstrapping technique was used to compare
   the health care costs between patients with T2DM and those without
   diabetes, stratified by MVD status.
   RESULTS: A total of 9,059 patients with T2DM were identified and were
   matched by age group and sex to a random group of patients without
   diabetes. MVD was present in 26.9\% (n = 2,441) of patients with T2DM
   versus 11.3\% (n = 1,027) of patients without diabetes. Patients with
   MVD and T2DM were, on average, a year younger than patients with MVD but
   without diabetes (54.55 vs. 55.55 years, P <0.001). Patients with T2DM
   but without MVD were nearly the same age as patients with neither
   diabetes nor MVD (50.44 vs. 50.59 years, P=0.092). The T2DM patients
   with MVD had average 12-month costs more than 3 times the costs for
   patients with T2DM but without medical claims with diagnosis codes for
   MVD-\$10,450 versus \$3,385, respectively. Pharmacy costs accounted for
   29.0\% and inpatient hospital costs accounted for 43.9\% of total
   medical costs in T2DM patients with MVD versus 55.0\% and 17.3\%,
   respectively, in T2DM patients without MVD. Patients with MVD diagnoses
   and T2DM had total average medical costs that were 1.7 times the total
   medical costs for MVD patients without T2DM-\$10,450 versus \$6,090,
   respectively.
   CONCLUSIONS: The results of this analysis suggest that MVD may triple
   the total medical care costs in patients with T2DM. These economic
   consequences would appear to support the importance of interventions
   intended to prevent macrovascular events in patients with T2DM.}},
ISSN = {{1083-4087}},
Unique-ID = {{ISI:000241356000002}},
}

@article{ ISI:000360185900010,
Author = {Orru, Hans and Lovenheim, Boel and Johansson, Christer and Forsberg,
   Bertil},
Title = {{Potential health impacts of changes in air pollution exposure associated
   with moving traffic into a road tunnel}},
Journal = {{JOURNAL OF EXPOSURE SCIENCE AND ENVIRONMENTAL EPIDEMIOLOGY}},
Year = {{2015}},
Volume = {{25}},
Number = {{5}},
Pages = {{524-531}},
Month = {{SEP-OCT}},
Abstract = {{A planned 21 km bypass (18 km within a tunnel) in Stockholm is expected
   to reduce ambient air exposure to traffic emissions, but same time
   tunnel users could be exposed to high concentrations of pollutants. For
   the health impacts calculations in 2030, the change in annual ambient
   NOX and PM10 exposure of the general population was modelled in 100 x
   100 m(2) grids for Greater Stockholm area. The tunnel exposure was
   estimated based on calculated annual average NOX concentrations, time
   spent in tunnel and number of tunnel users. For the general population,
   we estimate annually 23.7 (95\% Cl: 17.7-32.3) fewer premature deaths as
   ambient concentrations are reduced. At the same time, tunnel users will
   be exposed to NOX levels up to 2000 mu g/m(-3). Passing through the
   whole tunnel two times on working days would correspond to an additional
   annual NOX exposure of 9.6 mu g/m(3). Assuming that there will be
   similar to 55,000 vehicles daily each way and 1.3 persons of 30-74 years
   of age in each vehicle, we estimate the tunnel exposure to result in
   20.6 (95\% Cl: 14.1-25.6) premature deaths annually. If there were more
   persons per vehicle, or older and vulnerable people travelling, or
   tunnel dispersion conditions worsen, the adverse effect would become
   larger.}},
DOI = {{10.1038/jes.2015.24}},
ISSN = {{1559-0631}},
EISSN = {{1559-064X}},
Unique-ID = {{ISI:000360185900010}},
}

@article{ ISI:000074632000018,
Author = {Muls, E and Van Ganse, E and Closon, MC},
Title = {{Cost-effectiveness of pravastatin in secondary prevention of coronary
   heart disease: comparison between Belgium and the United States of a
   projected risk model}},
Journal = {{ATHEROSCLEROSIS}},
Year = {{1998}},
Volume = {{137}},
Number = {{S}},
Pages = {{S111-S116}},
Month = {{APR}},
Note = {{68th Meeting of the European-Atherosclerosis-Society (EAS), BRUGGE,
   BELGIUM, MAY 07-10, 1997}},
Organization = {{European Atherosclerosis Soc}},
Abstract = {{Methodological differences and variations in health care regulations
   among countries often preclude direct comparisons of cost-effectiveness
   studies. A projected risk model was applied, designed to determine the
   economic value in the United States of pravastatin in the secondary
   prevention of coronary heart disease (CHD), to Belgium using local
   health care costs. A Markov process was used to model the effectiveness
   of treatment for 3 years with pravastatin versus placebo in 1000 male
   CHD patients aged 60 years and clinically similar to those in the
   pravastatin limitation of atherosclerosis in the coronary arteries (PLAC
   I) and pravastatin, lipids and atherosclerosis in the carotid arteries
   (PLAC II) studies. The PLAC I and II trials have shown that pravastatin
   treatment for 3 years at a weighted mean dose of 36.64 mg daily
   significantly reduced the incidence of non-fatal myocardial infarction
   in patients with CHD. Framingham data were used to project the risk of
   mortality 10 years post-myocardial infarction. The incremental cost per
   life year gained (LYG), after discounting costs and benefits by 5\%
   annually, in the setting of Belgian health care regulations, was Belgian
   francs (BEF) 720 794 (US\$ 24 359) for CHD patients with one additional
   risk factor; BEF 526 464 (US\$ 17 792) for those with two additional
   risk factors; and BEF 392 765 (US\$ 13 274) for those with three or more
   additional risk factors. The cost per LYG in Belgium appeared to be more
   sensitive to drug acquisition cost than to costs of medical
   interventions. The cost-effectiveness ratios of pravastatin monotherapy
   for 3 years in secondary prevention of CHD, obtained with the same
   projected risk model, are from 86 to 92\% higher in Belgium than in the
   United States, due to differences in medical patterns of practice and in
   intervention costs. (C) 1998 Elsevier Science Ireland Ltd. All rights
   reserved.}},
DOI = {{10.1016/S0021-9150(97)00321-3}},
ISSN = {{0021-9150}},
EISSN = {{1879-1484}},
ResearcherID-Numbers = {{VAN GANSE, Eric/D-5876-2015}},
ORCID-Numbers = {{VAN GANSE, Eric/0000-0002-7463-9187}},
Unique-ID = {{ISI:000074632000018}},
}

@article{ ISI:000272247300020,
Author = {Genders, Tessa S. S. and Meijboom, W. Bob and Meijs, Matthijs F. L. and
   Schuijf, Joanne D. and Mollet, Nico R. and Weustink, Annick C. and
   Pugliese, Francesca and Bax, Jeroen J. and Cramer, Maarten J. and
   Krestin, Gabriel P. and de Feyter, Pim J. and Hunink, M. G. Myriam},
Title = {{CT Coronary Angiography in Patients Suspected of Having Coronary Artery
   Disease: Decision Making from Various Perspectives in the Face of
   Uncertainty}},
Journal = {{RADIOLOGY}},
Year = {{2009}},
Volume = {{253}},
Number = {{3}},
Pages = {{734-744}},
Month = {{DEC}},
Note = {{94th Scientific Assembly and Annual Meeting of the
   Radiological-Society-of-North-America, Chicago, IL, NOV 30-DEC 05, 2008}},
Organization = {{Radiol Soc N Amer}},
Abstract = {{Purpose: To determine the cost-effectiveness of computed tomographic
   (CT) coronary angiography as a triage test, performed prior to
   conventional coronary angiography, by using a Markov model.
   Materials and Methods: A Markov model was used to analyze the
   cost-effectiveness of CT coronary angiography performed as a triage test
   prior to conventional coronary angiography from the perspective of the
   patient, physician, hospital, health care system, and society by using
   recommendations from the United Kingdom, the United States, and the
   Netherlands for cost-effectiveness analyses. For CT coronary
   angiography, a range of sensitivities (79\%-100\%) and specificities
   (63\%-94\%) were used to help diagnose significant coronary artery
   disease (CAD). Optimization criteria (ie, outcomes considered) were:
   revised posttest probability of CAD, life-years, quality-adjusted
   life-years (QALYs), costs, and incremental cost-effectiveness ratios
   (ICERs). Extensive sensitivity analysis was performed.
   Results: For a prior probability of CAD of less than 40\%, the
   probability of CAD after CT coronary angiography with negative results
   was less than 1\%. The Markov model calculations from the
   patient/physician perspective suggest that CT coronary angiography
   maximizes life-years respectively in 60-year-old men and women at a
   prior probability of less than 38\% and 24\% and maximizes QALYs at a
   prior probability of less than 17\% and 11\%. From the hospital/health
   care perspective, CT coronary angiography helps reduce health care and
   direct nonhealth care-related costs (according to UK/U.S.
   recommendations), regardless of prior probability, and lowers all costs,
   including production losses (Netherlands recommendations) at a prior
   probability of less than 87\%-92\%. Analysis performed from a societal
   perspective by using a willingness-to-pay threshold level of (sic)80
   000/QALY suggests that CT coronary angiography is cost-effective when
   the prior probability is lower than 44\% and 37\% in men and women,
   respectively. Sensitivity analyses showed that results changed across
   the reported range of sensitivity of CT coronary angiography.
   Conclusion: The optimal diagnostic work-up depends on the optimization
   criterion, prior probability of CAD, and the diagnostic performance of
   CT coronary angiography. (C) RSNA, 2009}},
DOI = {{10.1148/radiol.2533090507}},
ISSN = {{0033-8419}},
Unique-ID = {{ISI:000272247300020}},
}

@article{ ISI:000249434300031,
Author = {Wichmann, H.-E.},
Title = {{Diesel exhaust particles}},
Journal = {{INHALATION TOXICOLOGY}},
Year = {{2007}},
Volume = {{19}},
Number = {{1}},
Pages = {{241-244}},
Note = {{10th International Inhalation Symposium, Hannover, GERMANY, MAY 31-JUN
   03, 2006}},
Organization = {{German Soc Toxicol; Fraunhofer Inst Toxicol \& Expt Med; Natl Hlth \&
   Environm Effects Res Lab; US EPA}},
Abstract = {{Diesel motor emission is a complex mixture of hundreds of constituents
   in either gas or particle form. Diesel particulate matter (DPM) is
   composed of a center core of elemental carbon and adsorbed organic
   compounds including PAHs and nitro-PAHs, and small amounts of sulfate,
   nitrate, metals, and other trace elements. DPM consists of fine
   particles including a high number of ultrafine particles. These
   particles are highly respirable and have a large surface area where
   organics can adsorb easily. Exposure to DPM can cause acute irritation
   and neurophysiological, respiratory, and asthma-like symptoms and can
   exacerbate allergenic responses to known allergens. Consistently, lung
   cancer risk is elevated among workers in occupations where diesel
   engines have been used. However, quantification of the cancer risk with
   respect to DPM concentrations is not possible. Furthermore, ambient fine
   and ultrafine particles, of which DPM is an important component,
   contribute to cardiopulmonary morbidity and mortality and lung cancer.
   In conclusion, diesel exhaust poses a cancer risk greater than that of
   any other air pollutant, as well as causing other short- and long-term
   health problems. One effective way to effectively reduce emission of DPM
   is the use of particle traps.}},
DOI = {{10.1080/08958370701498075}},
ISSN = {{0895-8378}},
Unique-ID = {{ISI:000249434300031}},
}

@article{ ISI:000079339800029,
Author = {Naglie, G and Tansey, C and Krahn, MD and O'Rourke, K and Detsky, AS and
   Bolley, H},
Title = {{Direct costs of coronary artery bypass grafting in patients aged 65
   years or more and those under age 65}},
Journal = {{CANADIAN MEDICAL ASSOCIATION JOURNAL}},
Year = {{1999}},
Volume = {{160}},
Number = {{6}},
Pages = {{805-811}},
Month = {{MAR 23}},
Abstract = {{Background: Over the past 20 years, there have been marked increases in
   rates of coronary artery bypass grafting (CABG) among older people in
   Canada. The objectives of this study were to accurately estimate the
   direct medical costs of CABG in older patients (age 65 years or more)
   and to compare CABG costs for this age group with those for patients
   less than 65 years of age.
   Methods: Direct medical costs were estimated from a sample of 205 older
   and 202 younger patients with triple-vessel or left main coronary artery
   disease who underwent isolated CABG at The Toronto Hospital, a tertiary
   care university-affiliated hospital, between Apr. 1, 1991, and Mar. 31,
   1992. Costs are expressed in 1992 Canadian dollars from a third-party
   payer perspective.
   Results: The mean costs of CABG in older and younger patients
   respectively were \$16500 and \$15600 for elective, uncomplicated cases,
   \$23200 and \$19200 for nonelective, uncomplicated cases, \$29200 and
   \$20300 for elective, complicated cases, and \$33600 and \$23700 for
   nonelective, complicated cases. Age remained a significant determinant
   of costs after adjustment for severity of heart disease and for
   comorbidity. Between 59\% and 91\% of the cost difference between older
   and younger patients was accounted for by higher intensive care unit and
   ward costs.
   Interpretation: CABG was more costly in older people, especially in
   complicated I cases, even after an attempt to adjust for severity of
   disease and comorbidity. Future studies should attempt to identify
   modifiable factors that contribute to longer intensive care and ward
   stays for older patients.}},
ISSN = {{0820-3946}},
Unique-ID = {{ISI:000079339800029}},
}

@article{ ISI:000242348400004,
Author = {Nutescu, Edith A.},
Title = {{Economic considerations in managing patients with chronic stable angina}},
Journal = {{JOURNAL OF MANAGED CARE PHARMACY}},
Year = {{2006}},
Volume = {{12}},
Number = {{8, S}},
Pages = {{S17-S21}},
Month = {{OCT}},
Note = {{18th Annual Meeting of the Academy-of-Managed-Care-Pharmacy, Seattle,
   WA, APR   06, 2006}},
Organization = {{Acad Managed Care Pharm}},
Abstract = {{OBJECTIVE: To quantify the economic burden of chronic stable angina in
   the United States, characterize recent trends in the use of coronary
   revascularization, and compare the clinical outcomes and long-term costs
   of percutaneous coronary intervention (PCI), coronary artery bypass
   grafting (CABG), and medical management in patients with stable angina.
   SUMMARY: The direct and indirect costs of stable angina are measured in
   tens of billions of dollars in the United States, with hospitalization
   contributing a large amount to the costs. The use of coronary
   revascularization, particularly PCI and insertion of coronary stents,
   has increased dramatically in recent years. The long-term costs of PCI
   and CABG are similar and high. Revascularization is sometimes used
   without an adequate trial of medical management, despite higher costs
   and a lack of evidence of long-term clinical benefits from
   revascularization.
   CONCLUSION: Chronic stable angina is a costly condition. Medical
   management should be used before considering costly revascularization,
   unless medical management is contraindicated.}},
ISSN = {{1083-4087}},
Unique-ID = {{ISI:000242348400004}},
}

@article{ ISI:000224910800004,
Author = {Javitz, HS and Ward, MM and Watson, JB and Jaana, M},
Title = {{Cost of illness of chronic angina}},
Journal = {{AMERICAN JOURNAL OF MANAGED CARE}},
Year = {{2004}},
Volume = {{10}},
Number = {{11, S}},
Pages = {{S358-S369}},
Month = {{OCT}},
Abstract = {{Background: Angina pectoris is one of the principal manifestations of
   coronary artery disease (CAD). Chronic angina is a debilitating
   condition that affects millions of people in the United States.
   Objective: The objective of the study is to estimate, from a societal
   perspective, the direct costs of chronic angina in the year 2000.
   Methods: Data on medical utilization related to chronic angina were
   extracted from National Center for Health Statistics public-use
   databases and from IMS databases on medications (nitrates,
   beta-blockers, and calcium channel blockers). National average Medicare
   reimbursement rates were used to estimate costs. We identified medical
   utilization related to chronic angina based on International
   Classification of Diseases, Ninth Revision (ICD-9) codes. When ICD-9
   codes that do not explicitly identify angina are used in medical
   databases, people with chronic angina may be coded as having CAD only.
   To address this, we developed upper- and lower-boundary estimates of the
   costs of chronic angina. The lower-boundary estimate is based on
   diagnoses that narrowly define the presence of chronic angina, and is
   termed ``narrowly defined chronic angina.{''} The upper-boundary
   estimate is based on diagnoses of CAD.
   Results: The lower boundary on the cost of chronic angina is the
   estimated direct medical cost of narrowly defined chronic angina (\$1.9
   billion when it is the first-listed diagnosis and \$8.9 billion when it
   is listed in any position). The upper boundary on the cost of chronic
   angina is the estimated total direct medical cost of CAD, which is \$33
   billion when it is the first-listed diagnosis and \$75 billion when it
   is listed in any position.
   Conclusion: These analyses capture the range of direct costs that might
   be attributed to the care of chronic angina in the United States for the
   year 2000. Some components of care were not available, and estimated
   costs will be significantly higher if private payer reimbursement rates
   are used.}},
ISSN = {{1088-0224}},
Unique-ID = {{ISI:000224910800004}},
}

@article{ ISI:A1992HN95200012,
Author = {SAMET, JM and HOWARD, CA and COULTAS, DB and SKIPPER, BJ},
Title = {{ACCULTURATION, EDUCATION, AND INCOME AS DETERMINANTS OF
   CIGARETTE-SMOKING IN NEW-MEXICO HISPANICS}},
Journal = {{CANCER EPIDEMIOLOGY BIOMARKERS \& PREVENTION}},
Year = {{1992}},
Volume = {{1}},
Number = {{3}},
Pages = {{235-240}},
Month = {{MAR-APR}},
Abstract = {{Surveys of cigarette smoking among Hispanics in the Southwest have shown
   a pattern of smoking distinct from that of non-Hispanic whites, but
   determinants of smoking by Hispanics remain inadequately characterized.
   We have assessed household income, education, and language preference as
   predictors of cigarette smoking in 1072 Hispanic adults residing in a
   community in New Mexico. Cigarette smoking status (never, former, or
   current smoker) varied strongly with educational attainment, showing the
   anticipated gradient of increasing smoking as level of education
   declined. In contrast, cigarette smoking status did not vary in a
   consistent pattern with reported language preference. A composite
   measure of socioeconomic status, combining education and household
   income, predicted continued smoking among ever smokers, whereas language
   preference had no effect. In males, the age at which subjects started to
   smoke increased significantly with increasing education; a similar trend
   in females did not reach statistical significance. Determinants of
   numbers of cigarettes smoked daily were not identified. The findings
   suggest that, as in other U.S. populations, Hispanics in the Southwest
   with lower education and less income should be targeted for smoking
   prevention and cessation.}},
ISSN = {{1055-9965}},
Unique-ID = {{ISI:A1992HN95200012}},
}

@article{ ISI:000227889700005,
Author = {Hay, JW and Sterling, KL},
Title = {{Cost effectiveness of treating low HDL-cholesterol in the primary
   prevention of coronary heart disease}},
Journal = {{PHARMACOECONOMICS}},
Year = {{2005}},
Volume = {{23}},
Number = {{2}},
Pages = {{133-141}},
Abstract = {{Background: A low serum level of high-density lipoprotein
   (HDL)-cholesterol is an independent risk factor for coronary heart
   disease (CHD). Fibrates, particularly gemfibrozil, have been shown to
   raise HDL-cholesterol levels and reduce the incidence of CHD. The
   literature on fibrate cost effectiveness is quite limited.
   Objective: The objective of this analysis is to determine the cost
   effectiveness of the fibrates gemfibrozil and fenofibrate in the primary
   prevention of CHD. The target population includes patients with low
   levels of HDL-cholesterol, but without pre-existing CHD or other CHD
   risk factors sufficiently elevated to indicate drug therapy.
   Study design and methods: From a societal perspective, a lifetime
   incremental cost-effectiveness model was developed to calculate baseline
   and treatment costs, life-years gained and QALYs gained. Model parameter
   values were taken from existing literature. In this `backward induction'
   model, the expected costs and outcomes for each 5-year time-interval are
   utilised in subsequent 5-year time period calculations over the
   patient's entire lifetime. The study population consisted of a
   hypothetical cohort of males and females in the US aged 45-74 years,
   with low levels of HDL-cholesterol and no prior history of CHD. The
   base-case CHD risk factors for this population were obtained from the
   VA-HIT (Veterans Affairs High-Density Lipoprotein Cholesterol
   Intervention Trial) population baseline characteristics, but assuming no
   prior CHD history. Estimates for the reduction in CHD risk associated
   with fibrate therapy reduction are also taken from the VA-HIT study.
   Results: Using a societal cost-effectiveness threshold of \$US50 000 per
   QALY, primary prevention of CHD in patients with low HDL-cholesterol
   levels using generic gemfibrozil therapy is cost effective for all age
   and sex categories, in contrast to fenofibrate therapy, which is cost
   effective for males, but not for females at baseline risks levels. In
   the base-case scenario, because of their higher CHD lifetime risk, it is
   more cost effective to treat males than females with either gemfibrozil
   or fenofibrate. For males and females the cost per QALY decreases with
   age for most age intervals. Gemfibrozil is more cost effective than
   fenofibrate for all age-sex categories because of the assumed equal
   efficacy and the higher fenofibrate drug cost. In the comparison
   scenario, generic lovastatin was more cost effective than gemfibrozil
   for men except at age 45 years and women at all ages, and more cost
   effective than fenofibrate for both men and women.
   Conclusions: This analysis suggests that fibrate therapy, particularly
   with generic. gemfibrozil, is cost effective in the primary prevention
   of CHD in individuals with low HDL-cholesterol levels, with or without
   elevated triglyceride levels. Certain patient subgroups, such as those
   with elevated triglyceride levels, smokers and those with diabetes
   mellitus are likely to achieve both CHD risk reduction and overall
   savings in net expected medical care costs. Comparable
   cost-effectiveness results are also shown for lovastatin therapy in the
   target patient population. Gemfibrozil dominates fenofibrate because of
   the lower cost of therapy (direct and indirect costs). These conclusions
   are robust to reasonable changes in model parameter values.}},
DOI = {{10.2165/00019053-200523020-00005}},
ISSN = {{1170-7690}},
Unique-ID = {{ISI:000227889700005}},
}

@article{ ISI:000271231200108,
Author = {Lekander, Ingrid and Borgstrom, Fredrik and Strom, Oskar and Zethraeus,
   Niklas and Kanis, John A.},
Title = {{Cost-Effectiveness of Hormone Therapy in the United States}},
Journal = {{JOURNAL OF WOMENS HEALTH}},
Year = {{2009}},
Volume = {{18}},
Number = {{10}},
Pages = {{1669-1677}},
Month = {{OCT}},
Abstract = {{Objective: To estimate the cost-effectiveness of 5 years of treatment
   with hormone therapy (HT) compared with no treatment for women with
   menopausal symptoms in the United States.
   Methods: A Markov cohort simulation model was used with tunnel
   techniques to assess the cost-effectiveness of HT in women aged 50
   years, based on a societal perspective. Clinical data, where possible,
   used results taken from the Women Health Initiative (WHI). The model had
   a lifetime horizon with cycle lengths of 1 year and contained the
   following disease states: hip fracture, vertebral fracture, wrist
   fracture, breast cancer, colorectal cancer, coronary heart disease,
   stroke, and venous thromboembolic events. An intervention was modelled
   by its impact on the disease risks during and after stopping treatment.
   The model required data on clinical effects, risks, mortality rates,
   quality of life weights, and costs. The main outcome of the model was
   cost per quality-adjusted life-year (QALY) gained on HT compared with no
   treatment.
   Results: The results indicated that it was cost-effective to treat women
   with menopausal symptoms with HT in the United States. The severity of
   menopausal symptoms was the single most important determinant of
   cost-effectiveness, but HT remained cost-effective even where symptoms
   were mild or effects on symptom relief were small.
   Conclusions: Treatment of women with menopausal symptoms with HT is
   cost-effective.}},
DOI = {{10.1089/jwh.2008.1246}},
ISSN = {{1540-9996}},
Unique-ID = {{ISI:000271231200108}},
}

@article{ ISI:000222098300003,
Author = {Sloss, EM and Wickstrom, SL and McCaffrey, DF and Garber, S and Rector,
   TS and Levin, RA and Guzy, PM and Gorelick, PB and Dake, MD and Vickrey,
   BG},
Title = {{Direct medical costs attributable to acute myocardial infarction and
   ischemic stroke in cohorts with atherosclerotic conditions}},
Journal = {{CEREBROVASCULAR DISEASES}},
Year = {{2004}},
Volume = {{18}},
Number = {{1}},
Pages = {{8-15}},
Abstract = {{Background: The cost of acute ischemic events in persons with
   established atherosclerotic conditions is unknown. Methods: The direct
   medical costs attributable to secondary acute myocardial infarction (
   AMI) or ischemic stroke among persons with established atherosclerotic
   conditions were estimated from 1995-1998 data on 1,143 patients enrolled
   in US managed care plans. Results: The average 180-day costs
   attributable to secondary AMI or stroke were estimated as USD 19,056 in
   the AMI cohort having a private insurance (commercial; n = 344), USD
   16,845 in the AMI cohort having government insurance ( Medicare, age 665
   years; n = 200), USD 10,267 for stroke commercial ( n = 108), USD 16,280
   for stroke Medicare ( n = 113), USD 15,224 for peripheral arterial
   disease commercial ( n = 170), and USD 15,182 for peripheral arterial
   disease Medicare ( n = 208). Conclusion: These estimates can be used to
   study the cost-effectiveness of interventions proven to reduce these
   secondary events. Copyright (C) 2004 S. Karger AG, Basel.}},
DOI = {{10.1159/000078602}},
ISSN = {{1015-9770}},
Unique-ID = {{ISI:000222098300003}},
}

@article{ ISI:000356766100001,
Author = {Song, Xue and Quek, Ruben G. W. and Gandra, Shravanthi R. and Cappell,
   Katherine A. and Fowler, Robert and Cong, Ze},
Title = {{Productivity loss and indirect costs associated with cardiovascular
   events and related clinical procedures}},
Journal = {{BMC HEALTH SERVICES RESEARCH}},
Year = {{2015}},
Volume = {{15}},
Month = {{JUN 25}},
Abstract = {{Background: The high acute costs of cardiovascular disease and acute
   cardiovascular events are well established, particularly in terms of
   direct medical costs. The costs associated with lost work productivity
   have been described in a broad sense, but little is known about
   workplace absenteeism or short term disability costs among high
   cardiovascular risk patients. The objective of this study was to
   quantify workplace absenteeism (WA) and short-term disability (STD)
   hours and costs associated with cardiovascular events and related
   clinical procedures (CVERP) in United States employees with high
   cardiovascular risk.
   Methods: Medical, WA and/or STD data from the Truven Health MarketScan
   (R) Research Databases were used to select full-time employees aged
   18-64 with hyperlipidemia during 2002-2011. Two cohorts (with and
   without CVERP) were created and screened for medical, drug, WA, and STD
   eligibility. The CVERP cohort was matched with a non-CVERP cohort using
   propensity score matching. Work loss hours and indirect costs were
   calculated for patients with and without CVERP and by CVERP type. Wages
   were based on the 2013 age-, gender-, and geographic region-adjusted
   wage rate from the United States Bureau of Labor Statistics.
   Results: A total of 5,808 WA-eligible, 21,006 STD-eligible, and 3,362
   combined WA and STD eligible patients with CVERP were well matched to
   patients without CVERP, creating three cohorts of patients with CVERP
   and three cohorts of patients without CVERP. Demographics were similar
   across cohorts (mean age 52.2-53.1 years, male 81.3-86.8 \%). During the
   first month of follow-up, patients with CVERP had more WA/STD-related
   hours lost compared with patients without CVERP (WA-eligible: 23.4 more
   hours, STD-eligible: 51.7 more hours, WA and STD-eligible: 56.3 more
   hours) (p < 0.001). Corresponding costs were \$683, \$895, and \$1,119
   higher, respectively (p < 0.001). Differences narrowed with longer
   follow-up. In the first month and year of follow-up, patients with
   coronary artery bypass graft experienced the highest WA/STD-related
   hours lost and costs compared with patients with other CVERP.
   Conclusions: CVERP were associated with substantial work loss and
   indirect costs. Prevention or reduction of CVERP could result in WA and
   STD-related cost savings for employers.}},
DOI = {{10.1186/s12913-015-0925-x}},
Article-Number = {{245}},
ISSN = {{1472-6963}},
Unique-ID = {{ISI:000356766100001}},
}

@article{ ISI:000341827200006,
Author = {Hochheiser, Louis I. and Juusola, Jessie L. and Monane, Mark and Ladapo,
   Joseph A.},
Title = {{Economic Utility of a Blood-Based Genomic Test for the Assessment of
   Patients with Symptoms Suggestive of Obstructive Coronary Artery Disease}},
Journal = {{POPULATION HEALTH MANAGEMENT}},
Year = {{2014}},
Volume = {{17}},
Number = {{5}},
Pages = {{287-296}},
Month = {{OCT}},
Abstract = {{Approximately 3 million patients with symptoms suggestive of obstructive
   coronary artery disease (CAD) present to primary care offices in the
   United States annually, resulting in approximately \$6.7 billion in
   cardiac workup costs. Despite wide application of existing diagnostic
   technologies, yield of obstructive CAD at invasive coronary angiography
   (ICA) is low. This study used a decision analysis model to assess the
   economic utility of a novel gene expression score (GES) for the
   diagnosis of obstructive CAD. Within a representative commercial health
   plan's adult membership, current practice for obstructive CAD diagnosis
   (usual care) was compared to a strategy that incorporates the GES test
   (GES-directed care). The model projected the number of diagnostic tests
   and procedures performed, the number of patients receiving medical
   therapy, type I and type II errors for each strategy of obstructive CAD
   diagnosis, and the associated costs over a 1-year time horizon. Results
   demonstrate that GES-directed care to exclude the diagnosis of
   obstructive CAD prior to myocardial perfusion imaging may yield savings
   to health plans relative to usual care by reducing utilization of
   noninvasive and invasive cardiac imaging procedures and increasing
   diagnostic yield at ICA. At a 50\% capture rate of eligible patients in
   GES-directed care, it is projected that a commercial health plan will
   realize savings of \$0.77 per member per month; savings increase
   proportionally to the GES capture rate. These findings illustrate the
   potential value of this new blood-based, molecular diagnostic test for
   health plans and patients in an age of greater emphasis on personalized
   medicine.}},
DOI = {{10.1089/pop.2013.0096}},
ISSN = {{1942-7891}},
EISSN = {{1942-7905}},
Unique-ID = {{ISI:000341827200006}},
}

@article{ ISI:000072833900036,
Author = {Goklaney, AK and Murphy, JD and Hillegass, WB},
Title = {{Abciximab therapy in percutaneous intervention: Economic issues in the
   United States}},
Journal = {{AMERICAN HEART JOURNAL}},
Year = {{1998}},
Volume = {{135}},
Number = {{4}},
Pages = {{S90-S97}},
Month = {{APR}},
Note = {{Meeting on Use of GP IIb/IIIa Inhibitors in Coronary Syndromes - State
   of the Art, DAVOS, SWITZERLAND, FEB 15-16, 1997}},
Organization = {{Eli Lilly \& Co, Indianapolis}},
Abstract = {{Whether abciximab therapy should be the standard of core during
   percutaneous intervention in the United States depends on its efficacy,
   safety, and economics. In view of the EPIC, CAPTURE, and EPILOG data,
   few question the superior efficacy and relative safety of abciximab
   compared with conventional high-dose heparin therapy during percutaneous
   intervention. Economic considerations have been the major issue limiting
   its use. Review of the economic data demonstrates that the incremental
   direct medical care cost of abciximab therapy is \$290 to \$600 per
   patient treated in the EPIC and EPILOG populations. In the patients with
   acute myocardial infarction and unstable angina, abciximab appears to
   reduce direct medical costs (produce cost savings) at 6 months. Given
   abciximab's significant incremental effectiveness, its relatively small
   incremental cost yielded a highly cost-effective therapy in the EPIC and
   EPILOG patient populations. Additional economic issues relate to
   minimizing bleeding complications, indirect costs, reduced frequency of
   emergency procedures, and rationalizing provider/payor policies and
   incentives to produce the optimal individual patient and societal
   outcomes. The currently available data concerning the efficacy, safety,
   and cost provide a compelling argument for embracing abciximab therapy
   in the treatment of patient subsets where it will be a cost-saving or
   cost-neutral adjunct to percutaneous coronary intervention. In other
   subsets, the direct medical cost will likely not be fully recouped, but
   the incremental cost-effectiveness will compare favorably to other
   widely accepted therapies.}},
DOI = {{10.1016/S0002-8703(98)70301-1}},
ISSN = {{0002-8703}},
Unique-ID = {{ISI:000072833900036}},
}

@article{ ISI:000073732200007,
Author = {Goklaney, AK and Murphy, JD and Hillegass, WB},
Title = {{Abciximab therapy in percutaneous intervention: Economic issues in the
   United States}},
Journal = {{EUROPEAN HEART JOURNAL}},
Year = {{1998}},
Volume = {{19}},
Number = {{D}},
Pages = {{D52-D58}},
Month = {{APR}},
Note = {{Meeting on Use of GP IIb/IIIa Inhibitors in Coronary Syndromes - State
   of the Art, DAVOS, SWITZERLAND, FEB 15-16, 1997}},
Organization = {{Eli Lilly \& Co, Indianapolis}},
Abstract = {{Whether abciximab therapy should be the standard of care during
   percutaneous intervention in the United States depends on its efficacy,
   safety, and economics. In view of the EPIC, CAPTURE, and EPILOG data,
   few question the superior efficacy and relative safety of abciximab
   compared with conventional high-dose heparin therapy during percutaneous
   intervention. Economic considerations have been the major issue limiting
   its use. Review of the economic data demonstrates that the incremental
   direct medical care cost of abciximab therapy is \$290 to \$600 per
   patient treated in the EPIC and EPILOG populations. In the patients with
   acute myocardial infarction and unstable angina, abciximab appears to
   reduce direct medical costs (pro duce cost savings) at 6 months. Given
   abciximab's significant incremental effectiveness, its relatively small
   incremental cost yielded a highly cost-effective therapy in the EPIC and
   EPILOG patient populations. Additional economic issues relate to
   minimizing bleeding complications, indirect costs, reduced frequency of
   emergency procedures, and rationalizing provider/payor policies and
   incentives to produce the optimal individual patient and societal
   outcomes. The currently available data concerning the efficacy, safety,
   and cost provide a compelling argument for embracing abciximab therapy
   in the treatment of patient subsets where it will be a cost-saving or
   cost-neutral adjunct to percutaneous coronary intervention. In other
   subsets, the direct medical cost will likely not be fully recouped, but
   the incremental cost-effectiveness will compare favorably to other
   widely accepted therapies.}},
ISSN = {{0195-668X}},
Unique-ID = {{ISI:000073732200007}},
}

@article{ ISI:000274446800009,
Author = {Berenson, Karina and Ogbonnaya, Augustina and Casciano, Roman and
   Makenbaeva, Dinara and Mozaffari, Essy and Lamerato, Lois and Corbelli,
   John},
Title = {{Economic consequences of ACS-related rehospitalizations in the US}},
Journal = {{CURRENT MEDICAL RESEARCH AND OPINION}},
Year = {{2010}},
Volume = {{26}},
Number = {{2}},
Pages = {{329-336}},
Month = {{FEB}},
Abstract = {{Objective:
   To examine economic consequences related to rehospitalization following
   initial acute coronary syndrome (ACS) treatment in United States managed
   care settings.
   Study design:
   Retrospective observational studies.
   Research design and methods:
   Retrospective observational studies were conducted on two managed care
   populations to examine medical encounter insurance claims and charges
   for ACS-related rehospitalizations following an index hospitalization
   for new onset ACS (2002-2007). All charges were adjusted to year 2007
   United States Dollars (USDs).
   Main outcome measures:
   The main outcomes for this study were the direct charges related to ACS
   rehospitalizations as captured in two separate medical encounter claims
   databases.
   Results:
   Of the 11,266 ACS patients identified for analysis in the health system
   plan, 3588 (32\%) had at least one ACS rehospitalization. Of the 97,177
   ACS patients enrolled in the nationally representative managed care
   database, 32,578 (34\%) had at least one ACS-related rehospitalization.
   Multivariate analyses demonstrated that coronary artery bypass graft
   (CABG) was the strongest predictor of increased charges during the
   recurrence in both populations (p<0.0001). When controlling for length
   of stay (LOS) in the model, CABG remained a significant predictor of
   increased charges, while percutaneous coronary intervention (PCI) and
   stent insertion became even stronger predictors of increased charges.
   Conclusions:
   The costs associated with ACS-related rehospitalizations in a real-world
   setting are high, even when controlling for known cost drivers such as
   length of stay.}},
DOI = {{10.1185/03007990903479331}},
ISSN = {{0300-7995}},
Unique-ID = {{ISI:000274446800009}},
}

@article{ ISI:000258482000044,
Author = {Kahn, Richard and Robertson, Rose Marie and Smith, Robert and Eddy,
   David},
Title = {{The impact of prevention on reducing the burden of cardiovascular
   disease}},
Journal = {{DIABETES CARE}},
Year = {{2008}},
Volume = {{31}},
Number = {{8}},
Pages = {{1686-1696}},
Month = {{AUG}},
Abstract = {{OBJECTIVE - Cardiovascular disease (CVD) is prevalent and expensive.
   While many interventions are recommended to prevent CVD, the potential
   effects of a comprehensive set of prevention activities on CVD
   morbidity, mortality, and costs have never been evaluated. We therefore
   determined the effects of I I nationally recommended prevention
   activities on CVD-related morbidity, mortality, and costs in the U.S.
   RESEARCH DESIGN AND METHODS - We used person-specific data from a
   representative sample of the U.S. population (National Health and
   Nutrition Education Survey IV) to determine the number and
   characteristics of adults aged 20-80 years in the U.S. today who are
   candidates for different prevention activities related to CVD. We used
   the Archimedes model to create a simulated population that matched the
   real U.S. population, person by person. We then used the model to
   simulate a series of clinical trials that examined the effects over the
   next 30 years of applying each prevention activity one by one, or
   altogether, to those who are candidates for the various activities and
   compared the health outcomes, quality of life, and direct medical costs
   to current levels of prevention and care. We did this under two sets of
   assumptions about performance and compliance: 100\% success for each
   activity and lower levels of success considered aggressive but still
   feasible.
   RESULTS - Approximately 78\% of adults aged 20-80 years alive today in
   the U.S. are candidates for at least one prevention activity. if
   everyone received the activities for which they are eligible, myocardial
   infarctions and strokes would be reduced by similar to 63\% and 31\%,
   respectively. If more feasible levels of performance are assumed,
   myocardial infarctions and strokes would be reduced similar to 36\% and
   20\%, respectively. Implementation of all prevention activities would
   add similar to 221 million life-years and 244 million quality-adjusted
   life-years to the U.S. adult population over the coming 30 years, or an
   average of 1.3 years of life expectancy for all adults. Of the specific
   prevention activities, the greatest benefits to the U.S. population come
   from providing aspirin to high-risk individuals, controlling
   pre-diabetes, weight reduction in obese individuals, lowering blood
   pressure in people with diabetes, and lowering LDL cholesterol in people
   with existing coronary artery disease (CAD). As currently delivered and
   at current prices, Most prevention activities are expensive when
   considering direct medical costs; smoking cessation is the only
   prevention strategy that is cost-saving over 30 years,
   CONCLUSIONS - Aggressive application of nationally recommended
   prevention activities could prevent a high proportion of the CAD events
   and strokes that are otherwise expected to occur in adults in the U.S.
   today. However, as they are currently delivered, most of the prevention
   activities will substantially increase costs. If preventive strategies
   are to achieve their full potential, ways must be found to reduce the
   costs and deliver prevention activities more efficiently.}},
DOI = {{10.2337/dc08-9022}},
ISSN = {{0149-5992}},
Unique-ID = {{ISI:000258482000044}},
}

@article{ ISI:000186228500003,
Author = {Evans, RW},
Title = {{Costs and insurance coverage associated with permanent mechanical
   cardiac assist/replacement devices in the United States}},
Journal = {{JOURNAL OF CARDIAC SURGERY}},
Year = {{2001}},
Volume = {{16}},
Number = {{4}},
Pages = {{280-293}},
Abstract = {{Each year over 50,000 persons in the United States could potentially
   benefit from some form of permanent cardiac replacement or assistance.
   Approximately 7000 of these persons get on the waiting list for a
   transplant, and 2300 are transplanted. About 2000 patients are
   reportedly exposed to a mechanical cardiac assist device, most often as
   a bridge to transplant. The majority of persons who might benefit from
   cardiac replacement are never referred for treatment and, thus, the
   number of deaths on the waiting list is a misleading indicator of access
   to transplantation and overall patient mortality. The total economic
   burden associated with coronary artery disease and congestive heart
   failure now exceeds \$140 billion each year, with approximately \$700
   million directly spent on heart transplant procedures alone. If a viable
   total artificial heart is devised to replace a failed heart, or a
   ventricular assist system to permanently assist a failing heart, direct
   aggregate expenditures alone are likely to be somewhere between \$5.4
   and \$24.0 billion annually. Based on individual patient care costs, as
   well as aggregate national expenditures, insurers will be reluctant to
   pay for the permanent use of such devices, even though cost is
   reportedly not a consideration in coverage decisions. Today, medical
   benefits and added value are concepts that will shape the coverage
   determination process, as will increasingly liberal policies regarding
   payment for treatment costs in relationship to clinical trials.
   Nonetheless, resource allocation and rationing decisions loom large as
   strange ``characters at play{''} on an international economic.
   stage,{''} while being ``directed{''} by worldwide health care needs.}},
DOI = {{10.1111/j.1540-8191.2001.tb00523.x}},
ISSN = {{0886-0440}},
Unique-ID = {{ISI:000186228500003}},
}

@article{ ISI:000182275100001,
Author = {O'Brien, JA and Patrick, AR and Caro, JJ},
Title = {{Cost of managing complications resulting from type 2 diabetes mellitus
   in Canada}},
Journal = {{BMC HEALTH SERVICES RESEARCH}},
Year = {{2003}},
Volume = {{3}},
Month = {{MAR 21}},
Abstract = {{Background: Decision makers need to have Canadian-specific cost
   information in order to develop an accurate picture of diabetes
   management. The objective of this study is to estimate direct medical
   costs of managing complications of diabetes. Complication costs were
   estimated by applying unit costs to typical resource use profiles. For
   each complication, the event costs refer to those associated with the
   acute episode and subsequent care in the first year. State costs are the
   annual costs of continued management. Data were obtained from many
   Canadian sources, including the Ontario Case Cost Project, physician and
   laboratory fee schedules, formularies, reports, and literature. All
   costs are expressed in 2000 Canadian dollars.
   Results: Major events (e.g., acute myocardial infarction: \$18,635 event
   cost; \$1,193 state cost), generate a greater financial burden than
   early stage complications (e.g., microalbuminuria: \$62 event cost; \$10
   state cost). Yet, complications that are initially relatively low in
   cost (e.g., microalbuminuria) can progress to more costly advanced
   stages (e.g., end-stage renal disease, \$63,045 state cost).
   Conclusions: Macrovascular and microvascular complication costs should
   be included in any economic analysis of diabetes. This paper provides
   Canadian-based cost information needed to inform critical decisions
   about spending limited health care dollars on emerging new therapies and
   public health initiatives.}},
DOI = {{10.1186/1472-6963-3-7}},
Article-Number = {{7}},
ISSN = {{1472-6963}},
Unique-ID = {{ISI:000182275100001}},
}

@article{ ISI:000341503900002,
Author = {Humphris, Gerry and Williams, Brian},
Title = {{Is disgust the driver behind the selection of images for UK tobacco
   packets?}},
Journal = {{HEALTH EDUCATION JOURNAL}},
Year = {{2014}},
Volume = {{73}},
Number = {{5}},
Pages = {{522-529}},
Month = {{SEP}},
Abstract = {{Objective: The use of pictorial warning labels on tobacco packets has
   gained almost universal international acceptance. In a public
   consultation exercise in 2006, the Department of Health in England,
   through a web-based answering system, asked people's preferences of 42
   images, asking which images might be effective to encourage tobacco
   cessation in smokers. On cursory inspection of the rank order of
   preference, a pattern appeared to suggest that effectiveness was
   associated with the level of disgust emotion generated; that is, the
   images rated the most likely to persuade smokers to quit tobacco
   consumption appeared revolting. The objective of this study was to
   confirm that disgust emotion generated by United Kingdom (UK) tobacco
   packet images was associated with the public's selection of possible
   effective images.
   Design: Three cross-sectional opinion surveys were conducted including
   students from medicine and psychology disciplines and a section of the
   public. In addition, a web opinion consultation database was made
   available for secondary analysis.
   Method: A total of 291 participants were involved in the three
   convenience surveys and 19,812 participants gave complete replies to the
   public consultation website. Each individual rated every image on a
   five-category rating scale ranging from `extremely disgusting' to `not
   disgusting'.
   Results: Significant correlations (ranging from 0.91 to 0.94) existed
   between the image rank order aggregated preference ratings from the
   original public consultation and the average final score of the disgust
   ratings for specific items for the three groups.
   Conclusion: The emotion of disgust may be a possible intervening
   variable to explain the initial reactions to health promotion materials
   and smoking cessation.}},
DOI = {{10.1177/0017896913496399}},
ISSN = {{0017-8969}},
EISSN = {{1748-8176}},
ResearcherID-Numbers = {{Williams, Brian/G-5736-2012}},
Unique-ID = {{ISI:000341503900002}},
}

@article{ ISI:000083629000002,
Author = {Balen, RM and Marra, CA and Zed, PJ and Cohen, M and Frighetto, L},
Title = {{Cost-effectiveness analysis of enoxaparin versus unfractionated heparin
   for acute coronary syndromes - A Canadian hospital perspective}},
Journal = {{PHARMACOECONOMICS}},
Year = {{1999}},
Volume = {{16}},
Number = {{5, 2}},
Pages = {{533-542}},
Month = {{NOV}},
Abstract = {{Objective: To determine the cost effectiveness of enoxaparin therapy
   versus unfractionated heparin (UFH) therapy for patients with unstable
   coronary artery disease from the perspective of a Canadian hospital.
   Design: A predictive decision analysis model using published clinical
   and economic evaluations and casts of medical care in Canada.
   Patients: A hypothetical cohort of patients presenting to hospital with
   unstable angina or non-Q-wave myocardial infarction as defined by the
   Efficacy and Safety of Subcutaneous Enoxaparin in Non-Q-Wave Coronary
   Events (ESSENCE) trial.
   Interventions: Two antithrombotic treatment strategies were compared:
   (i) enoxaparin 1 mg/kg subcutaneously every 12 hours, and (ii) UFH
   intravenous bolus and constant infusion adjusted to maintain a
   therapeutic activated partial thromboplastin time. Both treatment
   strategies included 100 to 325 mg of oral aspirin daily. Enoxaparin or
   UFH was continued for a minimum of 48 hours to a maximum of 8 days.
   Cumulative outcomes were considered up to 30 days after initial
   presentation to hospital.
   Results: At 30 days, 19.8\% of patients who received enoxaparin compared
   with 23.3\% of patients who received UFH reached one of the primary
   composite events. There was no difference in major bleeding between the
   2 treatment groups (6.5\% enoxaparin vs 6.8\% UFH). The average total
   direct medical cost per patient was \$Can848 with the enoxaparin
   strategy versus \$Can892 with the UFH strategy (1999 values). Therapy
   with enoxaparin was, therefore, considered to be the dominant strategy.
   Univariate sensitivity analysis indicated that the decision model was
   not robust to changes in the 30-day composite end-point, probability of
   recurrent angina, or base casts for treatment of recurrent angina or
   enoxaparin therapy.
   Conclusion: Enoxaparin is the dominant antithrombotic
   pharmacotherapeutic strategy for patients with unstable coronary artery
   disease.}},
DOI = {{10.2165/00019053-199916050-00009}},
ISSN = {{1170-7690}},
Unique-ID = {{ISI:000083629000002}},
}

@article{ ISI:000221957000006,
Author = {Rajaram, V and Pandhya, S and Patel, S and Meyer, PM and Goldin, M and
   Feinstein, MJM and Neems, R and Feinstein, SB},
Title = {{Role of surrogate markers in assessing patients with diabetes mellitus
   and the metabolic syndrome and in evaluating lipid-lowering therapy}},
Journal = {{AMERICAN JOURNAL OF CARDIOLOGY}},
Year = {{2004}},
Volume = {{93}},
Number = {{11, S}},
Pages = {{32C-48C}},
Month = {{JUN 3}},
Note = {{13th International Symposium on Atherosclerosis, KYOTO, JAPAN, SEP
   28-OCT 02, 2003}},
Abstract = {{Diabetes mellitus and the metabolic syndrome (MS) are reaching epidemic
   proportions in the United States, and cardiovascular disease continues
   to be the leading cause of death among patients with diabetes. A range
   of noninvasive screening tools may help reduce the morbidity and
   mortality of patients with diabetes because of early detection of
   subclinical cardiovascular disease and active monitoring of the
   effectiveness of therapy. Surrogate markers of subdinical disease
   include conventional and contrast-enhanced ultrasound imaging of carotid
   artery intima-media thickness (c-IMT), 2-dimensional echocardiography,
   coronary artery calcium imaging, cardiac magnetic resonance imaging,
   ankle-brachial indices, and brachial artery reactivity testing. Because
   these noninvasive imaging tools are relatively comfortable and entail
   relatively low risk to the patient, they are ideal for initial screening
   and for the repeated imaging that is required for monitoring the
   effectiveness of therapy. Moreover, when used in large numbers of
   patients with diabetes, prediabetes, and the MS, these imaging tools may
   be useful in developing and validating thresholds for the use of
   lipid-lowering therapy as well as clear therapeutic goals for this
   population. In addition, contrast-enhanced c-IMT scans now produce
   real-time images of the vasa vasorum and neovascularization of
   atherosclerotic plaque, potentially causing a paradigm shift in our view
   of the genesis of atherosclerosis and affecting treatment options for
   all populations. Thus, surrogate markers may not only help improve
   individual patient outcomes, they also may help direct scarce medical
   resources to maximize medical benefits, improve overall medical care,
   and minimize costs and untoward side effects. (C) 2004 by Excerpta
   Medica, Inc.}},
DOI = {{10.1016/j.amjcard.2004.02.004}},
ISSN = {{0002-9149}},
Unique-ID = {{ISI:000221957000006}},
}

@article{ ISI:000269229900002,
Author = {Allaqaband, Suhail and Kirvaitis, Romas and Jan, Fuad and Bajwa, Tanvir},
Title = {{Endovascular Treatment of Peripheral Vascular Disease}},
Journal = {{CURRENT PROBLEMS IN CARDIOLOGY}},
Year = {{2009}},
Volume = {{34}},
Number = {{9}},
Pages = {{359-476}},
Month = {{SEP}},
Abstract = {{Peripheral arterial disease (PAD) affects about 27 million people in
   North America and Europe, accounting for up to 413,000 hospitalizations
   per year with 88,000 hospitalizations involving the lower extremities
   and 28,000 involving embolectomy or thrombectomy of lower limb arteries.
   Many patients are asymptomatic and, among symptomatic patients, atypical
   symptoms are more common than classic claudication. Peripheral arterial
   disease also correlates strongly with risk of major cardiovascular
   events, and patients with PAD have a high prevalence of coexistent
   coronary and cerebrovascular disease. Because the prevalence of PAD
   increases progressively with age, PAD is a growing clinical problem due
   to the increasingly aged population in the United States and other
   developed countries. Until recently, vascular surgical procedures were
   the only alternative to medical therapy in such patients. Today,
   endovascular practice, percutaneous transluminal angioplasty with or
   without stenting, is used far more frequently for all types of lower
   extremity occlusive lesions, reflecting the continuing advances in
   imaging techniques, angioplasty equipment, and endovascular expertise.
   The role of endovascular intervention in the treatment of
   limb-threatening ischemia is also expanding, and its promise of limb
   salvage and symptom relief with reduced morbidity and mortality makes
   percutaneous; transluminal angioplasty/stenting an attractive
   alternative to surgery and, as most endovascular interventions are
   performed on an outpatient basis, hospital costs are cut considerably.
   In this monograph we discuss current endovascular intervention for
   treatment of occlusive PAD, aneurysmal arterial disease, and venous
   occlusive disease. (Curr Probl Cardiol 2009;34:359-476.)}},
DOI = {{10.1016/j.cpcardiol.2009.05.001}},
ISSN = {{0146-2806}},
Unique-ID = {{ISI:000269229900002}},
}

@article{ ISI:000088264000005,
Author = {Shaw, LJ and Miller, DD and Berman, DS and Hachamovitch, R},
Title = {{Clinical and economic outcomes assessment in nuclear cardiology}},
Journal = {{QUARTERLY JOURNAL OF NUCLEAR MEDICINE}},
Year = {{2000}},
Volume = {{44}},
Number = {{2}},
Pages = {{138-152}},
Month = {{JUN}},
Abstract = {{The future of nuclear medicine procedures, as understood within our
   current economic climate, depends upon its ability to provide relevant
   clinical information at similar or lower comparative costs. with an
   ever-increasing emphasis on cost containment, outcome assessment forms
   the basis of preserving the duality of patient cafe. Today, outcomes
   assessment encompasses a wide array of subjects including clinical
   economic, and humanistic (i.e., quality of life) outcomes. For nuclear
   cardiology evidence-based medicine mould require a threshold level of
   evidence in order to justify the added cost of any test in a patient's
   work-up. This evidence would include large multicenter, observational
   series as well as randomized trial data in sufficiently large and
   diverse patient populations. The nem movement in evidence-based medicine
   is also being applied to the introduction of new technologies, in
   particular when comparative modalities exist. In the past 5 years, me
   have seen a dramatic shift in the quality of outcomes data published in
   nuclear cardiology This includes the use of statistically rigorous
   risk-adjusted techniques as well as large populations (i.e., >500
   patients) representing multiple diverse medical care settings, This has
   been the direct result of the development of multiple outcomes databases
   that have now amassed thousands of patients worth of data. One of the
   benefits of examining outcomes in large patient datasets is the ability
   to assess individual endpoints (e.g., cardiac death) as compared with
   smaller datasets that often assess combined endpoints (e.g., death,
   myocardial infarction, or unstable angina), New technologies for the
   diagnosis of coronary artery disease have contributed to the rising
   costs of care. In the United States and in Europe, costs of care have
   risen dramatically, consuming an ever-increasing amount of available
   resources. The overuse of diagnostic angiography often leads to
   unnecessary revascularization that does not lead to improvement in
   outcome. Thus, the potential exists that stress SPECT imaging, a highly
   effective diagnostic tool, could effect substantial change in reducing
   inappropriate use of an invasive procedure resulting in cost effective
   cardiac care. A synthesis of current economic evidence in gated SPECT
   imaging will be presented In conclusion, a current state of the evidence
   review is presented on the clinical and economic data using nuclear
   cardiology imaging.}},
ISSN = {{0392-0208}},
Unique-ID = {{ISI:000088264000005}},
}

@article{ ISI:000179108300002,
Author = {Comay, D and Marshall, JK},
Title = {{Resource utilization for acute lower gastrointestinal hemorrhage: The
   Ontario GI Bleed Study}},
Journal = {{CANADIAN JOURNAL OF GASTROENTEROLOGY}},
Year = {{2002}},
Volume = {{16}},
Number = {{10}},
Pages = {{677-682}},
Month = {{OCT}},
Abstract = {{OBJECTIVES: Acute lower gastrointestinal hemorrhage (LGIH) is a common
   indication for hospitalization. However, there are few published studies
   of related health care resource utilization. Resource utilization,
   length of stay (LOS) and direct medical costs were characterized in a
   cohort of patients admitted for nonmalignant LGIH to centres in Ontario.
   METHODS: Consecutive admissions for LGIH were identified at four Ontario
   hospitals. Profiles of resource utilization, LOS and estimates of direct
   medical costs were compiled through detailed chart review and adaptation
   of an administrative database. All centres were participants in the
   Ontario Case Cost Project. Linear regression models of log-transformed
   data were constructed to identify demographic variables predictive of
   LOS and case cost.
   RESULTS: Among 124 patients enrolled (mean age 58.8 years) the average
   case cost was \$4,832 (SD \$7,187) for 7.5 days in hospital (SD 12.0).
   Diverticular disease was the bleeding source most often identified
   (34.6\%), followed by hemorrhoids (13.7\%) and ischemic colitis (9.7\%).
   Older age and comorbid illness, specifically coronary artery disease
   (CAD), were associated with both increased LOS and higher case cost in
   univariate regression analyses. Age persisted as the lone independent
   predictor of LOS in the multivariate model (P<0.05, R-2=0.076), and age
   and CAD were both independent predictors of cost (P<0.05, R-2=0.109) in
   a stepwise multiple linear regression analysis. Neither sex nor
   nonsteroidal anti-inflammatory drug use predicted LOS or cost.
   CONCLUSIONS: Admissions for acute LGIH are associated with significant
   resource utilization, particularly among elderly patients with CAD.}},
ISSN = {{0835-7900}},
Unique-ID = {{ISI:000179108300002}},
}

@article{ ISI:000273182400019,
Author = {Harrison, Kathleen McDavid and Song, Ruiguang and Zhang, Xinjian},
Title = {{Life Expectancy After HIV Diagnosis Based on National HIV Surveillance
   Data From 25 States, United States}},
Journal = {{JAIDS-JOURNAL OF ACQUIRED IMMUNE DEFICIENCY SYNDROMES}},
Year = {{2010}},
Volume = {{53}},
Number = {{1}},
Pages = {{124-130}},
Month = {{JAN 1}},
Abstract = {{Introduction: We estimate life expectancy and average years of life lost
   (AYLL) after an HIV diagnosis using population-based surveillance data
   from 25 states that have had name-based HIV surveillance since 1996.
   Methods: We used US national HIV surveillance data (cases >= 13 years
   old) to model life expectancy after an HIV diagnosis using the life
   table approach. We then compared life expectancy at HIV diagnosis with
   that in the general population of the same age, sex, and race/ethnicity
   in the same calendar year using vital statistics data to estimate the
   AYLL due to an HIV diagnosis.
   Results: Average life expectancy after HIV diagnosis increased from 10.5
   to 22.5 years from 1996 to 2005. Life expectancy (years) was better for
   females than for males but improved less for females (females: 12.6-23.6
   and males: 9.9-210). In 2005, life expectancy for black males was
   shortest, followed by Hispanic males and then white males. AYLL for
   cases diagnosed in 2005 was 21.1 years (males: 19.1 and females: 22.7)
   compared with 32.9 years in 1996.
   Conclusions: Disparity in life expectancy for females and both black and
   Hispanic males, compared with males and white males, respectively,
   persists and should be addressed.}},
ISSN = {{1525-4135}},
Unique-ID = {{ISI:000273182400019}},
}

@article{ ISI:000224910800003,
Author = {Reynolds, MW and Frame, D and Scheye, R and Rose, ME and George, S and
   Watson, JB and Hlatky, MA},
Title = {{A systematic review of the economic burden of chronic angina}},
Journal = {{AMERICAN JOURNAL OF MANAGED CARE}},
Year = {{2004}},
Volume = {{10}},
Number = {{11, S}},
Pages = {{S347-S357}},
Month = {{OCT}},
Abstract = {{Background: Chronic angina carries an economic burden because of symptom
   management, the risk of major cardiovascular events, and lost
   productivity. The level of these costs has not been systematically
   quantified.
   Objective: This study sought to assemble best evidence on the economic
   burden of chronic angina, including both the direct costs of healthcare
   and the indirect costs of lost productivity.
   Methods: Studies published in English from January 1990 to June 2003
   were located via electronic and manual searches and systematically
   reviewed. Eligible studies included those with information on cost of
   illness, cost of treatment, employment status, and/or work productivity
   and/or limitations for a population of patients with chronic angina.
   Results: Seventeen studies assessed the healthcare cost of managing
   chronic angina. Cost estimates varied widely because of differing
   patient populations, healthcare settings, countries of origin, and
   year(s) of data collection. The most critical determinant of healthcare
   costs appeared to be the use of revascularization procedures. Twenty
   studies reported work limitations, 5 of which quantified productivity
   loss in monetary terms. Interventions for chronic angina resulted in
   some improvement in employment and work limitations over the short term.
   However, the positive effect of revascularization procedures tended to
   erode over the long term (3 years and beyond) in a substantial number of
   patients.
   Conclusions: Chronic angina carries substantial healthcare costs caused
   by frequent medical visits, medications, and expensive revascularization
   procedures. Workplace productivity loss because of angina is also
   substantial, but lasting long-term improvement in work status has been
   difficult to achieve.}},
ISSN = {{1088-0224}},
Unique-ID = {{ISI:000224910800003}},
}

@article{ ISI:000361689800008,
Author = {Reisner, Sari L. and Conron, Kerith and Scout, Nfn and Mimiaga, Matthew
   J. and Haneuse, Sebastien and Austin, S. Bryn},
Title = {{Comparing In-Person and Online Survey Respondents in the US National
   Transgender Discrimination Survey: Implications for Transgender Health
   Research}},
Journal = {{LGBT HEALTH}},
Year = {{2014}},
Volume = {{1}},
Number = {{2}},
Pages = {{98-U119}},
Month = {{JUN}},
Abstract = {{Purpose: In the absence of probability sample studies of transgender
   people, new methods are needed to yield study samples that reflect the
   demographic diversity of the transgender population.
   Methods: The National Transgender Discrimination Survey is a large,
   convenience sample of 6,456 transgender adults between the ages of 18
   and 89. We examined characteristics of purposively sampled respondents
   who, in 2008, completed a one-time survey either in-person (435
   respondents) or online (6,021respondents). Missing data were multiply
   imputed, and multivariable logistic regression models were used to test
   for differences in sociodemographic and health indicators by data
   collection method.
   Results: A higher proportion of in-person respondents were young,
   male-to-female, people of color, publicly insured, with lower incomes
   and lower educational attainment than online respondents (all p < 0.05).
   In-person respondents also were more likely than online respondents to
   be current daily smokers, to endorse substance use to cope with
   mistreatment, and to self-report as HIV-positive (all p < 0.05).
   Conclusion: Findings indicate that online and in-person data collection
   methods reach transgender respondents with vastly different health and
   life experiences. To achieve a more diverse sample of transgender
   adults, then, requires diverse recruitment settings and survey
   modalities.}},
DOI = {{10.1089/lgbt.2013.0018}},
ISSN = {{2325-8292}},
EISSN = {{2325-8306}},
Unique-ID = {{ISI:000361689800008}},
}

@article{ ISI:000276847400002,
Author = {McCollum, Lauren and Pincus, Theodore},
Title = {{A Biopsychosocial Model to Complement a Biomedical Model: Patient
   Questionnaire Data and Socioeconomic Status Usually Are More Significant
   than Laboratory Tests and Imaging Studies in Prognosis of Rheumatoid
   Arthritis}},
Journal = {{RHEUMATIC DISEASE CLINICS OF NORTH AMERICA}},
Year = {{2009}},
Volume = {{35}},
Number = {{4}},
Pages = {{699+}},
Month = {{NOV}},
Abstract = {{Modern medical care is based largely on a paradigm known as a
   ``biomedical model,{''} in which a single ``gold standard{''}
   high-technology test guides clinical care. Patients with hypertension,
   diabetes, osteoporosis, and many other conditions often are unaware of
   their status in the absence of data from ``objective{''} tests. By
   contrast, in rheumatoid arthritis (RA) and most rheumatic diseases,
   patients generally are aware of symptoms, and information from patients
   often is as or more important to taking direct clinical decisions than
   laboratory tests, imaging studies, or even physical examination data.
   Physical function on a patient self-report questionnaire generally is as
   significant as, or more significant than laboratory, imaging, or
   physical examination data in predicting severe outcomes of RA, such as
   work disability, costs, and mortality. Patient questionnaires may be
   viewed as contributing to a complementary ``biopsychosocial model{''}
   that can overcome limitations of the traditional ``biomedical model{''}
   in RA and other chronic diseases. Further relevance of a
   ``biopsychosocial model{''} in RA and other rheumatic diseases is seen
   in evidence that socioeconomic status, most easily assessed as formal
   education level, identifies favorable or unfavorable clinical status and
   prognosis at high levels of significance. Socioeconomic status may be
   regarded as a surrogate for the importance of patient actions, in
   addition to actions of health professionals, in the course and outcomes
   of rheumatic and other chronic diseases.}},
DOI = {{10.1016/j.rdc.2009.10.003}},
ISSN = {{0889-857X}},
Unique-ID = {{ISI:000276847400002}},
}

@article{ ISI:000276311600014,
Author = {Danaei, Goodarz and Rimm, Eric B. and Oza, Shefali and Kulkarni, Sandeep
   C. and Murray, Christopher J. L. and Ezzati, Majid},
Title = {{The Promise of Prevention: The Effects of Four Preventable Risk Factors
   on National Life Expectancy and Life Expectancy Disparities by Race and
   County in the United States}},
Journal = {{PLOS MEDICINE}},
Year = {{2010}},
Volume = {{7}},
Number = {{3}},
Month = {{MAR}},
Abstract = {{Background: There has been substantial research on psychosocial and
   health care determinants of health disparities in the United States (US)
   but less on the role of modifiable risk factors. We estimated the
   effects of smoking, high blood pressure, elevated blood glucose, and
   adiposity on national life expectancy and on disparities in life
   expectancy and disease-specific mortality among eight subgroups of the
   US population (the ``Eight Americas{''}) defined on the basis of race
   and the location and socioeconomic characteristics of county of
   residence, in 2005.
   Methods and Findings: We combined data from the National Health and
   Nutrition Examination Survey and the Behavioral Risk Factor Surveillance
   System to estimate unbiased risk factor levels for the Eight Americas.
   We used data from the National Center for Health Statistics to estimate
   age-sex-disease-specific number of deaths in 2005. We used systematic
   reviews and meta-analyses of epidemiologic studies to obtain risk factor
   effect sizes for disease-specific mortality. We used epidemiologic
   methods for multiple risk factors to estimate the effects of current
   exposure to these risk factors on death rates, and life table methods to
   estimate effects on life expectancy. Asians had the lowest mean body
   mass index, fasting plasma glucose, and smoking; whites had the lowest
   systolic blood pressure (SBP). SBP was highest in blacks, especially in
   the rural South-5-7 mmHg higher than whites. The other three risk
   factors were highest in Western Native Americans, Southern low-income
   rural blacks, and/or low-income whites in Appalachia and the Mississippi
   Valley. Nationally, these four risk factors reduced life expectancy at
   birth in 2005 by an estimated 4.9 y in men and 4.1 y in women. Life
   expectancy effects were smallest in Asians (M, 4.1 y; F, 3.6 y) and
   largest in Southern rural blacks (M, 6.7 y; F, 5.7 y). Standard
   deviation of life expectancies in the Eight Americas would decline by
   0.50 y (18\%) in men and 0.45 y (21\%) in women if these risks had been
   reduced to optimal levels. Disparities in the probabilities of dying
   from cardiovascular diseases and diabetes at different ages would
   decline by 69\%-80\%; the corresponding reduction for probabilities of
   dying from cancers would be 29\%-50\%. Individually, smoking and high
   blood pressure had the largest effect on life expectancy disparities.
   Conclusions: Disparities in smoking, blood pressure, blood glucose, and
   adiposity explain a significant proportion of disparities in mortality
   from cardiovascular diseases and cancers, and some of the life
   expectancy disparities in the US.}},
DOI = {{10.1371/journal.pmed.1000248}},
Article-Number = {{e1000248}},
ISSN = {{1549-1277}},
Unique-ID = {{ISI:000276311600014}},
}

@article{ ISI:000318751300011,
Author = {Liu, Pang-Hsiang and Wang, Jung-Der and Keating, Nancy L.},
Title = {{Expected years of life lost for six potentially preventable cancers in
   the United States}},
Journal = {{PREVENTIVE MEDICINE}},
Year = {{2013}},
Volume = {{56}},
Number = {{5}},
Pages = {{309-313}},
Month = {{MAY}},
Abstract = {{Objective. This study aimed to quantify the reduced life expectancy for
   six types of potentially preventable cancer in the United States.
   Methods. A total of 1,579,310 patients diagnosed with cancers of the
   lung, colon and rectum, liver, breast, cervix, or prostate in 1992-2005
   were identified from the Surveillance, Epidemiology, and End Results
   registries. The lifetime survival functions for the cancer cohort and
   age-/sex-matched reference population were generated using a
   semiparametric extrapolation method with annual life tables. The average
   expected years of life lost (EYLL) for cancers were calculated by
   subtracting the estimated life expectancy of the cancer cohorts from
   that of the reference population.
   Results. Liver cancer and lung cancer had an average EYLL of over 13
   years, while the EYLL for prostate cancer was below 2 years. When
   considering the annual incidence in 2012, lung cancer would cause the
   greatest subtotal of EYLL (3,116,000 years) followed by female breast
   cancer (1,420,000 years) and colorectal cancer (932,000 years).
   Conclusion. The potential life years saved by successful prevention, in
   terms of EYLL since diagnosis, would be substantial for lung cancer,
   breast cancer, and colorectal cancer. This work will inform
   prioritization of strategies for cancer control to minimize the life
   expectancy loss. (C) 2013 Elsevier Inc. All rights reserved.}},
DOI = {{10.1016/j.ypmed.2013.02.003}},
ISSN = {{0091-7435}},
ResearcherID-Numbers = {{Liu, Michael Pang-Hsiang/B-9903-2015}},
ORCID-Numbers = {{Liu, Michael Pang-Hsiang/0000-0001-8842-2264}},
Unique-ID = {{ISI:000318751300011}},
}

@article{ ISI:000313253100012,
Author = {Cai, Liming},
Title = {{The Cost of an Additional Disability-Free Life Year for Older Americans:
   1992-2005}},
Journal = {{HEALTH SERVICES RESEARCH}},
Year = {{2013}},
Volume = {{48}},
Number = {{1}},
Pages = {{218-235}},
Month = {{FEB}},
Abstract = {{Objective To estimate the cost of an additional disability-free life
   year for older Americans in 19922005. Data Source This study used
   19922005 Medicare Current Beneficiary Survey, a longitudinal survey of
   Medicare beneficiaries with a rotating panel design. Study Design This
   analysis used multistate life table model to estimate probabilities of
   transition among a discrete set of health states (nondisabled, disabled,
   and dead) for two panels of older Americans in 1992 and 2002. Health
   spending incurred between annual health interviews was estimated by a
   generalized linear mixed model. Health status, including death, was
   simulated for each member of the panel using these transition
   probabilities; the associated health spending was cross-walked to the
   simulated health changes. Principal Findings Disability-free life
   expectancy (DFLE) increased significantly more than life expectancy
   during the study period. Assuming that 50 percent of the gains in DFLE
   between 1992 and 2005 were attributable to increases in spending, the
   average discounted cost per additional disability-free life year was
   \$71,000. There were small differences between gender and racial/ethnic
   groups. Conclusions The cost of an additional disability-free life year
   was substantially below previous estimates based on mortality trends
   alone.}},
DOI = {{10.1111/j.1475-6773.2012.01432.x}},
ISSN = {{0017-9124}},
Unique-ID = {{ISI:000313253100012}},
}

@article{ ISI:000266392900027,
Author = {Schleich, Joachim},
Title = {{Barriers to energy efficiency: A comparison across the German commercial
   and services sector}},
Journal = {{ECOLOGICAL ECONOMICS}},
Year = {{2009}},
Volume = {{68}},
Number = {{7}},
Pages = {{2150-2159}},
Month = {{MAY 15}},
Abstract = {{Based on a large sample for the German commercial and services sector,
   this paper econometrically assesses the relevance of various types of
   barriers to energy efficiency at the sectoral level and across fifteen
   subsectors. The results at the level of entire sectors suggest that the
   lack of information about energy consumption patterns and about energy
   efficiency measures, lack of staff time, priority setting within
   organizations, and - in particular - the investor/user dilemma are all
   relevant barriers. Allowing for sector-specific differences in the
   relevance of these individual barriers yields a more heterogeneous
   picture. The numbers and types of relevant barriers vary across
   sub-sectors, and the majority of sub-sectors are subject to relatively
   few barriers. The statistically most significant barriers are found for
   the sub-sector of public administrations. These findings are robust,
   independent of whether the definition of an organization's energy
   efficiency performance includes only measures that have actually been
   realized or also those that are being planned. For planned projects.
   however. organizations appear to underestimate internal priority setting
   as a barrier to energy efficiency. (C) 2009 Elsevier B.V. All rights
   reserved.}},
DOI = {{10.1016/j.ecolecon.2009.02.008}},
ISSN = {{0921-8009}},
Unique-ID = {{ISI:000266392900027}},
}

@article{ ISI:000258042800030,
Author = {Hogg, Robert and Lima, Viviane and Sterne, Jonathan A. C. and Grabar,
   Sophie and Battegay, Manuel and Bonarek, Mojgan and Monforte, Antonella
   D'Arminio and Esteve, Anna and Gill, M. John and Harris, Ross and
   Justice, Amy and Hayden, Anna and Lampe, Fiona and Mocroft, Amanda and
   Mugavero, Michael J. and Staszewski, Schlomo and Wasmuth, Jan-Christian
   and van Sighem, Ard and Kitahata, Mari and Guest, Jodie and Egger,
   Matthias and May, Margaret and Antiretroviral Therapy Cohort Coll},
Title = {{Life expectancy of individuals on combination antiretroviral therapy in
   high-income countries: a collaborative analysis of 14 cohort studies}},
Journal = {{LANCET}},
Year = {{2008}},
Volume = {{372}},
Number = {{9635}},
Pages = {{293-299}},
Month = {{JUL-AUG}},
Abstract = {{Background Combination antiretroviral therapy has led to significant
   increases in survival and quality of life, but at a population-level the
   effect on life expectancy is not well understood. Our objective was to
   compare changes in mortality and life expectancy among HIV-positive
   individuals on combination antiretroviral therapy.
   Methods The Antiretroviral Therapy Cohort Collaboration is a
   multinational collaboration of HIV cohort studies in Europe and North
   America. Patients were included in this analysis if they were aged 16
   years or over and antiretroviral-naive when initiating combination
   therapy. We constructed abridged life tables to estimate life
   expectancies for individuals on combination antiretroviral therapy in
   1996-99, 2000-02, and 2003-05, and stratified by sex, baseline CD4 cell
   count, and history of injecting drug use. The average number of years
   remaining to be lived by those treated with combination antiretroviral
   therapy at 20 and 35 years of age was estimated. Potential years of life
   lost from 20 to 64 years of age and crude mortality rates were also
   calculated.
   Findings 18 587, 13 914, and 10 854 eligible patients initiated
   combination antiretroviral therapy in 1996-99, 2000-02, and 2003-05,
   respectively. 2056 (4.7\%) deaths were observed during the study period,
   with crude mortality rates decreasing from 16.3 deaths per 1000
   person-years in 1996-99 to 10 . 0 deaths per 1000 person-years in
   2003-05. Potential years of life lost per 1000 person-years also
   decreased over the same time, from 366 to 189 years. Life expectancy at
   age 20 years increased from 36. 1 (S E 0 . 6) years to 49.4 (0.5) years.
   Women had higher life expectancies than did men. Patients with presumed
   transmission via injecting drug use had lower life expectancies than did
   those from other transmission groups (32.6 {[}1. 1] years vs 44.7
   {[}0.3] years in 2003-05). Life expectancy was lower in patients with
   lower baseline CD4 cell counts than in those with higher baseline counts
   (32.4 {[}1. 1] years for CD4 cell counts below 100 cells per mu L vs
   50.4 {[}0.4] years for counts of 200 cells per mu L or more).
   Interpretation life expectancy in HIV-infected patients treated with
   combination antiretroviral therapy increased between 1996 and 2005,
   although there is considerable variability between subgroups of
   patients. The average number of years remaining to be lived at age 20
   years was about two-thirds of that in the general population in these
   countries.
   Funding UK Medical Research Council, GlaxoSmithKIine.}},
ISSN = {{0140-6736}},
ResearcherID-Numbers = {{Mocroft, Amanda/C-1527-2008
   Mocroft, Amanda/G-8748-2011
   Hogg, Robert/B-2783-2012
   SHCS, all/G-4072-2011
   SHCS, int. coll. A/G-4083-2011}},
Unique-ID = {{ISI:000258042800030}},
}

@article{ ISI:000329859200001,
Author = {Singh, Gopal K. and Siahpush, Mohammad},
Title = {{Widening Rural-Urban Disparities in Life Expectancy, US, 1969-2009}},
Journal = {{AMERICAN JOURNAL OF PREVENTIVE MEDICINE}},
Year = {{2014}},
Volume = {{46}},
Number = {{2}},
Pages = {{E19-E29}},
Month = {{FEB}},
Abstract = {{Background: There is limited research on rural-urban disparities in U.
   S. life expectancy.
   Purpose: This study examined trends in rural-urban disparities in life
   expectancy at birth in the U.S. between 1969 and 2009.
   Methods: The 1969-2009 U.S. county-level mortality data linked to a
   rural-urban continuum measure were analyzed. Life expectancies were
   calculated by age, gender, and race for 3-year time periods between 1969
   and 2004 and for 2005-2009 using standard life-table methodology.
   Differences in life expectancy were decomposed by age and cause of
   death.
   Results: Life expectancy was inversely related to levels of rurality. In
   2005-2009, those in large metropolitan areas had a life expectancy of
   79.1 years, compared with 76.9 years in small urban towns and 76.7 years
   in rural areas. When stratified by gender, race, and income, life
   expectancy ranged from 67.7 years among poor black men in
   nonmetropolitan areas to 89.6 among poor Asian/ Pacific Islander women
   in metropolitan areas. Rural-urban disparities widened over time. In
   19691971, life expectancy was 0.4 years longer in metropolitan than in
   nonmetropolitan areas (70.9 vs 70.5 years). By 2005-2009, the life
   expectancy difference had increased to 2.0 years (78.8 vs 76.8 years).
   The rural poor and rural blacks currently experience survival
   probabilities that urban rich and urban whites enjoyed 4 decades
   earlier. Causes of death contributing most to the increasing rural-urban
   disparity and lower life expectancy in rural areas include heart
   disease, unintentional injuries, COPD, lung cancer, stroke, suicide, and
   diabetes.
   Conclusions: Between 1969 and 2009, residents in metropolitan areas
   experienced larger gains in life expectancy than those in
   nonmetropolitan areas, contributing to the widening gap.}},
DOI = {{10.1016/j.amepre.2013.10.017}},
ISSN = {{0749-3797}},
EISSN = {{1873-2607}},
Unique-ID = {{ISI:000329859200001}},
}

@article{ ISI:000234033500011,
Author = {Minicuci, N and Noale, A and ILSA grp},
Title = {{Influence of level of education on disability free life expectancy by
   sex: the ILSA study}},
Journal = {{EXPERIMENTAL GERONTOLOGY}},
Year = {{2005}},
Volume = {{40}},
Number = {{12}},
Pages = {{997-1003}},
Month = {{DEC}},
Abstract = {{Purpose: To assess the effect of education on Disability Free Life
   Expectancy among older Italians, using a hierarchical model as indicator
   of disability, with estimates based on the multistate life table method
   and IMaCh software.
   Methods: Data were obtained from the Italian Longitudinal Study on Aging
   which considered a random sample of 5632 individuals.
   Results: Total life expectancy ranged from 16.5 years for men aged 65
   years to 6 years for men aged 80. The age range for women was 19.6 and
   8.4 years, respectively. For both sexes, increasing age was associated
   with a lower probability of recovery from a mild state of disability,
   with a greater probability of worsening for all individuals presenting
   an independent state at baseline, and with a greater probability of
   dying except for women from a mild state of disability. A medium/high
   educational level was associated with a greater probability of recovery
   only in men with a mild state of disability at baseline, and with a
   lower probability of worsening in both sexes, except for men with a mild
   state of disability at baseline.
   Discussion: The positive effects of high education are well established
   in most research work and, being a modifiable factor, strategies focused
   on increasing level of education and, hence strengthening access to
   information and use of health services would produce significant
   benefits. (c) 2005 Elsevier Inc. All rights reserved.}},
DOI = {{10.1016/j.exger.2005.08.011}},
ISSN = {{0531-5565}},
Unique-ID = {{ISI:000234033500011}},
}

@inproceedings{ ISI:000301970600014,
Author = {Tavoni, Alessandro and Telesca, Luigi},
Editor = {{Telesca, L and StanoevskaSlabeva, K and Rakocevic, V}},
Title = {{The Wisdom of Sustainable Communities in the Digital Era: The Case of
   Efficient Energy Management}},
Booktitle = {{DIGITAL BUSINESS}},
Series = {{Lecture Notes of the Institute for Computer Sciences Social Informatics
   and Telecommunications Engineering}},
Year = {{2009}},
Volume = {{21}},
Pages = {{119-129}},
Note = {{1st International ICST Conference on Digital Business (DigiBiz 2009),
   City Univ London, London, ENGLAND, JUN 17-19, 2009}},
Abstract = {{Wise management of natural resources has become a fundamental challenge
   nowadays. Cooperative approaches are needed in order to provide a
   sustainable framework for stimulating the individual awareness and
   participation towards common environmental objectives. In order to reach
   mutually beneficial outcomes, public administrations, companies,
   individuals and communities will need to organize for managing their
   aggregated consumption, reducing unnecessary use of scarce resources.
   This is especially true in the field of energy management where the
   bounded nature of the resources and the behavioural impact of the
   stakeholders on the overall system both play a fundamental role. The
   proposed research aims at contributing to what remains a challenging
   issue across disciplines: explaining the evolution of cooperation among
   unrelated individuals in human societies. We utilize an evolutionary
   game theoretic modelling framework to identify conditions under which
   collaboration among energy end-users mediated by information and
   communication technologies (ICT) will support its sustainable
   exploitation.}},
ISSN = {{1867-8211}},
ISBN = {{978-3-642-11531-8}},
Unique-ID = {{ISI:000301970600014}},
}

@article{ ISI:000235565100005,
Author = {Deroubaix, JF and Leveque, F},
Title = {{The rise and fall of French Ecological Tax Reform: social acceptability
   versus political feasibility in the energy tax implementation process}},
Journal = {{ENERGY POLICY}},
Year = {{2006}},
Volume = {{34}},
Number = {{8}},
Pages = {{940-949}},
Month = {{MAY}},
Abstract = {{The French government has a 10-year history of negotiations with
   industry, resulting in voluntary agreements on energy consumption. When
   implemented, these voluntary agreements produced very few results in
   terms of global reduction of greenhouse emissions (Politiques et
   Management Public 11(4) (1993) 47), hence the idea of an energy tax
   became increasingly attractive for many French decision-makers.
   Ecological/Environmental Tax Reform (ETR) should have been one of the
   major political decisions and successes of the past leftwing coalition
   government. Instead it became one of its major failures as the
   Constitutional Court decided to terminate the energy tax project in
   December 2000. Through insights gleaned from focus groups and interviews
   with business-people and decision-makers, an attempt is made to
   understand the failure of the energy tax project. Firstly,
   decision-makers lacked crucial information about public and business
   opinions and secondly, there were conflicts between the relevant
   administrations. The fuel revolts of 2000 ended any hope of resolving
   the conflicts and implementing ETR. which was ultimately found
   unconstitutional. This paper examines the political controversies raised
   by the ETR project and the reasons for its eventual collapse, in the
   hope of contributing new understanding to the body of knowledge on the
   political difficulties of introducing environmental policy instruments.
   (c) 2004 Published by Elsevier Ltd.}},
DOI = {{10.1016/j.enpol.2004.08.047}},
ISSN = {{0301-4215}},
EISSN = {{1873-6777}},
Unique-ID = {{ISI:000235565100005}},
}

@article{ ISI:000293077400010,
Author = {Kunst, Anton E. and Amiri, Masoud and Janssen, Fanny},
Title = {{The Decline in Stroke Mortality Exploration of Future Trends in 7
   Western European Countries}},
Journal = {{STROKE}},
Year = {{2011}},
Volume = {{42}},
Number = {{8}},
Pages = {{2126-2130}},
Month = {{AUG}},
Abstract = {{Background and Purpose-This article aims to make projections of future
   trends in stroke mortality in the Year 2030 based on recent trends in
   stroke mortality in 7 Western European countries.
   Methods-Mortality data were obtained from national cause of death
   registries. Annual rates of decline in stroke mortality of 1980 to 2005
   were determined for men and women in the United Kingdom, France, the
   Netherlands, and 4 Nordic countries on the basis of regression analysis.
   Estimated rates of decline were extrapolated until 2030.
   Cause-elimination life tables were used to determine the effect of
   stroke in 2030 in terms of potential gain in life expectancy. The
   absolute numbers of stroke deaths in 2030 were estimated using national
   population projections of Eurostat.
   Results-In all countries, stroke mortality rates declined incessantly
   until 2005 among both men and women. If these trends were to continue,
   age-adjusted mortality rates would decline by approximately half between
   2005 and 2030 with larger declines in France (approximately two thirds)
   and smaller declines in the Netherlands, Denmark, and Sweden
   (approximately one fourth). Similar rates of decline would be observed
   in terms of potential gain in life expectancy. Because of population
   aging, the absolute number of stroke deaths would decline slowly in the
   United Kingdom and France and stabilize or even increase in other
   countries.
   Conclusions-In the near future, stroke may lose much of its effects on
   life expectancy but remain a frequent cause of death among elderly
   populations. The prevention of stroke-related disability instead of
   mortality may become increasingly more important. (Stroke.
   2011;42:2126-2130.)}},
DOI = {{10.1161/STROKEAHA.110.599712}},
ISSN = {{0039-2499}},
ResearcherID-Numbers = {{Amiri, Masoud/J-7797-2012}},
Unique-ID = {{ISI:000293077400010}},
}

@inproceedings{ ISI:000186522200015,
Author = {Wilson, RT},
Editor = {{Pearson, RA and Lhoste, P and Saastamoinen, M and MartinRosset, W}},
Title = {{The one-humped camel as a producer of rural and urban energy}},
Booktitle = {{WORKING ANIMALS IN AGRICULTURE AND TRANSPORT: A COLLECTION OF SOME
   CURRENT RESEARCH AND DEVELOPMENT OBSERVATIONS}},
Series = {{EAAP EUROPEAN ASSOCIATION FOR ANIMAL PRODUCTION TECHNICAL SERIES}},
Year = {{2003}},
Number = {{6}},
Pages = {{181-199}},
Note = {{Seminar on Working Animals in Agriculture and Transport, CAIRO, EGYPT,
   SEP 03, 2002}},
Organization = {{European Assoc Anim Product}},
Abstract = {{This paper briefly reviews the role of camels as sources of energy in
   rural and urban areas of the developing world. A short section provides
   information on the numbers of camels, their distribution in the tropics
   and subtropics and the kind of work they perform. Work performance as
   draught animals in agricultural and urban environments, as pack and
   riding animals and as prime movers for industrial applications is
   described. The effects of work on physiological and biochemical
   parameters from a wide range of literature sources are presented. Data
   on nutritional requirements and feeding standards have not been the
   subject of intensive or detailed research. It is shown that most
   recommendations are based on feeding standards for other species of work
   animals or on empirical standards used by colonial military
   administrations in the late nineteenth and early twentieth centuries.
   Harnesses and equipment for camels are similarly most often based on
   that in use for other species but there are opportunities to design new
   or adapt existing examples that would increase efficiency and improve
   animal welfare. The economic importance of camels in local and wider
   situations is presented in a series of case studies. A final section
   considers the future of camels as work animals in support of human
   livelihoods and the research needed to increase their performance.}},
ISSN = {{1570-7318}},
ISBN = {{90-76998-25-6}},
Unique-ID = {{ISI:000186522200015}},
}

@article{ ISI:000233226700006,
Author = {Vincent, VN and Cone, DC},
Title = {{Using the exception from informed consent regulations in research}},
Journal = {{ACADEMIC EMERGENCY MEDICINE}},
Year = {{2005}},
Volume = {{12}},
Number = {{11}},
Pages = {{1031-1039}},
Month = {{NOV}},
Note = {{Academic Emergency Medicine Consensus Conference on Ethical Conduct of
   Resuscitation Research, New York, NY, MAY   21, 2005}},
Abstract = {{This article reflects the proceedings of a breakout session, ``Using the
   Regulations in Research{''} at the 2005 Academic Emergency Medicine
   Consensus Conference, ``Ethical Conduct of Resuscitation Research.{''}
   There have been two organized studies, and a number of anecdotal
   reports, describing the decline in cardiac arrest resuscitation research
   in the United States since the implementation of the Final Rule. Paradis
   and colleagues found that the volume of human cardiac arrest research
   published in the United States was significantly less in a four-year
   period after the Final Rule was adopted as compared to the earlier
   period. Nichol and colleagues reported that both the absolute number of
   US-based randomized cardiac arrest trials and the proportion of US-based
   trials (vs. foreign trials, based on the mailing address of the first
   author) decreased by about 15\% annually. Despite the concern about a
   negative impact, there are at least five published trials, one in
   progress and one in planning that have been or are being conducted under
   the regulations. Those completed include the Diaspirin Cross-Linked
   Hemoglobin, Public Access Defibrillation, Multicenter Vest CPR,
   Brain-CPR, and Pre-Hospital Treatment of Status Epilepticus trials.
   Reports of how investigators met the regulations and their experience in
   doing so are reviewed. A summary table of the federal regulations is
   provided. Participants discussed what additional information and
   research about using the regulations would be helpful for the promotion
   of quality resuscitation and emergency care research in the United
   States. Areas suggested for further investigation include: impact on the
   quality as well as quantity of such research; current level of
   understanding of the regulations by investigators, regulatory/IRB
   personnel and potential subjects (the general public); costs incurred:
   additional time required for preparation, approval and conducting
   community consultation and public disclosure; impact on research on
   non-life-threatening conditions; value and cost of a registry; use of a
   standard reporting template for issues regarding meeting the
   requirements in individual clinical trials; whether more specific
   guidance would be helpful or restrictive; what constitutes effective
   community consultation and public disclosure; and whether titration of
   community consultation and public disclosure based on the risk of the
   proposed intervention to subjects is feasible and acceptable.}},
DOI = {{10.1197/j.aem.2005.06.021}},
ISSN = {{1069-6563}},
ORCID-Numbers = {{Cone, David/0000-0002-7437-959X}},
Unique-ID = {{ISI:000233226700006}},
}

@article{ ISI:000305500600007,
Author = {Hindorf, Cecilia and Chittenden, Sarah and Aksnes, Anne-Kirsti and
   Parker, Chris and Flux, Glenn D.},
Title = {{Quantitative imaging of Ra-223-chloride (Alpharadin) for targeted
   alpha-emitting radionuclide therapy of bone metastases}},
Journal = {{NUCLEAR MEDICINE COMMUNICATIONS}},
Year = {{2012}},
Volume = {{33}},
Number = {{7}},
Pages = {{726-732}},
Month = {{JUL}},
Abstract = {{Objective Ra-223 is an alpha particle emitter that targets areas of
   increased bone turnover in bone metastases. Alpha particles account for
   95\% of the 27.8 MeV emitted per decay. Less than 2\% of the emissions
   are from photons. This means that a high absorbed dose will be delivered
   locally, although the number of photons for imaging will be low. The
   purpose of this study was to investigate the possibility of quantitative
   imaging of Ra-223 to enable biodistribution studies.
   Methods A Philips Forte gamma camera, equipped with a medium-energy
   collimator, was used. Basic imaging parameters were determined from
   phantom studies, and the accuracy of activity quantification was tested
   in a phantom study and within a patient study.
   Results Imaging parameters were determined for the three most suitable
   photon peaks from the acquired energy spectrum (82, 154 and 270 keV).
   Camera sensitivity is constant for circular sources with areas greater
   than 10 cm(2). The spatial resolution (full-width at half-maximum) was
   1.1 cm for each of the three energy windows. The possibility for
   quantitative imaging was further investigated for the 82 keV energy
   window, which showed the highest sensitivity and spatial resolution. A
   phantom study showed that activity could be quantified to within 10\%
   for a 200 ml volume placed within water containing background activity
   and to within 50\% for a 0.5 ml phantom. Quantification of activity in
   bone after administrations of 100 kBq/kg of Ra-223-chloride proved the
   feasibility of quantitative imaging of patients who have received
   radionuclide therapy.
   Conclusion Because of the high-energy deposition of Ra-223, only a low
   injected activity is required for therapy, which results in a low count
   rate for the gamma camera. Nevertheless, this study has demonstrated
   that it is possible to quantify uptake with a sufficient degree of
   accuracy to obtain clinically relevant information. Nucl Med Commun
   33:726-732 (C) 2012 Wolters Kluwer Health vertical bar Lippincott
   Williams \& Wilkins.}},
DOI = {{10.1097/MNM.0b013e328353bb6e}},
ISSN = {{0143-3636}},
Unique-ID = {{ISI:000305500600007}},
}

@article{ ISI:000336976900047,
Author = {Liu, Lan and Du, Wei and Pang, Lihua and Chen, Gong and Zheng, Xiaoying},
Title = {{Incidence of road traffic disabilities trending upwards in transitional
   China: a retrospective analysis from 1980 to 2005}},
Journal = {{BMJ OPEN}},
Year = {{2014}},
Volume = {{4}},
Number = {{5}},
Abstract = {{Objective: To evaluate the change in incidence rates of road traffic
   disabilities from 1980 to 2005 in China.
   Methods: We employed the 2006 China National Sample Survey on Disability
   to derive weighted number of persons with disabilities resulting from
   road crashes and weighted age-gender-specific population at risk by
   disability occurrence year. The annual incidence rate of road traffic
   disabilities and corresponding 95\% CI were estimated. We used the World
   Population Prospects (WPP) and the death rate of people with
   disabilities (PWD) to estimate potential earlier loss of lives before
   2006. Both WPP-adjusted and PWD-adjusted incidence rates of road traffic
   disabilities were further adjusted using the life table analysis.
   Results: The WPP-adjusted incidence rate for road traffic disabilities
   increased over time from 1.50 (95\% CI 1.47 to 1.52) in 1980 to 11.19
   (95\% CI 11.13 to 11.25) per 100 000 persons in 2005. The PWD-adjusted
   incidence rate also increased from 1.71 (95\% CI 1.68 to 1.73) to 11.51
   (95\% CI 11.45 to 11.57) per 100 000 persons.
   Conclusions: Road crashes disable thousands of Chinese and remain a
   significant population health and development problem. The increasing
   burden of road traffic disabilities calls for more efforts and specific
   strategies to improve road safety in China.}},
DOI = {{10.1136/bmjopen-2013-004297}},
Article-Number = {{e004297}},
ISSN = {{2044-6055}},
Unique-ID = {{ISI:000336976900047}},
}

@article{ ISI:000361842200006,
Author = {Anderson, L. A. and Tavilla, A. and Brenner, H. and Luttmann, S. and
   Navarro, C. and Gavin, A. T. and Holleczek, B. and Johnston, B. T. and
   Cook, M. B. and Bannon, F. and Sant, M. and EUROCARE 5 Working Grp},
Title = {{Survival for oesophageal, stomach and small intestine cancers in Europe
   1999-2007: Results from EUROCARE-5}},
Journal = {{EUROPEAN JOURNAL OF CANCER}},
Year = {{2015}},
Volume = {{51}},
Number = {{15}},
Pages = {{2144-2157}},
Month = {{OCT}},
Abstract = {{Background: European regional variation in cancer survival was reported
   in the EUROCARE-4 study for patients diagnosed in 1995-1999. Relative
   survival (RS) estimates are here updated for patients diagnosed with
   cancer of the oesophagus, stomach and small intestine from 2000 to 2007.
   Trends in RS from 1999-2001 to 2005-2007 are presented to monitor and
   discuss improvements in patient survival in Europe.
   Materials and methods: EUROCARE-5 data from 29 countries (87 cancer
   registries) were used to investigate 1- and 5-year RS. Using
   registry-specific life-tables stratified by age, gender and calendar
   year, age-standardised `complete analysis' RS estimates by country and
   region were calculated for Northern, Southern, Eastern and Central
   Europe, and for Ireland and United Kingdom (UK). Survival trends of
   patients in periods 1999-2001, 2002-2004 and 2005-2007 were investigated
   using the `period' RS approach. We computed the 5-year RS conditional on
   surviving the first year (5-year conditional survival), as the ratio of
   age-standardised 5-year RS to 1-year RS.
   Results: Oesophageal cancer 1- and 5-year RS (40\% and 12\%,
   respectively) remained poor in Europe. Patient survival was worst in
   Eastern (8\%), Northern (11\%) and Southern Europe (10\%). Europe-wide,
   there was a 3\% improvement in oesophageal cancer 5-year survival by
   2005-2007, with Ireland and the UK (3\%), and Central Europe (4\%)
   showing large improvements. Europe-wide, stomach cancer 5-year RS was
   25\%. Ireland and UK (17\%) and Eastern Europe (19\%) had the poorest
   5-year patient survival. Southern Europe had the best 5-year survival
   (30\%), though only showing an improvement of 2\% by 2005-2007. Small
   intestine cancer 5-year RS for Europe was 48\%, with Central Europe
   having the best (54\%), and Ireland and UK the poorest (37\%). Five-year
   patient survival improvement for Europe was 8\% by 2005-2007, with
   Central, Southern and Eastern Europe showing the greatest increases
   (P9\%).
   Conclusions: Survival for these cancer sites, particularly oesophageal
   cancer, remains poor in Europe with wide variation. Further
   investigation into the wide variation, including analysis by histology
   and anatomical sub-site, will yield insights to better monitor and
   explain the improvements in survival observed over time. (C) 2015
   Elsevier Ltd. All rights reserved.}},
DOI = {{10.1016/j.ejca.2015.07.026}},
ISSN = {{0959-8049}},
EISSN = {{1879-0852}},
ResearcherID-Numbers = {{Cook, Michael/A-5641-2009
   Castro, Clara/M-4779-2013}},
ORCID-Numbers = {{Cook, Michael/0000-0002-0533-7302
   Castro, Clara/0000-0001-9653-4581}},
Unique-ID = {{ISI:000361842200006}},
}

@article{ ISI:000315568500001,
Author = {Zhao, Yuejen and Wright, Jo and Begg, Stephen and Guthridge, Steven},
Title = {{Decomposing Indigenous life expectancy gap by risk factors: a life table
   analysis}},
Journal = {{POPULATION HEALTH METRICS}},
Year = {{2013}},
Volume = {{11}},
Month = {{JAN 29}},
Abstract = {{Background: The estimated gap in life expectancy (LE) between Indigenous
   and non-Indigenous Australians was 12 years for men and 10 years for
   women, whereas the Northern Territory Indigenous LE gap was at least
   50\% greater than the national figures. This study aims to explain the
   Indigenous LE gap by common modifiable risk factors.
   Methods: This study covered the period from 1986 to 2005. Unit record
   death data from the Northern Territory were used to assess the
   differences in LE at birth between the Indigenous and non-Indigenous
   populations by socioeconomic disadvantage, smoking, alcohol abuse,
   obesity, pollution, and intimate partner violence. The population
   attributable fractions were applied to estimate the numbers of deaths
   associated with the selected risks. The standard life table and cause
   decomposition technique was used to examine the individual and joint
   effects on health inequality.
   Results: The findings from this study indicate that among the selected
   risk factors, socioeconomic disadvantage was the leading health risk and
   accounted for one-third to one-half of the Indigenous LE gap. A
   combination of all six selected risks explained over 60\% of the
   Indigenous LE gap.
   Conclusions: Improving socioeconomic status, smoking cessation, and
   overweight reduction are critical to closing the Indigenous LE gap. This
   paper presents a useful way to explain the impact of risk factors of
   health inequalities, and suggests that reducing poverty should be placed
   squarely at the centre of the strategies to close the Indigenous LE gap.}},
DOI = {{10.1186/1478-7954-11-1}},
Article-Number = {{1}},
ISSN = {{1478-7954}},
ResearcherID-Numbers = {{Begg, Stephen/B-5971-2014}},
ORCID-Numbers = {{Begg, Stephen/0000-0001-7482-3278}},
Unique-ID = {{ISI:000315568500001}},
}

@article{ ISI:000353591700001,
Author = {Asakura, Keiko and Haga, Megumi and Sasaki, Satoshi},
Title = {{Relative Validity and Reproducibility of a Brief-Type Self-Administered
   Diet History Questionnaire for Japanese Children Aged 3-6 Years:
   Application of a Questionnaire Established for Adults in Preschool
   Children}},
Journal = {{JOURNAL OF EPIDEMIOLOGY}},
Year = {{2015}},
Volume = {{25}},
Number = {{5}},
Pages = {{341-350}},
Month = {{MAY}},
Abstract = {{Background: Dietary intake assessment and subsequent dietary education
   or intervention in young children is important in decreasing prevalence
   of various noncontagious diseases in adulthood. Validation of diet
   assessment questionnaires for preschool children has just started in
   Japan. In this study, we rearranged the brief-type self-administered
   diet history questionnaire (BDHQ), a convenient diet assessment
   questionnaire that is widely used in a range of situations for adults,
   for use in children aged 3-6 years (BDHQ3y) and then validated the
   BDHQ3y in Japanese children.
   Methods: The guardians of 61 children aged 3-4 years completed the
   BDHQ3y twice at an interval of 1 month, along with a
   3-nonconsecutive-day diet record (DR) between the two administrations of
   the BDHQ3y. Dietary intakes for energy and 42 selected nutrients were
   estimated using both the DR and the BDHQ3y. Mean intakes estimated by
   the two methods were compared, and correlation coefficients were
   calculated. Reproducibility of the BDHQ3y estimates was investigated
   using intra-class correlation coefficients (ICCs).
   Results: No significant differences in mean intakes estimated by the DR
   and the BDHQ3y were observed for one- to two-thirds of energy and
   examined nutrients. The median of Pearson correlation coefficients
   between intakes energy-adjusted by the residual method was 0.31
   (interquartile range, 0.24 to 0.38). The median ICC was 0.72
   (interquartile range, 0.63 to 0.76) for the crude nutrient intakes.
   Conclusions: Although the BDHQ3y might be a good candidate for dietary
   intake assessment in Japanese preschool children, its validity is
   currently moderate to low. Shortcomings should be overcome by obtaining
   and utilizing more information about children's dietary habits.}},
DOI = {{10.2188/jea.JE20140174}},
ISSN = {{0917-5040}},
EISSN = {{1349-9092}},
Unique-ID = {{ISI:000353591700001}},
}

@inproceedings{ ISI:000273673200128,
Author = {Sun Bo},
Editor = {{Zhu, XN}},
Title = {{E-government: Sensible Choice of Administration}},
Booktitle = {{PROCEEDINGS OF 2009 INTERNATIONAL CONFERENCE ON PUBLIC ADMINISTRATION
   (5TH), VOL I}},
Year = {{2009}},
Pages = {{833-836}},
Note = {{5th International Conference on Public Administration, UESTC, Sch Polit 
   Sci \& Public Adm, Chengdu, PEOPLES R CHINA, OCT 23-25, 2009}},
Organization = {{Univ Elect Sci \& Technol China; Amer Soc Public Adm; Chinese Public Adm
   Soc; Moscow State Univ, Sch Public Adm; Chinese Public Adm Journal}},
Abstract = {{Development of information technology expedites emergence of
   E-government, getting government administration tend to be electrified
   and networked. To set up file material electronification centre could
   save large amount of time and energy of different departments, hence, to
   improve efficiency. Administrative mode of networking type which
   collaborated by government, citizens, society and market organizations
   has been the general trend. Mutual transfer of macro \& micro
   administrations which is macro trend of micro-administration and micro
   trend of macro-administration becomes possible due to network. The
   initiative is also given to the people by few persons in power. Digital
   gulf and construction of hardware is what E-government must face to. To
   unify planning and share common interest will be the comparatively good
   settlement. Advantages and benefits of electronification network should
   be tangibly felt by the other side. As to hardware construction,
   investment structure and management style should be progressively
   adjusted to coordinate interest relations of various parties and to
   commonly share information via interconnection instead of profit
   unification.}},
ISBN = {{978-7-5647-0139-0}},
Unique-ID = {{ISI:000273673200128}},
}

@article{ ISI:000308522500014,
Author = {Abrahamsson, Lars and Schutte, Thorsten and Ostlund, Stefan},
Title = {{Use of converters for feeding of AC railways for all frequencies}},
Journal = {{ENERGY FOR SUSTAINABLE DEVELOPMENT}},
Year = {{2012}},
Volume = {{16}},
Number = {{3}},
Pages = {{368-378}},
Month = {{SEP}},
Abstract = {{Railways are the most energy-efficient land-based mode of transport, and
   electrification is the most energy-efficient way to power the trains.
   There are many existing solutions to supply the trains with electricity.
   Regardless of which particular technology is chosen, it is beneficial to
   interconnect the public power grids to grids supplying power to the
   railways. This paper shows that the most efficient, flexible, and
   gentle-for-the-public-grid way of doing that is through power
   electronic-based power converters. Converters offer great benefits
   regardless of whether the overhead contact lines are of DC-type or AC
   type, and regardless of the AC grid frequency.
   This paper presents neither new theory nor new experimental results.
   Based on already available information, this paper presents logical
   arguments leading to this conclusion from collected facts. Over time
   what used to be advanced and high-cost equipment earlier can nowadays be
   purchased at reasonable cost. It is obvious that for most
   electrically-fed railways, the use of modern power converters is
   attractive. Where the individual trains are high consumers of energy,
   the railway gradients are substantial, and the public grids feeding the
   railway are weak, the use of converters would be technically desirable,
   if not necessary for electrification.
   It is expected that more high-speed railways will be built, and more
   existing railways will be electrified in the foreseeable future. This
   paper could provide some insights to infrastructure owners and decision
   makers in railway administrations about value additions that
   converter-fed electric railways would provide. (C) 2012 International
   Energy Initiative. Published by Elsevier Inc. All rights reserved.}},
DOI = {{10.1016/j.esd.2012.05.003}},
ISSN = {{0973-0826}},
ORCID-Numbers = {{Abrahamsson, Lars/0000-0003-2109-060X}},
Unique-ID = {{ISI:000308522500014}},
}

@inproceedings{ ISI:000321693000017,
Author = {Ciaccio, Giuseppe and Pastorino, Antonio and Ribaudo, Marina},
Editor = {{Castelnovo, W and Ferrari, E}},
Title = {{Open Data and Personal Information: A Smart Disclosure Approach Based on
   OAuth 2.0}},
Booktitle = {{PROCEEDINGS OF THE 13TH EUROPEAN CONFERENCE ON EGOVERNMENT}},
Year = {{2013}},
Pages = {{135-143}},
Note = {{13th European Conference on e-Government (ECEG), Univ Insubria, Dept
   Theoret \& Appl Sci, Como, ITALY, JUN 13-14, 2013}},
Abstract = {{Currently, public administration is undergoing significant
   transformations, driven by a greater demand for transparency and
   efficiency in a participative framework involving nonprofit
   organizations, enterprises, and citizens, with the modern network
   infrastructure as a common medium. The Open Data movement is considered
   one of the keys to this change. To the best of our knowledge, the
   current generation of Open Data has to date provided only static
   datasets in which no data concerning specific individuals could be
   included, due to obvious privacy issues. Public administrations hold a
   great deal of data of a personal kind, as do many private entities.
   Consider, for instance, the huge amount of personal data contributed to
   the various online social networks, or the electricity consumption data
   collected and stored by energy providers, or the telephone and internet
   data collected by telecommunications companies. The lack of such
   personal data in the Open Data realm, and the static nature of the
   released datasets, are weaknesses of the current generation of Open
   Data. Without personal data and without timeliness, it is impossible to
   build useful services tailored to the actual needs of a given individual
   at a given time. We argue that, by segregating or ``protecting{''} our
   personal data, those public and private entities become the ``owners{''}
   of our data. This means they hold a monopoly on services, while we, the
   legitimate owners of the data, must abide by their terms and conditions
   concerning how our data are treated and used. By unleashing personal
   data ``into the wild{''}, such a monopoly would collapse and a new
   ecosystem of personal services based on these data could flourish. Of
   course nobody wants personal data to enter the public domain without any
   control. We argue that an appropriate policy for online disclosure of
   personal data is one where the individuals are restored to their role of
   ``data owners{''} and are allowed to exert online control over data
   accesses being performed by third parties. This idea of ``smart
   disclosure{''} of personal data is expected to be one of the forthcoming
   evolutions of Open Data. Based on the above arguments, we propose a
   possible implementation of ``smart disclosure{''} that takes advantage
   of the OAuth 2.0 authorization framework. If properly implemented, OAuth
   2.0 guarantees access to selected personal data upon authorization by
   the individual data owner. An implementation is presented together with
   possible use cases.}},
ISBN = {{978-1-909507-24-1}},
Unique-ID = {{ISI:000321693000017}},
}

@article{ ISI:000297587300016,
Author = {Grieger, Lloyd D. and Danziger, Sheldon H.},
Title = {{Who Receives Food Stamps During Adulthood? Analyzing Repeatable Events
   With Incomplete Event Histories}},
Journal = {{DEMOGRAPHY}},
Year = {{2011}},
Volume = {{48}},
Number = {{4}},
Pages = {{1601-1614}},
Month = {{NOV}},
Abstract = {{Using data from the Panel Study of Income Dynamics (PSID) from 1968 to
   2005, we estimate the cumulative probability that young adults in the
   United States will receive food stamps during adulthood, and examine how
   that probability varies with an individual's income and education at age
   25 as well as by race and gender. We find that the probability of first
   food stamp receipt as an adult declines sharply with age, indicating
   that most adult recipients do so by age 40. Also, those receiving food
   stamps in early adulthood are likely to receive them again. For these
   reasons, and because food stamp receipt is a repeatable event, life
   table analyses that include individuals who are not observed until after
   they become exposed to the risk of food stamp receipt (whom we label
   ``late entrants{''}) are likely to overstate cumulative participation
   during adulthood. For example, one often-cited study included
   individuals who enter their sample after age 20 (late entrants) and
   report that 50.8\% of 20-year-olds are recipients by age 65. In
   contrast, when we exclude late entrants, we find that 39.2\% of
   20-year-olds and 29.7\% of 25-year-olds receive benefits during
   adulthood.}},
DOI = {{10.1007/s13524-011-0056-x}},
ISSN = {{0070-3370}},
Unique-ID = {{ISI:000297587300016}},
}

@inproceedings{ ISI:000323271800059,
Author = {Lewandowski, Christian and Groening, Sven and Wietfeld, Christian},
Book-Group-Author = {{IEEE}},
Title = {{metropol-E: A System for Analyzing and Optimizing Urban Electric Vehicle
   Fleets}},
Booktitle = {{2012 INTERNATIONAL CONFERENCE ON CONNECTED VEHICLES AND EXPO (ICCVE)}},
Series = {{International Conference on Connected Vehicles and Expo}},
Year = {{2012}},
Pages = {{292-297}},
Note = {{1st International Conference on Connected Vehicles and Expo, Tsinghua
   Univ, Beijing, PEOPLES R CHINA, DEC 12-16, 2012}},
Organization = {{IEEE; Int Federat Automat Control (IFAC); Transportat Res Board (TRB);
   Assoc Comp Machinery (ACM); IEEE Comp Soc; IEEE Transportat Electrificat
   Initiat; IEEE Stand Assoc; IEEE Consumer Elect Soc; IEEE Ind Elect Soc;
   IEEE Vehicular Technol Soc; IEEE Intelligent Transportat Syst Soc; IEEE
   Commun Soc}},
Abstract = {{Electric mobility becomes very important due to a lack of fossil fuels
   in the future. Hence, it is obvious to replace conventional vehicles
   with gasoline or diesel engines with Electric Vehicles (EVs). An
   important area of such replacements are vehicle fleets of companies or
   urban administrations. The goal of the research project metropol-E is to
   develop a concept for integrating Electric Mobility and renewable energy
   resources in the urban fleet of the City of Dortmund. The developed
   concept can be easily transferred to other municipalities.
   This work shortly introduces the metropol-E concept and concentrates on
   an Information System for Mobile Electric Mobility Services. On the one
   hand, this Information System is able to analyze the fleet movement by
   installing smartphones in the vehicles. On the other hand it connects
   the EV with the rest of the infrastructure services. With the help of
   the collected fleet movement data, the fleet and the charging
   infrastructure can be optimized. Exemplary results and mechanisms for
   such optimizations are also discussed in this work.}},
DOI = {{10.1109/ICCVE.2012.66}},
ISSN = {{2378-1289}},
ISBN = {{978-0-7695-4900-2; 978-1-4673-4705-1}},
Unique-ID = {{ISI:000323271800059}},
}

@inproceedings{ ISI:000258167800044,
Author = {Brozio, Sybille and Zeidler, Mirella and Laufer, Severine and Piorr,
   Hans-Peter and Torkler, Frank and Zeller, Heiko and Lorenz, Karsten},
Book-Group-Author = {{LUA}},
Title = {{Modelling of regional specific bioenergy and bioethanol potential in
   Germany, Poland and Baltic States}},
Booktitle = {{RURAL DEVELOPMENT 2007, VOL 3, BOOK 2, PROCEEDINGS}},
Series = {{Rural Development}},
Year = {{2007}},
Pages = {{263-270}},
Note = {{3rd International Scientific Conference on Rural Development, Kaunas
   City, LITHUANIA, NOV 08-10, 2007}},
Organization = {{Lithuanian Univ Agr}},
Abstract = {{Knowledge about estimation of potential yields in agriculture is
   compiled at the University of Applied Sciences Eberswalde, including the
   instrument of Geographic Information Systems (GIS) to develop a regional
   specific bioenergy model. Through the evaluation of an extensive yield
   database a biomass yield model {[}bym] was developed. It is based on
   site specific yield functions and crop rotation algorithms. In
   combination with geo data it is possible to calculate regional biomass.
   Therefore annual precipitation, soil information and area of arable land
   are determined for agricultural farms up to scales of municipalities in
   Germany. The conversion of the biomass yield model to a GIS was
   performed in Visual Basic for Application (VBA). Results of modelling
   visualise potential yields of harvestable biomass per hectare and year
   in various spatial scales and quantify local production areas for
   bioenergy. It is possible to compare organic with conventional farming
   or integrate energy farming systems. The visualisation of bioenergy
   yields is useful for discussions with farmers, administrations or
   companies. Exemplary biogas potential analysis in federal state
   Brandenburg (East Germany) and scenarios for bioethanol in the petrol
   refinery at Schwedt (North East Germany) are presented to point out
   possibilities for the evaluation of agricultural bioenergy potentials.}},
ISSN = {{1822-3230}},
Unique-ID = {{ISI:000258167800044}},
}

@article{ ISI:000312273700022,
Author = {Backholer, Kathryn and Mannan, Haider R. and Magliano, Dianna J. and
   Walls, Helen L. and Stevenson, Chris and Beauchamp, Alison and Shaw,
   Jonathan E. and Peeters, Anna},
Title = {{Projected socioeconomic disparities in the prevalence of obesity among
   Australian adults}},
Journal = {{AUSTRALIAN AND NEW ZEALAND JOURNAL OF PUBLIC HEALTH}},
Year = {{2012}},
Volume = {{36}},
Number = {{6}},
Pages = {{557-563}},
Month = {{DEC}},
Abstract = {{Objective: To project prevalence of normal weight, overweight and
   obesity by educational attainment, assuming a continuation of the
   observed individual weight change in the 5-year follow-up of the
   national population survey, the Australian Diabetes, Obesity and
   Lifestyle study (AusDiab; 2000-2005).
   Methods: Age-specific transition probabilities between BMI categories,
   estimated using logistic regression, were entered into
   education-level-specific, incidence-based, multi-state life tables.
   Assuming a continuation of the weight change observed in AusDiab, these
   life tables estimate the prevalence of normal weight, overweight and
   obesity for Australian adults with low (secondary), medium (diploma) and
   high (degree) levels of education between 2005 and 2025.
   Results: The prevalence of obesity among individuals with secondary
   level educational attainment is estimated to increase from 23\% in 2000
   to 44\% in 2025. Among individuals with a degree qualification or
   higher, it will increase from 14\% to 30\%. If all current educational
   inequalities in weight change could be eliminated, the projected
   difference in the prevalence of obesity by 2025 between the highest and
   lowest educated categories would only be reduced by half (to a 6
   percentage point difference from 14 percentage points).
   Conclusion: We predict that almost half of Australian adults with low
   educational status will be obese by 2025. Current trends in obesity have
   the potential to drive an increase in the absolute difference in obesity
   prevalence between educational categories in future years.
   Implications: Unless obesity prevention and management strategies focus
   specifically on narrowing social inequalities in obesity, inequalities
   in health are likely to widen.}},
DOI = {{10.1111/j.1753-6405.2012.00885.x}},
ISSN = {{1326-0200}},
ResearcherID-Numbers = {{Peeters, Anna/B-3663-2013
   Shaw, Jonathan/E-7388-2010}},
ORCID-Numbers = {{Shaw, Jonathan/0000-0002-6187-2203}},
Unique-ID = {{ISI:000312273700022}},
}

@article{ ISI:000349619000018,
Author = {Zeng, Hongmei and Zheng, Rongshou and Guo, Yuming and Zhang, Siwei and
   Zou, Xiaonong and Wang, Ning and Zhang, Limei and Tang, Jingao and Chen,
   Jianguo and Wei, Kuangrong and Huang, Suqin and Wang, Jian and Yu, Liang
   and Zhao, Deli and Song, Guohui and Chen, Jianshun and Shen, Yongzhou
   and Yang, Xiaoping and Gu, Xiaoping and Jin, Feng and Li, Qilong and Li,
   Yanhua and Ge, Hengming and Zhu, Fengdong and Dong, Jianmei and Guo,
   Guoping and Wu, Ming and Du, Lingbin and Sun, Xibin and He, Yutong and
   Coleman, Michel P. and Baade, Peter and Chen, Wanqing and Yu, Xue Qin},
Title = {{Cancer survival in China, 2003-2005: A population- based study}},
Journal = {{INTERNATIONAL JOURNAL OF CANCER}},
Year = {{2015}},
Volume = {{136}},
Number = {{8}},
Pages = {{1921-1930}},
Month = {{APR 15}},
Abstract = {{Limited population-based cancer registry data available in China until
   now has hampered efforts to inform cancer control policy. Following
   extensive efforts to improve the systematic cancer surveillance in this
   country, we report on the largest pooled analysis of cancer survival
   data in China to date. Of 21 population-based cancer registries, data
   from 17 registries (n=138,852 cancer records) were included in the final
   analysis. Cases were diagnosed in 2003-2005 and followed until the end
   of 2010. Age-standardized relative survival was calculated using
   region-specific life tables for all cancers combined and 26 individual
   cancers. Estimates were further stratified by sex and geographical area.
   The age-standardized 5-year relative survival for all cancers was 30.9\%
   (95\% confidence intervals: 30.6\%-31.2\%). Female breast cancer had
   high survival (73.0\%) followed by cancers of the colorectum (47.2\%),
   stomach (27.4\%), esophagus (20.9\%), with lung and liver cancer having
   poor survival (16.1\% and 10.1\%), respectively. Survival for women was
   generally higher than for men. Survival for rural patients was about
   half that of their urban counterparts for all cancers combined (21.8\%
   vs. 39.5\%); the pattern was similar for individual major cancers except
   esophageal cancer. The poor population survival rates in China emphasize
   the urgent need for government policy changes and investment to improve
   health services. While the causes for the striking urban-rural
   disparities observed are not fully understood, increasing access of
   health service in rural areas and providing basic health-care to the
   disadvantaged populations will be essential for reducing this disparity
   in the future.}},
DOI = {{10.1002/ijc.29227}},
ISSN = {{0020-7136}},
EISSN = {{1097-0215}},
ORCID-Numbers = {{Coleman, Michel/0000-0001-8940-3807}},
Unique-ID = {{ISI:000349619000018}},
}

@inproceedings{ ISI:000335582500023,
Author = {Vitale, Alessandro and Festa, Demetrio Carmine and Guido, Giuseppe and
   Rogano, Daniele},
Editor = {{DeSousa, JF and DeSousa, JP and Costa, A and Farias, T and Melo, S}},
Title = {{A Decision Support System based on smartphone probes as a tool to
   promote public transport}},
Booktitle = {{TRANSPORTATION: CAN WE DO MORE WITH LESS RESOURCES? - 16TH MEETING OF
   THE EURO WORKING GROUP ON TRANSPORTATION - PORTO 2013}},
Series = {{Procedia Social and Behavioral Sciences}},
Year = {{2014}},
Volume = {{111}},
Pages = {{224-231}},
Note = {{16th Meeting of the Euro-Working-Group-in-Transportation, Porto,
   PORTUGAL, SEP, 2013}},
Organization = {{Euro Working Grp Transportat}},
Abstract = {{In the last few years, the increase in mobility has coincided with an
   ever greater use of an individual mode of transport. The causes of this
   situation are imputable not only to a growth in economic wellbeing, but
   also to an inadequate organization of public transport services that
   still represent a valid alternative to the car use only in sporadic
   cases. Recently the research community, local public administrations,
   national and federal governments focused their attention on methods and
   techniques able to promote the use of public transport, reducing energy
   consumption, pollution levels, congestion levels and road traffic.
   However, in order to make more effective all initiatives to promote
   public transport, a large amount of information about service network
   accessible to users is essential. Based on this assumption, this paper
   presents a Decision Support System that relies on a logical network
   architecture characterized by the communication paradigm REST and
   powered by the use, on Client side, of smartphones that today have an
   enormous social relevance. Key goals of a REST-based platform include
   scalability of components interactions, generality of interfaces,
   independent deployment of components and intermediary components to
   enforce security and reduce latency.
   Through the elaboration of a large amount of transportation systems and
   land use data (Server side) and an user-friendly interface on the client
   it is possible to simultaneously register users' behavior on each trip
   they made (GPS sensors on smartphones allow the storage of the origin,
   the destination, the temporal window, the used mode of transport, the
   routes of the trips on the Server) and propose to users travel
   strategies alternative to car use.
   The Decision Support System is based on a Service Oriented Architecture
   (SOA) structure and it is characterized by iinteroperability of the
   entire set of data as well as support the independent Open Geospatial
   Consortium (OGC) web services, such as Web Feature Services (WFS) and
   Web Map Services (WMS), in order to provide a series of spatial analysis
   web services via a spatial database back end, as well provide a basis to
   share spatial data with different data models and from different sources
   without data conversion. (C) 2013 The Authors. Published by Elsevier
   Ltd.}},
DOI = {{10.1016/j.sbspro.2014.01.055}},
ISSN = {{1877-0428}},
ResearcherID-Numbers = {{Vitale, Alessandro/B-6887-2013}},
ORCID-Numbers = {{Vitale, Alessandro/0000-0001-7163-8114}},
Unique-ID = {{ISI:000335582500023}},
}

@article{ ISI:000281527600001,
Author = {Feng, Jianghua and Liu, Huili and Zhang, Limin and Bhakoo, Kishore and
   Lu, Lehui},
Title = {{An insight into the metabolic responses of ultra-small superparamagnetic
   particles of iron oxide using metabonomic analysis of biofluids}},
Journal = {{NANOTECHNOLOGY}},
Year = {{2010}},
Volume = {{21}},
Number = {{39}},
Month = {{OCT 1}},
Abstract = {{Ultra-small superparamagnetic particles of iron oxides (USPIO) have been
   developed as intravenous organ/tissue-targeted contrast agents to
   improve magnetic resonance imaging (MRI) in vivo. However, their
   potential toxicity and effects on metabolism have attracted particular
   attention. In the present study, uncoated and dextran-coated USPIO were
   investigated by analyzing both rat urine and plasma metabonomes using
   high-resolution NMR-based metabonomic analysis in combination with
   multivariate statistical analysis. The wealth of information gathered on
   the metabolic profiles from rat urine and plasma has revealed subtle
   metabolic changes in response to USPIO administration. The metabolic
   changes include the elevation of urinary alpha-hydroxy-n-valerate, o-
   and p-HPA, PAG, nicotinate and hippurate accompanied by decreases in the
   levels of urinary alpha-ketoglutarate, succinate, citrate,
   N-methylnicotinamide, NAG, DMA, allantoin and acetate following USPIO
   administration. The changes associated with USPIO administration
   included a gradual increase in plasma glucose, N-acetyl glycoprotein,
   saturated fatty acid, citrate, succinate, acetate, GPC, ketone bodies
   (beta-hydroxybutyrate, acetone and acetoacetate) and individual amino
   acids, such as phenylalanine, lysine, isoleucine, glycine, glutamine and
   glutamate and a gradual decrease of myo-inositol, unsaturated fatty acid
   and triacylglycerol. Hence USPIO administration effects are reflected in
   changes in a number of metabolic pathways including energy, lipid,
   glucose and amino acid metabolism. The size- and surface
   chemistry-dependent metabolic responses and possible toxicity were
   observed using NMR analysis of biofluids. These changes may be
   attributed to the disturbances of hepatic, renal and cardiac functions
   following USPIO administrations. The potential biotoxicity can be
   derived from metabonomic analysis and serum biochemistry analysis.
   Metabonomic strategy offers a promising approach for the detection of
   subtle physiological responses on mammalian metabolism, and can be
   employed to investigate the potential adverse effects of other
   nanoparticles and nanomaterials on the environment and human health.}},
DOI = {{10.1088/0957-4484/21/39/395101}},
Article-Number = {{395101}},
ISSN = {{0957-4484}},
ResearcherID-Numbers = {{SKL, PCOSS/D-4395-2013}},
Unique-ID = {{ISI:000281527600001}},
}

@article{ ISI:A1997WQ90700011,
Author = {Gonzalez, CA},
Title = {{Relative validity and reproducibility of a diet history questionnaire in
   Spain .2. Nutrients}},
Journal = {{INTERNATIONAL JOURNAL OF EPIDEMIOLOGY}},
Year = {{1997}},
Volume = {{26}},
Number = {{1}},
Pages = {{S100-S109}},
Abstract = {{Background. A pilot study was carried out to evaluate the relative
   validity and reproducibility of a dietary history questionnaire (DH)
   administered by interview and designed to be used in a prospective study
   an diet and cancer.
   Methods. The DH was administered twice, with a year's interval, to 91
   volunteers of various occupational categories, aged 35-60 years, of both
   sexes. Twelve 24-hour recalls applied monthly during the year between
   the two administrations of the DH were used as a reference method.
   Results. Mean values of daily intake between the two methods were very
   similar for most nutrients. The DH tended to underestimate intake,
   compared to the 24-hour recall, for some nutrients like saturated fat
   and dietary fibre in males and saturated and polyunsaturated fat,
   cholesterol and retinol in females. it tended to overestimate intake of
   vitamin C, retinol and B-carotene in males and dietary fibre, vitamin C
   and beta-carotene in females. Pearson correlation coefficients between
   the daily intake of nutrients based on the mean of the 12 24-hour
   recalls and the second use of the DH showed most values to be >0.80 in
   males (ranging from 0.28 for retinol to 0.89 for energy, lipids, mono
   and polyunsaturated fat) and 0.60 in females (ranging from 0.33 for
   cholesterol to 0.83 for alcohol). For the great majority of nutrients
   studied, more than 80\% of the subjects classified in the two highest
   quintiles and in the two lowest quintiles according to the DH2 which
   coincided with the highest and lowest quintiles of the classification
   according to the average of 24-hour recalls.
   Conclusions. The DH method provides quite good information on the
   habitual nutrient intake of the individual in a recent 1-year reference
   period.}},
ISSN = {{0300-5771}},
Unique-ID = {{ISI:A1997WQ90700011}},
}

@article{ ISI:A1992HU83400012,
Author = {KURTIN, PS and DAVIES, AR and MEYER, KB and DEGIACOMO, JM and KANTZ, ME},
Title = {{PATIENT-BASED HEALTH-STATUS MEASURES IN OUTPATIENT DIALYSIS - EARLY
   EXPERIENCES IN DEVELOPING AN OUTCOMES ASSESSMENT PROGRAM}},
Journal = {{MEDICAL CARE}},
Year = {{1992}},
Volume = {{30}},
Number = {{5, S}},
Pages = {{MS136-MS149}},
Month = {{MAY}},
Note = {{3RD CONF ON ADVANCES IN HEALTH STATUS ASSESSMENT, GEORGETOWN UNIV CONF
   CTR, WASHINGTON, DC, SEP 12-14, 1991}},
Organization = {{NATL ACAD SCI, INST MED; AGCY HLTH CARE POLICY \& RES; CTR DIS CONTROL;
   NIH; ELI LILLY; GLAXO; PFIZER}},
Abstract = {{This paper describes the initial development of a patient-based outcomes
   assessment program in an outpatient dialysis unit. This project
   presented four logistical and practical issues that are discussed in
   this paper: patient acceptance of quarterly administrations of a generic
   health status survey (the SF-36); timing of administration during
   dialysis session; respondent burden; and staff burden. Also discussed
   are three issues related to the clinical use of these assessments:
   medical record status of SF-36 data; use in clinical decisionmaking; and
   clinicians' responses to aggregate data from patient-based health status
   assessments. The investigation reported presents strong evidence of
   patient acceptance of the SF-36. Data collection problems reflected the
   nature of a busy dialysis unit, and most have been corrected.
   Considering functional status, the role functioning of dialysis patients
   is most adversely affected; among well-being measures, patients are most
   compromised by pain and lack of energy. Clinicians' reviews of these
   results point to the need for normative data, information about severity
   of primary and comorbid diseases, and knowledge of relationships between
   SF-36 scores and physiologic parameters to make clinical use of generic
   health outcome assessments.}},
ISSN = {{0025-7079}},
Unique-ID = {{ISI:A1992HU83400012}},
}

@article{ ISI:000240660800013,
Author = {Cenni, Gabriele and Blandina, Patrizio and Mackie, Ken and Nosi, Daniele
   and Formigli, Lucia and Giannoni, Patrizia and Ballini, Chiara and Della
   Corte, Laura and Mannaioni, Pier Francesco and Passani, M. Beatrice},
Title = {{Differential effect of cannabinoid agonists and endocannabinoids on
   histamine release from distinct regions of the rat brain}},
Journal = {{EUROPEAN JOURNAL OF NEUROSCIENCE}},
Year = {{2006}},
Volume = {{24}},
Number = {{6}},
Pages = {{1633-1644}},
Month = {{SEP}},
Abstract = {{Cannabinoids exert complex actions on neurotransmitter systems involved
   in cognition, locomotion, appetite, but no information was available so
   far on the interactions between the endocannabinoid system and
   histaminergic neurons that command several, similar behavioural states
   and memory. In this study, we investigated the effect of cannabimimetic
   compounds on histamine release using the microdialysis technique in the
   brain of freely moving rats. We found that systemic administration of
   the cannabinoid receptors 1 (CB1-r) agonist
   arachidonyl-2'chloroethylamide/N-(2chloroethyl)-5Z,8Z,11Z,14Z-eicosatetr
   aenamide (ACEA; 3 mg/kg) increased histamine release from the posterior
   hypothalamus, where the histaminergic tuberomamillary nuclei (TMN) are
   located. Local infusions of ACEA (150 nM) or R(+)-methanandamide (mAEA;
   1 mu M), another CB1-r agonist, in the TMN augmented histamine release
   from the TMN, as well as from two histaminergic projection areas, the
   nucleus basalis magnocellularis and the dorsal striatum. When the
   endocannabinoid uptake inhibitor AM404 was infused into the TMN,
   however, increased histamine release was observed only in the TMN. The
   cannabinoid-induced effects on histamine release were blocked by
   co-administrations with the CB1-r antagonist AM251. Using
   double-immunofluorescence labelling and confocal laser-scanning
   microscopy, CB1-r immunostaining was found in the hypothalamus, but was
   not localized onto histaminergic cells. The modulatory effect of
   cannabimimetic compounds on histamine release apparently did not involve
   inhibition of gamma-aminobutyric acid (GABA)ergic neurotransmission,
   which provides the main inhibitory input to the histaminergic neurons in
   the hypothalamus, as local infusions of ACEA did not modify GABA release
   from the TMN. These profound effects of cannabinoids on histaminergic
   neurotransmission may partially underlie some of the behavioural changes
   observed following exposure to cannabinoid-based drugs.}},
DOI = {{10.1111/j.1460-9568.2006.05046.x}},
ISSN = {{0953-816X}},
ResearcherID-Numbers = {{Mackie, Kenneth/B-7358-2011
   Mackie, Ken/E-3715-2013
   Giannoni, Patrizia/}},
ORCID-Numbers = {{Mackie, Ken/0000-0001-8501-6199
   Giannoni, Patrizia/0000-0003-2536-7688}},
Unique-ID = {{ISI:000240660800013}},
}

@article{ ISI:000085516100004,
Author = {Taren, D and de Tobar, M and Ritenbaugh, C and Graver, E and Whitacre, R
   and Aickin, M},
Title = {{Evaluation of the southwest food frequency questionnaire}},
Journal = {{ECOLOGY OF FOOD AND NUTRITION}},
Year = {{2000}},
Volume = {{38}},
Number = {{6}},
Pages = {{515-547}},
Abstract = {{The development of the Southwest Food Frequency Questionnaire (SWFFQ)
   was undertaken to provide a culturally appropriate means of collecting
   dietary information for the Southwest region of the United States. The
   study measured the reliability and validity of the SWFFQ and a modified
   shortened version (MSFFQ). Hispanic (n = 79) and non-Hispanic (n = 80)
   subjects participated in the study and were randomized to complete two
   administrations of either the SWFFQ or the MSFFQ. Each subject provided
   four days of dietary recalls over a four month period. FFQs were
   administered 2 and 4 weeks after the last 24 hour recall was completed.
   The SWFFQ had greater mean reproducibility coefficients (0.615 to 0.832)
   compared with the MSFFQ and greater validity coefficients (0.349 to
   0.700) when disattenuated for macronutrients,vitamins and minerals.
   Hispanics had greater reproducibility, but non-Hispanics had greater
   validity coefficients. In conclusion, the SWFFQ is an instrument that
   can be used effectively for its target population.}},
ISSN = {{0367-0244}},
Unique-ID = {{ISI:000085516100004}},
}

@article{ ISI:000276835700006,
Author = {Farrar, Sue and Moizer, Jonathan D.},
Title = {{How long might the younger-old live: A predictive model}},
Journal = {{FUTURES}},
Year = {{2010}},
Volume = {{42}},
Number = {{3}},
Pages = {{212-218}},
Month = {{APR}},
Abstract = {{Life expectancy amongst older people in industrialised countries has
   been improving over an extended period and still continues to do so.
   This has ramifications for providers of services to this population,
   thus necessitating a level of forward planning. Predictive models of
   remaining life expectancy for older age groups can assist long-term
   planning processes. This paper presents an extrapolative approach to
   forecasting remaining life expectancy. Based on logistic modelling of
   historic mortality and survivorship for the ``younger-old{''} male
   population of England and Wales over the period 1970-2005, a
   parsimonious two-parameter model is derived. This model provides a close
   correspondence to published period life table data. Trends in these
   parameters are then fitted and extrapolated to enable projections of
   life expectancy up to 40 years into the future. Alternative assumptions
   are used to determine a range of future life expectancy trajectories for
   a 65-year-old male. Occupational pension scheme provision is identified
   as an area of particular concern in the context of increasing longevity.
   As an illustration, the life expectancy trajectories are combined with
   differing discount rate assumptions to generate a number of alternative
   pension liability scenarios for the extrapolation period. (C) 2009
   Elsevier Ltd. All rights reserved.}},
DOI = {{10.1016/j.futures.2009.11.006}},
ISSN = {{0016-3287}},
Unique-ID = {{ISI:000276835700006}},
}

@article{ ISI:000331250100016,
Author = {Soneji, Samir and Beltran-Sanchez, Hiram and Sox, Harold C.},
Title = {{Assessing Progress in Reducing the Burden of Cancer Mortality, 1985-2005}},
Journal = {{JOURNAL OF CLINICAL ONCOLOGY}},
Year = {{2014}},
Volume = {{32}},
Number = {{5}},
Pages = {{444-U72}},
Month = {{FEB 10}},
Abstract = {{Purpose Measuring the effect of cancer interventions must take into
   account rising cancer incidence now that people live longer because of
   declines in mortality from cardiovascular disease (CVD). Cancer
   mortality rates in the population do not accomplish this objective. We
   sought a measure that would reveal the effects of changing mortality
   rates from other diseases.
   Methods We obtained annual breast, colorectal, lung, and prostate cancer
   mortality rates from the Surveillance, Epidemiology, and End Results
   registries; we obtained noncancer mortality rates from national death
   certificates, 1975 to 2005. We used life-table methods to calculate the
   burden of cancer mortality as the average person-years of life lost
   (PYLL) as a result of cancer (cancer-specific PYLL) and quantify
   individualand perhaps offsettingcontributions of the two factors that
   affect cancer-specific PYLL: mortality rates as a result of cancer and
   other-cause mortality.
   Results Falling cancer mortality rates reduced the burden of mortality
   from leading cancers, but increasing cancer incidence as a result of
   decreasing other-cause mortality rates partially offset this progress.
   Between 1985 and 1989 and between 2000 and 2004, the burden of lung
   cancer in males declined by 0.1 year of life lost. This decline reflects
   the sum of two effects: decreasing lung cancer mortality rates that
   reduced the average burden of lung cancer mortality by 0.33 years of
   life lost and declining other-cause mortality rates that raised it by
   0.23 years. Other common cancers showed similar patterns.
   Conclusion By using a measure that accounts for increased cancer
   incidence as a result of improvements in CVD mortality, we find that
   prior assessments have underestimated the impact of cancer
   interventions. (C) 2014 by American Society of Clinical Oncology}},
DOI = {{10.1200/JCO.2013.50.8952}},
ISSN = {{0732-183X}},
EISSN = {{1527-7755}},
Unique-ID = {{ISI:000331250100016}},
}

@incollection{ ISI:000291326200013,
Author = {McEnany, Geoffry Phillips},
Editor = {{Redeker, NS and McEnany, GP}},
Title = {{Sleep and Psychiatric Disorders}},
Booktitle = {{SLEEP DISORDERS AND SLEEP PROMOTION IN NURSING PRACTICE}},
Year = {{2011}},
Pages = {{195-217}},
Abstract = {{Sleep is of paramount importance to the care of people who live with
   psychiatric disorders, but the relationships between sleep and
   psychiatric disorders is complex. Sleep dysregulation is almost
   universal in psychiatric illness, whether in the form of insomnia (more
   common), hypersomnia, or disturbed circadian patterning of sleep-wake.
   Sleep disturbance and psychiatric disorders may both reflect underlying
   abnormalities in the central nervous system, and sleep symptoms are a
   component of many psychiatric diagnoses. Sleep disorders may contribute
   to or result from psychiatric disorders but may also result from
   medication treatment.
   Scientific interest in the relationship between sleep and psychiatric
   illness spans more than 30 years. Benca Obermeyer, Thisted, and Gillin
   (1992) ground-breaking historical meta-analysis of 177 studies
   representing 7,151 participants demonstrated the virtually universal
   nature of sleep disturbance and its association with psychiatric
   disorders. The objective findings revealed widespread reductions in
   sleep efficiency, total sleep time, and non-REM sleep. Although no
   single sleep alteration is specific for any particular psychiatric
   disorder, the patterns of sleep were most disturbed among patients with
   mood disorders. The investigators did not address the corollary of the
   lived experience associated with these objective changes in sleep
   architecture. However, Benca (2008) acknowledges that poor sleep
   efficiency and reduced sleep time result in sleep deprivation, namely
   daytime sleepiness, reduced energy, and possible cognitive cloudiness.
   These findings broadened the scientific perspective on sleep as a
   critical component in conceptualizing psychiatric disease, and interest
   in this area of research and practice remains strong (Krahn, 2005;
   Stores, 2007). For example, in a recent critical review on sleep and
   psychiatric disorders, Sateia (2009) documents high rates of comorbidity
   between sleep (especially insomnia) and various psychiatric disorders,
   especially mood, and anxiety disorders.
   Untreated sleep-related symptoms increase morbidity, decrease quality of
   life, and are associated with, impressive costs to the health care
   system. While there are no economic data on the overall impact of
   insomnia in the United States alone, Canadian data may provide a close
   approximation. Daley, Morin, LeBlanc, Gregoire, and Savard (2009)
   estimated the total annual cost of insomnia in the province of Quebec to
   be 6.5 billion Canadian dollars, which represents approximately 1\% of
   the province's \$228.5 billion in gross domestic product for 2002. In
   2008 in the United States alone, 56,287,000 prescriptions were dispensed
   for sleep medications, a 7\% rise since 2007. The implications of these
   data are compelling for contemporary nursing practice across all
   specialty areas of practice. Because nurses frequently care for patients
   who have insomnia, the specific approach to treatment has a powerful
   economic impact. Implementation of effective treatment strategies
   requires a detailed understanding of insomnia and the rationale behind
   effective treatment, as well as the impact of the 24-hour day. de Niet,
   Tiemens, Lendemeijer, and Hutschemaekers (2008), a group of nurse
   researchers, acknowledge that sleep disturbances are often misconstrued
   by providers as a night time concern and erroneously compartmentalize
   sleep to the darker hours of the 24-hour day. Such a myopic perspective
   will perpetuate inadequate assessment of and intervention for insomnia,
   contributing to the economic burden associated with the condition.
   This chapter will familiarize the reader with interactions between sleep
   and sleep disorders and psychiatric disorders. Implications for nurses
   who work with patients who have psychiatric disorders are discussed.
   Given the high prevalence of sleep disorders, their associations with
   medical, as well as psychiatric disorders, and their presence in
   patients who present for care across a wide range of clinical,
   community-based and hospital settings, the implications are broad.
   Patients with psychiatric disorders are treated across many practice
   settings. Therefore, the content of this chapter holds relevance for all
   nurses.
   The discussion addresses some of the most clinically salient and
   well-documented linkages between sleep and psychiatric illness and
   includes common mood disorders, anxiety disorders, schizophrenia,
   alcoholism, and attention deficit hyperactivity disorder (ADHD). The
   discussion of each diagnostic category addresses pharmacologic and
   behavioral interventions related to treatment of the particular disorder
   as it relates to sleep. Although this chapter focuses primarily on care
   of adults, childhood issues are addressed in the content related to
   ADHD. To clarify the discussion, important information is provided in a
   series of tables throughout the chapter: information on the diagnostic
   features of the disorders; changes seen in the polysomnographic changes
   in sleep across these illnesses; and the impact of pharmacologic
   treatment on sleep.}},
ISBN = {{978-0-8261-0658-2}},
Unique-ID = {{ISI:000291326200013}},
}

@article{ ISI:000304512900063,
Author = {Karas, Ismail Rakip and Demir, Sait},
Title = {{Use of geographic information systems in iron and steel industry}},
Journal = {{ENERGY EDUCATION SCIENCE AND TECHNOLOGY PART A-ENERGY SCIENCE AND
   RESEARCH}},
Year = {{2012}},
Volume = {{29}},
Number = {{2}},
Pages = {{1387-1398}},
Month = {{JUL}},
Abstract = {{Geographic Information Systems are information systems in which spatial
   data and non-spatial data are managed together. These data related to
   areas of factoring and production are allowed to be stored, processed,
   examined and analyzed together with the help of Geographic Information
   Systems, in contradistinction to other information systems. In our day,
   the use of Geographic Information Systems is becoming widespread in
   industrial foundations spread over large areas as a result of the fact
   that it contains extensive spatial data. Administrations such as
   inter-facility planning, synchronization of work groups, determining the
   most suitable areas through the use of environmental and spatial
   analyses based on location, optimization of production and
   transportation are some examples of this sort of usage. This paper is
   going to focus on the usability of Geographic Information Systems in
   iron-steel industry and bring forward proposals about Geographic
   Information Systems applications that can be implemented in an
   iron-steel plant. Advantages that will be gained through the use of
   Geographic Information Systems, time, cost and performance are going to
   be examined.}},
ISSN = {{1308-772X}},
Unique-ID = {{ISI:000304512900063}},
}

@article{ ISI:000311245400003,
Author = {Auluck, Ajit and Hislop, Greg and Bajdik, Chris and Hay, John and
   Bottorff, Joan L. and Zhang, Lewei and Rosin, Miriam P.},
Title = {{Gender- and ethnicity-specific survival trends of oral cavity and
   oropharyngeal cancers in British Columbia}},
Journal = {{CANCER CAUSES \& CONTROL}},
Year = {{2012}},
Volume = {{23}},
Number = {{12}},
Pages = {{1899-1909}},
Month = {{DEC}},
Abstract = {{A shift in etiology of oral cancers has been associated with a rise in
   incidence for oropharyngeal cancers (OPC) and decrease for oral cavity
   cancers (OCC); however, there is limited information about
   population-based survival trends. We report epidemiological transitions
   in survival for both OPC and OCC from a population-based cancer
   registry, focusing upon gender and ethnic differences.
   All primary oral cancers diagnosed between 1980 and 2005 were identified
   from the British Columbia Cancer Registry and regrouped into OPC and OCC
   by topographical subsites, time periods (1980-1993 and 1994-2005), stage
   at diagnosis, and ethnicity. Cases were then followed up to December
   2009. Using gender-based analysis, actuarial life tables were used to
   calculate survival rates, which were compared using Kaplan-Meier curves
   and log-rank tests.
   For OPC, survival improved, significant for tonsil and base of tongue in
   men and marginally significant at base of tongue in women. This
   improvement occurred in spite of an increase in late-stage diagnosis for
   OPC in both genders. Interestingly, there was no difference in survival
   for early- and late-stage disease for OPC in men. For OCC, there was a
   decrease in survival for floor of mouth cancers in both genders although
   significant in women only. South Asians had the poorest survival for OCC
   in both genders.
   Survival for OPC improved, more dramatically in men than women, in spite
   of late-stage diagnosis and increasing nodal involvement. Given the poor
   survival rates and need for early detection, targeted OCC screening
   programs are required for South Asians.}},
DOI = {{10.1007/s10552-012-0065-0}},
ISSN = {{0957-5243}},
ORCID-Numbers = {{Bottorff, Joan/0000-0001-9724-5351}},
Unique-ID = {{ISI:000311245400003}},
}

@article{ ISI:000277510300003,
Author = {Davies, Louise and Welch, H. Gilbert},
Title = {{Thyroid Cancer Survival in the United States Observational Data From
   1973 to 2005}},
Journal = {{ARCHIVES OF OTOLARYNGOLOGY-HEAD \& NECK SURGERY}},
Year = {{2010}},
Volume = {{136}},
Number = {{5}},
Pages = {{440-444}},
Month = {{MAY}},
Abstract = {{Objective: To compare the survival rate of people with papillary thyroid
   cancer limited to the thyroid gland who have not had immediate,
   definitive treatment for their thyroid cancer with the survival rate of
   those who have had such treatment.
   Design: Cohort study of incident cancer cases and initial treatment data
   from the National Cancer Institute's Surveillance, Epidemiology, and End
   Results (SEER) program. Data on cause of death was taken from the
   National Vital Statistics System.
   Patients: Patients with papillary thyroid cancer limited to the thyroid
   gland.
   Main Outcome Measure: Cancer-specific survival.
   Results: Of all eligible people in the data (n = 35 663), 1.2\% did not
   undergo immediate, definitive treatment (n = 440). The life table
   estimate of their 20-year cancer-specific survival rate was 97\% (95\%
   confidence interval {[}Cl], 96\%-100\%). The corresponding estimate for
   the patients who did receive treatment was 99\% (95\% Cl, 93\%-100\%).
   Among those who did not receive immediate, definitive treatment, 6 died
   from their cancer. This number is not statistically different from the
   number of thyroid cancer deaths in the treated group over the same
   period (n = 161) (P = .09).
   Conclusion: Papillary thyroid cancers of any size that are limited to
   the thyroid gland (no extraglandular extension or lymph node metastases
   at presentation) have favorable outcomes whether or not they are treated
   in the first year after diagnosis and whether they are treated, by
   hemithyroidectomy or total thyroidectomy.}},
ISSN = {{0886-4470}},
Unique-ID = {{ISI:000277510300003}},
}

@article{ ISI:000284491000019,
Author = {Wallace, Amy H. and Havrilesky, Laura J. and Valea, Fidel A. and
   Barnett, Jason C. and Berchuck, Andrew and Myers, Evan R.},
Title = {{Projecting the Need for Gynecologic Oncologists for the Next 40 Years}},
Journal = {{OBSTETRICS AND GYNECOLOGY}},
Year = {{2010}},
Volume = {{116}},
Number = {{6}},
Pages = {{1366-1372}},
Month = {{DEC}},
Abstract = {{OBJECTIVE: To estimate the ratio of gynecologic cancer cases to
   practicing gynecologic oncologists in the United States over the next 40
   years.
   METHODS: Using population projections from the U. S. Census Bureau and
   incidence and mortality rates from Surveillance, Epidemiology and End
   Results surveys, we estimated the annual number of new gynecologic
   cancer cases through 2050; the effects of human papillomavirus (HPV)
   vaccination was included in cervical cancer estimates. The number of
   practicing gynecologic oncologists was projected through 2050 using data
   from the 2005 Society of Gynecologic Oncologists Practice Survey,
   current Society of Gynecologic Oncologists membership information,
   American Board of Obstetrics and Gynecology and Gynecologic Oncology
   oral examination results, and mortality estimates from U. S. life
   tables. Projected time in practice was sex-dependent based on Society of
   Gynecologic Oncologists Practice Survey. For sensitivity analyses, we
   varied annual number and sex distribution of fellowship graduates, HPV
   vaccination coverage rates, and future incidence of overweight and
   obesity.
   RESULTS: At constant training rates, the annual number of new cancer
   cases per practicing gynecologic oncologist will rise from 112 in 2010
   to 133 in 2050, a 19\% increase. If the annual number of fellowship
   graduates increases by 25\%, the ratio of cancer cases per gynecologic
   oncologist will decrease to 106, a 5\% decrease. Projections are more
   sensitive to changes in physician demographics than to changes in HPV
   vaccination coverage rates.
   CONCLUSION: The gynecologic cancer caseload of practicing gynecologic
   oncologists will increase by almost 20\% over the next 40 years at
   constant training rates. Changes in the projected sex distribution of
   fellowship graduates and their time in practice affect these
   projections. (Obstet Gynecol 2010;116:1366-72)}},
DOI = {{10.1097/AOG.0b013e3181fc3a22}},
ISSN = {{0029-7844}},
Unique-ID = {{ISI:000284491000019}},
}

@article{ ISI:000230043700003,
Author = {Fishman, PA and Ebel, BE and Garrison, MM and Christakis, DA and Wiehe,
   SE and Rivara, FP},
Title = {{Cigarette tax increase and media campaign - Cost of reducing
   smoking-related deaths}},
Journal = {{AMERICAN JOURNAL OF PREVENTIVE MEDICINE}},
Year = {{2005}},
Volume = {{29}},
Number = {{1}},
Pages = {{19-26}},
Month = {{JUL}},
Abstract = {{Background: Tobacco use results in 500,000 premature deaths annually.
   Most smokers begin using tobacco before age 21, so the greatest impact
   on preventing smoking-related mortality is likely to come from campaigns
   targeting youths. This study estimates the cost-effectiveness of an
   anti-smoking media campaign and \$1 per pack increase in cigarette taxes
   on the lifetime decrease in smoking-attributable mortality among the
   cohort of all 18-year-olds in the United States during the year 2000.
   Methods: Cost-effectiveness analysis conducted from a societal
   perspective.
   Results: The combined effects of a media campaign and \$1 per pack Lax
   increase will result in a societal savings of between \$590,000 per
   life-year saved, at a 3\% discount rate and \$1.4 million per life year
   saved, at a 7\% discount rate.
   Conclusions: A media campaign and \$1 per pack cigarette tax increase
   will reduce overall smoking prevalence, significantly decrease
   smoking-attribu table mortality, and decrease net societal costs. (c)
   2005 American Journal of Preventive Medicine.}},
DOI = {{10.1016/j.amepre.2005.03.004}},
ISSN = {{0749-3797}},
ResearcherID-Numbers = {{Ebel, Beth/F-4544-2014
   Ebel, Beth/}},
ORCID-Numbers = {{Ebel, Beth/0000-0001-9310-8325}},
Unique-ID = {{ISI:000230043700003}},
}

@article{ ISI:000239674500008,
Author = {Booth, Heather},
Title = {{Demographic forecasting: 1980 to 2005 in review}},
Journal = {{INTERNATIONAL JOURNAL OF FORECASTING}},
Year = {{2006}},
Volume = {{22}},
Number = {{3}},
Pages = {{547-581}},
Abstract = {{Approaches and developments in demographic and population forecasting
   since 1980 are reviewed. Three approaches to forecasting demographic
   processes are extrapolation, expectation (individual-level birth
   expectations or population-level opinions of experts), and theory-based
   structural modelling involving exogenous variables. Models include 0-3
   factors (age, period and cohort). Decomposition and disaggregation are
   also used in multistate models, including macrosimulation and
   microsimulation. Forecasting demographic change is difficult; accuracy
   depends on the particular situation or trends, but it is not clear when
   a method will perform best. Estimates of uncertainty (model-based ex
   ante error, expert-opinion-based ex ante error, and ex post error)
   differ; uncertainty estimation is highly uncertain. Probabilistic
   population forecasts are based on stochastic population renewal or
   random scenarios. The approaches to population forecasting, demographic
   process forecasting and error estimation are closely linked.
   Complementary methods that combine approaches are increasingly employed.
   The paper summarises developments, assesses progress and considers the
   future. (c) 2006 International Institute of Forecasters. Published by
   Elsevier B.V. All rights reserved.}},
DOI = {{10.1016/j.ijforecast.2006.04.001}},
ISSN = {{0169-2070}},
EISSN = {{1872-8200}},
Unique-ID = {{ISI:000239674500008}},
}

@article{ ISI:000330354700004,
Author = {Woehrer, A. and Hackl, M. and Waldhoer, T. and Weis, S. and Pichler, J.
   and Olschowski, A. and Buchroithner, J. and Maier, H. and Stockhammer,
   G. and Thome, C. and Haybaeck, J. and Payer, F. and von Campe, G. and
   Kiefer, A. and Wuertz, F. and Vince, G. H. and Sedivy, R. and
   Oberndorfer, S. and Marhold, F. and Bordihn, K. and Stiglbauer, W. and
   Gruber-Moesenbacher, U. and Bauer, R. and Feichtinger, J. and
   Reiner-Concin, A. and Grisold, W. and Marosi, C. and Preusser, M. and
   Dieckmann, K. and Slavc, I. and Gatterbauer, B. and Widhalm, G. and
   Haberler, C. and Hainfellner, J. A. and Austrian Brain Tumour Registry},
Title = {{Relative survival of patients with non-malignant central nervous system
   tumours: a descriptive study by the Austrian Brain Tumour Registry}},
Journal = {{BRITISH JOURNAL OF CANCER}},
Year = {{2014}},
Volume = {{110}},
Number = {{2}},
Pages = {{286-296}},
Month = {{JAN 21}},
Abstract = {{Background: Unlike malignant primary central nervous system (CNS)
   tumours outcome data on non-malignant CNS tumours are scarce. For
   patients diagnosed from 1996 to 2002 5-year relative survival of only
   85.0\% has been reported. We investigated this rate in a contemporary
   patient cohort to update information on survival.
   Methods: We followed a cohort of 3983 cases within the Austrian Brain
   Tumour Registry. All patients were newly diagnosed from 2005 to 2010
   with a histologically confirmed non-malignant CNS tumour. Vital status,
   cause of death, and population life tables were obtained by 31 December
   2011 to calculate relative survival.
   Results: Overall 5-year relative survival was 96.1\% (95\% CI
   95.1-97.1\%), being significantly lower in tumours of borderline
   (90.2\%, 87.2-92.7\%) than benign behaviour (97.4\%, 96.3-98.3\%).
   Benign tumour survival ranged from 86.8 for neurofibroma to 99.7\% for
   Schwannoma; for borderline tumours survival rates varied from 83.2 for
   haemangiopericytoma to 98.4\% for myxopapillary ependymoma. Cause of
   death was directly attributed to the CNS tumour in 39.6\%, followed by
   other cancer (20.4\%) and cardiovascular disease (15.8\%).
   Conclusion: The overall excess mortality in patients with non-malignant
   CNS tumours is 5.5\%, indicating a significant improvement in survival
   over the last decade. Still, the remaining adverse impact on survival
   underpins the importance of systematic registration of these tumours.}},
DOI = {{10.1038/bjc.2013.714}},
ISSN = {{0007-0920}},
EISSN = {{1532-1827}},
Unique-ID = {{ISI:000330354700004}},
}

@article{ ISI:000250891000010,
Author = {Gonzalez, Angel and Kremers, Hilal Maradit and Crowson, Cynthia S. and
   Nicola, Paulo J. and Davis, III, John M. and Therneau, Terry M. and
   Roger, Veronique L. and Gabriel, Sherine E.},
Title = {{The widening mortality gap between rheumatoid arthritis patients and the
   general population}},
Journal = {{ARTHRITIS AND RHEUMATISM}},
Year = {{2007}},
Volume = {{56}},
Number = {{11}},
Pages = {{3583-3587}},
Month = {{NOV}},
Abstract = {{Objective. Overall. mortality rates in the general US population have
   declined substantially over the last 4-5 decades, but it is unclear
   whether patients with rheumatoid arthritis (RA) have experienced the
   same improvements in survival. The purpose of this study was to
   determine the mortality trends among RA patients compared with those in
   the general population.
   Methods. A population-based incidence cohort of RA patients was
   assembled, comprising all residents of Rochester, Minnesota ages a:18
   years in whom RA was first diagnosed (according to the American College
   of Rheumatology {[}formerly, the American Rheumatism Association] 1987
   criteria) between 1955 and 1995 and all residents of Olmsted County,
   Minnesota in whom RA was, first diagnosed between 1995 and 2000. The
   patients were followed up longitudinally through their complete
   (inpatient and outpatient) medical records until death or January 1,
   2007. Expected mortality was estimated from the National Center for
   Health Statistics life tables on the white population in Minnesota,
   using person-year methods. Poisson regression was used to model the
   observed mortality rates, adjusting for age, sex, and disease duration.
   Results. A cohort of 822 RA patients (72\% women, mean age at RA
   incidence 58 years) was followed up for a median of 11.7 years, during
   which 445 of the RA patients died. Between 1965 and 2005, the mortality
   rates across the calendar years for female and male RA patients were
   relatively constant at 2.4 and 2.5 per 100 person-years, respectively.
   In contrast, the expected mortality rate in the Minnesota white
   population decreased substantially over the same time period in both
   sexes. Mortality in the female general population declined from 1.0 per
   100 person-years in 1965 to 0.2 per 100 person-years in 2000. Mortality
   in the male general population decreased from 1.2 per 100 person-years
   in 1965 to 0.3 per 100 person-years in 2000. Therefore, the difference
   between the observed and expected mortality rates increased in more
   recent years, resulting in a widening of the mortality gap.
   Conclusion. Our findings show that RA patients have not experienced
   improvements in survival over the past 4 decades, despite dramatic
   improvements in the overall rates of mortality in the general US
   population. Further research into the causes of the widening gap in
   mortality between RA patients and the general population, and the
   influence of current therapeutic strategies on mortality, is needed in
   order to develop strategies to reduce the excess mortality observed in
   RA patients.}},
DOI = {{10.1002/art.22979}},
ISSN = {{0004-3591}},
Unique-ID = {{ISI:000250891000010}},
}

@article{ ISI:000308827800033,
Author = {Weberschock, Tobias and Strametz, Reinhard and Lorenz, Maria and
   Roellig, Christoph and Bunch, Charles and Bauer, Andrea and Schmitt,
   Jochen},
Title = {{Interventions for mycosis fungoides}},
Journal = {{COCHRANE DATABASE OF SYSTEMATIC REVIEWS}},
Year = {{2012}},
Number = {{9}},
Abstract = {{Background
   Mycosis fungoides is the most common type of cutaneous T-cell lymphoma,
   a malignant, chronic disease initially affecting the skin. Several
   therapies are available, which may induce clinical remission for a time.
   Objectives
   To assess the effects of interventions for mycosis fungoides in all
   stages of the disease.
   Search methods
   We searched the following databases up to January 2011: the Cochrane
   Skin Group Specialised Register, CENTRAL in The Cochrane Library,
   MEDLINE (from 2005), EMBASE (from 2010), and LILACS (from 1982). We also
   checked reference lists of included studies for further references to
   relevant RCTs. We searched online trials registries for further
   references to unpublished trials and undertook a separate search for
   adverse effects of interventions for mycosis fungoides in non-RCTs in
   MEDLINE in May 2011.
   Selection criteria
   Randomised controlled trials (RCTs) of interventions for mycosis
   fungoides in people with any stage of the disease. At least 90\% of
   participants in the trials must have been diagnosed with mycosis
   fungoides (Alibert-Bazin-type).
   Data collection and analysis
   Two authors independently assessed eligibility and methodological
   quality for each study and carried out data extraction. We resolved any
   disagreement by discussion. Primary outcomes were the impact on quality
   of life and the safety of interventions. When available, we reported on
   our secondary outcomes, which were the improvement or clearance of skin
   lesions, disease-free intervals, survival rates, relapse rates, and rare
   adverse effects. When possible, we combined homogeneous studies for
   meta-analysis. We used The Cochrane Collaboration's `Risk of bias' tool
   to assess the internal validity of all included studies in six different
   domains.
   Main results
   The review included 14 RCTs involving 675 participants, covering a wide
   range of interventions. Eleven of the included trials assessed
   participants in clinical stages IA to IIB only (please see Table 1 for
   definitions of these stages). Internal validity was considerably low in
   studies with a high or unclear risk of bias. The main reasons for this
   were low methodological quality or missing data, even after we contacted
   the study authors, and a mean dropout rate of 26\% (0\% to 72\%). Study
   size was generally small with a minimum of 4 and a maximum of 103
   participants. Only one study provided a long enough follow-up for
   reliable survival analysis.
   Included studies assessed topical treatments, such as imiquimod,
   peldesine, hypericin, nitrogen mustard, as well as intralesional
   injections of interferon-alpha (IFN-alpha). The light therapies
   investigated included psoralen plus ultraviolet Alight (PUVA),
   extracorporeal photopheresis (photochemotherapy), and visible light.
   Oral treatments included acitretin, bexarotene, and methotrexate.
   Treatment with parenteral systemic agents consisted of denileukin
   diftitox; a combination of chemotherapy and electron beam radiation; and
   intramuscular injections of active transfer factor. Nine studies
   evaluated therapies by using an active comparator; five were
   placebo-controlled RCTs.
   Twelve studies reported on common adverse effects, while only two
   assessed quality of life. None of these studies compared the
   health-related quality of life of participants undergoing different
   treatments. Most of the reported adverse effects were attributed to the
   interventions. Systemic treatments, and here in particular a combined
   therapeutic regimen of chemotherapy and electron beam, bexarotene, or
   denileukin diftitox, showed more adverse effects than topical or
   skin-directed treatments.
   In the included studies, clearance rates ranged from 0\% to 83\%, and
   improvement ranged from 0\% to 88\%. The meta-analysis combining the
   results of 2 trials comparing the effect of IFN-alpha and PUVA versus
   PUVA alone showed no significant difference in the relative risk of
   clearance: 1.07 (95\% confidence interval 0.87 to 1.31). None of the
   included studies demonstrated a significant increase in disease-free
   intervals, relapse, or overall survival.
   Authors' conclusions
   This review identified trial evidence for a range of different topical
   and systemic interventions for mycosis fungoides. Because of substantial
   heterogeneity in design, small sample sizes, and low methodological
   quality, the comparative safety and efficacy of these interventions
   cannot be established on the basis of the included RCTs. Taking into
   account the possible serious adverse effects and the limited
   availability of efficacy data, topical and skin-directed treatments are
   recommended first, especially in the early stages of disease. More
   aggressive therapeutic regimens may show improvement or clearance of
   lesions, but they also result in more adverse effects; therefore, they
   are to be considered with caution. Larger studies with comparable,
   clearly-defined end points for all stages of mycosis fungoides, and a
   focus on safety, quality of life, and duration of remission as part of
   the outcome measures, are necessary.}},
DOI = {{10.1002/14651858.CD008946.pub2}},
Article-Number = {{CD008946}},
ISSN = {{1469-493X}},
Unique-ID = {{ISI:000308827800033}},
}

@inproceedings{ ISI:000315350300285,
Author = {Taylor, Christine M. and Smith, Brian and Stein, David},
Book-Group-Author = {{IEEE}},
Title = {{The Role of MarineCadastre.gov in Offshore Energy Planning}},
Booktitle = {{2012 OCEANS}},
Year = {{2012}},
Note = {{MTS/IEEE Oceans Conference, Virginia Beach, VA, OCT 14-19, 2012}},
Organization = {{IEEE; Marine Technol Soc (MTS); IEEE OES (IEEE/OES)}},
Abstract = {{Many states along the U. S. East Coast are engaged in offshore wind
   energy planning through the Renewable Energy Task Force process led by
   the Bureau of Ocean Energy Management (BOEM). Participants from federal,
   state, and local government use the task forces as a venue to share
   information and minimize potential conflicts between existing ocean uses
   and offshore wind farm construction and operations. Task force
   participants often only make information available in static map form,
   making comparisons between data sets challenging. To address this, the
   North and South Carolina Renewable Energy Task Forces are collaborating
   with the MarineCadastre.gov team to facilitate data sharing.
   The National Oceanic and Atmospheric Administration (NOAA) and BOEM have
   been collaborating since 2007 on MarineCadastre. gov, an integrated
   marine information system that provides jurisdictional, legal, physical,
   ecological, and ocean use data in a common geographic information system
   (GIS) framework. The MarineCadastre. gov website was developed in
   response to a call for a marine information system to support
   alternative energy development on the outer continental shelf in section
   388 of the Energy Policy Act of 2005. Although the website has been
   designed specifically to support renewable energy siting within the U.
   S. outer continental shelf, it is also being used for various other
   ocean-related efforts. The MarineCadastre. gov website has three primary
   focus areas: Web map viewers and decision-support tools, a spatial data
   registry, and technical support and regional capacity building.
   The North and South Carolina Wind Energy Task Forces are combining
   national-scale data from the website with information specific to their
   planning areas into simple viewers available in the Map Gallery section
   of the website. This approach allows users to assess and minimize
   potential conflicts of offshore wind energy development and operation
   with existing ocean uses. Multiple issues, such as fishing, shipping,
   and defense, are viewed and considered simultaneously, in one location,
   allowing members of the task force to see their own data in a wider
   context. This enhances the utility of the information that was
   previously compared using static maps. Users can turn data layers on and
   off and pan and zoom to specific locations in the planning area as
   questions arise. The North and South Carolina Wind Energy Task Force
   data viewers are a simple but powerful mechanism for identifying areas
   of potential incompatibility, enhancing communication between task force
   members, and increasing the overall effectiveness of the task force
   process.
   The overarching goal of this work is to support the BOEM task forces in
   making sound decisions with the best available spatial information to
   facilitate responsible siting of offshore renewable energy
   infrastructure. This presentation will provide an overview of the
   primary focus areas of the MarineCadastre.gov project and its underlying
   technology, with particular attention given to the collaborations with
   the BOEM-led renewable energy task forces in North and South Carolina.
   Details on how these two BOEM task forces are incorporating use of the
   data viewers into their decision-making processes, the types of data
   being considered, and potential next steps for analyzing the spatial
   information in a group setting will be discussed.}},
ISBN = {{978-1-4673-0829-8}},
Unique-ID = {{ISI:000315350300285}},
}

@article{ ISI:000310464700018,
Author = {Mozzillo, Nicola and Ascierto, Paolo},
Title = {{Reduction of circulating regulatory T cells by intravenous high-dose
   interferon alfa-2b treatment in melanoma patients}},
Journal = {{CLINICAL \& EXPERIMENTAL METASTASIS}},
Year = {{2012}},
Volume = {{29}},
Number = {{7}},
Pages = {{801-805}},
Month = {{OCT}},
Abstract = {{High-dose interferon alfa-2b (IFN alpha-2b) is the only approved
   adjuvant systemic therapy for resected, high risk melanoma in the United
   States (Fecher and Flaherty, in Natl Compr Cancer Netw 7:295-304, 2009).
   Recently, two important meta-analyses of randomized trials (Wheatley et
   al., in J Clin Oncol, 2007; Mocellin et al. in J Natl Cancer Inst, 2010)
   investigating IFN alpha-2b versus observation in high risk melanoma
   patients, showed that adjuvant IFN alpha-2b has an impact both on
   relapse-free survival (RFS) and overall survival (OS) independently by
   dosage, duration and route compared with observation in high risk
   melanoma patients. Despite of an absolute benefits of 3 \% (Wheatley et
   al., in J Clin Oncol, 2007), this treatment is associated with
   significant toxicity, which impacts on patient quality of life. A better
   understanding of the mechanism of action may help to potentiate the
   clinical efficacy and reduce the toxicity of IFN alpha-2b/Peg-IFN
   alpha-2b. Numerous studies suggest that interferon's mechanism of action
   in melanoma is primarily immunomodulatory (Table 1) (de La Salmoniere,
   in Clin Cancer Res 6:4713-4718, 2000; Stuckert, in J Clin Oncol 25:8506,
   2007; Gogas et al., in N Engl J Med 354:709-718, 2006; Moschos et al.,
   in J Clin Oncol 24:3164-3171, 2006; Ascierto and Kirkwood, in J Transl
   Med 6:62, 2008) Recent efforts to elucidate the mechanism of action for
   interferon have focused upon signal transducers and activators of
   transcription (STAT) (Simons et al., in J Transl Med 9:52, 2011)
   signaling and immunoregulatory responses mediated by regulatory T cells
   (Tregs) (Wang et al., in Clin Cancer Res 13:1523-1531, 2007; Clin Cancer
   Res 14:8314-8320, 2008). Tregs are a suppressive CD4+ T cell population
   that is present, along with primed effector T cells, in tumor and
   tumor-draining lymph nodes (Hiura et al. in J Immunol 175:5058-5066,
   2005). Tregs express high levels of surface antigens such as CD25,
   cytotoxic T lymphocyte associated antigen 4 (CTLA-4), and
   glucocorticoid-induced tumor necrosis factor receptor (GITR) (Takahashi
   et al., in J Exp Med 192:303-310, 2000; Shimizu et al., in Nat Immunol
   3:135-142, 2002). Moreover, Tregs express a characteristic nuclear
   transcription regulator, forkhead box P3 (FoxP3) (Hori et al., in
   Science 299:1057-1061, 2003; Gabriel and Lattime, in Clin Cancer Res
   13:785-788, 2007). The presence of Tregs in tumor-draining lymph nodes
   and tumors provides a potential inhibitory population that may block or
   balance effector cell function. Thus, depletion of Tregs or blockade of
   Treg function using targeted antibodies or other strategies might be
   able to remove Treg suppression and enhance antitumor immunity (Viguier
   et al., in J Immunol 173:1444-1453, 2004). We conducted an observational
   study to examine whether the induction phase of the FDA-approved HDI
   regimen administered iv in patients with stage 3-4 melanoma (20 MU/m(2)
   intravenously (IV) five times per week for 4 weeks) reduced the number
   of Treg cells in the peripheral blood.}},
DOI = {{10.1007/s10585-012-9504-2}},
ISSN = {{0262-0898}},
Unique-ID = {{ISI:000310464700018}},
}

@inproceedings{ ISI:000327163303067,
Author = {Bransby, Martin and Shaw, George},
Book-Group-Author = {{ION}},
Title = {{ACCSEAS an e-Navigation Test Bed in Europe}},
Booktitle = {{PROCEEDINGS OF THE 25TH INTERNATIONAL TECHNICAL MEETING OF THE SATELLITE
   DIVISION OF THE INSTITUTE OF NAVIGATION (ION GNSS 2012)}},
Year = {{2012}},
Pages = {{3658-3664}},
Note = {{25th International Technical Meeting of the Satellite-Division of the
   Institute-of-Navigation, Nashville, TN, SEP 17-21, 2012}},
Organization = {{Inst Nav, Satellite Div}},
Abstract = {{The General Lighthouse Authorities of the UK and Ireland are
   participating and leading an international project in the North Sea
   Region (NSR) of Europe to plan and deliver prototype e-Navigation
   services. ACCessibility for Shipping, Efficiency Advantages and
   Sustainability (ACCSEAS) aims to identify issues which obstruct maritime
   access to the North Sea, identify solutions, prototype and demonstrate
   these successful solutions in an e-Navigation test-bed at the North Sea
   regional level as `proof-of-concept' and to develop a sustainability
   plan for future e-Navigation provision in the NSR and will look to
   inform e-Navigation initiative globally The entire process of the
   implementation of prototype solutions in the e-Navigation test-bed will
   be supported by training and simulation, so that the test-bed will have
   aspects of both real-world and simulated implementation. The project is
   part funded through the European Regional Development Fund's INTERREG
   IVB NSR initiative. European transport policy provides a shift to
   seaborne transport, using Short Sea Shipping to avoid road bottle necks
   to the movement of goods, services and people. This modal shift requires
   efficient and effective marine navigation services. The NSR, as a
   maritime hub, is at risk from increased shipping congestion and
   transport delays, safety issues and pollution/environmental risks that
   would inhibit the socio-economic development of the NSR. This is
   exacerbated by the proliferation of offshore installations (such as wind
   farms) for renewable energy.
   Globally, there is a trend towards larger bulk cargo and container
   carrying ships, which operate side-by-side with fishing boats and
   leisure craft in the same congested waters. Without the innovative
   services of e-Navigation, berth-to-berth operations may become less
   efficient. There may be increased risk of collisions and groundings,
   adversely impacting accessibility of ports and the effectiveness of
   logistics in the region. Consequences could be severe in terms of
   reduced economic sustainability, more environmental pollution incidents
   and the threat to safety-of-life.
   The International Maritime Organisation (IMO) concept of e-Navigation,
   formally recognised by the EU and the US, provides a potential solution
   via harmonised, integrated and exchangeable electronic maritime
   information on-board and ashore. The NSR, as a crossroads of regional
   and global shipping, is well positioned to benefit from an
   implementation of e-Navigation that can increase the efficient use of
   resources, provide better voyage planning and track-keeping and deliver
   improvements in regional accessibility.
   ACCSEAS aims to implement and demonstrate e-Navigation systems to
   alleviate NSR navigation risks. The aim of ACCSEAS is to identify issues
   which obstruct maritime access to the NSR, identify solutions, pilot and
   then demonstrate these successful solutions at regional level to develop
   a strategy for future e-Navigation provision. ACCSEAS builds on findings
   of previous and currently implemented related European projects and the
   ACCSEAS partnership includes several partners from those projects,
   allowing a smooth, efficient coordination between the projects and
   ensuring work is seamless without overlap.
   A regional e-Navigation service for the North Sea inherently requires a
   transnational approach. Improved maritime access can only be achieved by
   closer cooperation between competent authorities, navigation service
   providers and maritime stakeholders which encompasses: technology,
   infrastructure, services and operations within the broad policy,
   guidance and regulatory frame work of the European Union (EU), the
   International Association of Marine Aids to Navigation and Lighthouse
   Authorities (IALA) and IMO. ACCSEAS is a transnational project that
   brings together Beneficiaries (including competent navigation
   authorities from Denmark, Germany, Netherlands, Norway, Sweden and the
   United Kingdom).
   The North Sea presents unique challenges that will demand unique
   solutions both at priority locations and at the regional scale. Only
   through the NSR and the ACCSEAS project specifically, can the maritime
   administrations in the region be coordinated to address implementation
   of the e-Navigation solution to accessibility and to integrate with
   regional research providers, training organisations and suppliers.
   ACCSEAS produces four types of results and outputs: firstly, a practical
   test bed (real equipment and infrastructure in the form of e-Navigation
   prototypes and complementary simulations to test these); secondly, a
   database of information which demonstrates the effectiveness of the
   prototypes, primarily in the form of baseline information concerning
   vessel routes in the NSR and Coverage Maps of the geographical extent in
   the NSR of e-Navigation services for the prototypes that improve safe
   and efficient regional accessibility. This information will be stored
   within an ACCSEAS Geographical Information System (GIS); thirdly,
   `system of systems engineering' documentation concerning maritime access
   issues in the NSR, how the e-Navigation Prototypes and Simulations were
   developed to address these and an assessment of best practices involved
   in establishing e-Navigation regional solutions; fourthly, analysis of
   the lessons learned, advice and training needs for practical
   e-Navigation solutions; with training modules developed from this
   analysis.
   By the completion of the project in 2015, the ACCSEAS Partnership will
   have undertaken all activities to produce validated real world
   prototypes and simulations (validated by test/demonstrations to satisfy
   user requirements) including: a ship positioning unit and terrestrial
   Back-up; ship-to-shore based communications; e-Navigation services on
   ship and shore. The project should also have put in place a structure
   for co-ordination of future e-Navigation development across the NSR. The
   structure will comprise a road map for service expansion and a plan for
   the sustainability and harmonisation of e-Navigation in NSR.
   The prototypes, systems engineering lessons and training information
   will advise the further extension of e-Navigation across the NSR using a
   sustainability plan and roadmap. The results and outputs will allow the
   e-Navigation Architecture developed in the NSR by ACCSEAS to be readily
   ``transferable{''} to other EU regions and internationally. To achieve
   the transferability of outputs and results, ACCSEAS will disseminate
   information about the project to users, stakeholders, competent
   authorities, ports, policy and decision makers at national, regional
   European and International levels.}},
Unique-ID = {{ISI:000327163303067}},
}

@article{ ISI:000259575200011,
Author = {Johnson, III, Owen N. and Slidell, Mark B. and Macsata, Robyn A. and
   Faler, Byron J. and Amdur, Richard L. and Sidawy, Anton N.},
Title = {{Outcomes of surgical management for popliteal artery aneurysms: An
   analysis of 583 cases}},
Journal = {{JOURNAL OF VASCULAR SURGERY}},
Year = {{2008}},
Volume = {{48}},
Number = {{4}},
Pages = {{845-851}},
Month = {{OCT}},
Note = {{36th Annual Meeting of the Society-for-Clinical-Vascular-Surgery, Las
   Vegas, NV, MAR 05-08, 2008}},
Organization = {{Soc Clin Vasc Surg}},
Abstract = {{Background: This study aimed to analyze outcomes of surgical management
   for popliteal artery aneurysms (PAA).
   Methods: This is a retrospective analysis of prospectively collected
   data regarding operations for PAA obtained from 123 United States
   Veterans Affairs Medical Centers as part of the National Surgical
   Quality Improvement Program. Univariate analyses and multivariate
   logistic regression were used to characterize 33 risk factors and their
   associations with 30-day morbidity and mortality. Survival and
   amputation rates, observed at one and two years after surgery, were
   subject to life-table and Cox regression analyses.
   Results. There were 583 operations for PAA in 537 patients during
   1994-2005. Almost all were in men (99.8\%) and median age was 69 years
   (range, 34 to 92 years). Most had multiple co-morbidities, 88\% were ASA
   (American Society of Anesthesiologists) class 3 or 4, and 81\% were
   current or past smokers (median pack-years = 50). Only 16\% were
   diabetic. Serious complications occurred in 69 (11.8\%) cases, of which
   37 (6.3\%) required arterial-specific reinterventions. Eight patients
   died within 30 days, a mortality of 1.4\%. Risk factors associated with
   increased complications included: African-American race (odds ratio
   {[}OR] 2.8 {[}95\% confidence interval 1.5-5.2], P = .002), emergency
   surgery (OR 3.8 {[}2.0-7.0], P < .0001), ASA 4 (OR 1.9 {[}1.1-3.5], P =
   .04), dependent functional status (OR 2.5 {[}1.4-4.7], P = .004),
   steroid use (OR 3.2 {[}1.2-8.71, P = .03), and need for intraoperative
   red blood cell transfusion of any quantity (OR 6.3 {[}3.5-11.2], P <
   .0001). Independent predictors for complications in the multivariate
   model were dependent functional status (adjusted OR 2.1 {[}1.1-4.3], P =
   .049) and intraoperative transfusion (adjusted OR 4.5 {[}2.3-8.9], P =
   .0002). Postoperative bleeding complications within 72 hours
   independently predicted early amputation (adjusted OR 25.5 {[}1.7-393],
   P = .02). Unadjusted patient survival was 92.6\% at one year and 86.1\%
   at two years. Limb salvage in surviving patients was 99.0\% at 30 days,
   97.6\% at one year, and 96.2\% at two years. Dependent preoperative
   functional status was the only factor predictive of worse two-year limb
   salvage (adjusted OR 4.6 {[}1.9-10.9], P = .001), but remained high at
   88.2\% versus 97.1\% in independent patients.
   Conclusions: Surgical intervention for PAA is associated with low
   operative mortality and offers excellent two-year limb salvage, even in
   high-risk patients. Patients' preoperative functional status and
   perioperative blood transfusion requirements were the most predictive
   indicators of negative outcomes.}},
DOI = {{10.1016/j.jvs.2008.05.063}},
ISSN = {{0741-5214}},
ORCID-Numbers = {{Johnson III, Owen/0000-0001-6497-1285}},
Unique-ID = {{ISI:000259575200011}},
}

@article{ ISI:000234397700002,
Author = {Straughn, JM and Numnum, TM and Kilgore, LC and Partridge, EE and
   Phillips, JL and Markman, M and Thomas, GM and Burke, TW and Gynecologic
   Oncology Dis Site Team},
Title = {{The use of adjuvant radiation therapy in patients with intermediate-risk
   Stages IC and II uterine corpus cancer: A patient care evaluation study
   from the American College of Surgeons National Cancer Data Base}},
Journal = {{GYNECOLOGIC ONCOLOGY}},
Year = {{2005}},
Volume = {{99}},
Number = {{3}},
Pages = {{530-535}},
Month = {{DEC}},
Note = {{36th Annual Meeting of the Society-of-Gynecologic-Oncologists, Miami
   Beach, FL, MAR   20, 2005}},
Organization = {{Soc Gynecol Oncol}},
Abstract = {{Objective. To determine the outcomes of patients with intermediate-risk
   Stages IC and II uterine corpus cancer treated with surgery alone or
   surgery followed by radiation therapy.
   Methods. Patients with uterine corpus cancer diagnosed in 1995 were
   identified from hospitals in the United States with tumor registry
   databases. Data were collected on histology, surgical treatment,
   radiation therapy, recurrence, and survival. Survival analysis was
   performed using life-table computational method.
   Results. 713 hospitals submitted data on 10,726 patients with uterine
   corpus cancer. 9977 patients (93.0\%) underwent surgery, and 2624
   patients (26.3\%) received radiation therapy. Patients with clinical
   Stages IC and IIA disease who underwent surgery followed by radiation
   therapy compared to surgery alone had a trend toward improved 5-year
   relative survival (RS) (81.2\% vs. 92.5\%; 74.3\% vs. 96.0\%,
   respectively). The 5-year RS of patients with surgical Stage IC disease
   was not statistically different between the surgery alone group and the
   radiation group (93.9\% vs. 91.7\%). Patients with surgical Stage IIA
   and IIB disease did not benefit from radiation therapy compared to
   surgery alone (5-year RS; 83.7\% vs. 98.0\% and 82.3\% vs. 81.8\%,
   respectively).
   Conclusion. There is a trend toward improved survival in patients with
   clinical Stages IC and IIA uterine corpus cancer when radiation therapy
   is utilized following surgery. The survival of patients with surgical
   Stages IC and II uterine corpus cancer is not improved with adjuvant
   radiation therapy. (c) 2005 Elsevier Inc. All rights reserved.}},
DOI = {{10.1016/j.ygyno.2005.08.034}},
ISSN = {{0090-8258}},
Unique-ID = {{ISI:000234397700002}},
}

@article{ ISI:000232973700016,
Author = {Perez-Eman, JL},
Title = {{Molecular phylogenetics and biogeography of the Neotropical redstarts
   (Myioborus; Aves, Parulinae)}},
Journal = {{MOLECULAR PHYLOGENETICS AND EVOLUTION}},
Year = {{2005}},
Volume = {{37}},
Number = {{2}},
Pages = {{511-528}},
Month = {{NOV}},
Abstract = {{Montane areas in the Neotropics are characterized by high diversity and
   endemism of birds and other groups. The avian genus Myioborus
   (Parulinae) is a group of insectivorous warblers, characteristic of
   cloud forests, that represents one of the few Parulinae genera (New
   World warblers) that has radiated substantially in South America. The
   genus is distributed throughout most montane regions from the
   southwestern United States to northern Argentina. Here, I use
   mitochondrial sequences from the cytochrome b, ND2, and ND3 genes to
   present the first hypothesis of phylogenetic relationship among all
   Myioborius species level taxa. Phylogenetic reconstructions based on
   maximum parsimony, maximum likelihood, and Bayesian methods produced
   similar results and suggest a northern origin for the genus Myioborius
   with subsequent colonization of the Neotropical Montane Region. The
   lower-montane species, M. miniatus, is the sister taxon to a clade in
   which all taxa occupy upper-montane habitats. These ``highland{''} taxa
   diverged early in the history of the genus and produced two well-defined
   monophyletic lineages, a Central-northern Andean clade formed by M.
   albifrons, M. ornatus, and M. melanocephalus, and a Pantepui
   (table-mountains of southern Venezuela, northern Brazil, and western
   Guyana) clade consisting of M. castaneocapillus, M. albifacies, and M.
   cardonai, and probably M. pariae. M. brunniceps, M. flavivertex, and M.
   torquatus were included in this upper-montane clade but without clear
   relationships to other taxa. Lack of resolution of nodes defining the
   upper-montane species clade is likely to result from a period of rapid
   diversification mediated by geological and climatic events during the
   Late Pliocene. These results suggest that an interplay of dispersal and
   vicariance has shaped the current biogeographic patterns of Myioborus.
   (c) 2005 Published by Elsevier Inc.}},
DOI = {{10.1016/j.ympev.2005.04.013}},
ISSN = {{1055-7903}},
Unique-ID = {{ISI:000232973700016}},
}

@article{ ISI:000343852200013,
Author = {Rubio-Rivas, Manuel and Royo, Cristina and Pilar Simeon, Carmen and
   Corbella, Xavier and Fonollosa, Vicent},
Title = {{Mortality and survival in systemic sclerosis: Systematic review and
   meta-analysis}},
Journal = {{SEMINARS IN ARTHRITIS AND RHEUMATISM}},
Year = {{2014}},
Volume = {{44}},
Number = {{2}},
Pages = {{208-219}},
Month = {{OCT}},
Abstract = {{Objective: To determine the mortality, survival, and causes of death in
   patients with systemic sclerosis (SSc) through a meta-analysis of the
   observational studies published up to 2013.
   Methods: We performed a systematic review and meta-analysis of the
   observational studies in patients with SSc and mortality data from
   entire cohorts published in MEDLINE and SCOPUS up to July 2013.
   Results: A total of 17 studies were included in the mortality
   meta-analysis from 1964 to 2005 (mid-cohort years), with data from 9239
   patients. The overall SMR was 2.72 (95\% CI: 1.93-3.83). A total of 43
   studies have been included in the survival meta-analysis, reporting data
   from 13,529 patients. Cumulative survival from onset (first Raynaud's
   symptom) has been estimated at 87.6\% at 5 years and 74.2\% at 10 years,
   from onset (non-Raynaud's first symptom) 84.1\% at 5 years and 75.5\% at
   10 years, and from diagnosis 74.9\% at 5 years and 62.5\% at 10 years.
   Pulmonary involvement represented the main cause of death.
   Conclusions: SSc presents a larger mortality than general population
   (SMR = 2.72). Cumulative survival from diagnosis has been estimated at
   74.9\% at 5 years and 62.5\% at 10 years. Pulmonary involvement
   represented the main cause of death. (C) 2014 Elsevier Inc. All rights
   reserved.}},
DOI = {{10.1016/j.semarthrit.2014.05.010}},
ISSN = {{0049-0172}},
EISSN = {{1532-866X}},
ORCID-Numbers = {{corbella, xavier/0000-0001-9889-0272}},
Unique-ID = {{ISI:000343852200013}},
}

@inproceedings{ ISI:000356505100122,
Author = {Manuel Velasco, Jose and Gonzalez-Perez, Beatriz and Minana, Guadalupe
   and Lopez, Victoria and Caro, Raquel},
Editor = {{Wang, Y and Li, X and Cai, H}},
Title = {{An Explanatory Analysis of Electricity Prices within Day-Ahead Spanish
   Energy Market by Using a Graphical Automatization with R}},
Booktitle = {{PROCEEDINGS OF 2014 IEEE INTERNATIONAL CONFERENCE ON PROGRESS IN
   INFORMATICS AND COMPUTING (PIC)}},
Year = {{2014}},
Pages = {{631-636}},
Note = {{2nd IEEE International Conference on Progress in Informatics and
   Computing (PIC), Shanghai, PEOPLES R CHINA, MAY 16-18, 2014}},
Organization = {{IEEE; IEEE Beijing Sect; Shanghai Univ Finance \& Econ; Shanghai Jiao
   Tong Univ; Univ Technol Sydney; Donghua Univ}},
Abstract = {{Since 1998, the Spanish and Portuguese Administrations began to share a
   common path in building the Iberian Electricity Market (MIBEL). This
   cooperation has been very successful, not only for its contribution to
   the existence of an electricity market on an Iberian level, but also on
   a European scale, as a significant step in building the Internal Energy
   Market. The price of electricity in the MIBEL is very changeable. This
   creates a lot of uncertainty and risk in market actors. Due to
   continuous changes in demand and marginal price adjustment, buyers and
   sellers can not know in advance the evolution of prices. Our interest is
   to study of this uncertainty since the perspective of the buyer and not
   the seller's perspective. The aim of this work is to develop a graphical
   analysis of the variables involved in the Spanish Energy Market in order
   to explain the electric price and provide to small traders, that could
   be interested in participating in that market, better knowledge of the
   schedule. On the other hand, large industrial consumers use this
   information to design strategies to optimize its production capacity and
   improve their production costs. In this article the variable of interest
   is the marginal price instead of demand. This paper provides a graphical
   analysis by means of an easily reproducible automatization with the R
   project for statistical computing that allows to explore, visualize and
   understand the key variables that define its final value. Mibel 2011 and
   2012 data are used for ilustrations. The results show the importance of
   the calendar effect, seasonality and trend as principal factors to take
   into account for posterior fases: modeling and forecasting.}},
ISBN = {{978-1-4799-2030-3}},
Unique-ID = {{ISI:000356505100122}},
}

@inproceedings{ ISI:000076709300013,
Author = {Kyvelou-Chiotini, S and Karakos, A},
Editor = {{Butera, F and Grassi, A and Helm, P and Landabaso, A and Zervos, A}},
Title = {{Development of an energy management program for public administration
   buildings in Greece}},
Booktitle = {{REBUILD - THE EUROPEAN CITIES OF TOMORROW: SHAPING OUR EUROPEAN CITIES
   FOR THE 21ST CENTURY}},
Year = {{1998}},
Pages = {{45-48}},
Note = {{2nd European Conference on Shaping our European Cities for the 21st
   Century, FLORENCE, ITALY, APR 01-03, 1998}},
Organization = {{Commiss European Communities}},
Abstract = {{In Greece, government-related services and facilities are large energy
   users and important customers for energy-using products and services.
   Their energy savings potential is significant due to a relatively old
   building stock and a longer financial horizon for efficiency
   investments. In a context of integrating administrative modernization
   into spatial planning, modem management instruments are being developed
   by greek administration to meet sustainability targets. Energy
   management has been considered as an important instrument related to
   rational use of energy and use of renewable energy sources towards total
   quality management in public administration and a sustainable urban
   environment as well. The approach that we will attempt to develop in
   this paper concerns energy policy integrated in public administration
   reform. It concerns the role and contribution of public services' energy
   modernisation in (rebuilding) a sustainable urban environment or the
   role of public administration in sustainable urban planning and finally
   in sustainable development. The paper will be structured around three
   elements :First around the role of services' modernisation in
   (rebuilding),, a sustainable urban environment, secondly around me
   development of a comprehensive energy management program recently
   initiated in the greek public administration and especially on its part
   concerning public administration buildings all over Greece and thirdly
   about an energy management information system, designed so as to be used
   by public authorities at regional level and especially in a rural area
   with small and medium-sized cities.}},
Unique-ID = {{ISI:000076709300013}},
}

@article{ ISI:000319237900010,
Author = {Aydin, Nazli Yonca and Kentel, Elcin and Duzgun, H. Sebnem},
Title = {{GIS-based site selection methodology for hybrid renewable energy
   systems: A case study from western Turkey}},
Journal = {{ENERGY CONVERSION AND MANAGEMENT}},
Year = {{2013}},
Volume = {{70}},
Pages = {{90-106}},
Month = {{JUN}},
Abstract = {{Renewable energy sources are presently being considered as alternatives
   to fossil fuels, because they are perpetual, environmentally friendly,
   and release negligible amounts of greenhouse gases to the atmosphere
   while producing energy. A disadvantage of renewable energy systems,
   however, is that continuous energy generation is not possible by using
   only one type of renewable energy system, since renewable energy
   resources depend on climate and weather conditions. Two or more
   renewable energy systems can be integrated into a hybrid system to
   overcome this problem so that when one resource is not available, the
   other can continue producing energy. Another disadvantage of renewable
   energy sources is that they are not available at every geographic
   location. Their use is mostly advantageous at remote locations that
   often are of high ecological value. Thus, identification of preferable
   locations for renewable energy systems is a decision-making problem that
   requires evaluation of the potential of the resource together with
   economic and environmental limitations. This paper introduces a
   methodology for site selection of hybrid wind solar-PV renewable energy
   systems. First, environmental acceptability and economic feasibility
   objectives are identified through a comprehensive review of the
   literature, current Turkish laws and legislations, and interviews with
   the General Directorate of Electrical Power Resources Survey and
   Development Administration of Turkey. Second, viable locations in terms
   of environmental acceptability and economic feasibility are determined
   through a fuzzy decision-making procedure that uses ordered weighted
   averaging algorithm for aggregating multiple objectives. Then, priority
   sites are identified separately for wind and solar energy systems by
   using Geographic Information System (GIS) and finally associated maps
   are overlaid to obtain the most feasible locations for hybrid wind
   solar-PV systems. (C) 2013 Elsevier Ltd. All rights reserved.}},
DOI = {{10.1016/j.enconman.2013.02.004}},
ISSN = {{0196-8904}},
Unique-ID = {{ISI:000319237900010}},
}

@article{ ISI:000306212200002,
Author = {Vinsel, Lee Jared},
Title = {{The crusade for credible energy information and analysis in the United
   States, 1973-1982}},
Journal = {{HISTORY AND TECHNOLOGY}},
Year = {{2012}},
Volume = {{28}},
Number = {{2}},
Pages = {{149-176}},
Abstract = {{Until the oil-based `energy crisis' of 1973, the American Petroleum
   Institute and other private interests created the vast majority of
   energy statistics consumed in the United States. As the OPEC embargo set
   in, however, the American Petroleum Institute and the petroleum
   companies fell under a pall of perceived conspiracy. The US executive
   branch began creating its own statistics as part of the newly created
   Federal Energy Agency, but legislators quickly came to believe that the
   agency was purposely skewing the data to support the president's
   policies. In this context, Congress set about, again, to create a
   statistics-building group, which became known as the Energy Information
   Administration, that would be `independent' from both presidential and
   legislative politics and that could manufacture trust. This article
   argues that federal bureaucrats used various means, both interpersonal
   and mechanical (mathematical and statistical), to build credible energy
   information and analysis.}},
DOI = {{10.1080/07341512.2012.694206}},
ISSN = {{0734-1512}},
Unique-ID = {{ISI:000306212200002}},
}

@article{ ISI:000173040000003,
Author = {Hobbs, M and Mellish, M and Murphy, FH and Newcombe, R and Sanders, R
   and Whitman, P},
Title = {{Rebuilding the coal model in the energy information administration's
   National Energy Modeling system}},
Journal = {{INTERFACES}},
Year = {{2001}},
Volume = {{31}},
Number = {{5}},
Pages = {{24-42}},
Month = {{SEP-OCT}},
Abstract = {{The Energy Information Administration uses the National Energy Modeling
   System (NEMS) to forecast prices and quantities in energy markets. The
   coal model that the Energy Information Administration first used in NEMS
   contributed to convergence problems in NEMS because of its design.
   Furthermore, because the coal model could not be modified efficiently to
   incorporate the new sulfur dioxide market created by the Clean Air Act
   Amendments of 1990, we had to build a new model. Building the new model
   also allowed us to incorporate improved knowledge about coal resources
   and other aspects of coal markets, further improving the quality of the
   forecasts.}},
DOI = {{10.1287/inte.31.5.24.9651}},
ISSN = {{0092-2102}},
Unique-ID = {{ISI:000173040000003}},
}

@article{ ISI:000079973500002,
Author = {Zeyner, A and Harmeyer, J},
Title = {{Metabolic functions of L-carnitine and its effects as feed additive in
   horses. A review}},
Journal = {{ARCHIVES OF ANIMAL NUTRITION-ARCHIV FUR TIERERNAHRUNG}},
Year = {{1999}},
Volume = {{52}},
Number = {{2}},
Pages = {{115-138}},
Abstract = {{L-carnitine, a betaine derivative of beta-hydroxybutyrate, is found in
   virtually all cells of higher animals and also in some microorganisms
   and plants. In animals it is synthesized almost exclusively in the
   liver. Two essential amino acids, i.e., lysine and methionine serve as
   primary substrates for its biosynthesis. Also required for its synthesis
   are sufficient amounts of vitamin B-6, nicotinic acids, vitamin C and
   folate. The first discovered ergogenic function of L-carnitine is the
   transfer of activated long-chain fatty acids across the inner
   mitochondrial membrane into the mitochondrial matrix. For this transfer
   acyl-CoA esters are transesterified to form acylcarnitine esters. Thus,
   in carnitine deficiency fat oxidation and energy production from fatty
   acids are markedly impaired. Skeletal muscles constitute the main
   reservoir of carnitine in the body and have a carnitine concentration at
   least 200 times higher than blood plasma. Uptake of carnitine by
   skeletal muscles takes place by an active transport mechanism which
   transports L-carnitine into muscles probably in the form of an exchange
   process with gamma-butyrobetain.
   In young animals including foals, the capacity for biosynthesis of
   carnitine is not yet fully developed and apparently cannot meet the
   requirements of sucking animals. Sucking animals depend therefore on an
   extra supply of carnitine which is usually provided with milk.
   Additionally, young animals including foals possess a lower
   concentration of carnitine in blood plasma than adult animals. Besides
   its role as carrier of activated acyl groups, L-carnitine functions as a
   buffer for acetyl groups which may be present in excess in different
   tissues during ketosis and hypoxic muscular activity.
   Other functions of L-carnitine are protection of membrane structures.
   stabilizing of a physiologic CoA-SH/acetyl-CoA ratio and reduction of
   lactate production. Animal's derived feeds are rich in L-carnitine
   whereas plants contain usually very little or no carnitine. Carnitine is
   absorbed from the small intestine by active and passive transport
   mechanisms. From the increase in renal excretion of L-carnitine after
   oral supplementations of 10 g/d to horses it has been concluded that the
   efficiency of absorption of L-carnitine is rather low (about 5 to 10\%
   of the supplied dose). A further decrease in fractional carnitine
   absorption was observed when the oral dose of carnitine was increased.
   L-carnitine is virtually not degraded in the body and renal excretion of
   carnitine is comparatively small under normal conditions. The
   concentration of L-carnitine in blood plasma of horses varies markedly
   between animals and between different days. In addition, circadian
   changes in carnitine concentration in plasma have been reported. Peak
   concentrations were found during late afternoon, being up to 30\% higher
   than those in the morning.
   In breeding mares the carnitine concentration in blood plasma declines
   with onset of lactation. In resting skeletal muscles about 90\% of the
   total carnitine content is present as free carnitine with the remaining
   part being available as carnitine esters. With increasing exercise
   intensity a continuing greater proportion of free carnitine (up to 80\%)
   is converted into carnitine esters, mainly into acetylcarnitine. This
   shift from free to acetylcarnitine is readily reversed within about 30
   min after termination of exercise. It appears that acute exercise does
   not have a marked effect on the content of total carnitine in skeletal
   muscle whereas training seems to elevate its total concentration in the
   middle gluteal muscle of 3 to 6 year old horses and to reduce variation
   of its concentration compared to age-matched untrained horses.
   Oral supplementations of 5 to 50 g of L-carnitine per day to horses
   elevated the carnitine concentration in blood plasma to about twice its
   basal concentration. No clear relationship existed, however, between the
   orally administered dose of carnitine and the increase of L-carnitine
   concentration in blood plasma.
   Oral supplementations of carnitine also tended to elevate the carnitine
   concentration in milk of mares and in blood plasma of sucking foals.
   Long-term oral administration of L-carnitine (e.g., for months) also
   appeared to increase the carnitine concentration in skeletal muscles.
   But information is lacking as to whether such administrations also
   affect physical performance of the exercising muscle. Oral
   supplementation of carnitine to horses reduced the resting values of
   lactate in plasma and appeared to reduce the concentration of
   non-esterified fatty acids in plasma during exercise. These effects of
   carnitine appeared also to be influenced by the amount and type of fat
   which is contained in the feed. Oral supplementations of carnitine to
   stallions mag. improve impaired motility of sperm, improvements of feed
   conversion and weight gain in growing horses due to oral
   supplementations of carnitine have been reported. But these preliminary
   findings probably require further confirmation.
   Further studies are also required to better evaluate possible effects of
   oral supplementations of carnitine on energy metabolism, cardiac
   functions and physical performance in horses at rest and during
   exercise, and to perhaps better characterize the conditions under which
   carnitine may be beneficial to horses.}},
ISSN = {{0003-942X}},
Unique-ID = {{ISI:000079973500002}},
}

@article{ ISI:000348880600020,
Author = {Hernandez-Escobedo, Q. and Rodriguez-Garcia, E. and Saldana-Flores, R.
   and Fernandez-Garcia, A. and Manzano-Agugliaro, F.},
Title = {{Solar energy resource assessment in Mexican states along the Gulf of
   Mexico}},
Journal = {{RENEWABLE \& SUSTAINABLE ENERGY REVIEWS}},
Year = {{2015}},
Volume = {{43}},
Pages = {{216-238}},
Month = {{MAR}},
Abstract = {{The development of renewable energy has increased over the past few
   years due to the high cost of fossil fuels and our great dependence on
   them. Solar energy has been evaluated in the majority of developed
   countries. Mexico is known to possess large quantities of renewable
   energy resources, for example, approximately 6000 MW of wind energy
   resources. Nevertheless, solar energy is not sufficiently developed in
   Mexico. In this work, the global solar resources in Mexican states along
   the Gulf of Mexico were assessed. The data used in the analysis were
   obtained from the Automatic Meteorological Stations (AMEs) of the
   National Meteorological Service of Mexico (NMS) every 10 min over a
   period of 10 years, as well as from the Surface Meteorology and Solar
   Energy (SMSE) of the National Aeronautics and Space Administration
   (NASA) every month over 22 years. AMEs and SMSE validation data were
   compared to calculate their determination coefficient, R-2, which was
   above 90\%. A total of 13 maps generated by a Geographic Information
   System (GIS), one per month, and annually averaged global solar
   resources were used to determine the areas and the periods of the year
   with the greatest global solar energy resources. According to the
   results obtained in this study, the highest amount of solar energy,
   i.e., greater than 622 kWh/m(2)/day, was registered on July in the state
   of Tamaulipas. Based on the average annual energy map, the southern
   region of Veracruz State registered the largest resource, i.e., greater
   than 5.03 kWh/m(2)/day. From the foregoing analysis, the primary
   conclusion arrived at in the present work is that solar energy has
   significant potential for complementing energetic requirements in
   Mexican states along the Gulf of Mexico. It is recommended that the
   government adopt policies supporting and promoting the utilization of
   solar energy to maintain fossil fuel reserves and to reduce greenhouse
   gases. (C) 2014 Elsevier Ltd. All rights reserved.}},
DOI = {{10.1016/j.rser.2014.10.025}},
ISSN = {{1364-0321}},
ResearcherID-Numbers = {{Manzano-Agugliaro, Francisco/K-8184-2014}},
ORCID-Numbers = {{Manzano-Agugliaro, Francisco/0000-0002-0085-030X}},
Unique-ID = {{ISI:000348880600020}},
}

@article{ ISI:000312620000075,
Author = {Comodi, Gabriele and Cioccolanti, Luca and Polonara, Fabio and Brandoni,
   Caterina},
Title = {{Local authorities in the context of energy and climate policy}},
Journal = {{ENERGY POLICY}},
Year = {{2012}},
Volume = {{51}},
Pages = {{737-748}},
Month = {{DEC}},
Abstract = {{Several measures to boost the energy system towards a low-carbon future
   can be planned and implemented by local authorities, such as
   energy-saving initiatives in public buildings and lighting, information
   campaigns, and renewable energy pilot projects. This work analyzes the
   public administration's role in energy and climate policies by assessing
   carbon-lowering measures for properties and services managed directly by
   local governments in central Italy.
   Both short- and long-term schemes were considered in the analysis of
   local authority energy strategies. The MARKAL-TIMES energy model was
   applied to long-term energy planning to assess the effect of low-carbon
   initiatives on public-sector energy consumption up to 2030. Two energy
   scenarios were built, i.e. a Business As Usual (BAU) scenario based on
   current or soon-to-be-adopted national policies, and an Exemplary Public
   Scenario (EPS) including some further virtuous local policies suggested
   by local authorities.
   Our results show that a 20\% primary energy reduction can be achieved
   with respect to the baseline year by means of short-term energy policies
   (5-year time span), while a primary energy saving of about 30\% can be
   reached with longer-term energy policies (25-year time span), even after
   taking the increase in energy demand into account.
   This work goes to show the part that local governments can play in
   energy policy and their contribution to the achievement of climate
   goals. (C) 2012 Elsevier Ltd. All rights reserved.}},
DOI = {{10.1016/j.enpol.2012.09.019}},
ISSN = {{0301-4215}},
ResearcherID-Numbers = {{Comodi, Gabriele/A-2990-2012
   Cioccolanti, Luca/}},
ORCID-Numbers = {{Comodi, Gabriele/0000-0003-4606-5283
   Cioccolanti, Luca/0000-0002-1306-8624}},
Unique-ID = {{ISI:000312620000075}},
}

@article{ ISI:000266442100003,
Author = {Ozalp, Nesrin},
Title = {{Utilization of Heat, Power, and Recovered Waste Heat for Industrial
   Processes in the US Chemical Industry}},
Journal = {{JOURNAL OF ENERGY RESOURCES TECHNOLOGY-TRANSACTIONS OF THE ASME}},
Year = {{2009}},
Volume = {{131}},
Number = {{2}},
Month = {{JUN}},
Note = {{2nd International Conference on Energy Sustainability, Jacksonville, FL,
   AUG 10-14, 2008}},
Organization = {{ASME, Adv Energy Syst Div; ASME, Solar Energy Div}},
Abstract = {{This paper presents energy end-use model of the U.S. Chemical Industry.
   The model allocates combustible fuel and renewable energy inputs among
   generic end-uses including intermediate conversions through on-site
   power and steam generation. The results of this model provide the basis
   to scale energy process-step models. The main federal database to
   construct energy end-use models is Manufacturing Energy Consumption
   Survey of the U.S. Energy Information Administration. This database
   provides information on how much energy is used for each end-use on a
   national scale in each industry. The secondary federal database to
   construct the energy end-use models is the Energy Information
   Administration's ``EIA-860B: Annual Electric Generator Report.{''} This
   database provides information about fuel consumed, gross generation, and
   recovered waste heat at the prime mover level of detail. The results of
   the model show that the majority of the fuel input is used directly for
   the end-uses. Although the rest of the fuel is used to generate steam
   and power, most of this energy contributes to the end-uses as steam.
   Therefore, the purpose of fuel consumption at nonutility plants is to
   run their end-uses. During the course of this study, the most recent
   U.S. federal energy database available was for the year 1998. Currently,
   the most recent available U.S. federal energy database is given for the
   year 2002 based on the data collected from 15,500 establishments.}},
DOI = {{10.1115/1.3120382}},
Article-Number = {{022401}},
ISSN = {{0195-0738}},
Unique-ID = {{ISI:000266442100003}},
}

@article{ ISI:000328789400009,
Author = {Hadian, Saeed and Madani, Kaveh},
Title = {{The Water Demand of Energy: Implications for Sustainable Energy Policy
   Development}},
Journal = {{SUSTAINABILITY}},
Year = {{2013}},
Volume = {{5}},
Number = {{11}},
Pages = {{4674-4687}},
Month = {{NOV}},
Abstract = {{With energy security, climate change mitigation, and sustainable
   development as three main motives, global energy policies have evolved,
   now asking for higher shares of renewable energies, shale oil and gas
   resources in the global energy supply portfolios. Yet, concerns have
   recently been raised about the environmental impacts of the renewable
   energy development, supported by many governments around the world. For
   example, governmental ethanol subsidies and mandates in the U. S. are
   aimed to increase the biofuel supply while the water footprint of this
   type of energy might be 70-400 times higher than the water footprint of
   conventional fossil energy sources. Hydrofracking, as another example,
   has been recognized as a high water-intensive procedure that impacts the
   surface and ground water in both quality and quantity. Hence, monitoring
   the water footprint of the energy mix is significantly important and
   could have implications for energy policy development. This paper
   estimates the water footprint of current and projected global energy
   policies, based on the energy production and consumption scenarios,
   developed by the International Energy Outlook of the U. S. Energy
   Information Administration. The outcomes reveal the amount of water
   required for total energy production in the world will increase by
   37\%-66\% during the next two decades, requiring extensive improvements
   in water use efficiency of the existing energy production technologies,
   especially renewables.}},
DOI = {{10.3390/su5114674}},
ISSN = {{2071-1050}},
ResearcherID-Numbers = {{Madani, Kaveh/E-9366-2011}},
ORCID-Numbers = {{Madani, Kaveh/0000-0003-0378-3170}},
Unique-ID = {{ISI:000328789400009}},
}

@article{ ISI:000351788700014,
Author = {Lin, Boqiang and Wang, Ailun},
Title = {{Estimating energy conservation potential in China's commercial sector}},
Journal = {{ENERGY}},
Year = {{2015}},
Volume = {{82}},
Pages = {{147-156}},
Month = {{MAR 15}},
Abstract = {{With low energy intensity and great potential for growth, the commercial
   sector has become one of the key sectors for energy conservation and
   emission reduction in the context of China's rapid urbanization process.
   Based on the EIA (Energy Information Administration) statistical
   methods, this paper calculates the energy consumption of China's
   commercial sector from 1981 to 2012, specifies the determinants of
   commercial energy demand, forecasts future energy consumption and
   estimates the energy conservation potentials using the Johansen
   co-integration methodology. The results indicate: (i) GDP (Gross
   Domestic Product) and urbanization have positive effects on the energy
   consumption of the commercial sector while labor productivity and energy
   price contribute to reduction in the sector's energy consumption. (ii)
   Under the basic scenario, energy consumption of the commercial sector
   will be 317.34 and 469.84 Mtce (million tons of coal equivalent) in 2015
   and 2020 respectively. (iii) Under the moderate and advanced scenario,
   about 187.00 and 531.45 Mtce respectively of the energy consumption of
   the commercial sector can be conserved from 2013 to 2020. The findings
   have important implications for policy-makers to enact energy-saving
   policies. (C) 2015 Elsevier Ltd. All rights reserved.}},
DOI = {{10.1016/j.energy.2015.01.021}},
ISSN = {{0360-5442}},
EISSN = {{1873-6785}},
Unique-ID = {{ISI:000351788700014}},
}

@inproceedings{ ISI:000281966900023,
Author = {Hu, Yang and Archer, David H. and Yin, Hongxi},
Book-Group-Author = {{ASME}},
Title = {{DESIGN AND MODEL BASED PERFORMANCE ANALYSIS OF A DISTRICT ENERGY SUPPLY
   SYSTEM}},
Booktitle = {{ES2009: PROCEEDINGS OF THE ASME 3RD INTERNATIONAL CONFERENCE ON ENERGY
   SUSTAINABILITY, VOL 2}},
Year = {{2009}},
Pages = {{187-196}},
Note = {{3rd International Conference on Energy Sustainability, San Francisco,
   CA, JUL 19-23, 2009}},
Organization = {{ASME, Adv Energy Syst Div; ASME, Solar Energy Div}},
Abstract = {{A district energy supply system for Almono, Pittsburgh has been studied
   by the Center for Building Performance and Diagnostics, Carnegie Mellon
   University. Almono is a mixed residential/commercial redevelopment
   proposed for a 178 acre brown field site on the banks of the Monongahela
   River in Pittsburgh, PA. The district energy supply system would provide
   electric power, cooling, and heating for the occupants and the buildings
   of the site and for possible additional energy based developments.
   The various energy requirements of Almono's proposed residential and
   commercial buildings for power, cooling, heating, and hot water have
   been estimated first based on Energy Information Administration data
   (1993), and then again on the advanced building code of the
   International Energy Conservation Code 2006 (IECC 2006). A comparison of
   these estimates highlights the importance of building envelopes on the
   energy requirements of the Almono development. The daily and seasonal
   load profiles for power, cooling, and heating that challenge efficient
   and economic operation of district energy supply have been developed.
   Various prime mover technologies for combined cooling/heating/power,
   CCHP, systems have been considered: gas turbine, internal combustion
   engine, and steam turbine. These technologies affect the choice of fuel,
   and the fractions of power and heat provided.
   The paper estimates loads of the Almono site based on the operation and
   performance of both conventional and advanced residential and commercial
   office buildings, suggests additional energy loads that would provide
   for improved technical and economic performance of system, and considers
   the selection of a fuel and the use of solar energy as the energy
   sources. It presents preliminary overall flow diagrams for various
   district energy supplies that include various possible fuel and solar
   energy inputs, and use of the river as a heat source/sink. It also
   comments on operation of the district energy supply to meet the hourly
   and seasonal energy loads of the Almono site.}},
ISBN = {{978-0-7918-4890-6}},
Unique-ID = {{ISI:000281966900023}},
}

@inproceedings{ ISI:000350462600005,
Author = {Reznikov, Dmitry O.},
Editor = {{Makhutov, NA and Baecher, GB}},
Title = {{Technological and Intelligent Terrorism: Specific Features and
   Assessment Approaches}},
Booktitle = {{COMPARATIVE ANALYSIS OF TECHNOLOGICAL AND INTELLIGENT TERRORISM IMPACTS
   ON COMPLEX TECHNICAL SYSTEMS}},
Series = {{Nato Science for Peace and Security Series E-Human and Societal Dynamics}},
Year = {{2012}},
Volume = {{102}},
Pages = {{45-60}},
Note = {{NATO Advanced Research Workshop on Comparative Analysis of Technological
   and Sociological Consequences of Terrorism, Moscow, RUSSIA, APR 05-07,
   2011}},
Organization = {{NATO}},
Abstract = {{The paper addresses specific features of assessing terrorist risks for
   complex technical systems (CTS). These include feedback between CTS
   vulnerability towards a specific type of terrorist attack and the threat
   of such attack, ability of terrorists to learn lessons from previous
   attacks, react upon actions taken by counterterrorist forces; high level
   of uncertainty regarding terrorists' intentions, resources, and system
   of values. Conventional safety analysis for CTS is to be focused on the
   question: What is the way for an accident scenario to be realized in the
   given system? When addressing security problems for CTS one should also
   consider the situation from the terrorist's standpoint. Hence the
   modified question for security analysis should be: What is to be done
   for the given scenario to be realized in CTS? Two types of attacks at
   complex technical systems are assessed: (1) Attack of technological
   terrorism implies powerful unauthorized impacts at CTS capable of: (a)
   breaking through the CTS protection system; (b) initiating secondary
   catastrophic processes due to hazardous substances, energy, and
   information, stored or processed at the CTS; (c) escalation of the
   accident outside the CTS boundaries with substantially increased
   secondary and cascade losses. (2) Attack of intelligent terrorism (smart
   terrorism, insiders terrorism), i.e. a purposeful unauthorized
   interference into the process of designing, building and/or operating
   the CTS aimed at the increase of its existing vulnerabilities and
   creation of new ones in the system so that to use these input
   vulnerabilities, insider's knowledge of the system and access to its
   elements for future realization of most disastrous scenarios of a
   terrorist attack. Comparative assessment of these two types of terrorism
   is presented. Dynamic three-sided models that allow one to assess the
   situation from standpoints of terrorists, law enforcement agencies and
   administrations of CTS and analyze actions and counteractions of various
   sides involved.}},
DOI = {{10.3233/978-1-61499-131-1-45}},
ISSN = {{1879-8268}},
ISBN = {{978-1-61499-131-1; 978-1-61499-130-4}},
Unique-ID = {{ISI:000350462600005}},
}

@article{ ISI:000295888100002,
Author = {Fox, Don B. and Sutter, Daniel and Tester, Jefferson W.},
Title = {{The thermal spectrum of low-temperature energy use in the United States}},
Journal = {{ENERGY \& ENVIRONMENTAL SCIENCE}},
Year = {{2011}},
Volume = {{4}},
Number = {{10}},
Pages = {{3731-3740}},
Month = {{OCT}},
Abstract = {{A detailed analysis of U.S. energy consumption was performed to
   determine the amount of primary energy consumed as a function of its
   utilization temperature from 0 to 260 degrees C. The study highlights
   the changes that have occurred in U. S. energy use since the 1970s and
   suggests how renewable energy could provide a large fraction of the
   energy used for direct use at low end-use temperatures that is currently
   mostly supplied by high grade fossil fuels. For example, most of the
   low-temperature energy used for water and space heating is provided by
   combusting natural gas and oil at very high temperatures. This process
   downgrades the thermodynamic potential of the fossil fuels for
   generating power resulting in large reduction in the exergy or
   availability of the combustion products. By focusing attention on the
   thermodynamic losses inherent to our current energy system, we suggest a
   paradigm shift in the way we view and use energy by strategically
   matching the source providing the energy to the end-use temperature of
   the application. Thermal energy demands below 260 degrees C could be
   supplied more sustainably without large exergetic losses by geothermal
   or solar thermal energy resources, as well as by waste heat from fuel
   combustion processes. In addition, direct thermal use of available
   low-temperature thermal energy results in higher overall efficiencies
   compared to electricity generation by avoiding the substantial 2nd Law
   losses incurred in converting thermal energy to electricity. Using the
   U.S. Energy Information Administration database as a primary source of
   information, we found that the total thermal demand in the temperature
   range from 0 to 260 degrees C in 2008 was 33.5 EJ (31.7 quads), which is
   about one third of the entire U.S. demand. More than half of the thermal
   energy demand below 260 degrees C (55\%) comes from the residential
   sector, while the rest comes from the industrial (24\%) and commercial
   (21\%) sectors. Additionally, almost 80\% of 33.5 EJ is used to provide
   heat below 150 degrees C. Space heating and water heating have end-use
   temperatures of 40 to 60 degrees C and are responsible for 38\% of the
   thermal energy consumption below 260 degrees C in the residential and
   commercial sectors.}},
DOI = {{10.1039/c1ee01722e}},
ISSN = {{1754-5692}},
Unique-ID = {{ISI:000295888100002}},
}

@article{ ISI:A1991FW98000022,
Author = {CAMPBELL, RG and JOHNSON, RJ and TAVERNER, MR and KING, RH},
Title = {{INTERRELATIONSHIPS BETWEEN EXOGENOUS PORCINE SOMATOTROPIN (PST)
   ADMINISTRATION AND DIETARY-PROTEIN AND ENERGY-INTAKE ON PROTEIN
   DEPOSITION CAPACITY AND ENERGY-METABOLISM OF PIGS}},
Journal = {{JOURNAL OF ANIMAL SCIENCE}},
Year = {{1991}},
Volume = {{69}},
Number = {{4}},
Pages = {{1522-1531}},
Month = {{APR}},
Abstract = {{Exogenous porcine somatotropin (PST) administration stimulates protein
   deposition and inhibits lipogenesis, resulting in dose-related
   improvements in growth performance and reduction of carcass fat content.
   However, the associated impacts of this technology on dietary nutrient
   requirements and energy partitioning between maintenance, protein, and
   fat remain unclear.  Studies with pigs between 25 and 60 kg body weight
   indicate that, because of unknown improvements in amino acid utilization
   and(or) in the energy available for protein synthesis, only marginal
   increases in dietary protein percentage are required to support 20 to
   25\% improvements in protein deposition induced by PST administration. 
   In contrast, an increased dietary protein concentration is required to
   support maximal protein deposition in pigs 60 to 100 kg.  Exogenous PST
   administration increased the maintenance energy requirement and altered
   the relationship between energy intake and protein deposition, although
   the magnitude of these changes and the consequent effects on expression
   of dietary protein (amino acid) requirements was influenced by gender. 
   Albeit limited, information suggests that PST alters nutrient demand at
   the tissue level.  Information of this type will form the basis for
   rational decisions concerning the method for expression of dietary
   nutrient requirements (\% vs g/d) for PST-treated pigs.  Further
   quantitative information is required on the effects of PST dosage on the
   relationship of protein deposition to energy intake and on any
   underlying changes in amino acid utilization and metabolism.}},
ISSN = {{0021-8812}},
Unique-ID = {{ISI:A1991FW98000022}},
}

@article{ ISI:000300749900007,
Author = {Zhou, Yuyu and Weng, Qihao and Gurney, Kevin R. and Shuai, Yanmin and
   Hu, Xuefei},
Title = {{Estimation of the relationship between remotely sensed anthropogenic
   heat discharge and building energy use}},
Journal = {{ISPRS JOURNAL OF PHOTOGRAMMETRY AND REMOTE SENSING}},
Year = {{2012}},
Volume = {{67}},
Pages = {{65-72}},
Month = {{JAN}},
Abstract = {{This paper examined the relationship between remotely sensed
   anthropogenic heat discharge and energy use from residential and
   commercial buildings across multiple scales in the city of Indianapolis,
   Indiana, USA. The anthropogenic heat discharge was estimated with a
   remote sensing-based surface energy balance model, which was
   parameterized using land cover, land surface temperature, albedo, and
   meteorological data. The building energy use was estimated using a
   GIS-based building energy simulation model in conjunction with
   Department of Energy/Energy Information Administration survey data, the
   Assessor's parcel data, GIS floor areas data, and remote sensing-derived
   building height data. The spatial patterns of anthropogenic heat
   discharge and energy use from residential and commercial buildings were
   analyzed and compared. Quantitative relationships were evaluated across
   multiple scales from pixel aggregation to census block. The results
   indicate that anthropogenic heat discharge is consistent with building
   energy use in terms of the spatial pattern, and that building energy use
   accounts for a significant fraction of anthropogenic heat discharge. The
   research also implies that the relationship between anthropogenic heat
   discharge and building energy use is scale-dependent. The simultaneous
   estimation of anthropogenic heat discharge and building energy use via
   two independent methods improves the understanding of the surface energy
   balance in an urban landscape. The anthropogenic heat discharge derived
   from remote sensing and meteorological data may be able to serve as a
   spatial distribution proxy for spatially-resolved building energy use,
   and even for fossil-fuel CO2 emissions if additional factors are
   considered. (C) 2011 International Society for Photogrammetry and Remote
   Sensing, Inc. (ISPRS) Published by Elsevier B.V. All rights reserved.}},
DOI = {{10.1016/j.isprsjprs.2011.10.007}},
ISSN = {{0924-2716}},
ResearcherID-Numbers = {{Shuai, Yanmin/G-1329-2012}},
Unique-ID = {{ISI:000300749900007}},
}

@incollection{ ISI:000324079200033,
Author = {Lyons, Kevin W. and Sriram, Ram D. and Chordia, Lalit and Weissman,
   Alexander},
Editor = {{Rao, KR}},
Title = {{TOWARD ENERGY EFFICIENT MANUFACTURING ENTERPRISES}},
Booktitle = {{ENERGY AND POWER GENERATION HANDBOOK: ESTABLISHED AND EMERGING
   TECHNOLOGIES}},
Year = {{2011}},
Pages = {{AE1-AE16}},
Abstract = {{Industrial enterprises have significant negative impacts on the global
   environment. Collectively, from energy consumption to greenhouse gases
   to solid waste, they are the single largest contributor to a growing
   number of planet-threatening environmental problems. According to the
   Department of Energy's Energy Information Administration, the industrial
   sector consumes 30\% of the total energy and the transportation sector
   consumes 29\% of the energy. Considering that a large portion of the
   transportation energy costs is involved in moving manufactured goods,
   the energy consumption of the industrial sector could reach nearly 45\%
   of the total energy costs. Hence, it is very important to improve the
   energy efficiency of our manufacturing enterprises. In this chapter, we
   outline several different strategies for improving the energy efficiency
   in manufacturing enterprises. Energy efficiency can be accomplished
   through energy savings, improved productivity, new energy generation,
   and the use of enabling technologies. These include reducing energy
   consumption at the process level, reducing energy consumption at the
   facilities level, and improving the efficiency of the energy generation
   and conversion process. The primary focus of this chapter is on process
   level energy efficiency. We will provide case studies to illustrate
   process level energy efficiency and the other two strategies.}},
ISBN = {{978-0-7918-5955-1}},
Unique-ID = {{ISI:000324079200033}},
}

@inproceedings{ ISI:000254287400062,
Author = {Deru, Michael},
Book-Group-Author = {{ASME}},
Title = {{Establishing standard source energy and emission factors for energy use
   in buildings}},
Booktitle = {{PROCEEDINGS OF THE ENERGY SUSTAINABILITY CONFERENCE 2007}},
Year = {{2007}},
Pages = {{541-548}},
Note = {{ASME Energy Sustainability Conference, Long Beach, CA, JUN 27-30, 2007}},
Organization = {{ASME, Adv Energy Syst; ASME, Solar Energy Div}},
Abstract = {{Energy use in buildings is most commonly analyzed by using the energy
   measured at the site. Some analysts also calculate the source energy and
   emissions from the site energy. Source energy use and emission profiles
   offer better indicators of the environmental impact of buildings and
   allow other metrics for comparison of performance. However, there are no
   standard factors for calculating the source energy and emissions from
   the site energy. The energy and emission factors used are derived from
   different data using different methods resulting in wide variations,
   which makes comparisons difficult. In addition, these factors do not
   include the full life cycle of the fuels and energies, but only the
   combustion and transmission portions of the life cycle. The recently
   available U.S. Life Cycle Inventory (LCI) Database provides LCI data for
   energy, transportation, and common materials. The LCI data for fuels
   include all the energy and emissions associated with the extraction,
   transportation, and processing of the fuels. This paper describes how
   the LCI data, along with other emissions data and energy consumption
   data from the Energy Information Administration, were used to generate
   source energy and emission factors specifically for energy use in
   buildings. The factors are provided on national, interconnect, and state
   levels. This effort was part of the U.S. Department of Energy
   Performance Metrics Project, which worked to establish standard
   procedures and performance metrics for energy performance of buildings.}},
ISBN = {{978-0-7918-4797-8}},
Unique-ID = {{ISI:000254287400062}},
}

@article{ ISI:A1995TD61000009,
Author = {MURPHY, FH and SHAW, SH},
Title = {{THE EVOLUTION OF ENERGY MODELING AT THE FEDERAL-ENERGY-ADMINISTRATION
   AND THE ENERGY-INFORMATION-ADMINISTRATION}},
Journal = {{INTERFACES}},
Year = {{1995}},
Volume = {{25}},
Number = {{5}},
Pages = {{173-193}},
Month = {{SEP-OCT}},
Abstract = {{Energy modeling at the Energy Information Administration started with
   the Project Independence Evaluation System in 1974 and moved to the
   Intermediate Future Forecasting System in 1983, which was replaced by
   the National Energy Modeling System in 1993. The models were shaped by
   the forces affecting energy markets and by policy concerns. These forces
   included changing world markets for oil, shortages of natural gas, and
   environmental concerns. The models have been used to analyze legislative
   proposals, and these analyses have met with a variety of reactions that
   ranged from extreme gratitude to rage. Working as policy analysts when
   energy issues were at the center of national attention was exciting,
   exhausting, rewarding, and at times dismaying.}},
DOI = {{10.1287/inte.25.5.173}},
ISSN = {{0092-2102}},
Unique-ID = {{ISI:A1995TD61000009}},
}

@inproceedings{ ISI:000265637200008,
Author = {Ozalp, Nesrin},
Book-Group-Author = {{ASME}},
Title = {{UTILIZATION OF HEAT, POWER AND RECOVERED WASTE HEAT FOR INDUSTRIAL
   PROCESSES IN THE US CHEMICAL INDUSTRY}},
Booktitle = {{ES2008: PROCEEDINGS OF THE 2ND INTERNATIONAL CONFERENCE ON ENERGY
   SUSTAINABILITY - 2008, VOL 1}},
Year = {{2009}},
Pages = {{57-67}},
Note = {{2nd International Conference on Energy Sustainability, Jacksonville, FL,
   AUG 10-14, 2008}},
Organization = {{ASME, Adv Energy Syst Div; ASME, Solar Energy Div}},
Abstract = {{This paper presents energy end-use model of the U.S. Chemical Industry.
   The model allocates combustible fuel and renewable energy inputs among
   generic end-uses including intermediate conversions through onsite power
   and steam generation. Results of this model provide the basis to scale
   energy process-step models. Two federal databases used to construct
   energy end-use models arc Manufacturing Energy Consumption Survey of the
   U.S. Energy Information Administration, and the Energy Information
   Administration's ``EIA-860B: Annual Electric Generator Report{''}. These
   databases provide information on energy consumption for each end-use,
   electricity generation, and recovered waste heat at the prime mover
   level of detail for each industry on a national scale. Results of the
   model show that the majority of the fuel input is used directly for the
   end-uses. Although the rest of the fuel is used to generate steam and
   power, most of this energy contributes to the end-uses as steam.
   Therefore, the purpose of fuel consumption at non-utility plants is to
   run their end-uses. During the course of this study, the most recent
   U.S. federal energy database available was for the year 1998. Currently,
   the most recent available U.S. federal energy database is given for the
   year 2002 based on the data collected from 15,500 establishments.}},
ISBN = {{978-0-7918-4319-2}},
Unique-ID = {{ISI:000265637200008}},
}

@article{ ISI:000360586600037,
Author = {Scott, Christopher A. and Sugg, Zachary P.},
Title = {{Global Energy Development and Climate-Induced Water Scarcity-Physical
   Limits, Sectoral Constraints, and Policy Imperatives}},
Journal = {{ENERGIES}},
Year = {{2015}},
Volume = {{8}},
Number = {{8}},
Pages = {{8211-8225}},
Month = {{AUG}},
Abstract = {{The current accelerated growth in demand for energy globally is
   confronted by water-resource limitations and hydrologic variability
   linked to climate change. The global spatial and temporal trends in
   water requirements for energy development and policy alternatives to
   address these constraints are poorly understood. This article analyzes
   national-level energy demand trends from U.S. Energy Information
   Administration data in relation to newly available assessments of water
   consumption and life-cycle impacts of thermoelectric generation and
   biofuel production, and freshwater availability and sectoral allocations
   from the U.N. Food and Agriculture Organization and the World Bank.
   Emerging, energy-related water scarcity flashpoints include the world's
   largest, most diversified economies (Brazil, India, China, and USA among
   others), while physical water scarcity continues to pose limits to
   energy development in the Middle East and small-island states. Findings
   include the following: (a) technological obstacles to alleviate water
   scarcity driven by energy demand are surmountable; (b) resource
   conservation is inevitable, driven by financial limitations and
   efficiency gains; and (c) institutional arrangements play a pivotal role
   in the virtuous water-energy-climate cycle. We conclude by making
   reference to coupled energy-water policy alternatives including
   water-conserving energy portfolios, intersectoral water transfers,
   virtual water for energy, hydropower tradeoffs, and use of impaired
   waters for energy development.}},
DOI = {{10.3390/en8088211}},
ISSN = {{1996-1073}},
Unique-ID = {{ISI:000360586600037}},
}

@article{ ISI:000344444600072,
Author = {Kialashaki, Arash and Reisel, John R.},
Title = {{Development and validation of artificial neural network models of the
   energy demand in the industrial sector of the United States}},
Journal = {{ENERGY}},
Year = {{2014}},
Volume = {{76}},
Pages = {{749-760}},
Month = {{NOV 1}},
Abstract = {{In the United States, the industrial sector is the driving engine of
   economic development, and energy consumption in this sector may be
   considered as the fuel for this engine. In order to keep this sector
   sustainable (diverse and productive over the time), energy planning
   should be carried out comprehensively and precisely. This paper
   describes the development of two types of numerical energy models which
   are able to predict the United States' future industrial energy-demand.
   One model uses an ANN (artificial neural network) technique, and the
   other model uses a MLR (multiple linear regression) technique. Various
   independent variables (GDP, price of energy carriers) are tested. The
   future industrial energy demand can then be forecasted based on a
   defined scenario.
   The ANN model anticipates a 16\% increase in energy demand from 2012 by
   2030. In this forecast, the model assumes that the effective independent
   parameters remain constant during this period and only GDP grows with a
   second-order polynomial trend. The forecast result, which shows
   consistency with published predictions, may be considered as an
   indication of the need for development of new and low-cost energy
   sources.
   This study suggests that the ANN technique is a reliable and powerful
   technique which can effectively perform input/output mapping. In order
   to validate the performance of the models, the results of the ANN model
   is compared to the projections from the Energy Information
   Administration of the U.S. Department of Energy. (C) 2014 Elsevier Ltd.
   All rights reserved.}},
DOI = {{10.1016/j.energy.2014.08.072}},
ISSN = {{0360-5442}},
EISSN = {{1873-6785}},
ORCID-Numbers = {{Kialashaki, Arash/0000-0003-1966-431X}},
Unique-ID = {{ISI:000344444600072}},
}

@inproceedings{ ISI:000361161100014,
Author = {Fowler, Nathaniel and Wiand, Jeff and Eddy, Bryan and Lowery, Andrew D.
   and Smith, James E.},
Book-Group-Author = {{ASME}},
Title = {{GREEN HEAT: HOT WATER ENERGY OFFSET SYSTEM}},
Booktitle = {{PROCEEDINGS OF THE ASME POWER CONFERENCE, 2014, VOL 2}},
Year = {{2014}},
Note = {{ASME Power Conference 2014, Baltimore, MD, JUL 28-31, 2014}},
Organization = {{ASME, Power Div}},
Abstract = {{The implementation of renewable energy systems is often regarded by the
   consumer to be too costly and too complex to maintain and operate. For
   instance converting sunlight or wind energy to electricity along with
   the conditioning equipment required to put energy into the system can be
   cost prohibitive for a residential or commercial application. The
   proposed system implements multiple renewable energy components working
   in series. These components bypass those costly electrical energy
   conversions by converting the acquired energy into heat, which can be
   utilized to offset a portion of the energy consumed within the home or
   business. This system can be made completely transparent with little or
   no impact on the consumers' lifestyle. Also, the proposed system, by
   only attempting to offset a portion of the current usage, will be simple
   and inexpensive to assemble and maintain with a short return on
   investment.
   According to the U.S. Energy Information Administration an estimated 10
   quadrillion Btu's are consumed by 113.6 million houses in the United
   States, while 1.8 quadrillion Btu's of the total energy is used for hot
   water heating {[}1]. It has been shown that approximately 20\% of the
   energy costs associated with most residential and small commercial
   businesses stem from hot water heating. A patent-pending technology,
   called a viscous controller, attached at the base of a wind turbine,
   which operates in series with a traditional thermal solar collector to
   supplement the energy used in the hot water tank. This technology
   reduces the cost of the system and allows for the average homeowner and
   small business owner to offset their current energy usage, incorporate
   renewable energy sources, and offer a 4-5 year return on initial
   investment. More importantly, if this system is implemented in only a
   portion of the target market, it has the potential to completely offset
   the rising energy demands for the United States each year for the
   foreseeable future.}},
Article-Number = {{V002T09A008}},
ISBN = {{978-0-7918-4609-4}},
Unique-ID = {{ISI:000361161100014}},
}

@article{ ISI:000308828600016,
Author = {Ota, Erika and Tobe-Gai, Ruoyan and Mori, Rintaro and Farrar, Diane},
Title = {{Antenatal dietary advice and supplementation to increase energy and
   protein intake}},
Journal = {{COCHRANE DATABASE OF SYSTEMATIC REVIEWS}},
Year = {{2012}},
Number = {{9}},
Abstract = {{Background
   Gestational weight gain is positively associated with fetal growth, and
   observational studies of food supplementation in pregnancy have reported
   increases in gestational weight gain and fetal growth.
   Objectives
   To assess the effects of advice during pregnancy to increase energy and
   protein intake, or of actual energy and protein supplementation, on
   energy and protein intakes, and the effect on maternal and infant health
   outcomes.
   Search methods
   We searched the Cochrane Pregnancy and Childbirth Group's Trials
   Register (22 July 2011) and contacted researchers in the field. We
   updated the search on 12 July 2012 and added the results to the awaiting
   classification section of the review.
   Selection criteria
   Randomised controlled trials of dietary advice to increase energy and
   protein intake, or of actual energy and protein supplementation, during
   pregnancy.
   Data collection and analysis
   Two review authors independently assessed trials for inclusion and
   assessed risk of bias. Two review authors independently extracted data
   and checked for accuracy. Extracted data were supplemented by additional
   information from the trialists we contacted.
   Main results
   We examined 110 reports corresponding to 46 trials. Of these trials, 15
   were included, 30 were excluded, and one is ongoing. Overall, 15 trials
   involving 7410 women were included.
   Nutritional advice (four trials, 790 women)
   Women given nutritional advice had a lower relative risk of having a
   preterm birth (two trials, 449 women) (risk ratio (RR) 0.46, 95\% CI
   0.21 to 0.98), head circumference at birth was increased in one trial
   (389 women) (mean difference (MD) 0.99 cm, 95\% CI 0.43 to 1.55) and
   protein intake increased (three trials, 632 women) (protein intake: MD
   +6.99 g/day, 95\% CI 3.02 to 10.97). No significant differences were
   observed on any other outcomes.
   Balanced energy and protein supplementation (11 trials, 5385 women)
   Risk of stillbirth was significantly reduced for women given balanced
   energy and protein supplementation (RR 0.62, 95\% CI 0.40 to 0.98, five
   trials, 3408 women), mean birthweight was significantly increased
   (random-effects MD +40.96 g, 95\% CI 4.66 to 77.26, Tau(2) = 1744, I-2 =
   44\%, 11 trials, 5385 women). There was also a significant reduction in
   the risk of small-for-gestational age (RR 0.79, 95\% CI 0.69 to 0.90,
   I-2 = 16\%, seven trials, 4408 women). No significant effect was
   detected for preterm birth or neonatal death.
   High-protein supplementation (one trial, 1051 women)
   High-protein supplementation (one trial, 505 women), was associated with
   a significantly increased risk of small-for-gestational age babies (RR
   1.58, 95\% CI 1.03 to 2.41).
   Isocaloric protein supplementation (two trials, 184 women)
   Isocaloric protein supplementation (two trials, 184 women) had no
   significant effect on birthweight and weekly gestational weight gain.
   Authors' conclusions
   This review provides encouraging evidence that antenatal nutritional
   advice with the aim of increasing energy and protein intake in the
   general obstetric population appears to be effective in reducing the
   risk of preterm birth, increasing head circumference at birth and
   increasing protein intake, there was no evidence of benefit or adverse
   effect for any other outcome reported.
   Balanced energy and protein supplementation seems to improve fetal
   growth, and may reduce the risk of stillbirth and infants born
   small-for-gestational age. High-protein supplementation does not seem to
   be beneficial and may be harmful to the fetus. Balanced-protein
   supplementation alone had no significant effects on perinatal outcomes.
   The results of this review should be interpreted with caution, the risk
   of bias was either unclear or high for at least one category examined in
   several of the included trials and the quality of the evidence was low
   for several important outcomes. Also the anthropometric characteristics
   of the general obstetric population is changing, therefore, those
   developing interventions aimed at altering energy and protein intake
   should ensure that only those women likely to benefit are included.
   Large, well designed randomised trials are needed to assess the effects
   of increasing energy and protein intake during pregnancy in women whose
   intake is below recommended levels.}},
DOI = {{10.1002/14651858.CD000032.pub2}},
Article-Number = {{CD000032}},
ISSN = {{1469-493X}},
EISSN = {{1361-6137}},
Unique-ID = {{ISI:000308828600016}},
}

@article{ ISI:000277606600014,
Author = {Price, Stephen R. and Hilchey, Catherine A. and Darredeau, Christine and
   Fulton, Heather G. and Barrett, Sean P.},
Title = {{Energy drink co-administration is associated with increased reported
   alcohol ingestion}},
Journal = {{DRUG AND ALCOHOL REVIEW}},
Year = {{2010}},
Volume = {{29}},
Number = {{3}},
Pages = {{331-333}},
Month = {{MAY}},
Abstract = {{Introduction and Aims. While energy drinks (EDs) and alcohol have been
   reported to be frequently co-administered, little is known about the
   effect of this co-administration on alcohol drinking patterns. The
   purpose of the present research was to characterise patterns of ED and
   alcohol co-administration. Design and Methods. Seventy-two ED users were
   recruited from the Halifax university community. Participants provided
   information about their lifetime ED and other substance use, in addition
   to detailing instances of their ED and alcohol use during the previous
   week using a timeline follow-back interview. Results. Seventy-six per
   cent of participants reported ever deliberately mixing alcohol with EDs
   and 19\% reported doing so during the previous week. Relative to alcohol
   drinking sessions in which EDs were not used, participants reported
   drinking significantly more alcohol when it was co-administered with
   EDs. Discussion and Conclusions. Alcohol and ED co-administration is
   relatively common among ED users and seems to be associated with
   increased alcohol ingestion. It is recommended that this matter receive
   more clinical and research attention. {[}Price SR, Hilchey CA, Darredeau
   C, Fulton HG, Barrett SP. Energy drink co-administration is associated
   with increased reported alcohol ingestion. Drug Alcohol Rev 2010].}},
DOI = {{10.1111/j.1465-3362.2009.00163.x}},
ISSN = {{0959-5236}},
Unique-ID = {{ISI:000277606600014}},
}

@inproceedings{ ISI:000271673200086,
Author = {Ozalp, Nesrin and Hyman, Barry},
Editor = {{Klemes, J}},
Title = {{Energy Allocation And Energy Intensity Estimates For The US Organic
   Chemicals Industry}},
Booktitle = {{PRES'09: 12TH INTERNATIONAL CONFERENCE ON PROCESS INTEGRATION, MODELLING
   AND OPTIMISATION FOR ENERGY SAVING AND POLLUTION REDUCTION, PTS 1 AND 2}},
Series = {{Chemical Engineering Transactions}},
Year = {{2009}},
Volume = {{18}},
Pages = {{531-536}},
Note = {{12th Conference on Process Integration, Modelling and Optimisation for
   Energy Saving and Pollution Reduction, Rome, ITALY, FEB 10-MAY 13, 2009}},
Organization = {{Italian Assoc Chem Engn}},
Abstract = {{Manufacturing energy intensity is a measure of energy consumption per
   unit of manufacturing output. In this paper, we examine energy
   intensities in the U.S. Organic Chemicals industry. Process end uses
   that were included in the model are: process heating, process cooling \&
   refrigeration, machine drive, electro-chemical processes, and other
   process uses. The main federal database that we used for constructing
   energy end-use models is the U.S. Energy Information Administration
   Manufacturing Energy Consumption Survey (MECS). The secondary federal
   database used is the U.S. Energy Information Administration 86013:
   Annual Electric Generator Report. The estimates and models are created
   for the most recent data which is given for 2002. The data for 2006 is
   still under progress by the U.S. Energy Information Administration.}},
DOI = {{10.3303/CET0918086}},
ISSN = {{1974-9791}},
ISBN = {{978-88-95608-04-4}},
Unique-ID = {{ISI:000271673200086}},
}

@article{ ISI:000293657200005,
Author = {Clement, Matthew Thomas and Schultz, Jessica},
Title = {{Political Economy, Ecological Modernization, and Energy Use: A Panel
   Analysis of State-Level Energy Use in the United States, 1960-1990}},
Journal = {{SOCIOLOGICAL FORUM}},
Year = {{2011}},
Volume = {{26}},
Number = {{3}},
Pages = {{581-600}},
Month = {{SEP}},
Abstract = {{The present study will examine energy consumption from two competing
   perspectives within environmental social science: political economy and
   ecological modernization. These frameworks will be evaluated with a
   fixed-effects panel analysis of state-level energy use between the years
   1960 and 1990, based on data for 50 states plus Washington, DC, from the
   Energy Information Administration's State Energy Data System. The
   results from the panel analysis show that the increase in total energy
   use between 1960 and 1990 depended on both increasing economic growth
   and urbanization, even after controlling for population size,
   industrialization, and inflation-adjusted energy prices. The results
   challenge the claims of ecological modernization theory and support a
   political economic approach to the study of changes in energy use. In
   the conclusion, the study's findings will be framed within the context
   of the early twenty-first-century economic and ecological crises. In
   light of efforts to reduce greenhouse gas emissions, this study can also
   further advance the renewable energy debate by reminding us of the
   social drivers of energy use.}},
DOI = {{10.1111/j.1573-7861.2011.01263.x}},
ISSN = {{0884-8971}},
Unique-ID = {{ISI:000293657200005}},
}

@article{ ISI:000298119500019,
Author = {Espinoza, Omar and Bond, Brian H. and Buehlmann, Urs},
Title = {{ENERGY AND THE US HARDWOOD INDUSTRY - PART I: PROFILE AND IMPACT OF
   PRICES}},
Journal = {{BIORESOURCES}},
Year = {{2011}},
Volume = {{6}},
Number = {{4}},
Pages = {{3883-3898}},
Abstract = {{According to the Energy Information Administration two fifths of the
   energy used by US wood products manufacturers comes from electricity and
   natural gas, the costs of which have pointedly increased over the last
   decade. Empirical indications exist that higher energy prices affect the
   industry's profitability. Together with other developments such as, for
   example, unfavorable trends in hardwood stumpage prices, higher
   transportation costs, increasing government regulations, a challenging
   economic situation, or the ongoing globalization of markets, the US
   hardwood industry has to cope with some serious challenges threatening
   its profit potential. To understand the impact of energy prices on wood
   products manufacturers' profitability and to gain insights regarding
   actions the industry is taking to respond to energy-related challenges,
   a survey was conducted among Eastern US primary hardwood products
   manufacturers in late 2010. Results show that, overall, the share of
   energy expenses on total production costs of respondents was 7.9\%. A
   majority of respondents (61.8\%) agreed that their energy expenses have
   increased by an average of 18.7\% during the last five years. Half of
   the respondents reported a 5\% or higher negative impact of higher
   energy prices on their profits over the same period. Actions undertaken
   by the industry to alleviate the negative impact of rising energy prices
   are presented in a second paper in this two-part series.}},
ISSN = {{1930-2126}},
Unique-ID = {{ISI:000298119500019}},
}

@article{ ISI:000186941000001,
Author = {Meng, CJ and Pinker, RT and Tarpley, JD and Laszlo, I},
Title = {{A satellite approach for estimating regional land surface energy budget
   for GCIP/GAPP}},
Journal = {{JOURNAL OF GEOPHYSICAL RESEARCH-ATMOSPHERES}},
Year = {{2003}},
Volume = {{108}},
Number = {{D22}},
Month = {{NOV 25}},
Abstract = {{Conventional observations cannot provide information on land surface
   energy fluxes, or information for land surface parameterizations, on a
   global or regional scale. In this paper, a satellite approach for
   estimating regional land surface energy budget is developed and
   implemented to the Mississippi River Basin, which serves as the focus of
   the World Climate Research Program Global Energy and Water cycles
   Experiment ( GEWEX) Continental Scale International Project ( GCIP) and
   GEWEX Americas Prediction Project (GAPP). The objective of this study is
   to evaluate the potential of using recently available satellite
   information to advance current capabilities in determining regional land
   surface energy budget. The primary forcing parameters in this approach,
   namely, surface shortwave radiation and skin temperature, are derived
   from the Geostationary Operational Environmental Satellite ( GOES)
   observations, using inference schemes that are operationally executed at
   the National Oceanic and Atmospheric Administration National
   Environmental Satellite Data and Information Service (NESDIS). Shortwave
   radiation is used to define the absorbed energy at the surface. Diurnal
   variation of skin temperature is used to define the surface energy
   partitioning. The real-time NESDIS GOES product covers the continental
   United States (25degrees - 53 degrees N, 67degrees - 125 degreesW), at a
   0.5degrees spatial resolution and an hourly temporal resolution.
   Atmospheric conditions of near-surface air temperature, humidity, and
   wind speed are obtained from the NOAA National Centers for Environmental
   Prediction (NCEP) Eta model output. A 1-year simulation ( May 1997 to
   May 1998) of the Mississippi River Basin surface energy budget is
   performed. Model inputs of shortwave radiation and skin temperature, and
   resulting latent and sensible heat fluxes, are evaluated on various
   spatial and temporal scales. On a local scale, over the 1-year study
   period, the RMS difference between estimated and observed monthly
   shortwave fluxes and latent and sensible heat fluxes are 32, 21, and 20
   Wm(-2), respectively. On a regional scale the estimated summertime
   energy fluxes are of similar pattern and same order of magnitude as the
   corresponding reanalysis results from NCEP and National Center for
   Atmospheric Research.}},
DOI = {{10.1029/2002JD003088}},
Article-Number = {{8861}},
ISSN = {{2169-897X}},
ResearcherID-Numbers = {{Laszlo, Istvan/F-5603-2010
   Pinker, Rachel/F-6565-2010}},
ORCID-Numbers = {{Laszlo, Istvan/0000-0002-5747-9708
   }},
Unique-ID = {{ISI:000186941000001}},
}

@incollection{ ISI:000271156900007,
Author = {Ryan, David L. and Young, Denise},
Editor = {{Utrick, JB}},
Title = {{ENERGY USE IN CANADIAN BUILDINGS: WHAT HAVE WE LEARNED FROM RECENT DATA?}},
Booktitle = {{ENERGY AND BUILDING: EFFICIENCY, AIR QUALITY AND CONSERVATION}},
Year = {{2009}},
Pages = {{177-207}},
Abstract = {{In recent years, detailed surveys such as the Commercial and
   Institutional Building Energy Use Survey (CIBEUS) and the Survey of
   Household Energy Use (SHEU) have been conducted in order to collect data
   on energy use in residential and commercial buildings in Canada.
   The information contained in these surveys, as well as data on house
   energy characteristics from energy audits conducted pre- and
   post-retrofit, available in the Canadian EnerGuide for Houses Database,
   have provided researchers at the Canadian Building Energy End-Use Data
   and Analysis Centre (CBEEDAC) the opportunity to study several aspects
   of the determinants of energy use and energy efficiency in a variety of
   Canadian building types.
   Among other things, these studies have examined the roles of
   technologies (such as heating systems, thermostats, lighting systems,
   water heaters, home appliances) on the intensity of energy use by
   Canadian businesses and households. Additional studies have looked at
   the roles of private versus public building ownership and the types of
   activities undertaken (such as food retail, non-food retail,
   administration, etc.) on the demand for various types of energy in
   commercial buildings.
   In this chapter, we provide an overview of data sources available for
   the study of energy efficiency in Canadian buildings. We then summarize
   the analysis and findings from a number of studies undertaken by
   CBEEDAC, with a focus on the factors that have had a significant impact
   on energy consumption.
   These findings are discussed in the context of energy policy programs
   and initiatives in Canada.}},
ISBN = {{978-1-60741-049-2}},
Unique-ID = {{ISI:000271156900007}},
}

@article{ ISI:A1994NK15700002,
Author = {CHONG, PKK and JUNG, RT and SCRIMGEOUR, CM and RENNIE, MJ},
Title = {{THE EFFECT OF PHARMACOLOGICAL DOSAGES OF GLUCOCORTICOIDS ON FREE-LIVING
   TOTAL-ENERGY EXPENDITURE IN MAN}},
Journal = {{CLINICAL ENDOCRINOLOGY}},
Year = {{1994}},
Volume = {{40}},
Number = {{5}},
Pages = {{577-581}},
Month = {{MAY}},
Abstract = {{OBJECTIVES Weight gain had previously been thought to be due to
   increased calorie intake alone though no information on its effect on
   total energy expenditure is available in humans. We therefore assessed
   whether weight gain associated with glucocorticoids is due to a
   reduction in energy expenditure.
   DESIGN We performed an open study with 1 mg of betamethasone given
   orally twice a day for 21 days.
   SUBJECTS Seven healthy female volunteers, age range 26-55 years, body
   mass index 19 to 40, mean 27 kg/m(2).
   MEASUREMENTS Total free living energy expenditure was measured by the
   doubly labelled water method (D-2 O-18), resting metabolic rate by
   ventilated hood indirect calorimetry and fat free mass from the dilution
   volume of oxygen-18 labelled water. Body composition and components of
   energy expenditure were assessed before and during the final 14 days of
   betamethasone administration.
   RESULTS Weight increased by a mean of 1.2 kg (P < 0.05) because of a
   significant rise in fat mass (1.5 kg) with no change in fat free mass.
   Resting metabolic rate remained unaltered on betamethasone but total
   energy expenditure increased in all subjects with a significant mean
   rise of 26\% from 11.7 to 14.7 MJ/24 h (P < 0.05). The energy component
   of physical activity with thermogenesis increased on average 52\% (from
   5.8 to 8.9 MJ/24 h; P < 0.05). The rise in energy expenditure was still
   apparent after correction for the increase in body weight. Fasting
   respiratory quotient (RQ) increased from 0.81 to 0.86 with no change in
   fasting blood glucose. Betamethasone did not result in an energy sparing
   effect on the two components of energy expenditure studied.
   CONCLUSIONS Body weight increased on betamethasone entirely due to an
   increase in fat mass. This occurred despite a rise in total energy
   expenditure which involved specifically that component accounted for by
   physical activity plus thermogenesis. The most likely explanation is
   that betamethasone increased dietary energy intake significantly in
   excess of expenditure. We estimate that an average extra energy intake
   of 2.8 MJ/day would have had to be consumed for this rise in fat mass to
   occur even before taking into account the energy intake cost of the rise
   in expenditure.}},
DOI = {{10.1111/j.1365-2265.1994.tb03007.x}},
ISSN = {{0300-0664}},
Unique-ID = {{ISI:A1994NK15700002}},
}

@article{ ISI:A1995TD15200010,
Author = {NIELSEN, K and KONDRUP, J and MARTINSEN, L and DOSSING, H and LARSSON, B
   and STILLING, B and JENSEN, MG},
Title = {{LONG-TERM ORAL REFEEDING OF PATIENTS WITH CIRRHOSIS OF THE LIVER}},
Journal = {{BRITISH JOURNAL OF NUTRITION}},
Year = {{1995}},
Volume = {{74}},
Number = {{4}},
Pages = {{557-567}},
Month = {{OCT}},
Abstract = {{A previous study has shown that malnourished, clinically stable patients
   with liver cirrhosis are in protein and energy balance at their
   spontaneous dietary intake and that an improvement in nutritional status
   cannot be anticipated at this intake (Nielsen et al. 1993). In the
   present study we examined to what extent oral intake could be increased
   by nutritional support, and to what extent dietary protein would be
   retained with increased intake. The techniques used for balance studies
   were also validated since this information is not available for patients
   with liver cirrhosis. Fifteen malnourished patients with alcoholic liver
   cirrhosis were given increasing amounts of a balanced ordinary diet for
   38 (SE 3) d. Intakes of protein and energy were recorded by weighing
   servings and leftovers on food trays. Protein intake was calculated from
   food tables, Total N disposal was calculated after measurement of
   urinary N excretion, and protein balance was calculated from the N
   balance. A validation study of protein balance in a subgroup of patients
   (analysis of N in food by the duplicate portion technique, correction
   for incomplete recovery of urine by measurement of urinary
   para-aminobenzoic acid (PABA) after administration of PAPA tablets, and
   measurement of faecal N) did not change protein balance values. Protein
   intake increased from 1.0 (SE 0.1) g/kg per d to 1.8 (SE 0.1) g/kg per
   d. With increasing protein intake, 84 (SE 8)\% of the increase in intake
   was retained. The rate of protein retention was not saturated at the
   intakes obtained in this study. Protein intolerance was only encountered
   in one patient. Available evidence indicates that the requirement for
   achieving N balance is increased in these patients but protein retention
   is highly efficient with increased intake, Protein retention is
   dependent on energy balance. Energy intake was calculated from food
   tables and total energy expenditure was calculated by the factorial
   method. A validation study was performed in a subgroup of patients. The
   energy contents of food sampled by the duplicate portion technique, and
   of urine and faeces were measured by bomb calorimetry, Resting energy
   expenditure (REE) was measured by indirect calorimetry before and at the
   end of the study, and O-2 uptake during bicycle exercise was measured
   before and at the end of the study. The measured intake of metabolizable
   energy was on average 13\% lower than the value given in food tables.
   Calculated energy expenditure was not changed by the validation study.
   Mean energy intake was 163 (SE 10) kJ/kg per d and mean energy
   expenditure was 134 (SE 5) kJ/kg per d (P = 0.007), indicating that the
   protein retention described occurred at a positive energy balance, It is
   concluded that a substantial retention of dietary protein can be
   obtained by oral nutrition support over a prolonged period of time in
   patients with liver cirrhosis. Requirements of protein for maintenance
   and repletion in these patients are discussed.}},
DOI = {{10.1079/BJN19950158}},
ISSN = {{0007-1145}},
ResearcherID-Numbers = {{Kondrup, Jens/C-6193-2008}},
Unique-ID = {{ISI:A1995TD15200010}},
}

@article{ ISI:000311821000202,
Author = {McDonald, Robert I. and Olden, Julian D. and Opperman, Jeffrey J. and
   Miller, William M. and Fargione, Joseph and Revenga, Carmen and Higgins,
   Jonathan V. and Powell, Jimmie},
Title = {{Energy, Water and Fish: Biodiversity Impacts of Energy-Sector Water
   Demand in the United States Depend on Efficiency and Policy Measures}},
Journal = {{PLOS ONE}},
Year = {{2012}},
Volume = {{7}},
Number = {{11}},
Month = {{NOV 21}},
Abstract = {{Rising energy consumption in coming decades, combined with a changing
   energy mix, have the potential to increase the impact of energy sector
   water use on freshwater biodiversity. We forecast changes in future
   water use based on various energy scenarios and examine implications for
   freshwater ecosystems. Annual water withdrawn/manipulated would increase
   by 18-24\%, going from 1,993,000-2,628,000 Mm(3) in 2010 to
   2,359,000-3,271,000 Mm(3) in 2035 under the Reference Case of the Energy
   Information Administration (EIA). Water consumption would more rapidly
   increase by 26\% due to increased biofuel production, going from
   16,700-46,400 Mm(3) consumption in 2010 to 21,000-58,400 Mm(3)
   consumption in 2035. Regionally, water use in the Southwest and
   Southeast may increase, with anticipated decreases in water use in some
   areas of the Midwest and Northeast. Policies that promote energy
   efficiency or conservation in the electric sector would reduce water
   withdrawn/manipulated by 27-36 m(3)GJ(-1) (0.1-0.5 m(3)GJ(-1)
   consumption), while such policies in the liquid fuel sector would reduce
   withdrawal/manipulation by 0.4-0.7 m(3)GJ(-1) (0.2-0.3 m(3) GJ(-1)
   consumption). The greatest energy sector withdrawal/manipulation are for
   hydropower and thermoelectric cooling, although potential new EPA rules
   that would require recirculating cooling for thermoelectric plants would
   reduce withdrawal/manipulation by 441,000 Mm(3) (20,300 Mm(3)
   consumption). The greatest consumptive energy sector use is evaporation
   from hydroelectric reservoirs, followed by irrigation water for biofuel
   feedstocks and water used for electricity generation from coal.
   Historical water use by the energy sector is related to patterns of fish
   species endangerment, where water resource regions with a greater
   fraction of available surface water withdrawn by hydropower or consumed
   by the energy sector correlated with higher probabilities of
   imperilment. Since future increases in energy-sector surface water use
   will occur in areas of high fish endemism (e.g., Southeast), additional
   management and policy actions will be needed to minimize further species
   imperilment.}},
DOI = {{10.1371/journal.pone.0050219}},
Article-Number = {{e50219}},
ISSN = {{1932-6203}},
ResearcherID-Numbers = {{Miller, William/B-7650-2009
   Olden, Julian/
   Miller, William/}},
ORCID-Numbers = {{Olden, Julian/0000-0003-2143-1187
   Miller, William/0000-0003-0750-6314}},
Unique-ID = {{ISI:000311821000202}},
}

@article{ ISI:000335944500009,
Author = {Christensen, Toke Haunstrup and Gram-Hanssen, Kirsten and de
   Best-Waldhober, Marjolein and Adjei, Afi},
Title = {{Energy retrofits of Danish homes: is the Energy Performance Certificate
   useful?}},
Journal = {{BUILDING RESEARCH AND INFORMATION}},
Year = {{2014}},
Volume = {{42}},
Number = {{4, SI}},
Pages = {{489-500}},
Month = {{JUL 4}},
Abstract = {{Energy retrofitting of the existing dwelling stock represents one of the
   major challenges for the transition to a low carbon society, as about
   19\% of the final energy consumption in the European Union relates to
   heating of dwellings. Danish homeowners' experiences with the Energy
   Performance Certificate (EPC) are examined, as it was introduced in 1997
   (prior to a similar scheme introduced later in the European Union). The
   main research question is whether the EPC has an influence on Danish
   homeowners' energy retrofit practices. Homeowners' understanding of and
   trust in the EPC are analyzed, based on an online survey of homeowners
   (N=743) living in a home with a recently issued EPC. Results indicate
   that the EPC has a limited influence on homeowners' energy retrofit
   practices. Despite most homeowners finding the EPC reliable and easy to
   understand, relatively few find it useful as a source of information for
   home retrofits. In its current form, the EPC is insufficient to
   encourage homeowners to undertake energy retrofits of their home.
   Improvements to address this problem in the administration, scope and
   layout of the EPC are suggested.}},
DOI = {{10.1080/09613218.2014.908265}},
ISSN = {{0961-3218}},
EISSN = {{1466-4321}},
ORCID-Numbers = {{Gram-Hanssen, Kirsten/0000-0002-8543-2501}},
Unique-ID = {{ISI:000335944500009}},
}

@article{ ISI:000329081300072,
Author = {Wilkerson, Jordan T. and Cullenward, Danny and Davidian, Danielle and
   Weyant, John P.},
Title = {{End use technology choice in the National Energy Modeling System (NEMS):
   An analysis of the residential and commercial building sectors}},
Journal = {{ENERGY ECONOMICS}},
Year = {{2013}},
Volume = {{40}},
Pages = {{773-784}},
Month = {{NOV}},
Abstract = {{The National Energy Modeling System (NEMS) is arguably the most
   influential energy model in the United States. The U.S. Energy
   Information Administration uses NEMS to generate the federal
   government's annual long-term forecast of national energy consumption
   and to evaluate prospective federal energy policies. NEMS is considered
   such a standard tool that other models are calibrated to its forecasts,
   in both government and academic practice. As a result, NEMS has a
   significant influence over expert opinions of plausible energy futures.
   NEMS is a massively detailed model whose inner workings, despite its
   prominence, receive relatively scant critical attention.
   This paper analyzes how NEMS projects energy demand in the residential
   and commercial sectors. In particular, we focus on the role of
   consumers' preferences and financial constraints, investigating how
   consumers choose appliances and other end-use technologies. We identify
   conceptual issues in the approach the model takes to the same question
   across both sectors. Running the model with a range of consumer
   preferences, we estimate the extent to which this issue impacts
   projected consumption relative to the baseline model forecast for final
   energy demand in the year 2035. In the residential sector, the impact
   ranges from a decrease of 0.73 quads (-6.0\%) to an increase of 0.24
   quads (+2.0\%). In the commercial sector, the impact ranges from a
   decrease of 1.0 quads (-9.0\%) to an increase of 0.99 quads (+9.0\%).
   (C) 2013 Elsevier B.V. All rights reserved.}},
DOI = {{10.1016/j.eneco.2013.09.023}},
ISSN = {{0140-9883}},
EISSN = {{1873-6181}},
ORCID-Numbers = {{Cullenward, Danny/0000-0002-6803-9572
   Wilkerson, Jordan/0000-0003-1447-9465}},
Unique-ID = {{ISI:000329081300072}},
}

@article{ ISI:000285405200007,
Author = {Bhuiyan, Shahjahan H.},
Title = {{Modernizing Bangladesh public administration through e-governance:
   Benefits and challenges}},
Journal = {{GOVERNMENT INFORMATION QUARTERLY}},
Year = {{2011}},
Volume = {{28}},
Number = {{1}},
Pages = {{54-65}},
Month = {{JAN}},
Abstract = {{More and more public administration emphasizes how Information and
   Communication Technology (ICT) can be used to support transformational
   change in governmental functions globally to achieve efficiency and
   cost-effective service delivery to citizens. Bangladesh public
   administration employs energies to achieve this goal. Experience in some
   developing countries has shown that e-governance can improve
   transparency which leads to, among other things, corruption control and
   poverty reduction. This article examines the role that e-governance can
   play in the modernization of public administration for efficient and
   effective service delivery to the citizens of Bangladesh, as well as its
   potential to control corruption and reduce poverty. Based on the lessons
   learned from successful practices in developing countries and literature
   review, it suggests that e-governance can play a significant role for
   corruption control and poverty reduction, and thus offers opportunities
   to cost-effective service delivery to the citizens in Bangladesh. (C)
   2010 Elsevier Inc. All rights reserved.}},
DOI = {{10.1016/j.giq.2010.04.006}},
ISSN = {{0740-624X}},
ORCID-Numbers = {{Bhuiyan, Shahjahan/0000-0001-8551-7647}},
Unique-ID = {{ISI:000285405200007}},
}

@article{ ISI:000242033900012,
Author = {Winebrake, James J. and Sakva, Denys},
Title = {{An evaluation of errors in US energy forecasts: 1982-2003}},
Journal = {{ENERGY POLICY}},
Year = {{2006}},
Volume = {{34}},
Number = {{18}},
Pages = {{3475-3483}},
Month = {{DEC}},
Abstract = {{Planners, policy-makers, and the private sector rely on energy forecasts
   to help make policy and investment decisions. In the US, the federal
   Department of Energy (through the Energy Information Administration and
   its predecessors) has conducted national forecasts of energy production
   and consumption for decades. This paper explores US energy forecasts in
   order to uncover potential systemic errors in US forecasting models. We
   apply an error decomposition technique to forecasts within each major
   energy sector (commercial, industrial, residential, and transportation)
   made during the period 1982 to 2003. We find that low errors for total
   energy consumption are concealing much larger sectoral errors that
   cancel each other out when aggregated. For example, 5-year forecasts
   made between 1982 and 1998 demonstrate a mean percentage error for total
   energy consumption of 0.1\%. Yet, this hides the fact that the
   industrial sector was overestimated by an average of 5.9\%, and the
   transportation sector was underestimated by an average of 4.5\%. We also
   find no evidence that forecasts within each sector have improved over
   the two decades studied here. (c) 2005 Elsevier Ltd. All rights
   reserved.}},
DOI = {{10.1016/j.enpol.2005.07.018}},
ISSN = {{0301-4215}},
ResearcherID-Numbers = {{Winebrake, James/D-2478-2010}},
Unique-ID = {{ISI:000242033900012}},
}

@article{ ISI:000322568300025,
Author = {Trivedi, Amit and Sinn, John K. H.},
Title = {{Early versus late administration of amino acids in preterm infants
   receiving parenteral nutrition}},
Journal = {{COCHRANE DATABASE OF SYSTEMATIC REVIEWS}},
Year = {{2013}},
Number = {{7}},
Abstract = {{Background
   Observational studies in preterm newborns suggest that delay in
   administering amino acids could result in a protein catabolic state and
   could impact on growth and development.
   Objectives
   To determine the effect of early administration of amino acids in
   premature newborns on growth, neurodevelopmental outcome, mortality and
   clinically important side effects.
   Search methods
   The standard search strategy of the Neonatal Review Group as outlined in
   The Cochrane Library was used. Relevant randomised controlled trials
   were identified by searching the Cochrane Central Register of Controlled
   Trials (CENTRAL, The Cochrane Library 2012 Issue 9), MEDLINE, EMBASE and
   CINAHL from their earliest dates to September 2012. The trial registry
   portal of the World Health Organization's International Cilinical Trial
   Registry Platform and ClinicalTrials.gov (US National Institute of
   Health) was searched to identify ongoing and completed but unpublished
   studies.
   Selection criteria
   Randomised controlled trials comparing early administration of amino
   acids with late administration in premature newborn infants were
   included. Early administration of amino acid solution was defined as the
   administration of amino acids in isolation or with total parenteral
   nutrition within the first 24 hours of birth; late initiation was
   defined as the administration of amino acids in isolation or with total
   parenteral nutrition after the first 24 hours of birth. The primary
   outcome measures were growth, neurodevelopmental outcome and mortality
   at 28 days. The secondary outcomes were biochemical abnormalities,
   sepsis and mortality.
   Data collection and analysis
   Both review authors independently selected trials, assessed trial
   quality and extracted data from the included studies. We contacted
   authors for further information. Fixed-effect analyses were performed.
   The treatment effect was expressed as mean difference for continuous
   variables and as risk difference and risk ratio for dichotomous
   variables. All results included 95\% confidence intervals (CIs).
   Main results
   Seven randomised controlled trials were included in this review. One
   randomised controlled trial reported no difference in crown-heel length
   and occipitofrontal head circumference by day 10. Four trials that
   enrolled 93 premature infants showed positive nitrogen balance (The mean
   difference with 95\% CI was 250.42 (224.91 to 275.93 P value < 0.00001).
   Four trials showed a significant difference in the level of blood urea
   nitrogen (BUN) in the first 48 hours (P value < 0.00001). Early
   administration of amino acids did not result in metabolic acidosis in
   the first 24 hours.
   Authors' conclusions
   There is no available evidence of the benefits of early administration
   of amino acids on mortality, early and late growth and
   neuro-development. There is evidence from four randomised controlled
   trials included in this review that early administration of amino acids
   is associated with a positive nitrogen balance. The clinical relevance
   of this finding is not known. Acid-base status and ammonia levels were
   normal in the infants who received amino acids early. Given the small
   number of infants in the randomised controlled trials included in this
   review, the clinical heterogeneity among them, and the lack of data on
   important clinical outcomes, there is insufficient evidence to guide
   practice regarding the early versus late administration of amino acids
   to infants less than 37 weeks gestation.}},
DOI = {{10.1002/14651858.CD008771.pub2}},
Article-Number = {{CD008771}},
ISSN = {{1469-493X}},
EISSN = {{1361-6137}},
Unique-ID = {{ISI:000322568300025}},
}

@article{ ISI:000170179200011,
Author = {Lange, KHW and Isaksson, F and Rasmussen, MH and Juul, A and Bulow, J
   and Kjaer, M},
Title = {{GH administration and discontinuation in healthy elderly men: effects on
   body composition, GH-related serum markers, resting heart rate and
   resting oxygen uptake}},
Journal = {{CLINICAL ENDOCRINOLOGY}},
Year = {{2001}},
Volume = {{55}},
Number = {{1}},
Pages = {{77-86}},
Month = {{JUL}},
Abstract = {{BACKGROUND AND OBJECTIVES GH administration results in increased lean
   body mass (LBM), decreased fat mass (FM) and increased energy
   expenditure (EE). GH therapy may therefore have potential benefits,
   especially in the elderly, who are known to have decreased function of
   the GH/IGF-I axis. Several studies have focused on effects of GH
   administration in the elderly in the last decade. However, very limited
   information is available regarding changes in body composition and EE
   upon GH discontinuation in the elderly. The present study therefore
   investigated the effects of 12 weeks of GH administration and subsequent
   discontinuation on body composition, resting oxygen uptake (VO2),
   resting heart rate (HR) and GH related serum markers in healthy elderly
   men.
   SUBJECTS AND METHODS Sixteen healthy men {[}age 74 +/- 1 years (mean
   SEM), height 174.2 +/- 1.6 cm, body weight 80.7 +/- 2.6 kg, body fat
   27.5 +/- 1.1\%] completed the study protocol. Recombinant human GH (1.80
   +/- 0.24 IU/day) was administered for 12 weeks in a single-blinded,
   placebo-controlled design. Body composition (dual energy X-ray
   absorptiometry), resting VO2 (indirect calorimetry), resting HR
   (telemetry) and serum IGF-I, IGF-II, IGFBP-3 and acid labile subunit
   (ALS) were measured at baseline, after 12 weeks of GH administration
   and, additionally in the GH group, 1, 2, 3, 4, 5 and 9 days after GH
   discontinuation.
   RESULTS Body weight was unchanged from baseline to 12 weeks in both
   groups. However, GH administration caused a decrease in FM (3.4 +/- 1.0
   kg, P < 0.012), paralleled by a similar increase in LBM (3.2 +/- 0.4 kg,
   P < 0.0002). Resting VO2 and resting HR increased by 31 +/- 3.6\% and
   7.3 +/- 1.9 per minute, respectively, in the GH-group, where significant
   increases in serum IGF-I, IGFBP-3 and ALS also were noted. None of the
   above parameters changed in the placebo group. Within 2-3 days after GH
   discontinuation, the GH related serum markers and resting HR returned to
   baseline levels, whereas resting VO2 remained elevated even 9 days after
   GH discontinuation. In addition, GH discontinuation caused a significant
   decrease in body weight (1.86 +/- 0.35 kg), derived exclusively from a
   decrease in LBM (1.63 +/- 0.43 kg), while the decreased FM was
   maintained (12 weeks: 17.93 +/- 1.65 kg, +9 days: 17.74 +/- 1.62 kg).
   CONCLUSIONS The increases in serum IGF-I, IGFBP-3, ALS and resting heart
   rate induced by 12 weeks of GH administration in elderly men returned to
   baseline levels within 2-3 days after GH discontinuation. However,
   resting VO2 remained elevated for a longer period. GH administration
   reduced fat mass but maintained body weight by increasing lean body
   mass. In contrast, 9 days of GH discontinuation reduced body weight
   exclusively by reducing lean body mass.}},
DOI = {{10.1046/j.1365-2265.2001.01344.x}},
ISSN = {{0300-0664}},
ResearcherID-Numbers = {{Juul, Anders /F-5864-2013}},
Unique-ID = {{ISI:000170179200011}},
}

@article{ ISI:A1992HG13100002,
Author = {KENT, C and RODEKOHR, M},
Title = {{THE ROLE OF GOVERNMENT INFORMATION DURING PERIODS OF NATIONAL CRISIS -
   THE ENERGY INFORMATION ADMINISTRATION AND THE PERSIAN-GULF-WAR}},
Journal = {{GOVERNMENT INFORMATION QUARTERLY}},
Year = {{1992}},
Volume = {{9}},
Number = {{1}},
Pages = {{11-33}},
Abstract = {{This article reviews the role of the Energy Information Administration
   (EIA) during the Persian Gulf War in providing the energy data and
   analyses used to minimize the impact of this crisis.  The article is
   divided into three major sections.  The first discusses the impact of
   petroleum supply disruptions on the economy and provides background
   material about previous petroleum supply disruptions and why these
   events are considered to be important from the national perspective. 
   The second section describes the EIA's response to the 1990 Persian Gulf
   Crisis.  The last section provides conclusions which can serve as
   guidelines for maximizing the effectiveness of statistical information
   agencies during national emergencies.}},
DOI = {{10.1016/0740-624X(92)90030-P}},
ISSN = {{0740-624X}},
Unique-ID = {{ISI:A1992HG13100002}},
}

@article{ ISI:000360211100010,
Author = {Wang, Xiuying and Liu, Yulan and Li, Shuang and Pi, Dingan and Zhu,
   Huiling and Hou, Yongqing and Shi, Haifeng and Leng, Weibo},
Title = {{Asparagine attenuates intestinal injury, improves energy status and
   inhibits AMP-activated protein kinase signalling pathways in weaned
   piglets challenged with Escherichia coli lipopolysaccharide}},
Journal = {{BRITISH JOURNAL OF NUTRITION}},
Year = {{2015}},
Volume = {{114}},
Number = {{4}},
Pages = {{553-565}},
Month = {{AUG 28}},
Abstract = {{The intestine requires a high amount of energy to maintain its health
   and function; thus, energy deficits in intestinal mucosa may lead to
   intestinal damage. Asparagine (Asn) is a precursor for many other amino
   acids such as aspartate, glutamine and glutamate, which can be used to
   supply energy to enterocytes. In the present study, we hypothesise that
   dietary supplementation of Asn could alleviate bacterial
   lipopolysaccharide (LPS)-induced intestinal injury via improvement of
   intestinal energy status. A total of twenty-four weaned piglets were
   assigned to one of four treatments: (1) non-challenged control; (2) LPS
   + 0\% Asn; (3) LPS + 0.5\% Asn; (4) LPS + 1.0\% Asn. On day 19, piglets
   were injected with LPS or saline. At 24 h post-injection, piglets were
   slaughtered and intestinal samples were collected. Asn supplementation
   improved intestinal morphology, indicated by higher villus height and
   villus height: crypt depth ratio, and lower crypt depth. Asn
   supplementation also increased the ratios of RNA: DNA and protein: DNA
   as well as disaccharidase activities in intestinal mucosa. In addition,
   Asn supplementation attenuated bacterial LPS-induced intestinal energy
   deficits, indicated by increased ATP and adenylate energy charge levels,
   and decreased AMP: ATP ratio. Moreover, Asn administration increased the
   activities of key enzymes involved in the tricarboxylic acid cycle,
   including citrate synthase, isocitrate dehydrogenase and
   alpha-ketoglutarate dehydrogenase complex. Finally, Asn administration
   decreased the mRNA abundance of intestinal AMP-activated protein
   kinase-alpha 1 (AMPK alpha 1), AMPK alpha 2, silent information
   regulator 1 (SIRT1) and PPAR gamma coactivator-1 alpha (PGC1 alpha), and
   reduced intestinal AMPK alpha phosphorylation. Collectively, these
   results indicate that Asn supplementation alleviates bacterial
   LPS-induced intestinal injury by modulating the AMPK signalling pathway
   and improving energy status.}},
DOI = {{10.1017/S0007114515001877}},
ISSN = {{0007-1145}},
EISSN = {{1475-2662}},
Unique-ID = {{ISI:000360211100010}},
}

@article{ ISI:000302514300007,
Author = {Marczinski, Cecile A. and Fillmore, Mark T. and Henges, Amy L. and
   Ramsey, Meagan A. and Young, Chelsea R.},
Title = {{Effects of Energy Drinks Mixed With Alcohol on Information Processing,
   Motor Coordination and Subjective Reports of Intoxication}},
Journal = {{EXPERIMENTAL AND CLINICAL PSYCHOPHARMACOLOGY}},
Year = {{2012}},
Volume = {{20}},
Number = {{2}},
Pages = {{129-138}},
Month = {{APR}},
Abstract = {{The consumption of alcohol mixed with energy drinks (AmED) has become a
   popular and controversial practice among young people. Increased rates
   of impaired driving and injuries have been associated with AmED
   consumption. The purpose of this study was to examine if the consumption
   of AmED alters cognitive processing and subjective measures of
   intoxication compared with the consumption of alcohol alone. Eighteen
   participants (nine men and nine women) attended four test sessions where
   they received one of four doses in random order (0.65g/kg alcohol, 3.57
   ml/kg energy drink, AmED, or a placebo beverage). Performance on a
   psychological refractory period (PRP) task was used to measure dual-task
   information processing and performance on the Purdue pegboard task was
   used to measure simple and complex motor coordination following dose
   administration. In addition, various subjective measures of stimulation,
   sedation, impairment, and level of intoxication were recorded. The
   results indicated that alcohol slowed dual-task information processing
   and impaired simple and complex motor coordination. The coadministration
   of the energy drink with alcohol did not alter the alcohol-induced
   impairment on these objective measures. For subjective effects, alcohol
   increased various ratings indicative of feelings of intoxication. More
   importantly, coadministration of the energy drink with alcohol reduced
   perceptions of mental fatigue and enhanced feelings of stimulation
   compared to alcohol alone. In conclusion, AmED may contribute to a
   high-risk scenario for a drinker. The mix of behavioral impairment with
   reduced fatigue and enhanced stimulation may lead AmED consumers to
   erroneously perceive themselves as better able to function than is
   actually the case.}},
DOI = {{10.1037/a0026136}},
ISSN = {{1064-1297}},
Unique-ID = {{ISI:000302514300007}},
}

@article{ ISI:000300655100002,
Author = {Stillwater, Tai and Kurani, Kenneth},
Title = {{Field Test of Energy Information Feedback Driver Responses and
   Behavioral Theory}},
Journal = {{TRANSPORTATION RESEARCH RECORD}},
Year = {{2011}},
Number = {{2252}},
Pages = {{7-15}},
Abstract = {{The Energy Information Administration estimates that, in 2007, U.S.
   domestic passenger vehicles burned 113 billion gallons of fuel and thus
   generated more than 16\% of U.S. greenhouse gas emissions. Past field
   experiments and simulations suggest that energy information feedback to
   drivers could have spared 10\% to 25\% of those gallons. However, the
   theoretical underpinnings of past experiments have primarily been ad
   hoc, with application of their results limited to specific conditions of
   the experiment and feedback design. More rigorous behavioral theory
   would allow researchers to account for more variation in driver response
   to feedback, create testable hypotheses about the effectiveness of
   current systems, and provide a basis for designing more-effective
   systems. This paper presents drivers' responses to energy feedback in a
   field test involving 98 participants from 43 households in California
   and compares the results with the concepts that underlie the theory of
   planned behavior and the extended model of goal-directed behavior. About
   40\% of participants reported more economical driving behaviors after
   viewing the feedback; estimation of actual changes in fuel use is left
   for future research. After viewing real-time energy information,
   numerous drivers reported setting goals, having emotional reactions, and
   creating new driving behaviors. Distraction from the primary driving
   task was a persistent problem for some drivers. Web-accessible
   information was not as motivating to participants. Finally, the study
   finds evidence of correspondence between theoretical behavioral factors
   and drivers' responses.}},
DOI = {{10.3141/2252-02}},
ISSN = {{0361-1981}},
Unique-ID = {{ISI:000300655100002}},
}

@inproceedings{ ISI:000248332001165,
Author = {Hui, Yao},
Editor = {{Jing, G and Gao, J and Zhou, A and Gou, P}},
Title = {{On establishing innovation-oriented coal enterprises}},
Booktitle = {{Progress in Mining Science and Safety Technology, Pts A and B}},
Year = {{2007}},
Pages = {{2166-2172}},
Note = {{International Symposium on Mining Science and Safety Technology,
   Jiaozuo, PEOPLES R CHINA, APR 16-19, 2007}},
Organization = {{Henan Polytech Univ; China Occupat Safety \& Hlth Assoc; China Coal
   Assoc; Japan Muroran Inst Technol; Japan Kyushu Univ; Poland Slaska
   Univ; Mining Fac Penn Univ; France Lille Univ; TAFE, Australia Cent
   Gippsland Inst; Polland Res Inst Labor Protect; Int Journal Occupat
   Safety \& Ergon}},
Abstract = {{The basic aim of enterprises' technology innovation is to improve their
   market competition, the basic-sign of which is their economic
   performance. Technology innovation actually refers that the enterprises
   use new knowledge, new technology and new method of production and
   administration to produce new products, new techniques and to offer new
   services, occupy the market and achieve the market value. The criterion
   to the success or failure of technology innovation is profit. The
   national and international practice of technology innovation shows that
   technology innovation could not be separated from the market. On the
   basis of the market's request, technology innovation puts forward the
   direction of innovation and then makes a tentative plan into a product
   and sells it in the market. The product will be improved after it is
   tested in the market. Then new direction of innovation will be put
   forward. That comes into being a circulation. In the process of
   enterprises' technology innovation, enterprises are the main body,
   customers are the guidance, the market is the mechanism, the government
   is the environment, and the institutes are the support. During the
   process of innovation, entrepreneurs are the soul. This could be a
   complete innovation system! To Chinese enterprises' technology
   innovation, under the circumstances of the variation of market request
   and science and technology developing fast, the ability of technology
   innovation is not enough for good economic performance of enterprises'
   technology innovation, enterprises need to have the ability to know
   their customers' demand in time and accurately, the ability to make use
   of the market, the ability of administration innovation and the ability
   to make use of those abilities comprehensively. Obviously, the principle
   power of technology innovation is enterprises, the dominant power is
   entrepreneurs. Chinese coal enterprises have entered a national and
   international market and are facing fierce market competition and the
   challenge of new energies and replaceable energies. Chinese coal
   enterprises must walk out of the traditional developing mode; improve
   themselves in the aspects of value innovation, system innovation,
   technology innovation, market and administration innovation in order to
   establish new type enterprises. In the aspect of technology innovation,
   Chinese coal enterprises need to be independent in innovation, regard
   establishing automatic mines as the main body, regard the equipments
   modernization, systems automation and information administration to
   establish high-technology, high-administration, high-efficiency and
   high-profit enterprises and build up an intensive producing pattern; to
   develop green coal technology, establish green mines, make the best use
   of coal materials and create best social benefits; regard the resources
   administration as the guidance, persist ``Man First{''} and improve
   security technology. In order to enhance coal enterprises' independent
   innovation ability, the enterprises should learn to get used to new
   situation and cultivate and introduce innovation talents in order to
   form the inner environment of innovation. The government should support
   enterprises' innovation in the aspects of finance, taxes, distribution
   system. The government should form the system of encouragement
   theoretically and create the outer environment for encouraging
   enterprises' independent innovation; innovative ecosystem.}},
ISBN = {{978-7-03-018737-6}},
Unique-ID = {{ISI:000248332001165}},
}

@article{ ISI:000325070700019,
Author = {Nautiyal, Sunil},
Title = {{A transition from wood fuel to LPG and its impact on energy conservation
   and health in the Central Himalayas, India}},
Journal = {{JOURNAL OF MOUNTAIN SCIENCE}},
Year = {{2013}},
Volume = {{10}},
Number = {{5}},
Pages = {{898-912}},
Month = {{OCT}},
Abstract = {{The aim of the study was to evaluate the impacts of the transition from
   wood fuel to Liquefied Petroleum Gas (LPG) from energy use and health
   perspectives along an altitudinal gradient (viz., lower altitude; middle
   altitude; and higher altitude) of the Central Himalayas. Empirical field
   study and questionnaire based survey was conducted for obtaining the
   data. A total of 20 households from each altitude were selected for
   obtaining reliable information on the actual quantity of fuelwood
   consumed. Of the 20 households, five households each based on the family
   size i.e., small families (< 4 members), medium (5-8 members) and large
   (> 9 members) from all the altitudinal regions were selected. This was
   followed by an administration of a questionnaire on the quantity of
   fuelwood consumed. After the completion of the questionnaire survey, the
   data was validated using a weighted survey for the randomly selected
   households for obtaining precise information on the actual quantity of
   fuelwood consumed. Energy analysis is done with respect to the time
   spent on fuelwood collection and energy value of burning of per kg of
   fuelwood. Study indicates that declining biomass requirement from
   forests contributes significantly towards energy conservation, also has
   positive impact on human health. Per capita annual energy expenditure on
   collection of fuelwood is 752 MJ which is higher than any other activity
   in villages of Central Himalaya. The LPG substitution has contributed to
   energy saving which is equivalent to 2976-3,742 MJ per capita per year
   in middle and lower altitudes respectively. In the higher altitude the
   energy saving is calculated to be about 257 MJ per capita per year.
   Replacing fuelwood with LPG has made positive impact on society in terms
   of improving the health while reducing diseases that are caused due to
   indoor air pollution.}},
DOI = {{10.1007/s11629-013-2698-1}},
ISSN = {{1672-6316}},
Unique-ID = {{ISI:000325070700019}},
}

@article{ ISI:000309042100031,
Author = {Hojjati, Behjat and Wade, Steven H.},
Title = {{U.S. household energy consumption and intensity trends: A decomposition
   approach}},
Journal = {{ENERGY POLICY}},
Year = {{2012}},
Volume = {{48}},
Pages = {{304-314}},
Month = {{SEP}},
Abstract = {{Concerns over impacts from U.S. energy use on the environment, the
   economy and the national security warrant an understanding of the key
   drivers of energy consumption. This paper focuses on decomposing U.S.
   household energy consumption changes into several factors that have
   affected its growth. The interval analyzed is based on household surveys
   conducted by the U.S. Energy Information Administration from 1980
   through 2005. Drivers of total household energy consumption, total
   household electricity consumption and natural gas use for space heating
   are analyzed and contrasted. While not definitive, sub-period analyses
   split at 1990, show greater reductions in energy intensity in the later
   sub-period and provide prima fascia evidence of the efficacy of U.S.
   efforts to promote energy efficiency through various standards and
   programs. Published by Elsevier Ltd.}},
DOI = {{10.1016/j.enpol.2012.05.024}},
ISSN = {{0301-4215}},
Unique-ID = {{ISI:000309042100031}},
}

@article{ ISI:000283561900022,
Author = {Kaza, Nikhil},
Title = {{Understanding the spectrum of residential energy consumption: A quantile
   regression approach}},
Journal = {{ENERGY POLICY}},
Year = {{2010}},
Volume = {{38}},
Number = {{11, SI}},
Pages = {{6574-6585}},
Month = {{NOV}},
Abstract = {{Residential energy consumption accounts for 22\% of the total energy
   consumption in the US. However, the impacts of local planning policies,
   such as increasing density and changing the housing type mix, on
   residential energy consumption are not well understood. Using
   Residential Energy Consumption Survey Data from the Energy Information
   Administration, quantile regression analysis was used to tease out the
   effects of various factors on entire distribution on the energy
   consumption spectrum instead of focusing on the conditional average.
   Results show that while housing size matters for space conditioning,
   housing type has a more nuanced impact. Self-reported neighborhood
   density does not seem to have any impact on energy use. Furthermore, the
   effects of these factors at the tails of the energy use distribution are
   substantially different than the average, in some cases differing by a
   factor of six. Some, not all, types of multifamily housing offer almost
   as much savings as reduction in housing area by 100 m(2), compared to
   single family houses. (C) 2010 Elsevier Ltd. All rights reserved.}},
DOI = {{10.1016/j.enpol.2010.06.028}},
ISSN = {{0301-4215}},
Unique-ID = {{ISI:000283561900022}},
}

@article{ ISI:000178690200004,
Author = {Romm, J},
Title = {{The internet and the new energy economy}},
Journal = {{RESOURCES CONSERVATION AND RECYCLING}},
Year = {{2002}},
Volume = {{36}},
Number = {{3}},
Pages = {{197-210}},
Month = {{OCT}},
Abstract = {{From 1996 through 2000, the US experienced an unprecedented 2.7\% annual
   reduction in energy intensity. This is three times the rate of the
   previous 10 years and far higher than the rate projected by traditional
   energy forecasters. There is increasing data and analysis to support the
   view that there is a connection between the recent reductions in energy
   intensity and the astonishing growth in information technology (IT) and
   the internet economy. Growth in the Internet economy can cut energy
   intensity in two ways. First, the IT sector is less energy-intensive
   than traditional manufacturing, so growth in this sector engenders less
   incremental energy consumption. Second, the internet economy appears to
   be increasing efficiency in every sector of the economy, which is the
   primary focus of this paper. The impact of the Internet economy on
   manufacturing, buildings, and transportation are all explored. The paper
   also considers the implications for growth in energy consumption and
   greenhouse gas emissions during the next 10 years. Also, there has been
   a widely quoted argument put forward by two analysts, Mark Mills and
   Peter Huber, that the Internet is using a large and rapidly growing
   share of the nation's electricity, which in turn is supposedly driving
   an acceleration of overall US electricity demand. That analysis should
   be rejected as it is based on seriously faulty analysis and is
   inconsistent with recent data and analyses. Finally, the Bush
   administration put forward a new approach to US climate change strategy,
   based on reducing carbon intensity. This paper suggests that such an
   approach may not lead to reductions in carbon emissions beyond business
   as usual trends. (C) 2002 Elsevier Science B.V. All rights reserved.}},
DOI = {{10.1016/S0921-3449(02)00084-8}},
Article-Number = {{PII S0921-3449(02)00084-8}},
ISSN = {{0921-3449}},
Unique-ID = {{ISI:000178690200004}},
}

@article{ ISI:000171238400009,
Author = {Hadley, SW and Short, W},
Title = {{Electricity sector analysis in the clean energy futures study}},
Journal = {{ENERGY POLICY}},
Year = {{2001}},
Volume = {{29}},
Number = {{14, SI}},
Pages = {{1285-1298}},
Month = {{NOV}},
Abstract = {{This paper examines the impact of policies to reduce carbon and other
   air emissions in the electric sector. The analysis is from a recent
   scenario development effort, Scenarios for a Clean Energy Future (CEF),
   by five National Laboratories. The CEF assesses how policies can be used
   to promote energy-efficient and clean energy technologies to address key
   energy and environmental challenges facing the United States. The impact
   of policies in the electric sector is evaluated using the CEF-NEMS
   model, which is derived from the National Energy Modeling System (NEMS)
   model developed by the DOE Energy Information Administration. The
   analysis shows that by 2020 under the policies analyzed, CO2 and other
   emissions can be substantially reduced by moving from coal to advanced
   gas combined cycle systems and renewable energy. Prices show little
   change and may drop due to decreased end-use demands. Published by
   Elsevier Science Ltd.}},
DOI = {{10.1016/S0301-4215(01)00073-8}},
ISSN = {{0301-4215}},
ResearcherID-Numbers = {{Hadley, Stanton/O-1465-2015}},
ORCID-Numbers = {{Hadley, Stanton/0000-0002-6514-8802}},
Unique-ID = {{ISI:000171238400009}},
}

@inproceedings{ ISI:000335710300135,
Author = {Picon-Feliciano, Ruben and Pillich, Jose and Gonzalez-Cruz, Jorge E.},
Book-Group-Author = {{ASME}},
Title = {{IMPACTS OF A WARMING CLIMATE ON ENERGY DEMANDS ON US NORTHEAST REGION}},
Booktitle = {{PROCEEDINGS OF THE ASME 6TH INTERNATIONAL CONFERENCE ON ENERGY
   SUSTAINABILITY - 2012, PTS A AND B}},
Year = {{2012}},
Pages = {{1173-1178}},
Note = {{6th ASME International Conference on Energy Sustainability, San Diego,
   CA, JUL 23-26, 2012}},
Organization = {{ASME, Adv Energy Syst Div; ASME, Solar Energy Div}},
Abstract = {{This paper analyzes the impacts of a changing climate to long-term
   energy activity reflected in power consumption and carbon emissions for
   the United States (US) Northeast (NE) region. This region represents
   approximately four percent of the total power consumption of the US. The
   paper revises the potential changes in the regional climate in the NE by
   analyzing long-term records of climatological data, and how these
   potential changes are impacting the energy demands and anthropogenic
   emissions due to power production. Climate records from 372 stations
   spread over the 9 states in the NE region were used for the period of
   time comprising from 1970 to 2010. The stations are part of NOAA's
   Cooperative Observation Stations (COOP) that includes data for
   precipitation and surface maximum, minimum and average temperatures. Sea
   surface temperatures (SSTs) for the region were analyzed from NOAA
   extended reconstructed sea surface temperature (ERSST) records. Long
   term records for state energy profiles were generated by examining the
   end-use sectors: residential, commercial and industrial sector using
   data from the Energy Information Administration (ETA). Results from the
   COOP stations and SSTs reflect that the NE region presents an asymmetric
   warming reflected in significant coastal warming and inland cooling. A
   maximum land temperature variability of 1.61 degrees C/decade was
   observed during this period of time with a mean value of 0.012 degrees
   C/decade for the entire region. This coastal warming may be attributed
   to a combined effect of global warming and population growth reflected
   in urbanization and related effects such as the Urban Heat Island (UHI).
   A symmetric warming was found in minimum surface temperatures across the
   region with an average of 0.06 degrees C/decade. Both land surface
   temperature increases are consistent with regional SSTs trends. The
   energy analysis suggests that a correlation may exist between the
   locations of highest energy consumption and urbanized coastal areas.
   Total energy consumption in coastal regions increased by 13 percent
   during 1960-2010, in contrast, inland sites consumption increased by 9
   percent. At the sector level, CO2 emissions associated to residential
   energy demand drastically decreased over 37 percent per capita,
   attributed to energy efficiencies and possibly to a warmer region in
   winter times. Despite these trends, the NE region continues to be one of
   the largest CO2 sources of US accounting for more than 15\% of all
   emissions. These results reflect the need for better understanding of
   the connections between climate, energy demands and production to
   achieve sustainable growth.}},
ISBN = {{978-0-7918-4481-6}},
Unique-ID = {{ISI:000335710300135}},
}

@inproceedings{ ISI:000313202800018,
Author = {Kosovich, Judy},
Editor = {{Valone, T}},
Title = {{The Regulation of Energy Medicine}},
Booktitle = {{SPACE, PROPULSION \& ENERGY SCIENCES INTERNATIONAL FORUM}},
Series = {{Physics Procedia}},
Year = {{2012}},
Volume = {{38}},
Pages = {{242-252}},
Note = {{Space, Propulsion and Energy Sciences International Forum (SPESIF), Univ
   Maryland, College Park, MD, FEB 29-MAR 02, 2012}},
Organization = {{Integr Res Inst (IRI); Astrosociol Res Inst; Arcos Cielos Res Fdn;
   Global Gateway Fdn; Energy \& Propuls Syst}},
Abstract = {{This paper describes the laws and regulations that affect the practice
   of energy medicine. State law often has more impact on a health care
   practice than federal law, but federal law provides a common denominator
   among states. Device law is emphasized here because practitioners of
   energy medicine are more likely to use devices than drugs. For purposes
   of this paper, energy medicine is defined as practices that measure or
   benefit energy flow and overall energy in the body. This broad
   definition encompasses things as diverse as certain forms of exercise,
   measurement of meridian resistance, the use of electrical current or
   magnetic pulses to relieve pain, and the use of light, sound, scent,
   touch, position, or movement to stimulate the body(sic) own electrical
   systems. What is of greatest importance in determining legal
   implications of a practice is whether there are any health-related
   claims. Two federal entities are pivotal. The Food and Drug
   Administration (EFDAS) is authorized to protect health and safety and
   the Federal Trade Commission (EFTCS) is authorized to protect consumers
   from false or misleading advertising. There are 5 things that FDA looks
   at: 1) intended use, 2) claims made in advertising and in labeling, 3)
   substantial equivalence to a predicate, 4) safety, and 5) effectiveness.
   A concern regarding any one of these can be the basis for denying
   clearance to market a device. The FTC looks at whether statements are
   true and substantiated and whether they might be misleading. The FTC
   often consults with the FDA on the interpretation of technical
   information. (C) 2012 Published by Elsevier B.V. Selection and/or
   peer-review under responsibility of the Integrity Research Institute.}},
DOI = {{10.1016/j.phpro.2012.08.025}},
ISSN = {{1875-3892}},
Unique-ID = {{ISI:000313202800018}},
}

@article{ ISI:000285732700011,
Author = {Howard, Meagan A. and Marczinski, Cecile A.},
Title = {{Acute Effects of a Glucose Energy Drink on Behavioral Control}},
Journal = {{EXPERIMENTAL AND CLINICAL PSYCHOPHARMACOLOGY}},
Year = {{2010}},
Volume = {{18}},
Number = {{6}},
Pages = {{553-561}},
Month = {{DEC}},
Abstract = {{There has been a dramatic rise in the consumption of glucose energy
   drinks (e.g., Amp, Monster, and Red Bull) in the past decade,
   particularly among high school and college students. However, little
   laboratory research has examined the acute objective and subjective
   effects of energy drinks. The purpose of this study was to investigate
   the acute effects of a glucose energy drink (Red Bull) on cognitive
   functioning. Participants (N = 80) were randomly assigned to one of five
   conditions: 1.8 ml/kg energy drink, 3.6 ml/kg energy drink, 5.4 ml/kg
   energy drink, placebo beverage, or no drink. Participants completed a
   well-validated behavioral control task (the cued go/no-go task) and
   subjective measures of stimulation, sedation, and mental fatigue both
   before and 30 minutes following beverage administration. The results
   indicated that compared with the placebo and no drink conditions, the
   energy drink doses decreased reaction times on the behavioral control
   task, increased subjective ratings of stimulation and decreased ratings
   of mental fatigue. Greatest improvements in reaction times and
   subjective measures were observed with the lowest dose and improvements
   diminished as the dose increased. The findings suggest that energy drink
   consumption can improve cognitive performance on a behavioral control
   task, potentially explaining the dramatic rise in popularity of these
   controversial new beverages.}},
DOI = {{10.1037/a0021740}},
ISSN = {{1064-1297}},
Unique-ID = {{ISI:000285732700011}},
}

@inproceedings{ ISI:000357346100078,
Author = {Pardhasaradhi, Y.},
Editor = {{Zhu, X and Zhao, S}},
Title = {{Towards Global Public Administration: Compulsions and Constraints}},
Booktitle = {{PROCEEDINGS OF 2014 INTERNATIONAL CONFERENCE ON PUBLIC ADMINISTRATION
   (10TH), VOL I}},
Year = {{2014}},
Pages = {{663-668}},
Note = {{10th International Conference on Public Administration, Univ Elect Sci
   \& Technol China, Sch Polit Sci \& Publ Adm, Chengdu, PEOPLES R CHINA,
   OCT 24-26, 2014}},
Organization = {{Univ Elect Sci \& Technol China; Amer Soc Publ Adm; Chinese Publ Adm
   Soc; Chinese Publ Adm Journal; Moscow State Univ, Sch Publ Adm; Cape
   Peninsula Univ Technol, Fac Business; Univ Elect Sci \& Technol China,
   PA Informat Res Ctr}},
Abstract = {{Much has been debated about the relevance of traditional public
   administration in an age of globalization and virtual market economy.
   The processes of globalization demand radical policy changes and
   restructuring of government organizations with emphasis on enhanced
   skills of the public employees. Market economy or the knowledge economy
   requires collaboration across the board government to government
   interoperability, free trade agreements among a set of neighbouring
   nations, playing by the rules set by the World Trade Organization,
   intellectual property rights and competitive ventures between
   multi-national companies. This. situation calls in for specialization in
   the bureaucratic structure of countries, especially those from the
   developing world. The genesis for global public administration can be
   traced in the New Public Management movement (NPM) of the early 1980s.
   NPM has been called market-based public administration, managerialism,
   reinvention of government, and a post-bureaucratic model. Now, the
   concepts of governance and good governance by extension E-governance and
   E-government - are being increasingly used in development literature.
   E-government is an essential condition for global administration and
   integration with the world economy. However, there are many critical
   issues that can mar the concept of global public administration. Global
   terrorism, natural and human disasters, epidemic diseases, economic
   crises, energy and environmental problems, and ethnic conflicts, are all
   globally interconnected. Even problems within the traditional domestic
   policy realms, such as public transportation, information management,
   and defense and security, have been pushed across national boundaries by
   extended privatization and contracting out, demanding global
   perspectives in building knowledge and seeking solutions. With this
   background, this paper will try to present a perspective on the
   compulsions of global public administration and the major challenges
   that it faces in its spread.}},
ISBN = {{978-7-5647-2652-2}},
Unique-ID = {{ISI:000357346100078}},
}

@inproceedings{ ISI:000298299400080,
Author = {Wang Tao and Wang Haidong and Du Huibin},
Editor = {{Zhang, W}},
Title = {{Regulation on Energy Industry in China under Asymmetric Information}},
Booktitle = {{2010 INTERNATIONAL CONFERENCE ON ENERGY, ENVIRONMENT AND DEVELOPMENT
   (ICEED2010)}},
Series = {{Energy Procedia}},
Year = {{2011}},
Volume = {{5}},
Pages = {{462-466}},
Note = {{International Conference on Energy, Environment and Development (ICEED),
   Kuala Lumpur, MALAYSIA, DEC 08-09, 2010}},
Abstract = {{This paper studies the implementation of a regulation problem of China
   in which the energy industry's private information is unknown to the
   state-owned assets supervision and administration commission of the
   state council ( SASAC). It's reasonable to use a fuzzy variable to
   denote the subjective assessment of the SASAC to the private
   information. A principal-agent model is then set up to maximize the
   welfare of the SASAC. Pontryagin maximum principle is adopted in this
   paper to obtain the necessary condition of the optimal solutions. (C)
   2011 Published by Elsevier Ltd. Selection and peer-review under
   responsibility of RIUDS}},
DOI = {{10.1016/j.egypro.2011.03.080}},
ISSN = {{1876-6102}},
Unique-ID = {{ISI:000298299400080}},
}

@article{ ISI:000321437000004,
Author = {Barbose, Galen L. and Goldman, Charles A. and Hoffman, Ian M. and
   Billingsley, Megan},
Title = {{The future of utility customer-funded energy efficiency programs in the
   USA: projected spending and savings to 2025}},
Journal = {{ENERGY EFFICIENCY}},
Year = {{2013}},
Volume = {{6}},
Number = {{3}},
Pages = {{475-493}},
Month = {{AUG}},
Abstract = {{We develop projections of future spending on, and savings from, energy
   efficiency programs funded by electric and gas utility customers in the
   USA, under three scenarios through 2025. Our analysis, which updates a
   previous LBNL study, relies on detailed bottom-up modeling of current
   state energy efficiency policies, regulatory decisions, and demand-side
   management and utility resource plans. The three scenarios are intended
   to represent a range of potential outcomes under the current policy
   environment (i.e., without considering possible major new policy
   developments).
   Key findings from the analysis are as follows:
   By 2025, spending on electric and gas efficiency programs (excluding
   load management programs) is projected to double from 2010 levels to
   \$9.5 billion in the medium case, compared to \$15.6 billion in the high
   case and \$6.5 billion in the low case.
   Compliance with statewide legislative or regulatory savings or spending
   targets is the primary driver for the increase in electric program
   spending through 2025, though a significant share of the increase is
   also driven by utility DSM planning activity and integrated resource
   planning.
   Our analysis suggests that electric efficiency program spending may
   approach a more even geographic distribution over time in terms of
   absolute dollars spent, with the Northeastern and Western states
   declining from over 70 \% of total USA spending in 2010 to slightly more
   than 50 \% in 2025, and the South and Midwest splitting the remainder
   roughly evenly.
   Under our medium case scenario, annual incremental savings from
   customer-funded electric energy efficiency programs increase from 18.4
   TWh in 2010 in the USA (which is about 0.5 \% of electric utility retail
   sales) to 28.8 TWh in 2025 (0.8 \% of retail sales).
   These savings would offset the majority of load growth in the Energy
   Information Administration's most recent reference case forecast, given
   specific assumptions about the extent to which future energy efficiency
   program savings are captured in that forecast.
   The pathway that customer-funded efficiency programs ultimately take
   will depend on a series of key challenges and uncertainties associated
   both with the broader market and policy context and with the
   implementation and regulatory oversight of the energy efficiency
   programs themselves.}},
DOI = {{10.1007/s12053-012-9187-1}},
ISSN = {{1570-646X}},
Unique-ID = {{ISI:000321437000004}},
}

@article{ ISI:000247662200019,
Author = {Lightfoot, H. Douglas},
Title = {{Understand the three different scales for measuring primary energy and
   avoid errors}},
Journal = {{ENERGY}},
Year = {{2007}},
Volume = {{32}},
Number = {{8}},
Pages = {{1478-1483}},
Month = {{AUG}},
Abstract = {{Three quite different scales for measuring the amount of primary energy
   the world uses annually are currently in use. The Engineering
   Information Administration, the International Energy Agency and the
   Working Group III (WG III) of the Intergovernmental Panel on Climate
   Change (IPCC), each has its own scale for measuring and recording
   primary energy. The purpose of this paper is to clarify the relationship
   between these scales so the reader can avoid introducing errors into
   work involving primary energy. An example is presented to show how
   mixing of these scales, and not identifying them, constitutes an error
   in 16 of the 40 energy scenarios in the Special Report on Emissions
   Scenarios prepared by WG III of the IPCC. These three scales arise
   mainly because of legitimate differences of opinion about how to measure
   and record primary energy, and especially for generating electricity
   from nuclear and renewable energies. All three scales use ``Joules{''}
   as the unit of energy measurement, but these ``Joules{''} are arbitrary
   units and are not the precise Joule as defined and used in physics and
   chemistry. (c) 2006 Elsevier Ltd. All rights reserved.}},
DOI = {{10.1016/j.energy.2006.10.009}},
ISSN = {{0360-5442}},
Unique-ID = {{ISI:000247662200019}},
}

@inproceedings{ ISI:000238049700093,
Author = {Chen, Biao and Jing, Zhenxue and Smith, Andrew P. and Parikh, Samir and
   Parisky, Yuri},
Editor = {{Flynn, MJ and Hsieh, J}},
Title = {{Dual-energy contrast-enhanced digital mammography (DE-CEDM):
   Optimization on digital subtraction with practical x-ray low/high-energy
   spectra - art. no. 61422N}},
Booktitle = {{Medical Imaging 2006: Physics of Medical Imaging, Pts 1-3}},
Series = {{PROCEEDINGS OF THE SOCIETY OF PHOTO-OPTICAL INSTRUMENTATION ENGINEERS
   (SPIE)}},
Year = {{2006}},
Volume = {{6142}},
Number = {{1-3}},
Pages = {{N1422}},
Note = {{Medical Imaging 2006 Conference, San Diego, CA, FEB 12-14, 2006}},
Organization = {{SPIE}},
Abstract = {{Dual-energy contrast enhanced digital mammography (DE-CEDM), which is
   based upon the digital subtraction of low/high-energy image pairs
   acquired before/after the administration of contrast agents, may provide
   physicians physiologic and morphologic information of breast lesions and
   help characterize their probability of malignancy. This paper proposes
   to use only one pair of post-contrast low/high-energy images to obtain
   digitally subtracted dual-energy contrast-enhanced images with an
   optimal weighting factor deduced from simulated characteristics of the
   imaging chain. Based upon our previous CEDM framework, quantitative
   characteristics of the materials and imaging components in the x-ray
   imaging chain, including x-ray tube (tungsten) spectrum, filters, breast
   tissues/lesions, contrast agents (non-ionized iodine solution), and
   selenium detector, were systemically modeled. Using the base-material
   (polyethylene-PMMA) decomposition method based on entrance
   low/high-energy x-ray spectra and breast thickness, the optimal
   weighting factor was calculated to cancel the contrast between fatty and
   glandular tissues while enhancing the contrast of iodized lesions. By
   contrast, previous work determined the optimal weighting factor through
   either a calibration step or through acquisition of a pre-contrast
   low/high-energy image pair. Computer simulations were conducted to
   determine weighting factors, lesions' contrast signal values, and dose
   levels as functions of x-ray techniques and breast thicknesses. Phantom
   and clinical feasibility studies were performed on a modified Selenia
   full field digital mammography system to verify the proposed method and
   computer-simulated results. The resultant conclusions from the computer
   simulations kind phantom/clinical feasibility studies will be used in
   the upcoming clinical study.}},
DOI = {{10.1117/12.653203}},
Article-Number = {{61422N}},
ISSN = {{0277-786X}},
ISBN = {{0-8194-6185-7}},
Unique-ID = {{ISI:000238049700093}},
}

@inproceedings{ ISI:000229929500140,
Author = {Kwan, ALC and Boone, JM and Le-Petross, H and Lindfors, KK and Seibert,
   JA and Lewin, JM},
Editor = {{Flynn, MJ}},
Title = {{Contrast-enhanced dual-energy digital subtraction mammography:
   Optimization of the beam energy}},
Booktitle = {{Medical Imaging 2005: Physics of Medical Imaging, Pts 1 and 2}},
Series = {{PROCEEDINGS OF THE SOCIETY OF PHOTO-OPTICAL INSTRUMENTATION ENGINEERS
   (SPIE)}},
Year = {{2005}},
Volume = {{5745}},
Number = {{1-2}},
Pages = {{1317-1321}},
Note = {{Medical Imaging 2005 Conference, San Diego, CA, FEB 15-17, 2005}},
Organization = {{SPIE}},
Abstract = {{The implementation of contrast-enhanced dual-energy digital subtraction
   mammography may lead to better identification of breast tumors, and thus
   provide a lower cost and more widely available alternative to breast
   MRI. This technique involves the acquisition of low- and high-energy
   images after the IV administration of iodinated contrast agent. In this
   study, the effect of the beam energy (kVp) was examined using the
   CNR2/dose metric, where CNR is the contrast-to-noise ratio and dose
   implies the mean glandular dose. The mean glandular dose was calculated
   using parameterized normalized glandular dose coefficients (DgN), which
   allowed the computation of the mean glandular dose for the modeled
   spectra considered in this study, coupled with incident kerma
   measurements. Optimization studies were performed using a dedicated
   cone-beam breast CT scanner designed and fabricated in our laboratory,
   with the system operating in stationary imaging mode. A flat
   tissue-equivalent phantom (7.5 cm in thickness) was placed at the
   isocenter of the scanner, and an air gap of 34.5 cm was used in lieu of
   a grid. Dilute iodine-based contrast agent was introduced into the
   phantoms using plastic vials. Data were acquired from 40 to 90 kVp at 10
   kVp intervals. Due to the low mA available on the breast CT system, a
   large number of images (1000) were acquired in fluoroscopic mode, which
   allowed us to match the dose and noise properties for each kVp
   combinations by changing the number of images used for averaging.
   Preliminary results demonstrate that the best CNR2/dose is achieved with
   a 50 kVp low-energy image and a 90 kVp high-energy image. Consequently,
   radiation doses for contrast-enhanced mammography should be far lower
   than regular mammography. Since the spatial resolution requirements
   should also be lower than regular mammography, dual-energy
   contrast-enhanced mammography, when performed using the optimal
   technique factor, may indeed provide very similar diagnostic information
   as breast MRI but at significantly reduced costs.}},
DOI = {{10.1117/12.595887}},
ISSN = {{0277-786X}},
ISBN = {{0-8194-5719-1}},
Unique-ID = {{ISI:000229929500140}},
}

@article{ ISI:000307861600006,
Author = {Larson, William and Liu, Feng and Yezer, Anthony},
Title = {{Energy footprint of the city: Effects of urban land use and
   transportation policies}},
Journal = {{JOURNAL OF URBAN ECONOMICS}},
Year = {{2012}},
Volume = {{72}},
Number = {{2-3}},
Pages = {{147-159}},
Month = {{SEP-NOV}},
Abstract = {{Urban land use and transportation policies have dramatic effects on the
   density and spatial distribution of residences in large cities. Effects
   of these policies have been analyzed using numerical urban simulation
   models. At the same time, the US Energy Information Administration's
   Residential Energy Consumption Survey has allowed researchers to
   investigate the relation between household energy consumption and
   characteristics of housing units.
   This paper links these two lines of inquiry by demonstrating how
   simulation results on the implications of land use and transportation
   policies for the spatial form of cities can be used to compute
   implications for energy consumption. The resulting Urban Energy
   Footprint Model, ``UEFM,{''} allows one to trace the implications of a
   change in land use zoning or transportation policy through its effects
   on housing markets and residential location to the resulting changes in
   energy use for residential and commuting purposes - i.e. to understand
   the energy footprint of transportation, housing, and land use policies.
   Accordingly, the UEFM provides, perhaps for the first time, a link
   between urban and energy economics, and can allow measurement of rebound
   effects of energy policies in a more general equilibrium context. (C)
   2012 Elsevier Inc. All rights reserved.}},
DOI = {{10.1016/j.jue.2012.05.001}},
ISSN = {{0094-1190}},
Unique-ID = {{ISI:000307861600006}},
}

@article{ ISI:000304486400006,
Author = {Su, Ming-Chien and Kao, Nien-Hsin and Huang, Wen-Jar},
Title = {{Potential assessment of establishing a renewable energy plant in a rural
   agricultural area}},
Journal = {{JOURNAL OF THE AIR \& WASTE MANAGEMENT ASSOCIATION}},
Year = {{2012}},
Volume = {{62}},
Number = {{6}},
Pages = {{662-670}},
Abstract = {{An evaluation of the green energy potential generated from biogas and
   solar power, using agricultural manure waste and a photovoltaic (PV)
   system, was conducted in a large geographical area of a rural county
   with low population density and low pollution. The studied area,
   Shoufeng Township in Hualien County, is located in eastern Taiwan, where
   a large amount of manure waste is generated from pig farms that are
   scattered throughout the county. The objective of the study is to assess
   the possibility of establishing an integrated manure waste treatment
   plant by using the generated biogas incorporated with the PV system to
   produce renewable energy and then feed it back to the incorporated
   farms. A filed investigation, geographic information system (GIS)
   application, empirical equations development, and RETScreen modeling
   were conducted in the study. The results indicate that Shoufeng Township
   has the highest priority in setting up an integrated treatment and
   renewable energy plant by using GIS mapping within a 10-km radius of the
   transportation range. Two scenarios were plotted in assessing the
   renewable energy plant and the estimated electricity generation, plus
   the greenhouse gas (GHG) reduction was evaluated. Under the current
   governmental green energy scheme and from a long-term perspective, the
   assessment shows great potential in establishing the plant, especially
   in reducing environmental pollution problems, waste treatment, and
   developing suitable renewable energy.
   Implications: The livestock industry is a major point source that
   creates an enormous environmental pollution problem; generally,
   traditional treatment of manure waste can only reduce a portion of the
   problem without a better solution. Establishing an integrated treatment
   plant can lead to the development of renewable energy by using the
   treated waste; moreover, modeling results indicated that incorporated
   with the photovoltaic application, the system can achieve a win-win
   solution for the environment and energy utilization. Under the current
   governmental green energy scheme and from a long-term perspective, the
   assessment shows great potential and provides a better policy for the
   Environmental Protection Administration, Taiwan, in solving the
   pollution issue.}},
DOI = {{10.1080/10962247.2012.665415}},
ISSN = {{1096-2247}},
Unique-ID = {{ISI:000304486400006}},
}

@article{ ISI:000078323200003,
Author = {Walls, WD},
Title = {{Energy policy and energy price dispersion: Methods and application to US
   Data}},
Journal = {{ENERGY EXPLORATION \& EXPLOITATION}},
Year = {{1998}},
Volume = {{16}},
Number = {{5}},
Pages = {{443-451}},
Abstract = {{Energy policy is increasingly aimed at achieving an efficient allocation
   of energy resources across alternative uses through the design and
   implementation of market-based incentives. According to the economists'
   `law of one price,' an efficient allocation is one that reduces spatial
   price dispersion to that which is consistent with transportation and
   transaction costs. Using data from the U.S. Energy Information
   Administration's State Energy Price and Expenditure Report, this paper
   examines the dispersion of U.S. energy prices for the period 1970- 1993
   using a variety of metrics. If is found that prices for electric utility
   inputs have converged. Dispersion for other energy products has
   increased, not due to rising energy prices, but primarily because energy
   prices are falling faster in regions with below-average pries than in
   regions with above-average prices. The current increased level of price
   dispersion appears to be a transient effect in the transition from a
   regulated sector to one based on free market principles.}},
ISSN = {{0144-5987}},
Unique-ID = {{ISI:000078323200003}},
}

@article{ ISI:000331894900002,
Author = {Klabunde, Carrie N. and Clauser, Steven B. and Liu, Benmei and Pronk,
   Nicolaas P. and Ballard-Barbash, Rachel and Huang, Terry T. -K. and
   Smith, Ashley Wilder},
Title = {{Organization of Primary Care Practice for Providing Energy Balance Care}},
Journal = {{AMERICAN JOURNAL OF HEALTH PROMOTION}},
Year = {{2014}},
Volume = {{28}},
Number = {{3}},
Pages = {{E67-E80}},
Month = {{JAN-FEB}},
Abstract = {{Purpose. Primary care physicians (PCPs) may not adequately counsel or
   monitor patients regarding diet, physical activity, and weight control
   (i. e., provide energy balance care). We assessed the organization of
   PCPs' practices for providing this care.
   Design. The study design was a nationally representative survey
   conducted in 2008.
   Setting. The study setting was U. S. primary care practices.
   Subjects. A total of 1740 PCPs completed two sequential questionnaires
   (response rate, 55.5\%).
   Measures. The study measured PCPs' reports of practice resources, and
   the frequency of body mass index assessment, counseling, referral for
   further evaluation/management, and monitoring of patients for energy
   balance care.
   Analysis. Descriptive statistics and logistic regression modeling were
   used.
   Results. More than 80\% of PCPs reported having information resources on
   diet, physical activity, or weight control available in waiting/exam
   rooms, but fewer billed (45\%), used reminder systems (, 30\%), or
   received incentive payments (3\%) for energy balance care. A total of
   26\% reported regularly assessing body mass index and always/often
   providing counseling as well as tracking patients for progress related
   to energy balance. In multivariate analyses, PCPs in practices with full
   electronic health records or those that bill for energy balance care
   provided this care more often and more comprehensively. There were
   strong specialty differences, with pediatricians more likely (odds
   ratio, 1.78; 95\% confidence interval, 1.262.51) and
   obstetrician/gynecologists less likely (odds ratio, 0.28; 95\%
   confidence interval, 0.17-0.44) than others to provide energy balance
   care.
   nce care. Further research is needed to understand PCP care-related
   specialty differences.}},
DOI = {{10.4278/ajhp.121219-QUAN-626}},
ISSN = {{0890-1171}},
EISSN = {{2168-6602}},
Unique-ID = {{ISI:000331894900002}},
}

@article{ ISI:000326016400002,
Author = {Fumo, N. and Bortone, V. and Zambrano, J. C.},
Title = {{Comparative Analysis of Solar Thermal Cooling and Solar Photovoltaic
   Cooling Systems}},
Journal = {{JOURNAL OF SOLAR ENERGY ENGINEERING-TRANSACTIONS OF THE ASME}},
Year = {{2013}},
Volume = {{135}},
Number = {{2}},
Month = {{MAY}},
Abstract = {{The Energy Information Administration of the United States Department of
   Energy projects that more than 80\% of the energy consumption of the U.
   S. by 2035 will come from fossil fuels. This projection should be the
   fuel to promote projects related to renewable energy in order to reduce
   energy consumption from fossil fuels to avoid their undesirable
   consequences such as carbon dioxide emissions. Since solar radiation
   match pretty well building cooling demands, solar cooling systems will
   be an important factor in the next decades to meet or exceed the green
   gases reduction that will be demanded by the society and regulations in
   order to mitigate environmental consequences such as global warming.
   Solar energy can be used as source of energy to produce cooling through
   different technologies. Solar thermal energy applies to technology such
   as absorption chillers and desiccant cooling, while electricity from
   solar photovoltaic can be used to drive vapor compression electric
   chillers. This study focuses on the comparison of a solar thermal
   cooling system that uses an absorption chiller driven by solar thermal
   energy, and a solar photovoltaic cooling system that uses a vapor
   compression system (electric chiller) driven by solar electricity (solar
   photovoltaic system). Both solar cooling systems are compared against a
   standard air cooled cooling system that uses electricity from the grid.
   The models used in the simulations to obtain the results are described
   in the paper along with the parameters (inputs) used. Results are
   presented in two figures. Each figure has one curve for the solar
   thermal cooling system and one for the solar photovoltaic cooling
   system. One figure allows estimation of savings calculated based the
   present value of discounted energy consumption cost. The other figure
   allows estimating primary energy consumption reduction and emissions
   reduction. Both figures presents the result per ton of refrigeration and
   as a function of area of solar collectors or/and area of photovoltaic
   modules. This approach to present the result of the simulations of the
   systems makes these figures quite general. This means that the results
   can be used to compare both solar cooling systems independently of the
   cooling demand (capacity of the system), as well as allow the analysis
   for different sizes of the solar system used to harvest the solar energy
   (collectors or photovoltaic modules).}},
DOI = {{10.1115/1.4007935}},
Article-Number = {{UNSP 021002}},
ISSN = {{0199-6231}},
EISSN = {{1528-8986}},
ORCID-Numbers = {{Zambrano, Juan Carlo/0000-0002-8416-2060}},
Unique-ID = {{ISI:000326016400002}},
}

@inproceedings{ ISI:000321076700013,
Author = {Fumo, N. and Bortone, V. and Zambrano, J. C.},
Book-Group-Author = {{ASME}},
Title = {{COMPARATIVE ANALYSIS OF SOLAR THERMAL COOLING AND SOLAR PHOTOVOLTAIC
   COOLING SYSTEMS}},
Booktitle = {{PROCEEDINGS OF THE ASME 5TH INTERNATIONAL CONFERENCE ON ENERGY
   SUSTAINABILITY 2011, PTS A-C}},
Year = {{2012}},
Pages = {{85-90}},
Note = {{ASME 5th International Conference on Energy Sustainability, Washington,
   DC, AUG 07-10, 2011}},
Organization = {{ASME, Adv Energy Syst Div; ASME, Solar Energy Div}},
Abstract = {{The Energy Information Administration of the United States Department of
   Energy projects that more than 80\% of the energy consumption of the
   U.S. by 2035 will come from fossil fuels. This projection should be the
   fuel to promote projects related to renewable energy in order to reduce
   energy consumption from fossil fuels to avoid their undesirable
   consequences such as carbon dioxide emissions.
   Since solar radiation match pretty well building cooling demands, solar
   cooling systems will be an important factor in the next decades to meet
   or exceed the green gases reduction that will be demanded by the society
   and regulations in order to mitigate environmental consequences such as
   global warming.
   Solar energy can be used as source of energy to produce cooling through
   different technologies. Solar thermal energy applies to technology such
   as absorption chillers and desiccant cooling, while electricity from
   solar photovoltaic can be used to drive vapor compression electric
   chillers. This study focuses on the comparison of a Solar Thermal
   Cooling System that uses an absorption chiller driven by solar thermal
   energy, and a Solar Photovoltaic Cooling System that uses a vapor
   compression system (electric chiller) driven by solar electricity (solar
   photovoltaic system). Both solar cooling systems are compared against a
   standard air cooled cooling system that uses electricity from the grid.
   The models used in the simulations to obtain the results are described
   in the paper along with the parameters (inputs) used.
   Results are presented in two figures. Each figure has one curve for the
   Solar Thermal Cooling System and one for the Solar Photovoltaic Cooling
   System. One figure allows estimation of savings calculated based the net
   present value of energy consumption cost. The other figure allows
   estimating primary energy consumption reduction and emissions reduction.
   Both figures presents the result per ton of refrigeration and as a
   function of area of solar collectors or/and area of photovoltaic
   modules. This approach to present the result of the simulations of the
   systems makes these figures quite general. This means that the results
   can be used to compare both solar cooling systems independently of the
   cooling demand (capacity of the system), as well as allow the analysis
   for different sizes of the solar system used to harvest the solar energy
   (collectors or photovoltaic modules).}},
ISBN = {{978-0-7918-5468-6}},
Unique-ID = {{ISI:000321076700013}},
}

@article{ ISI:000245832100002,
Author = {Auffhammer, Maximilian},
Title = {{The rationality of EIA forecasts under symmetric and asymmetric loss}},
Journal = {{RESOURCE AND ENERGY ECONOMICS}},
Year = {{2007}},
Volume = {{29}},
Number = {{2}},
Pages = {{102-121}},
Month = {{MAY}},
Abstract = {{The United States Energy Information Administration publishes annual
   forecasts of nationally aggregated energy consumption, production,
   prices, intensity and GDP. These government issued forecasts often serve
   as reference cases in the calibration of simulation and econometric
   models, which climate and energy policy are based on. This study tests
   for rationality of published EIA forecasts under symmetric and
   asymmetric loss. We find strong empirical evidence of asymmetric loss
   for oil, coal and electricity prices as well as natural gas consumption,
   electricity sales, GDP and energy intensity. (c) 2006 Elsevier B.V. All
   rights reserved.}},
DOI = {{10.1016/j.reseneeco.2006.05.001}},
ISSN = {{0928-7655}},
Unique-ID = {{ISI:000245832100002}},
}

@article{ ISI:A1994NR70300016,
Author = {HALE, DR and GREENLAND, A},
Title = {{MODEL EVALUATION AT THE ENERGY INFORMATION ADMINISTRATION}},
Journal = {{INTERFACES}},
Year = {{1994}},
Volume = {{24}},
Number = {{3}},
Pages = {{121-138}},
Month = {{MAY-JUN}},
Abstract = {{The Energy Information Administration's model quality program is based
   on objective information about model assumptions, equations, and data
   sources, and the ability of outside examiners to review models and
   replicate results. Agency standards and management enforce incentives
   for preparing and submitting timely documentation and building archive
   versions of models throughout the development process. Programs require
   regular review of models during the development process by outside
   experts and the detailed mathematical, statistical, and econometric
   review and software verification at key developmental stages of
   development. The agency gauges the effectiveness of the model quality
   program by the numbers of models documented and reviewed and by
   compliance with recommendations to retire, modify, or enhance the models
   reviewed.}},
DOI = {{10.1287/inte.24.3.121}},
ISSN = {{0092-2102}},
Unique-ID = {{ISI:A1994NR70300016}},
}

@article{ ISI:000224780600008,
Author = {Hallschmid, M and Benedict, C and Born, J and Fehm, HL and Kern, W},
Title = {{Manipulating central nervous mechanisms of food intake and body weight
   regulation by intranasal administration of neuropeptides in man}},
Journal = {{PHYSIOLOGY \& BEHAVIOR}},
Year = {{2004}},
Volume = {{83}},
Number = {{1}},
Pages = {{55-64}},
Month = {{OCT 30}},
Abstract = {{Maintaining a stable body weight set-point is assumed to rely on a
   homeostatic central nervous system (CNS) regulation of body fat with the
   particular involvement of hypothalamic pathways. The peripheral
   adiposity signals insulin and leptin convey information on the amount of
   energy stored as body fat to the arcuate nucleus of the hypothalamus,
   where anabolic/orexigenic and catabolic/anorexigenic pathways interact
   to regulate food intake and energy expenditure. One of the most
   prominent orexigenic messengers is neuropeptide Y (NPY), whereas
   melanocortins, including alpha-melanocyte-stimulating hormone
   (alpha-MSH), are essential for inducing anorexigenic effects. The
   melanocortin receptor 4 (MC4-R) plays the most important role in
   mediating catabolic effects of alpha-MSH. In this review, we present a
   series of own studies on NPY, insulin and MSH/ACTH(4-10), an MC4-R
   agonist. The studies were all based on the intranasal route of
   administration which enables a direct access of the peptides to
   hypothalamic functions. NPY acutely attenuated electrocortical signs of
   meal-related satiety. Prolonged intranasal administration of insulin as
   well as of MSH induced weight loss in healthy human subjects. However,
   overweight subjects did not lose body fat after MSH administration. The
   results corroborate in humans the significance of all three messengers
   for the central nervous regulation of adiposity and might contribute to
   the future development of medical strategies against body-weight-related
   disorders. (C) 2004 Elsevier Inc. All rights reserved.}},
DOI = {{10.1016/j.physbeh.2004.07.023}},
ISSN = {{0031-9384}},
Unique-ID = {{ISI:000224780600008}},
}

@article{ ISI:000340328800002,
Author = {Posso, F. and Zambrano, J.},
Title = {{Estimation of electrolytic hydrogen production potential in Venezuela
   from renewable energies}},
Journal = {{INTERNATIONAL JOURNAL OF HYDROGEN ENERGY}},
Year = {{2014}},
Volume = {{39}},
Number = {{23}},
Pages = {{11846-11853}},
Month = {{AUG 4}},
Abstract = {{An initial estimation of the potential for hydrogen (H-2) production in
   Venezuela is made, obtained by water electrolysis using electricity from
   renewable sources, taking advantage of the great potential of the
   country for solar, wind and mini hydro energies. For the first two, its
   potential maps is obtained from insolation and wind speed maps,
   respectively, prepared from satellite data, and for mini-hydro, the
   potential is obtained from documentary information. To calculate the
   amount of H-2 to produce is used the Higher Heating Value, considering
   the electrolytic system overall efficiency of 75\%, including power
   requirements of the electrolyzer, auxiliary equipment, and system
   losses. In addition, in the calculation of usable renewable potential
   are excluded land areas under special administration, marine, lake and
   urban areas, and other limitations are considered concerning energy
   conversion efficiencies and useful areas available for the location of
   the different renewable technologies.
   The results give a total production of 2.073 x 10(10) kg of H-2/year,
   with a contribution of 95\% of solar photovoltaic energy. The H-2
   produced covers entirely the energy requirements of rural population
   without energy service, and the remainder could be used as a chemical
   feedstock in industrial processes such as oil refining or petrochemical,
   whose demand in not entirely satisfied with the annual production of H-2
   from the country, or even for export. It is concluded that the results
   are the initial point of a detailed research, with more accurate
   estimation of the potentials that include economic and social topics
   related with the production on H-2, on the way to determine the
   feasibility of developing of the Solar-H-2 system, in its different
   forms in Venezuela. Copyright (C) 2014, Hydrogen Energy Publications,
   LLC. Published by Elsevier Ltd. All rights reserved.}},
DOI = {{10.1016/j.ijhydene.2014.06.033}},
ISSN = {{0360-3199}},
EISSN = {{1879-3487}},
Unique-ID = {{ISI:000340328800002}},
}

@article{ ISI:000310405800016,
Author = {Chang, Yusang and Lee, Jinsoo and Yoon, Hyerim},
Title = {{Alternative projection of the world energy consumption-in comparison
   with the 2010 international energy outlook}},
Journal = {{ENERGY POLICY}},
Year = {{2012}},
Volume = {{50}},
Pages = {{154-160}},
Month = {{NOV}},
Abstract = {{A projection of future energy consumption is a vital input to many
   analyses of economic, energy, and environmental policies. We provide a
   benchmark projection which can be used to evaluate any other projection.
   Specifically, we base our projection of future energy consumption on its
   historical trend, which can be identified by an experience model. We
   compare our projection with forecasts by the U.S. Energy Information
   Administration (EIA) for eight countries-U.S., China, India, Brazil,
   Japan, South Korea, Canada, and Mexico. We find that the EIA's
   projections are lower than ours in the case of China, the U.S., India,
   Japan, and Mexico. This indicates that for these five countries, the EIA
   uses assumptions which cannot be rationalized by historical data. (C)
   2012 Elsevier Ltd. All rights reserved.}},
DOI = {{10.1016/j.enpol.2012.07.059}},
ISSN = {{0301-4215}},
Unique-ID = {{ISI:000310405800016}},
}

@article{ ISI:000208763700013,
Author = {Guilford, Megan C. and Hall, Charles A. S. and O' Connor, Pete and
   Cleveland, Cutler J.},
Title = {{A New Long Term Assessment of Energy Return on Investment (EROI) for US
   Oil and Gas Discovery and Production}},
Journal = {{SUSTAINABILITY}},
Year = {{2011}},
Volume = {{3}},
Number = {{10}},
Pages = {{1866-1887}},
Month = {{OCT}},
Abstract = {{Oil and gas are the main sources of energy in the United States. Part of
   their appeal is the high Energy Return on Energy Investment (EROI) when
   procuring them. We assessed data from the United States Bureau of the
   Census of Mineral Industries, the Energy Information Administration
   (EIA), the Oil and Gas Journal for the years 1919-2007 and from oil
   analyst Jean Laherrere to derive EROI for both finding and producing oil
   and gas. We found two general patterns in the relation of energy gains
   compared to energy costs: a gradual secular decrease in EROI and an
   inverse relation to drilling effort. EROI for finding oil and gas
   decreased exponentially from 1200: 1 in 1919 to 5: 1 in 2007. The EROI
   for production of the oil and gas industry was about 20: 1 from 1919 to
   1972, declined to about 8: 1 in 1982 when peak drilling occurred,
   recovered to about 17: 1 from 1986-2002 and declined sharply to about
   11: 1 in the mid to late 2000s. The slowly declining secular trend has
   been partly masked by changing effort: the lower the intensity of
   drilling, the higher the EROI compared to the secular trend. Fuel
   consumption within the oil and gas industry grew continuously from 1919
   through the early 1980s, declined in the mid-1990s, and has increased
   recently, not surprisingly linked to the increased cost of finding and
   extracting oil.}},
DOI = {{10.3390/su3101866}},
ISSN = {{2071-1050}},
Unique-ID = {{ISI:000208763700013}},
}

@inproceedings{ ISI:000281966900018,
Author = {Ozalp, Nesrin and Hyman, Barry},
Book-Group-Author = {{ASME}},
Title = {{ENERGY END-USE MODELS OF THE US ORGANIC AND INORGANIC CHEMICALS
   INDUSTRIES}},
Booktitle = {{ES2009: PROCEEDINGS OF THE ASME 3RD INTERNATIONAL CONFERENCE ON ENERGY
   SUSTAINABILITY, VOL 2}},
Year = {{2009}},
Pages = {{145-151}},
Note = {{3rd International Conference on Energy Sustainability, San Francisco,
   CA, JUL 19-23, 2009}},
Organization = {{ASME, Adv Energy Syst Div; ASME, Solar Energy Div}},
Abstract = {{In this paper, energy end-use models of U.S. Organic Chemicals and the
   U.S. Inorganic Chemicals industries are given. The energy end-use model
   is developed based on the waste heat recovery characterization of the
   U.S. Chemical Industry and the onsite power and steam generation model.
   The primary database used in this study is the Energy Information
   Administration's (ETA) data: EIA 906, EIA-920, EIA-860B and MECS
   (Manufacturing Energy Consumption Survey). Based on the results found
   from the models; the majority of the fuel is used for the end-uses in
   these manufacturing sectors either directly or through onsite power and
   steam generation. The approach to create these models is applicable to
   all other industries for which data is available and the model is
   consistent with the most available U.S. Department of Energy data, which
   is currently given for 2002 while the data for 2006 is under progress.
   When used in conjunction with similar models for other years, it can be
   used to identify the changes and trends in energy utilization even at
   the prime mover level of detail.}},
ISBN = {{978-0-7918-4890-6}},
Unique-ID = {{ISI:000281966900018}},
}

@inproceedings{ ISI:000276109800010,
Author = {Tian, Peizhe and Zhou, Hui and Li, Nianping and Su, Qie},
Editor = {{Zhang, XS and Qian, H and Zhou, B and Yin, YG}},
Title = {{Survey on Energy Consumption and Indoor Thermal Environment of
   University Building in Changsha, China}},
Booktitle = {{6TH INTERNATIONAL SYMPOSIUM ON HEATING, VENTILATING AND AIR
   CONDITIONING, VOLS I-III, PROCEEDINGS}},
Year = {{2009}},
Pages = {{65-71}},
Note = {{6th International Symposium on Heating, Ventilating and Air
   Conditioning, Nanjing, PEOPLES R CHINA, NOV 06-09, 2009}},
Organization = {{SE Univ; Tsinghua Univ; Univ Hong Kong; Jiangsu Assoc Refrigerat}},
Abstract = {{Many studies of building energy consumption have been conducted among
   provinces, municipalities and special administration regions in China,
   but little information about campus building is available on the hot
   summer and cold winter zone, an understanding of energy consumption
   trends is crucial to the development of a sustainable campus. Reported
   here is an in-depth survey of energy consumption and thermal comfort on
   campus building in Changsha, a typical city in hot summer and cold
   winter zone. The study included questionnaires and measurements
   concerning thermal comfort, along with a survey of energy consumption
   and equipment use. This study provides empirical thermal comfort data
   from a university campus and is aimed at obtaining a broad understanding
   of energy consumption characteristics and students' thermal comfort
   sensations within the buildings as a contributory factor to energy
   services demand and use.}},
ISBN = {{978-962-85138-9-5}},
Unique-ID = {{ISI:000276109800010}},
}

@article{ ISI:000227132200003,
Author = {O'Neill, BC and Desai, M},
Title = {{Accuracy of past projections of US energy consumption}},
Journal = {{ENERGY POLICY}},
Year = {{2005}},
Volume = {{33}},
Number = {{8}},
Pages = {{979-993}},
Month = {{MAY}},
Abstract = {{Energy forecasts play a key role in development of energy and
   environmental policy. Evaluations of the accuracy of past projections
   can provide insight into the uncertainty that may be associated with
   current forecasts. They can also be used to identify sources of
   inaccuracies, and potentially lead to improvements in projections over
   time. Here we assess the accuracy of projections of US energy
   consumption produced by the Energy Information Administration over the
   period 1982-2000. We find that energy consumption projections have
   tended to underestimate future consumption. Projections 10-13 years into
   the future have had an average error of about 4\%, and about half that
   for shorter time horizons. These errors mask much larger, offsetting
   errors in the projection of GDP and energy intensity (EI). GDP
   projections have consistently been too high, and El projection
   consistently too low, by more than 15\% for projections of 10 years or
   more. Further work on the source of these sizable inaccuracies should be
   a high priority. Finally, we find no evidence of improvement in
   projections of consumption, GDP, or El since 1982. (C) 2003 Elsevier
   Ltd. All rights reserved.}},
DOI = {{10.1016/j.enpol.2003.10.020}},
ISSN = {{0301-4215}},
ResearcherID-Numbers = {{O'Neill, Brian/E-6531-2013}},
Unique-ID = {{ISI:000227132200003}},
}

@article{ ISI:A1995TE91900003,
Author = {BAGHELAI, C and MOUMEN, F and COHEN, M and KYDES, A and HARRIS, CM},
Title = {{UNCERTAINTY IN THE NATIONAL ENERGY MODELING SYSTEM .1. METHOD
   DEVELOPMENT}},
Journal = {{JOURNAL OF ENERGY ENGINEERING-ASCE}},
Year = {{1995}},
Volume = {{121}},
Number = {{3}},
Pages = {{108-124}},
Month = {{DEC}},
Abstract = {{This work documents a major part of a large effort to characterize the
   uncertainty present in key elements of the U.S. Department of Energy's
   new National Energy Modeling System (NEMS). It is expected that NEMS
   will be used to estimate the impact that Federal policy initiatives,
   such as taxes, subsidies, and regulations, will have on energy markets
   well into the 21st century. But, the effective use of NEMS requires that
   the uncertainties in its predictions be well understood. So, the Energy
   Information Administration, the Washington Consulting Group, and the
   School of Information Technology and Engineering of George Mason
   University collaborated on the development and testing of methods for
   quantifying uncertainty in the three most important NEMS submodel types,
   namely, linear-optimization, econometric, and heuristic or balance
   equations. We constructed assessment procedures for each of these
   classes, and used them on the Energy Information Administration
   transportation sector demand model, petroleum market model, and
   electricity fuel dispatch model. The methods used include special
   sampling procedures applied to computer-based experiments, response
   surface techniques, and Taylor series methods, and they are described in
   this first of a two-part paper on the complete study. The important
   numerical results of our experiments and their subsequent analyses are
   presented in the companion paper.}},
DOI = {{10.1061/(ASCE)0733-9402(1995)121:3(108)}},
ISSN = {{0733-9402}},
Unique-ID = {{ISI:A1995TE91900003}},
}

@article{ ISI:A1995TE91900004,
Author = {BAGHELAI, C and MOUMEN, F and COHEN, M and KYDES, A and HARRIS, CM},
Title = {{UNCERTAINTY IN THE NATIONAL ENERGY MODELING SYSTEM .2. ANALYSIS OF
   RESULTS}},
Journal = {{JOURNAL OF ENERGY ENGINEERING-ASCE}},
Year = {{1995}},
Volume = {{121}},
Number = {{3}},
Pages = {{125-148}},
Month = {{DEC}},
Abstract = {{This is the second of two papers on characterizing the uncertainty
   present in key elements of the U.S. Department of Energy's new National
   Energy Modeling System. The theory behind the assessment procedures
   developed was described in the first paper, and the current work
   presents the Important numerical results and analyses of our
   experiments, all done as a collaborative effort between the Energy
   Information Administration the Washington Consulting Group, and the
   School of Information Technology and Engineering of George Mason
   University. The method testing involved the three most important
   National Energy Modeling System submodel types, namely, linear
   optimization, econometric, and heuristic or balance equations. The
   results of using the uncertainty procedures on the Energy Information
   Administration's transportation sector demand and petroleum market
   models are provided here.}},
DOI = {{10.1061/(ASCE)0733-9402(1995)121:3(125)}},
ISSN = {{0733-9402}},
Unique-ID = {{ISI:A1995TE91900004}},
}

@article{ ISI:A1991GW66700007,
Author = {SMITS, GAHJ and HEERSCHAP, A and OOSTERHOF, GON and RUYS, JHJ and
   HILBERS, CW and DEBRUYNE, FMJ and SCHALKEN, JA},
Title = {{EARLY METABOLIC RESPONSE TO HIGH-ENERGY SHOCK-WAVES IN A HUMAN TUMOR
   KIDNEY XENOGRAFT MONITORED BY P-31 MAGNETIC-RESONANCE SPECTROSCOPY}},
Journal = {{ULTRASOUND IN MEDICINE AND BIOLOGY}},
Year = {{1991}},
Volume = {{17}},
Number = {{8}},
Pages = {{791-801}},
Abstract = {{The effects of electromagnetically generated high-energy shock waves
   (HESW, Siemens Lithostar) on the phosphate metabolite levels of the NU-1
   human kidney cancer xenograft implanted under the skin of the hind limb
   of nude mice were monitored by P-31 magnetic resonance spectroscopy
   (MRS).  Administration of 200 and 800 HESW (18.1 kV, P(+) = 37.5 MPa,
   P(-) = 5.2 MPa, t(r) = 30-120 nsec, t(w) = 340 nsec, freq. = 1.25 Hz),
   focused on the tumor centre, resulted in an immediate tumor decline; 2 h
   after exposure to the HESW, the high-energy phosphate resonances had
   decreased drastically.  This decline in energy rich molecules was
   accompanied by a concomitant increase in the inorganic phosphate
   resonance and a decrease in pH of the tumor.  During the following
   period, a dose-time dependent recovery of the original high-energy
   phosphate resonance intensities was observed.  These changes are
   qualitatively similar to those produced by ischemic inhibition of energy
   metabolism and are correlated with early histological features like
   vascular disruption, stasis within capillaries, and focal thrombosis. 
   These results demonstrate that experimental HESW treatment of the NU-1
   kidney tumor is effective in provoking a temporary reduction of both
   high-energy phosphate metabolism and tissue pH of the tumor.  The data
   presented here strongly suggest that these effects are predominantly
   indirect by affecting tumor vascularity.  Overall, this study shows that
   MRS is a powerful technique for longitudinal investigations of
   HESW-induced effects and can provide information about its mode of
   action.}},
DOI = {{10.1016/0301-5629(91)90162-P}},
ISSN = {{0301-5629}},
ResearcherID-Numbers = {{Heerschap, Arend/G-5228-2010
   Schalken, Jack/B-1277-2014}},
ORCID-Numbers = {{Schalken, Jack/0000-0001-8274-7797}},
Unique-ID = {{ISI:A1991GW66700007}},
}

@article{ ISI:000362602000002,
Author = {Kalehsar, Omid Shokri},
Title = {{ENERGY FACTOR IN IRAN-TURKEY RELATIONS}},
Journal = {{ENERGY \& ENVIRONMENT}},
Year = {{2015}},
Volume = {{26}},
Number = {{5}},
Pages = {{777-787}},
Month = {{SEP}},
Abstract = {{This paper outlines the mutually beneficial opportunities for
   cooperation on energy policy that are likely to emerge between Iran and
   Turkey. A number of recent developments, in both countries' domestic
   political situation and beyond, have prompted renewed cooperation in
   spite of a difficult past. Keeping in mind Iran's important role as an
   energy producer, and Turkey's ideal geopolitical position as a key
   conduit to Western markets, convergence on energy policy follows as a
   logical matter of course for both actors. A qualitative analysis of the
   perceptions of various key decision-makers will be presented here, using
   information obtained from interviews, to provide some understanding of
   the constantly changing relationship between the two countries. These
   insightful qualitative analyses will be supported by empirical data
   showing the real economic and political impacts of these various periods
   of diplomatic warming and cooling. With Western markets seeking a viable
   alternative to Russian gas exports, and Iranian sanctions likely to be
   eased gently over the foreseeable period, the possibility of both states
   achieving their individual energy policy goals may be within reach, and
   could provide an economic boost to the region as a whole.}},
ISSN = {{0958-305X}},
Unique-ID = {{ISI:000362602000002}},
}

@inproceedings{ ISI:A1997BJ73U00015,
Author = {Jones, R and Tierney, B},
Book-Group-Author = {{INT ASSOC ENERGY ECON}},
Title = {{Carbon emissions - A Kaya identity perspective on historic emissions and
   proposed emission reduction targets and timetables}},
Booktitle = {{INTERNATIONAL ENERGY MARKETS, COMPETITION AND POLICY, CONFERENCE
   PROCEEDINGS}},
Year = {{1997}},
Pages = {{131-139}},
Note = {{18th Annual North American Conference on International Energy Markets,
   Competition and Policy, SAN FRANCISCO, CA, SEP 07-10, 1997}},
Organization = {{US assoc energy Econ; Int Assoc Energy Econ; Aramo Serv Co; Atlantic
   Richfield Co; Cornerstone Res; EDS; Elect Power Res Inst; Exxon Corp;
   Law \& Econ Sonculting Grp; Petr Econ Ltd}},
Abstract = {{The Kaya(1) identity decomposes carbon emissions in a way that allows
   comparison of past changes in key components affecting emissions with
   changes that would be required to meet carbon emission targets currently
   being negotiated under the Framework Convention on Climate Change. The
   most dramatic alteration of U.S. carbon emissions trends in the past 35
   plus years occurred during the 1974-1986 period, sometimes referred to
   as the energy crisis years. Although U.S. carbon emissions in 1985 and
   1986 almost exactly matched emissions in 1973, the intervening years
   were marked by very large increases in real energy prices, numerous
   government programs to promote energy efficiency, and a 50\% reduction
   in the rate of growth of per capita GDP. Over this period, the
   energy/GDP ratio declined an average of 2.1\% per year.
   The Kaya identity approach, using the Energy Information
   Administration's Annual Energy Outlook 1997 reference case as a
   baseline, makes it clear that the effort required to reach carbon
   emission limitation goals proposed in the current Berlin Mandate
   negotiations would significantly exceed that required to limit energy
   use in the 1974-1986 period. In one sense, the EIA reference case itself
   appears optimistic in that it projects a 1.0\% per year decline in the
   energy/GDP ratio over the 2001-2015 period compared to a decline of
   0.4\% per year over 1987-1995. In a what-if assessment with strong
   ceteris paribus assumptions, annual changes in the energy intensity of
   GDP would have to average -2.7\% to -3.1\% per year from 2001 to 2015 to
   reach a target of 1990 level carbon emissions in 2015. To reach the EU
   target of 15\% below 1990 levels, the change would have to average
   -3.7\% to -4.1\% per year. These required changes would be three to four
   times that in the EIA baseline and about 40\% to 100\% greater than
   those which occurred in the energy crisis years. Under the ceteris
   paribus assumptions, there would de no concurrent reductions in
   projected population growth or in the already slow projected growth in
   per capita GDP. Such large alterations in the energy/GDP rate of change,
   especially without slowing economic growth, are a questionable prospect.}},
Unique-ID = {{ISI:A1997BJ73U00015}},
}

@article{ ISI:000330339700024,
Author = {Lawrence, Scott and Liu, Qin and Yakovenko, Victor M.},
Title = {{Global Inequality in Energy Consumption from 1980 to 2010}},
Journal = {{ENTROPY}},
Year = {{2013}},
Volume = {{15}},
Number = {{12}},
Pages = {{5565-5579}},
Month = {{DEC}},
Abstract = {{We study the global probability distribution of energy consumption per
   capita around the world using data from the U. S. Energy Information
   Administration (EIA) for 1980-2010. We find that the Lorenz curves have
   moved up during this time period, and the Gini coefficient, G, has
   decreased from 0.66 in 1980 to 0.55 in 2010, indicating a decrease in
   inequality. The global probability distribution of energy consumption
   per capita in 2010 is close to the exponential distribution with G =
   0.5. We attribute this result to the globalization of the world economy,
   which mixes the world and brings it closer to the state of maximal
   entropy. We argue that global energy production is a limited resource
   that is partitioned among the world population. The most probable
   partition is the one that maximizes entropy, thus resulting in the
   exponential distribution function. A consequence of the latter is the
   law of 1/3: the top 1/3 of the world population consumes 2/3 of produced
   energy. We also find similar results for the global probability
   distribution of CO2 emissions per capita.}},
DOI = {{10.3390/e15125565}},
ISSN = {{1099-4300}},
ResearcherID-Numbers = {{Yakovenko, Victor/A-7559-2008
   Yakovenko, Victor M./}},
ORCID-Numbers = {{Yakovenko, Victor M./0000-0003-3754-1794}},
Unique-ID = {{ISI:000330339700024}},
}

@inproceedings{ ISI:000237331200018,
Author = {Tyrell, David and Martinez, Eloy and Severson, Kristine and Jacobsen,
   Karina and Parent, Daniel and Priante, Michelle and Perlman, A. Benjamin},
Book-Group-Author = {{ASME}},
Title = {{Overview of a crash energy management specification for passenger rail
   equipment}},
Booktitle = {{Proceedings of the 2006 Joint Rail Conference on Restoring and Upgrading
   Rail Infrastructure, Rolling Stock and Systems}},
Series = {{ASME RTD}},
Year = {{2006}},
Volume = {{31}},
Pages = {{131-140}},
Note = {{Joint Rail Conference on Restoring and Upgrading Rail Infrastructure,
   Rolling Stock and Systems, Atlanta, GA, APR 04-06, 2006}},
Organization = {{ASME, Rail Transportat Div; IEEE Vehicular Technol Soc, Land Transportat
   Div}},
Abstract = {{At the request of METROLINK, the Federal Railroad Administration (FRA),
   with the Federal Transit Administration and the American Public
   Transportation Association, formed the ad hoc Crash Energy Management
   Working Group in May 2005. This group developed recommendations for
   crush zones in passenger rail cars for METROLINK to include in its
   procurement specification. The Volpe Center provided the Working Group
   with technical information from the research on passenger rail equipment
   crashworthiness it is conducting for FRA. METROLINK released its
   specification, including the recommendations from the Working Group, on
   September 16, 2005, as part of an invitation for bid.
   The specification includes three levels of requirements: train, car, and
   mechanism. The train level requirements specify a collision scenario for
   which there must be no intrusion into the occupied areas and limits on
   the relative velocities at which the operator and passenger may impact
   interior surfaces. The car and mechanism level requirements follow from
   the train level requirements. The car level requirements include
   specifications for a cab end crush zone capable of absorbing 3.0 million
   ft-lbs of energy and a non-cab end crush zone capable of absorbing 2.0
   million ft-lbs. There are also specifications on the crush zone
   kinematics and on the target force/crush characteristics. Mechanism
   level requirements include specifications for the coupling mechanism,
   the load transfer mechanism, and the principal energy absorption
   mechanism. The coupling mechanism permits the coupler to push back,
   allowing the ends of adjacent cars to remain aligned and come together
   during an impact. The load transfer mechanism transmits the load from
   the adjacent equipment into the crush zone in a manner that allows the
   principal energy absorption mechanism to function as intended. The cab
   end load transfer mechanism can include a deformable LD that acts
   similarly to an automobile bumper, and resolves eccentric impact loads
   into loads that can be appropriately reacted by the supporting
   structure. The principal energy absorption mechanism is the section of
   the carbody structure intended to deform gracefully and to provide most
   of the required energy absorption.
   The specification prescribes performance for the train, the cab and
   trailer cars, and the mechanisms. Each requirement includes quantitative
   criteria for evaluation of compliance. The Working Group extensively
   discussed various evaluation methodologies, including non-linear large
   deformation finite element analysis and dynamic component tests, and
   worked to assure that practical evaluation methodologies are available
   for each requirement. For components critical to the functioning of the
   crush zone, tests are required. This paper describes the requirements,
   the associated criteria, and the available evaluation techniques. The
   technical bases driving the need for each of the requirements are
   discussed.}},
DOI = {{10.1109/RRCON.2006.215303}},
ISBN = {{0-7918-4203-7}},
Unique-ID = {{ISI:000237331200018}},
}

@inproceedings{ ISI:000189002100170,
Author = {Mozaffari, H},
Book-Group-Author = {{ISHVAC}},
Title = {{Energy demand reduction in residential buildings in Beijing-China}},
Booktitle = {{PROCEEDINGS OF THE 4TH INTERNATIONAL SYMPOSIUM ON HEATING, VENTILATING
   AND AIR CONDITIONING, VOLS 1 AND 2}},
Year = {{2003}},
Pages = {{1156-1163}},
Note = {{4th International Symposium on Heating, Ventilating and Air
   Conditioning, BEIJING, PEOPLES R CHINA, OCT 09-11, 2003}},
Organization = {{Tsinghua Univ, Dpet Bldg Sci, Sch Architecture; Natl Nat Sci Fdn China;
   Amer Soc Heating, Refrigerating \& Air Conditioning Engineers; Chartered
   Inst Bldg Serv Engineers; Soc Heating, Air Conditioning \& Sanitary
   Engineers Japan; Scandinavian Federat Heating; Federat European Heating
   \& Air Conditioning Assoc; China Assoc Refrigerat; Chinese Architecture
   Assoc, Comm Heating, Ventilating \& Air Conditioning; Beijing Assoc
   Refrigerat}},
Abstract = {{Due to the rapid growth of the Chinese economy, increased efficiency of
   energy use has become an important element of a strategy to achieve
   sustainable development in the country. According to the Energy
   Information Administration EIA, within the next few decades, China will
   be the world's largest producer of CO2 and in the future, buildings will
   consume up to one-third of the total energy used in the world. The aim
   of this paper is to study possible reductions of energy demand in
   residential dwellings in China. The computer simulations in this paper
   have been done by using Simulink, which is based on Matlab. Three cases
   have been studied. In the first basic case, the thermal response and
   energy demand of the model with the current construction of the house is
   studied. In the remaining two cases, the impact of insulation layers,
   shading factors and the number of window panes are considered.}},
ISBN = {{7-302-07326-0}},
Unique-ID = {{ISI:000189002100170}},
}

@inproceedings{ ISI:000321102300042,
Author = {Sridhar, S. and Baskaran, R. and Chandrasekar, P.},
Editor = {{Giannakopoulos, G and Sakas, DP and Vlachos, DS and KyriakiManessi, D}},
Title = {{Energy supported AODV (EN-AODV) for QoS routing in MANET}},
Booktitle = {{PROCEEDINGS OF THE 2ND INTERNATIONAL CONFERENCE ON INTEGRATED
   INFORMATION (IC-ININFO 2012)}},
Series = {{Procedia Social and Behavioral Sciences}},
Year = {{2013}},
Volume = {{73}},
Pages = {{294-301}},
Note = {{2nd International Conference on Integrated Information (IC-ININFO),
   Budapest, HUNGARY, AUG 30-SEP 03, 2012}},
Abstract = {{A Mobile Ad-hoc Network (MANET) is a wireless network competent of
   autonomous actions. No infrastructure is required for nodes to
   communicate with each other in the network. MANET operates without
   centralized administration. The nodes are self configuring, independent,
   quickly deployable. Nodes are movable since topology is very vibrant and
   they have restricted energy and computing resources. Routing protocols
   should incorporate QoS metrics in route finding and maintenance, to
   support end-to-end QoS. General AODV routing faces problems like long
   route, time delay, mobility and many other while routing. The nodes low
   in energy level will not be in a position to complete the routing. The
   QoS parameters like throughput, PDR and delay are affected directly. The
   proposed Energy based AODV protocol (EN-AODV) announces energy and based
   on nodes sending and receiving rates and the sizes of the data to be
   transmitted it justifies whether its energy level is maintained or
   decreased. It calculates the energy levels of the nodes before they are
   selected for routing path. A threshold value is defined and nodes are
   considered for routing only if its energy level is above this threshold
   value. The work is implemented and simulated on NS-2. The simulation
   results have shown an increase in PDR, decrease in delay and throughput
   is maintained. The proposed EN-AODV provides more consistent and
   reliable data transfer compared to general AODV. (C) 2013 The Authors.
   Published by Elsevier Ltd. Selection and/or peer-review under
   responsibility of The 2nd International Conference on Integrated
   Information.}},
DOI = {{10.1016/j.sbspro.2013.02.055}},
ISSN = {{1877-0428}},
Unique-ID = {{ISI:000321102300042}},
}

@inproceedings{ ISI:000267581900030,
Author = {Sivasankar, P. and Balaji, S. and Chellappan, C.},
Book-Group-Author = {{IEEE}},
Title = {{Performance Evaluation of Energy Efficient On-demand Routing Algorithms
   for MANET}},
Booktitle = {{IEEE REGION 10 COLLOQUIUM AND THIRD INTERNATIONAL CONFERENCE ON
   INDUSTRIAL AND INFORMATION SYSTEMS, VOLS 1 AND 2}},
Year = {{2008}},
Pages = {{164-168}},
Note = {{IEEE Region 10 Colloquium/3rd International Conference on Industrial and
   Information Systems, Indian Inst Technol Kharagpur, Kharagpur, INDIA,
   DEC 08-10, 2008}},
Organization = {{IEEE Kharagpur Sect; IEEE Sri Lanka Sect; Damodar Valley Corp; Govt
   India, Dept Atom Energy, Board Red Nucl Sci; IEEE Reg 10}},
Abstract = {{Mobile Ad hoc networks are a class of dynamic networks without any
   centralized administration. A major bottleneck in Mobile Ad hoc networks
   (MANETs) is the energy consumption since nodes are usually mobile and
   battery operated. To maximize the lifetime of mobile ad hoc networks
   (i.e., the lifetime of the nodes themselves) the power depletion of
   network must be evenly distributed, Le., there must be a uniform drain
   of energy from the nodes, and the overall transmission power requirement
   for each connection request must be minimized. This paper proposes two
   algorithms called Energy Efficient Delay Time Routing (EEDTR) and
   Maximised Energy Efficient Routing (MEER), which try to increase the
   operational lifetime of Mobile Ad hoc networks. These algorithms are
   modified versions of the existing Dynamic Source Routing (DSR)
   algorithm. These algorithms select fully distributed routes, thus
   balancing power consumption of the entire network. The first
   algorithm(EEDTR) introduces a delay in forwarding the packets by nodes,
   which is inversely proportional to the remaining energy level of the
   node. The second algorithm includes energy information on the route
   request packet and select the routes based on this information (MEER).
   These algorithms are designed and implemented using Global Mobile
   Simulator (GloMoSim), a scalable, simulation environment for network
   simulation. Based on the results obtained, this paper concludes that the
   proposed algorithms increase the lifetime of mobile ad hoc networks, at
   the expense of end to end delay and control overhead.}},
ISBN = {{978-1-4244-2805-2}},
Unique-ID = {{ISI:000267581900030}},
}

@article{ ISI:000253779100002,
Author = {Merem, Edmund C. and Twumasi, Yaw A.},
Title = {{Using geospatial information technology in natural resources management:
   The case of urban land management in West Africa}},
Journal = {{SENSORS}},
Year = {{2008}},
Volume = {{8}},
Number = {{2}},
Pages = {{607-619}},
Month = {{FEB}},
Abstract = {{In the past several decades, Lagos Metropolis emerged as one of the
   fastest urbanizing cities in the West African Sub-region. In the absence
   of a regular use of geospatial information management systems, limited
   effort had been made to keep track of changes in the natural environment
   in the rapidly growing city for policy making in land administration.
   The ubiquitous energy radiated by the rapid urbanization rate in the
   area not only created unprecedented consequences by diminishing the
   quality of the environment and natural resources but it raises serious
   implications for land management in the region. The factors fuelling the
   land crisis in the area which are not far fetched consists of
   socio-economic, ecological and policy elements. To tackle these issues
   in a mega city, up-to-date knowledge would be required to capture and
   analyze land information trends. Such an effort will help manage the
   city's expansion as well as infrastructure development through the right
   choices in planning and (spatial) designs using the latest tools in
   geospatial technologies of Geographic Information Systems GIS) and
   remote sensing. This study investigates the spatial implications of the
   rapid expansion of metropolitan Lagos for land management using GIS and
   Remote sensing technology. The result of the research provides a
   valuable road map that can enable planners contribute to improved land
   administration necessary for effective management of natural resources.}},
DOI = {{10.3390/s8020607}},
ISSN = {{1424-8220}},
Unique-ID = {{ISI:000253779100002}},
}

@article{ ISI:000352625800026,
Author = {Peacock, Amy and Cash, Catherine and Bruno, Raimondo},
Title = {{Cognitive Impairment Following Consumption of Alcohol With and Without
   Energy Drinks}},
Journal = {{ALCOHOLISM-CLINICAL AND EXPERIMENTAL RESEARCH}},
Year = {{2015}},
Volume = {{39}},
Number = {{4}},
Pages = {{733-742}},
Month = {{APR}},
Abstract = {{BackgroundThe aim of this study was to assess the relative effects of
   alcohol mixed with energy drink (AmED) versus alcohol alone on cognitive
   performance across the ascending and descending breath alcohol
   concentration (BrAC) limb using doses similar to real-world intake.
   MethodsUsing a single-blind, placebo-controlled, crossover design, 19
   participants completed 4 sessions where they received: (i) placebo, (ii)
   alcohol, (iii) AmED 500ml energy drink (ED), and (iii) AmED 750ml ED.
   Performance on measures of psychomotor function (Compensatory Tracking
   Task {[}CTT]), information processing (Digit Symbol Substitution Task
   {[}DSST]; Inspection Time Task {[}ITT]), and response inhibition (Brief
   Stop-Signal Task {[}Brief SST]) was assessed at similar to 0.05\%
   ascending BrAC, similar to 0.08\% peak BrAC, and similar to 0.05\%
   descending BrAC.
   ResultsThe ITT and Brief SST showed no differential effect of AmED
   versus alcohol (gs<0.30 and gs<0.36, respectively). Moderate magnitude
   improvements in alcohol-induced impairment of CTT and DSST performance
   were observed after AmED versus alcohol on the descending BrAC limb
   (gs>0.45 and gs>0.37, respectively). A moderate magnitude decrease in
   DSST errors was also observed after AmED relative to alcohol at 0.050\%
   ascending target BrAC (gs>0.43).
   ConclusionsChanges in cognitive function after AmED administration were
   dependent on the degree of intoxication, BrAC curve limb, and ED volume.
   Co-administration of ED doses which matched (500ml) and exceeded (500ml)
   maximum daily intake guidelines with alcohol decreased impairment of
   psychomotor function and global information processing after alcohol
   consumption. These results cannot be necessarily interpreted to suggest
   that people are less impaired after AmED, as behavior is the result of
   coordination of multiple cognitive functions, and reduced impairment on
   one aspect of cognition may not translate into global improvements.}},
DOI = {{10.1111/acer.12680}},
ISSN = {{0145-6008}},
EISSN = {{1530-0277}},
ResearcherID-Numbers = {{Peacock, Amy/L-8523-2013}},
ORCID-Numbers = {{Peacock, Amy/0000-0002-5705-2026}},
Unique-ID = {{ISI:000352625800026}},
}

@inproceedings{ ISI:000289812500258,
Author = {Wang, Juan and Yang, Haizhen and Lu, Zhibo},
Editor = {{liu, JT and Ni, WD}},
Title = {{Energy Demand Outlook and Scenario Analysis of Carbon Dioxide Emission
   of China}},
Booktitle = {{2010 THE SECOND CHINA ENERGY SCIENTIST FORUM, VOL 1-3}},
Year = {{2010}},
Pages = {{1280-1286}},
Note = {{2nd China Energy Scientist Forum, Xuzhou, PEOPLES R CHINA, OCT, 2010}},
Abstract = {{Continually rapid economic growth and huge population cause a
   substantial increasing of energy demand in China, coal-dominated energy
   structure also make China the world's second largest country following
   the United States according to the total quantity of carbon dioxide
   emissions. Based on the economic growth forecasted by the U.S. Energy
   Information Administration and the population projection made by the
   United Nations, the outlook of primary energy demand in China is
   forecasted. Furthermore, high, medium and low scenarios of carbon
   dioxide emissions are designed to forecast carbon dioxide emissions in
   China. Finally the forecasting result is compared with the similar
   prediction made by other research institutions, which provides basis for
   the further study on CO(2) emission reduction measure in China.}},
ISBN = {{978-1-935068-37-2}},
Unique-ID = {{ISI:000289812500258}},
}

@article{ ISI:A1995TD18400017,
Author = {WIESENFELD, PL},
Title = {{NUTRITION LABELING - ENERGY VALUES OF FOODS AND FAT SUBSTITUTES}},
Journal = {{AMERICAN JOURNAL OF CLINICAL NUTRITION}},
Year = {{1995}},
Volume = {{62}},
Number = {{5, S}},
Pages = {{1143-1146}},
Month = {{NOV}},
Abstract = {{The Federal Food, Drug, and Cosmetic Act requires the listing of all
   food ingredients on the label. However, until this year, nutrition
   labeling for most foods was not required. The Nutrition Labeling and
   Education Act, passed by the US Congress in November 1990, requires
   nutrition labeling (on the package or at the site of purchase) of
   virtually all foods packaged after May 8, 1994. (A law was passed by
   Congress and signed by the President of the United States on May 26,
   1994, that delayed applicability of the Nutrition Labeling and Education
   Act until after August 8, 1994, for certain products whose labels were
   printed before May 8, 1994, and for which there was supporting
   documentation that after August 8, 1994, the product labels would be in
   compliance.) Prominent among the nutrition information required is
   labeling of the total energy content of food and the energy content
   derived from fat. In Title 21, Code of Federal Regulations, five methods
   are specified for determining the energy content of foods. The US Food
   and Drug Administration expects also to include specific food factors
   (digestibility coefficients) in food additive and GRAS (generally
   recognized as safe) listings for calculating the energy values of novel
   foods and ingredients.}},
ISSN = {{0002-9165}},
EISSN = {{1938-3207}},
Unique-ID = {{ISI:A1995TD18400017}},
}

@article{ ISI:000314735500029,
Author = {Kwak, Younghoon and Seo, Donghyun and Jang, Cheolyong and Huh, Jung-Ho},
Title = {{Feasibility study on a novel methodology for short-term real-time energy
   demand prediction using weather forecasting data}},
Journal = {{ENERGY AND BUILDINGS}},
Year = {{2013}},
Volume = {{57}},
Pages = {{250-260}},
Month = {{FEB}},
Abstract = {{This study was designed to investigate a method for short-term,
   real-time energy demand prediction to cope with changing loads for the
   effective operation and management of buildings. Through a case study, a
   novel methodology for real-time energy demand prediction with the use of
   weather forecasting data was suggested. To perform the input and output
   operations of weather data, and to calculate solar radiation and
   EnergyPlus, a BCVTB (Building Control Virtual Test Bed) was designed.
   The BCVTB was used to predict daily energy demand, based on four kinds
   of real-time weather data and two kinds of solar radiation calculations.
   Weather parameters that were used in a model equation to calculate solar
   radiation were sourced from weather data of the KMA (Korea
   Meteorological Administration). After conducting energy demand
   prediction for four days, it was found that all inputted weather data
   have an effect on the prediction results. These data were applied to
   real buildings in order to examine their validity. The information data
   exchange between real-time weather data and simulation data was carried
   out fairly through the BCVTB. (c) 2012 Elsevier B.V. All rights
   reserved.}},
DOI = {{10.1016/j.enbuild.2012.10.041}},
ISSN = {{0378-7788}},
Unique-ID = {{ISI:000314735500029}},
}

@article{ ISI:000294311000004,
Author = {Freeman, Jody},
Title = {{THE OBAMA ADMINISTRATION'S NATIONAL AUTO POLICY: LESSONS FROM THE ``CAR
   DEAL{''}}},
Journal = {{HARVARD ENVIRONMENTAL LAW REVIEW}},
Year = {{2011}},
Volume = {{35}},
Number = {{2}},
Pages = {{343-374}},
Abstract = {{This Article is the first comprehensive analysis of the Obama
   Administration's national auto policy, which set the first federal
   greenhouse gas standards and strictest fuel efficiency standards for new
   cars and trucks in U.S. history. It describes the complicated legal.
   administrative and political background that led to a harmonized federal
   program, including the history of litigation and conflict among the auto
   industry, environmental groups. California and federal regulators. It
   explains how a confluence of events - a tune administration, a domestic
   auto industry in crisis, a landmark Supreme Court decision, and
   collective exhaustion with a thirty-year struggle over fuel efficiency
   standards - primed all of the parties to support a solution, one that
   would require significant legal and administrative dexterity to devise
   and implement. The Article describes in detail the joint rulemaking by
   the U.S. Environmental Protection Agency and the National Highway
   Traffic Safety Administration, through which the agencies established a
   new uniform program. It explores how the joint rulemaking process
   afforded the agencies an opportunity to pool information and expertise.
   harmonize potentially inconsistent regulatory approaches and bridge
   cultural differences. It also chronicles the innovative use of
   commitment letters to formalize industry and state support for the joint
   rule, and to settle pending preemption litigation. The Article discusses
   the implications of the ``car deal{''} for the Obama Administration,
   which at the time was bailing out the auto industry, pressing Congress
   for comprehensive energy and climate legislation, and anticipating the
   U.N sponsored climate negotiations in Copenhagen. It also discusses the
   importance of the car deal to environmental law. As the first binding
   federal regulation of greenhouse gas emissions under the Clean Air Act.
   this mobile source rule exerted a legal domino effect. leading,
   inexorably, to EPA regulation of stationary sources as well. The
   national auto policy thus unleashed the most powerful existing tool the
   administration had at its disposal for tackling the problem of global
   climate change. The Article concludes with a discussion of the
   implications for administrative law. arguing that one of the most
   important legacies of the car deal is the new prominence it brought to
   joint rulemaking, which has significant potential to improve the clarity
   and quality of regulation in situations where agencies share overlapping
   or closely related regulatory authority.}},
ISSN = {{0147-8257}},
Unique-ID = {{ISI:000294311000004}},
}

@article{ ISI:000267627400004,
Author = {Fischer, Carolyn and Herrnstadt, Evan and Morgenstern, Richard},
Title = {{Understanding errors in EIA projections of energy demand}},
Journal = {{RESOURCE AND ENERGY ECONOMICS}},
Year = {{2009}},
Volume = {{31}},
Number = {{3}},
Pages = {{198-209}},
Month = {{AUG}},
Abstract = {{This paper investigates the potential for systematic errors in the
   Energy Information Administration's (EIA) widely used Annual Energy
   Outlook, focusing on the near- to mid-term projections of energy demand.
   Based on analysis of the EIA's 22-year projection record, we find a
   fairly modest but persistent tendency to underestimate total energy
   demand by an average of 2 percent per year after controlling for
   projection errors in gross domestic product, oil prices, and
   heating/cooling degree days. For 14 individual fuels/consuming sectors
   routinely reported by the EIA, we observe a great deal of directional
   consistency in the errors over time, ranging up to 7 percent per year.
   Electric utility renewables, electric utility natural gas,
   transportation distillate, and residential electricity show significant
   biases on average. Projections for certain other sectors have
   significant unexplained errors for selected time horizons. Such
   independent evaluation can be useful for validating analytic efforts and
   for prioritizing future model revisions. (C) 2009 Elsevier B.V. All
   rights reserved.}},
DOI = {{10.1016/j.reseneeco.2009.04.003}},
ISSN = {{0928-7655}},
Unique-ID = {{ISI:000267627400004}},
}

@article{ ISI:000232448900002,
Author = {Popovic, V and Dunlas, LH},
Title = {{Leptin TRH and ghrelin: Influence on energy homeostasis at rest and
   during exercise}},
Journal = {{HORMONE AND METABOLIC RESEARCH}},
Year = {{2005}},
Volume = {{37}},
Number = {{9, SI}},
Pages = {{533-537}},
Month = {{SEP}},
Note = {{Conference on Thyroid and Sports, Athens, GREECE, JUL 02-04, 2004}},
Organization = {{European Thyroid Assoc; Med Directory ATHEN}},
Abstract = {{The hypothalamus has long been recognized as a major site in the central
   nervous system (CNS) where a spectrum of internal and external
   environmental information is integrated for energy homeostasis. The
   isolation and sequencing of leptin in the mid 90 s, together with the
   demonstration of leptin administration's ability to correct the obesity
   syndrome in leptin-deficient ob/ob mice and humans by suppressing
   food,intake and weight gain in laboratory rodents, confirmed the
   hypothesized existence of a direct humoral signal from adipose tissue to
   the hypothalamus, thus integrating the energy-related signals. In the 80
   s, neuropeptide Y (NPY) was identified as a potent appetite-stimulating
   neuropeptide produced, released and acting locally within the
   hypothalamus. This is recognized as a major physiological appetite
   transducer and central neurochemical substrate receiving, interpreting
   and processing incoming information on energy status. More recently,
   ghrelin, produced in the stomach and released into the general
   circulation, has drawn attention as the other limb of the feedback
   circuit that stimulates appetite at NPY network level. Prolonged fasting
   suppresses serum leptin, while suppressing TSH secretion. Intervention
   with leptin replacement can prevent fasting-induced changes in TSH,
   suggesting that leptin regulates TSH. Low leptin levels in sportsmen and
   sportswomen as well as in recreational runners are consistent with
   reduction in body fat, but are also influenced by the presence of low
   insulin, hypothyroxemia, and elevated cortisol levels. These metabolic
   adaptations to chronic energy deficits indicate a role in leptin
   regulation. A study within the general population found that activity
   levels and leptin were significantly negatively associated in both
   sexes. Circulating ghrelin levels, however, do not change during energy
   expenditure.}},
DOI = {{10.1055/s-870418}},
ISSN = {{0018-5043}},
Unique-ID = {{ISI:000232448900002}},
}

@article{ ISI:000180422100005,
Author = {McCall, M and Jeejeebhoy, K and Pencharz, P and Moulton, R},
Title = {{Effect of neuromuscular blockade on energy expenditure in patients with
   severe head injury}},
Journal = {{JOURNAL OF PARENTERAL AND ENTERAL NUTRITION}},
Year = {{2003}},
Volume = {{27}},
Number = {{1}},
Pages = {{27-35}},
Month = {{JAN-FEB}},
Abstract = {{Background: The purpose of this study was to determine the effect of
   neuromuscular blockade on energy expenditure in severely head-injured
   patients; to determine the effects of body temperature, nutrition
   support, and morphine use on metabolic rate; and to compare measured
   energy expenditure with values from predictive equations. Methods:
   Energy expenditure was measured using indirect calorimetry in 2 groups
   of ventilated patients-18 with severe head injury during and after
   administration of pancuronium bromide and morphine, and second, 14
   severely traumatized patients without severe head injury (trauma group)
   who received morphine without neuromuscular blockade. Results: The mean
   energy expenditure of head-injured patients increased significantly once
   pancuronium was discontinued, ie, from 24.2 +/- 3.1 to, 28.7 +/- 4.6
   kcal/kg (p =.002). This effect was independent of other relevant
   variables such as morphine dose, body temperature, and nutrition
   support. When compared with the Harris-Benedict and World Health
   Organization predictive equations, neuromuscular blockade resulted in a
   stress factor of only 0.96 and 0.95, respectively, which increased to
   1.19 and 1.18, respectively, once. blockade was discontinued.
   Head-injured patients not on neuromus-cular blockade had a significantly
   greater energy expenditure when compared with the trauma group (p=.02).
   Conclusions: Neuromuscular blockade in severely head-injured patients
   decreases energy expenditure to basal levels, independent of morphine
   use, body temperature, and feeding. Levels of hypermetabolism in both
   the head-injured and trauma groups were relatively low, at 19\% and 5\%
   above predicted values, respectively. This study provides useful
   information for the management of nutrition support in severely
   traumatized patients.}},
DOI = {{10.1177/014860710302700127}},
ISSN = {{0148-6071}},
Unique-ID = {{ISI:000180422100005}},
}

@inproceedings{ ISI:000184350700019,
Author = {Mylonas, E and Sakkas, N},
Editor = {{Brebbia, CA and Sakellaris, I}},
Title = {{Business models and technical architectures for an advanced energy
   management combined with IT services at the residential level. The
   COGENVAD initiative}},
Booktitle = {{ENERGY AND THE ENVIRONMENT}},
Series = {{SUSTAINABLE WORLD}},
Year = {{2003}},
Volume = {{7}},
Pages = {{189-198}},
Note = {{1st International Conference on Sustainable Energy, Planning and
   Technology in Relationship to the Environment, HALKIDIKI, GREECE, MAY,
   2003}},
Organization = {{Wessex Inst Technol; Aristotle Univ Thessaloniki}},
Abstract = {{The open residential and commercial office space, viewed in terms of its
   wind and solar energy, represents a serious source of income, which
   currently escapes, almost completely, all practical research and serious
   exploitation. At the same time, the energy business in its current
   deregulation spiral, is seeking a competitive advantage in offering,
   next to energy, also other added value services. These can be
   significantly facilitated and rendered cost efficient by taking
   advantage of the existing power network cabling. New and appropriate
   technology and innovative business models will however be required to
   jointly and cost efficiently harness the wind and solar potential as
   well as the energy provider networks for the eventual practical
   materialisation of such novel services.
   The current paper presents the results and developments of many years of
   research at the cross-point of energy management and information
   technology coded, for historical reasons, as COGENVAD (Combinatorial
   Control Environment for Distributed Power Generation Administration).
   COGENVAD is built on technologies that may offer, at a limited marginal
   cost, a radical and extensive set of add-on services, of a significant
   commercial and social impact, together with important savings on the
   energy bill. Parts of the solution have already been put into commercial
   use, whereas two to three more years of R\&D are considered necessary
   for the completion of all major architectural elements, To this purpose,
   partnerships are intensively sought, be they industrial investors or
   product oriented researchers that would see the opportunity and would
   like to embark on standardization activities soon to be launched at
   international standard bodies.}},
ISSN = {{1476-9581}},
ISBN = {{1-85312-970-4}},
Unique-ID = {{ISI:000184350700019}},
}

@inproceedings{ ISI:000084312500032,
Author = {Capareda, SC},
Editor = {{Overend, RP and Chornet, E}},
Title = {{Geographic Information Systems (GIS)-based assessment of rice hull
   energy resource in the Philippines}},
Booktitle = {{BIOMASS: A GROWTH OPPORTUNITY IN GREEN ENERGY AND VALUE-ADDED PRODUCTS,
   VOLS 1 AND 2}},
Year = {{1999}},
Pages = {{203-208}},
Note = {{4th Biomass Conference of the Americas on Growth Opportunity in Green
   Energy and Value-Added Products, OAKLAND, CA, AUG 29-SEP 02, 1999}},
Organization = {{US DOE; Nat Resource Canada; CA Energy Comm}},
Abstract = {{Geographic Information System (GIS) was used as a tool in encoding
   available rice hull production data in the Philippines to determine the
   exact location of rice hull resources, the potential electrical power
   that could be generated given a certain radius of coverage, and the
   trend in yearly production.
   Data from the Bureau of Agricultural Statistics (1997), the National
   Statistics Office (1994), and the National Food Authority (1997) were
   used to calculate and validate available rice hull resources. Maps from
   the National Mapping and Resource Information Administration (1997) were
   digitized and the available rice hull resource was estimated for each
   municipality in the top producing regions. In 1996, an estimated 2.3
   million metric tons of rice hull produced over a wide geographic range
   with an energy equivalent of about 970 MW. Central Luzon, Western
   Visayas and the Cagayan Valley are the regions with the largest rice
   hull resource. There is sufficient rice hull resource in the Philippines
   to merit the development of technologies for thermal energy production.}},
ISBN = {{0-08-043019-8}},
Unique-ID = {{ISI:000084312500032}},
}

@inproceedings{ ISI:A1997BJ14G00003,
Author = {McCoy, GA and Rooks, JA and Tutterow, VC},
Book-Group-Author = {{IEEE}},
Title = {{MotorMaster+: An energy-efficient motor selection and energy management
   tool for the Pulp \& Paper industry}},
Booktitle = {{CONFERENCE RECORD OF 1997 ANNUAL PULP AND PAPER INDUSTRY TECHNICAL
   CONFERENCE}},
Series = {{PULP AND PAPER INDUSTRY TECHNICAL CONFERENCE}},
Year = {{1997}},
Pages = {{29-35}},
Note = {{1997 Annual Pulp and Paper Industry Technical Conference, CINCINNATI,
   OH, JUN 16-20, 1997}},
Organization = {{IEEE Ind Applicat Soc, Proc Ind Dept, Pulp \& Paper Ind Comm; ABB Ind
   Syst; Anixter; Avtron; BE\&K Engn; BICC Cables; Brown \& Root; Cooper
   Cinergy, Bussmann Div; Cooper Power Syst; Cutler Hammer; E Elect;
   Dresser Rand, Elect Machinery; Eurotherm Drives; Fransen Engn; Gen
   Elect; Global Engn; Harris Grp; Louis Allis; Natl Elect Carbon Prod;
   Okonite; PDS Inc; Post Glover; Rockwell, Allen Bradley; Rockwell,
   Reliance Elect; S \& C Elect; Sandwell; Serv Wire; Siemens Energy \&
   Automat; Simons Engn; Southwire; Toshiba; Virginia Transformer; Wesco}},
Abstract = {{MotorMaster and MotorMaster+ software programs are distributed by the US
   Department of Energy's Motor Challenge program with development and
   support furnished by the Washington State University Cooperative
   Extension Energy Program in conjunction with the Bonneville Power
   Administration. Following a brief description of the Motor Challenge
   Program, this paper discusses MotorMaster (DOS format), which is used by
   many within Pulp \& Paper and other industries to evaluate and select
   motors for energy efficiency and lowest life cycle cost. The last
   portions of this paper will describe MotorMaster+, an enhanced version
   of MotorMaster, presented in the Windows format. The discussion covers
   MotorMaster+'s motor and motor-driven system energy management
   capabilities, the determination of motor load and efficiency from field
   testing measurements, energy savings determination and life cycle
   costing, use of utility rate information, and the types of motor
   selection scenarios addressed within the software.}},
DOI = {{10.1109/PAPCON.1997.595210}},
ISSN = {{0190-2172}},
ISBN = {{0-7803-3919-3}},
Unique-ID = {{ISI:A1997BJ14G00003}},
}

@article{ ISI:000302848700016,
Author = {Grubert, Emily},
Title = {{Reserve reporting in the United States coal industry}},
Journal = {{ENERGY POLICY}},
Year = {{2012}},
Volume = {{44}},
Pages = {{174-184}},
Month = {{MAY}},
Abstract = {{United States energy policymaking can be better supported with accurate
   and consistent data on coal reserves, both in the public and private
   sectors. In particular, reserve data for coal and other energy resources
   should be directly comparable so that decision-makers can easily
   understand the relationship among available resources. Long-term policy
   and investment choices regarding energy security, the environment, and
   resource allocation depend on accurate information, but existing and
   easily available data on the magnitude of geologically, environmentally,
   economically, socially, and legally accessible coal reserves are of
   insufficient quality to guide such decisions. Even still, these data are
   often presented for use in policy and energy analysis. Currently, coal
   reserves are overstated relative to competitor energy resource reserves,
   in part because coal reporting standards have historically been more
   liberal and vague than standards for resources like natural gas.
   Overstating the marketable coal resource could lead to inefficient
   allocation of limited capital investment that can be difficult to
   reverse. US government bodies like the Energy Information
   Administration, United States Geological Survey, Securities and Exchange
   Commission, and Bureau of Land Management can help correct deficiencies
   by clarifying standards and collecting data that are relevant for
   decision-makers, such as energy-based reserve information. (C) 2012
   Elsevier Ltd. All rights reserved.}},
DOI = {{10.1016/j.enpol.2012.01.035}},
ISSN = {{0301-4215}},
Unique-ID = {{ISI:000302848700016}},
}

@inproceedings{ ISI:000276074402114,
Author = {Carr, Timothy R. and Iqbal, Asif and Callaghan, Nick and
   Adkins-Heljeson, Dana and Look, Kurt and Saving, Shawn and Nelson, Ken},
Editor = {{Gale, J and Herzog, H and Braitsch, J}},
Title = {{A national look at carbon capture and storage - National carbon
   sequestration database and geographical information system (NatCarb)}},
Booktitle = {{GREENHOUSE GAS CONTROL TECHNOLOGIES 9}},
Series = {{Energy Procedia}},
Year = {{2009}},
Volume = {{1}},
Number = {{1}},
Pages = {{2841-2847}},
Note = {{9th International Conference on Greenhouse Gas Control Technologies,
   Washington, DC, NOV 16-20, 2008}},
Abstract = {{The US Department of Energy's Regional Carbon Sequestration Partnerships
   (RCSPs) are responsible for generating geospatial data for the maps
   displayed in the Carbon Sequestration Atlas of the United States and
   Canada. Key geospatial data (carbon sources, potential storage sites,
   transportation, land use, etc.) are required for the Atlas, and for
   efficient implementation of carbon sequestration on a national and
   regional scale. The National Carbon Sequestration Database and
   Geographical Information System (NatCarb) is a relational database and
   geographic information system (GIS) that integrates carbon storage data
   generated and maintained by the RCSPs and various other sources. The
   purpose of NatCarb is to provide a national view of the carbon capture
   and storage potential in the U. S. and Canada. The digital spatial
   database allows users to estimate the amount of CO(2) emitted by sources
   (such as power plants, refineries and other fossil-fuel-consuming
   industries) in relation to geologic formations that can provide safe,
   secure storage sites over long periods of time. The NatCarb project is
   working to provide all stakeholders with improved online tools for the
   display and analysis of CO(2) carbon capture and storage data.
   NatCarb is organizing and enhancing the critical information about CO(2)
   sources and developing the technology needed to access, query, model,
   analyze, display, and distribute natural resource data related to carbon
   management. Data are generated, maintained and enhanced locally at the
   RCSP level, or at specialized data warehouses, and assembled, accessed,
   and analyzed in real-time through a single geoportal. NatCarb is a
   functional demonstration of distributed data-management systems that
   cross the boundaries between institutions and geographic areas. It forms
   the first step toward a functioning National Carbon Cyberinfrastructure
   (NCCI). NatCarb provides access to first-order information to evaluate
   the costs, economic potential and societal issues of CO(2) capture and
   storage, including public perception and regulatory aspects. NatCarb
   online access has been modified to address the broad needs of a spectrum
   of users. NatCarb includes not only GIS and database query tools for
   high-end user, but simplified display for the general public using
   readily available web tools such as Google Earth (TM) and Google Maps
   (TM).
   Not only is NatCarb connected to all the RCSPs, but data are also pulled
   from public servers including the U. S. Geological Survey-EROS Data
   Center and from the Geography Network. Data for major CO2 sources have
   been obtained from U. S. Environmental Protection Agency (EPA)
   databases, and data on major coal basins and coalbed methane wells were
   obtained from the Energy Information Administration (EIA). (C) 2009
   Elsevier Ltd. All rights reserved.}},
DOI = {{10.1016/j.egypro.2009.02.057}},
ISSN = {{1876-6102}},
Unique-ID = {{ISI:000276074402114}},
}

@article{ ISI:000329774400005,
Author = {Fregonara, Elena and Curto, Rocco and Grosso, Mario and Mellano, Paolo
   and Rolando, Diana and Tulliani, Jean-Marc},
Title = {{Environmental Technology, Materials Science, Architectural Design, and
   Real Estate Market Evaluation: A Multidisciplinary Approach for
   Energy-Efficient Buildings}},
Journal = {{JOURNAL OF URBAN TECHNOLOGY}},
Year = {{2013}},
Volume = {{20}},
Number = {{4}},
Pages = {{57-80}},
Month = {{OCT 1}},
Abstract = {{The aim of this paper is to illustrate a multidisciplinary approach to
   selecting, designing, and evaluating sustainable solutions for
   energy-efficient buildings that are integrated into their neighborhoods
   at the early design stage. The paper discusses the Strategic Choice
   Approach (SCA), a tool which supports decision-makers in shaping
   problems in complex contexts. SCA is proposed as a tool for developing a
   sort of preliminary platform in which information derived from four
   disciplines (environmental technology, materials science and technology,
   architectural design, and real estate market evaluation) could be shared
   and accessed by stakeholders during the early design stage in order to
   manage the multidimensionality and uncertainty of building design. The
   challenge is to structure a support tool for designers, builders,
   developers, and urban planning authorities involved in
   sustainability-oriented land administration.}},
DOI = {{10.1080/10630732.2013.855512}},
ISSN = {{1063-0732}},
EISSN = {{1466-1853}},
Unique-ID = {{ISI:000329774400005}},
}

@article{ ISI:000251069800001,
Author = {Jeong, Wootae and Nof, Shimon Y.},
Title = {{Timeout-based information forwarding protocol for wireless sensor
   networks}},
Journal = {{INTERNATIONAL JOURNAL OF DISTRIBUTED SENSOR NETWORKS}},
Year = {{2007}},
Volume = {{3}},
Number = {{4}},
Pages = {{331-346}},
Abstract = {{Recent wireless microsensor network protocols provide more flexible
   leverage to the applications with dynamically changing topology, but
   they should be designed to overcome energy constraints, the bandwidth
   limit, and system latency. Thus, microsensor network protocols should be
   effective both in energy and in latency. In addition, they should be
   evaluated through designated tools at each level of networking
   characteristics. This paper proposes a new Timeout-based Information
   Forwarding (TIF) protocol for wireless sensor networks. It uses a
   relatively simple logic to forward the data packet with multi-hop
   fashion to reduce the overall network energy consumption. The TIF
   protocol has been implemented into a network evaluation tool, called
   TIE/MEMS, and provides a design strategy for distributed wireless sensor
   network systems needed for various emerging applications. The simulated
   results show that the TIF protocol has low energy consumption and
   provides design guidelines between energy consumption and latency
   according to the number of hops by adjusting weight values in the
   timeout function.}},
DOI = {{10.1080/15501320601062148}},
ISSN = {{1550-1329}},
Unique-ID = {{ISI:000251069800001}},
}

@article{ ISI:000344004300004,
Author = {Goekce, H. Ufuk and Goekce, K. Umut},
Title = {{Integrated System Platform for Energy Efficient Building Operations}},
Journal = {{JOURNAL OF COMPUTING IN CIVIL ENGINEERING}},
Year = {{2014}},
Volume = {{28}},
Number = {{6}},
Month = {{NOV}},
Abstract = {{The buildings provide a significant contribution to total energy
   consumption and CO 2 emissions. Integrated monitoring, analysis, and
   control methodologies can reduce this by up to 30\%. However, the
   adoption of monitoring and control systems for building management and
   control applications is hampered by the unavailability of appropriate
   tool environments. In this paper a model-driven holistic system
   architecture integrating IT systems at design, construction, and
   operation stages of buildings is presented to provide optimized building
   operations. The main aim is to create a holistic environment for
   wireless embedded monitoring and control systems to increase the
   efficiency of the overall system development process and to exploit
   their potential for reduction of building energy consumption. To reach
   this objective, new methods, tools, and hardware covering integrated
   design, energy simulation models, and data warehouse technologies are
   introduced. The developed system, which is explained in this work, is
   applied in a residential building of the Turkish Prime Ministry Housing
   Development Administration in Istanbul, Turkey, and the results are
   elaborated to improve current building conditions.}},
DOI = {{10.1061/(ASCE)CP.1943-5487.0000288}},
Article-Number = {{05014005}},
ISSN = {{0887-3801}},
EISSN = {{1943-5487}},
Unique-ID = {{ISI:000344004300004}},
}

@article{ ISI:000304794400009,
Author = {Peake, Sandra L. and Chapman, Marianne J. and Davies, Andrew R. and
   Moran, John L. and O'Connor, Stephanie and Ridley, Emma and Williams,
   Patricia and George Inst Global Hlth and Australian New Zealand
   Intensive},
Title = {{Enteral nutrition in Australian and New Zealand intensive care units: a
   point-prevalence study of prescription practices}},
Journal = {{CRITICAL CARE AND RESUSCITATION}},
Year = {{2012}},
Volume = {{14}},
Number = {{2}},
Pages = {{148-153}},
Month = {{JUN}},
Abstract = {{Background: Enteral nutrition (EN) is widely accepted as the preferred
   method for providing nutrition therapy to critically ill patients.
   However, optimal energy goals and the best way to achieve those goals
   are ill defined.
   Objective: To determine the type and energy concentration of commonly
   prescribed EN formulations and whether energy-dense formulations (> 1
   kcal/mL) are used.
   Design: Prospective, observational, multicentre, single-day,
   point-prevalence study.
   Participants and setting: All patients present in 38 Australian and New
   Zealand intensive care units at 10:00 on 17 November 2010.
   Main outcome measures: Demographic data, admission diagnosis and
   information on EN administration were collected.
   Results: 522 patients were enrolled. Mean age was 58.7 (SD, 17.3) years,
   65\% were male and 79\% were mechanically ventilated. On study day,
   220/522 patients received EN (43\%; 95\% CI, 39\%-48\%). ICU admission
   source, Acute Physiology and Chronic Health Evaluation (APACHE) III
   diagnostic category, APACHE II score and ventilation on study day
   predicted receipt of EN. Of those receiving EN, 111/220 (51\%; 95\% CI,
   44\%-57\%) received a 1 kcal/mL formulation and the remainder received
   an energy-dense formulation 2 kcal/mL, 39/220 (18\%; 95\% CI,
   13\%-23\%); and 1.5 kcal/mL, 32/220 (15\%; 95\% CI, 10\%-20\%). There
   were no significant predictors for receipt of energy-dense versus 1
   kcal/mL EN.
   Conclusions: 1 kcal/mL and energy-dense formulations are administered
   with about equal frequency in Australian and New Zealand ICUs. This
   finding supports future research into the evaluation of optimal
   nutritional delivery amounts using EN formulations with differing energy
   concentrations. Crit Care Resusc 2012; 14: 148-153}},
ISSN = {{1441-2772}},
Unique-ID = {{ISI:000304794400009}},
}

@article{ ISI:000290482700004,
Author = {Fertel, Marvin S.},
Title = {{STATUS AND OUTLOOK FOR NUCLEAR ENERGY IN THE UNITED STATES}},
Journal = {{ENERGY \& ENVIRONMENT}},
Year = {{2011}},
Volume = {{22}},
Number = {{1-2}},
Pages = {{25-36}},
Month = {{FEB}},
Abstract = {{The US nuclear power industry is performing well, uprating many of its
   104 existing plants and planning for new capacity. Production cost is
   low and licence extensions promise 60-year operating lives for present
   plants. However, the Obama administration has derailed plans for a waste
   repository in Nevada, and the matter has been referred to a high-level
   commission which is fully reviewing waste management, including the
   question of closing the fuel cycle in USA. Meanwhile four new enrichment
   projects are moving ahead, uranium mining is reviving, and the industry
   is in good shape to cope with likely high uranium prices. Several
   factors converge to support the prospect of building as many as 20 new
   power reactors in the next two decades. The next generation of nuclear
   plants will benefit from an improved licensing process, which was
   completely overhauled in 1992. The new nuclear power projects will
   employ advanced versions of the light water reactor technology used in
   the 104 operating plants. Small reactors including high-temperature
   gas-cooled designs and fast neutron reactors are on the drawing boards.
   Financing new plants will require up to \$2 trillion by 2030, but some
   stimulus, including loan guarantees, is provided by the 2005 Energy
   Policy Act. Both Environmental Protection Agency (EPA) and the Energy
   Information Administration (EIA) show that substantial increases in
   nuclear generating capacity will be essential to meet carbon reduction
   goals. A substantial majority of Americans support the use of nuclear
   energy now, and nearly 90 percent said they view nuclear energy as
   important in the future.}},
DOI = {{10.1260/0958-305X.22.1-2.25}},
ISSN = {{0958-305X}},
Unique-ID = {{ISI:000290482700004}},
}

@article{ ISI:000276326200025,
Author = {Serletis, Apostolos and Timilsina, Govinda R. and Vasetsky, Olexandr},
Title = {{Interfuel substitution in the United States}},
Journal = {{ENERGY ECONOMICS}},
Year = {{2010}},
Volume = {{32}},
Number = {{3}},
Pages = {{737-745}},
Month = {{MAY}},
Abstract = {{In this paper, we use the locally flexible translog functional form to
   investigate the demand for energy and interfuel substitution in the
   United States and to provide a comparison of our results with most of
   the existing empirical energy demand literature. Motivated by the
   widespread practice of ignoring theoretical regularity, we follow
   Barnett's (2002) suggestions and estimate the model subject to
   theoretical regularity, using methods developed by Diewert and Wales
   (1987) and Ryan and Wales (2000), in an attempt to produce inference
   consistent with neoclassical microeconomic theory. Moreover, we use the
   most recent data, published by the U.S. Energy Information
   Administration (EIA). and in addition to investigating interfuel
   substitution possibilities in total U.S. energy demand, we follow
   Serletis et al. (2009) and also examine interfuel substitution
   possibilities in energy demand by sector. Moreover, we test for weak
   separability, with the objective of discovering the structure of the
   functional form in total energy demand as well as energy demand by
   sector. (C) 2010 Elsevier B.V. All rights reserved.}},
DOI = {{10.1016/j.eneco.2010.01.013}},
ISSN = {{0140-9883}},
Unique-ID = {{ISI:000276326200025}},
}

@article{ ISI:000170803300015,
Author = {Guo, ZH and Peng, SL and Wang, BS},
Title = {{Estimation of solar energy use efficiency and spatiotemporal pattern in
   Guangdong based on multitemporal NOAA-AVHRR NDVI and GLS methods}},
Journal = {{ACTA BOTANICA SINICA}},
Year = {{2001}},
Volume = {{43}},
Number = {{8}},
Pages = {{857-862}},
Month = {{AUG}},
Abstract = {{With the aid of the geographic information system (GIS) software
   ARC/INFO and remote sensing (RS) digital image-processing software
   ERMapper, using multitemporal National Oceanic and Atmospheric
   Administration (NOAA)-advanced very high resolution radiometer (AVHRR)
   mormalized difference vegetation index (NDVI) data and the ground
   meteorological data, and on the basis of the estimated
   photosynthetically active radiation ( PAR) and net primary production (
   NPP), we estimated the solar energy use efficiency (e) in Guangdong,
   China, which lies mainly in subtropical and tropical monsoon climate
   zone. The results were: (1) the assessed values of e were consistent
   with the values measured before in the same regions, so the above method
   for the estimation of e is effectual and reliable; (2) the annual
   average of e for Guangdong varied between 0 - 2.96\%, and for the whole
   region was (1.43 +/- 0.53)\%; (3) the zonal variations of e in Guangdong
   were very obvious, so the spatial distribution of e values indicated the
   feature of `uneven' vegetation in Guangdong, together with the
   distribution of NPP and other indexes; and the seasonal variations of e
   in Guangdong were very remarkable too. The mean of e in summer (Apr. to
   Oct.) was 2.9 times as high as that in winter (Nov. to next Mar.); this
   difference depended on the features of solar radiation and the
   vegetation, and, the seasonal variations could be attributed to those in
   temperature and precipitation; (4) even in the evergreen broad-leaved
   forests, the values of e for different subtypes were not the same and
   with large seasonal changes.}},
ISSN = {{0577-7496}},
Unique-ID = {{ISI:000170803300015}},
}

@article{ ISI:000071187800007,
Author = {Lu, W},
Title = {{Information system for ocean wave resources and its application to wave
   power utilization}},
Journal = {{CHINA OCEAN ENGINEERING}},
Year = {{1997}},
Volume = {{11}},
Number = {{3}},
Pages = {{325-334}},
Abstract = {{An information system for ocean wave resources and its application to
   wave power utilization are introduced. It can manage, analyze and
   process the data in the monthly report of ocean wave observation records
   of the State Ocean Administration, and can provide various kinds of
   curves and numerical characters of statistics. This system has been put
   into utility in Guangzhou Institute of Energy Conversion (GIEC), the
   Chinese Academy of Sciences since 1996. An application example is given
   of the investigation and analysis on ocean wave resource of the Nan Ao
   Island, Guangdong Province, where a 100 kW onshore OWC (oscillating
   water column) wave power station will be built. The wave power
   distribution is obtained in different wave directions for different wave
   periods. It is found that 70 percent of the wave power comes from the
   direction of ENE, and more than 95 percent of the wave power is related
   with direction E. The average wave power density is about 3 kW/m, and
   more than 80 percent of the wave power is distributed in the wave
   periods of 4 second to 5 second. Based on the analysis of wave
   resources, a site on the east coast of the island and a design width of
   20 m for the 100 kW station are suggested.}},
ISSN = {{0890-5487}},
Unique-ID = {{ISI:000071187800007}},
}

@article{ ISI:000318553900035,
Author = {Hill, Melissa L. and Mainprize, James G. and Carton, Ann-Katherine and
   Muller, Serge and Ebrahimi, Mehran and Jong, Roberta A. and Dromain,
   Clarisse and Yaffe, Martin J.},
Title = {{Anatomical noise in contrast-enhanced digital mammography. Part I.
   Single-energy imaging}},
Journal = {{MEDICAL PHYSICS}},
Year = {{2013}},
Volume = {{40}},
Number = {{5}},
Month = {{MAY}},
Abstract = {{Purpose: The use of an intravenously injected iodinated contrast agent
   could help increase the sensitivity of digital mammography by adding
   information on tumor angiogenesis. Two approaches have been made for
   clinical implementation of contrast-enhanced digital mammography (CEDM),
   namely, single-energy (SE) and dual-energy (DE) imaging. In each
   technique, pairs of mammograms are acquired, which are then subtracted
   with the intent to cancel the appearance of healthy breast tissue to
   permit sensitive detection and specific characterization of lesions.
   Patterns of contrast agent uptake in the healthy parenchyma, and
   uncanceled signal from background tissue create a ``clutter{''} that can
   mask or mimic an enhancing lesion. This type of ``anatomical noise{''}
   is often the limiting factor in lesion detection tasks, and thus, noise
   quantification may be useful for cascaded systems analysis of CEDM and
   for phantom development. In this work, the authors characterize the
   anatomical noise in CEDM clinical images and the authors evaluate the
   influence of the x-ray energy used for acquisition, the presence of
   iodine in the breast, and the timing of imaging postcontrast
   administration on anatomical noise. The results are presented in a
   two-part report, with SE CEDM described here, and DE CEDM in Part II.
   Methods: A power law is used to model anatomical noise in CEDM images.
   The exponent, beta, which describes the anatomical structure, and the
   constant alpha, which represents the magnitude of the noise, are
   determined from Wiener spectra (WS) measurements on images. A total of
   42 SE CEDM cases from two previous clinical pilot studies are assessed.
   The parameters alpha and beta are measured both from unprocessed images
   and from subtracted images.
   Results: Consistent results were found between the two SE CEDM pilot
   studies, where a significant decrease in beta from a value of
   approximately 3.1 in the unprocessed images to between about 1.1 and 1.8
   in the subtracted images was observed. Increasing the x-ray energy from
   that used in conventional DM to those of typical SE CEDM spectra with
   mean energies above 33 keV significantly decreased alpha by about a
   factor of 19, in agreement with theory. Compared to precontrast images,
   in the unprocessed postcontrast images at 30 s postinjection, alpha was
   larger by about 7.4 x 10(-7) mm(2) and beta was decreased by 0.2. While
   alpha did not vary significantly with the time after contrast
   administration, beta from the unprocessed image WS increased linearly,
   and beta from subtracted image WS increased with an initial quadratic
   relationship that plateaued by about 5 min postinjection.
   Conclusions: The presence of an iodinated contrast agent in the breast
   produced small, but significant changes in the power law parameters of
   unprocessed CEDM images compared to the precontrast images. Image
   subtraction in SE CEDM significantly reduced anatomical noise compared
   to conventional DM, with a reduction in both alpha and beta by about a
   factor of 2. The data presented here, and in Part II of this work, will
   be useful for modeling of CEDM backgrounds, for systems characterization
   and for lesion detectability experiments using models that account for
   anatomical noise. (c) 2013 American Association of Physicists in
   Medicine.}},
DOI = {{10.1118/1.4801905}},
Article-Number = {{051910}},
ISSN = {{0094-2405}},
Unique-ID = {{ISI:000318553900035}},
}

@article{ ISI:000316998300064,
Author = {Averyt, K. and Macknick, J. and Rogers, J. and Madden, N. and Fisher, J.
   and Meldrum, J. and Newmark, R.},
Title = {{Water use for electricity in the United States: an analysis of reported
   and calculated water use information for 2008}},
Journal = {{ENVIRONMENTAL RESEARCH LETTERS}},
Year = {{2013}},
Volume = {{8}},
Number = {{1}},
Month = {{JAN-MAR}},
Abstract = {{Water use by the electricity sector represents a significant portion of
   the United States water budget (41\% of total freshwater withdrawals;
   3\% consumed). Sustainable management of water resources necessitates an
   accurate accounting of all water demands, including water use for
   generation of electricity. Since 1985, the Department of Energy (DOE)
   Energy Information Administration (EIA) has collected self-reported data
   on water consumption and withdrawals from individual power generators.
   These data represent the only annual collection of water consumption and
   withdrawals by the electricity sector. Here, we compile publically
   available information into a comprehensive database and then calculate
   water withdrawals and consumptive use for power plants in the US. In
   effect, we evaluate the quality of water use data reported by EIA for
   the year 2008. Significant differences between reported and calculated
   water data are evident, yet no consistent reason for the discrepancies
   emerges.}},
DOI = {{10.1088/1748-9326/8/1/015001}},
Article-Number = {{015001}},
ISSN = {{1748-9326}},
ORCID-Numbers = {{Meldrum, James/0000-0001-5250-3759}},
Unique-ID = {{ISI:000316998300064}},
}

@inproceedings{ ISI:000339260700051,
Author = {Leem, Yountaik and Lee, Sang Ho and Kim, Min Su},
Editor = {{Yigitcanlar, T and Bulu, M}},
Title = {{HOUSEHOLDS' CHARACTERISTICS IN ENERGY CONSUMPTION - Data from Carbon
   Emission Monitoring System(CEMS) in Sejong City, Korea -}},
Booktitle = {{PROCEEDINGS OF THE 6TH KNOWLEDGE CITIES WORLD SUMMIT (KCWS 2013)}},
Year = {{2013}},
Pages = {{563-579}},
Note = {{6th Knowledge Cities World Summit (KCWS), Istanbul, TURKEY, SEP 09-12,
   2013}},
Organization = {{World Capital Inst; Istanbul Sehir Univ; KOSGEB; Istanbul Kalkinma
   Ajansi; Univ Caxias Sul; Arab Urban Dev Inst; Colegio Frontera Norte;
   Tecnologico Monterrey; Inst Management Technol; Queensland Univ Technol;
   Istanbul Buyuksehir Belediyesi}},
Abstract = {{Korean Government has developed Sejong City as a new administration
   city. This city of future was planned and designed toward one of the
   most eco-friendly city on the basis of ICTs. To attain this object, a
   carbon emission monitoring system (CEMS) was designed and installed as a
   part of u-city service which provides various information anytime and
   anywhere to enrich the people's quality of life.
   In this paper, at first, the structure and functions of CEMS are
   introduced. This system is consist of 5 parts - data collection from
   user and linked DBs, transforming data into meaningful information for
   the policy makers, system-user interfacing via statistical tables and
   graphs and system maintaining. This system can be operated by the
   citizen participation through whole the process. With the help of GIS
   map and graphic interface, statistics of monitored data for both citizen
   and decision maker provided and after feed-back, they have affected on
   the behaviour of citizen's energy consumption and related policy as
   well.
   By the CEMS, energy consumption data of 124 agreed households were
   collected during 10 months. Electricity, gas for heating and cooking,
   and water consumption meters were read automatically by the system and
   analysed. This showed that similar to similar to
   Even the effect of this system on CO2 emission could not be verified due
   to 10 months of data collection, this paper analyzed the energy
   consumption characteristics of households in Sejong City. The 394
   households who willingly participated to this experiment were classified
   into 12 groups by the number of family members and the size of unit
   area. Data of 10 months shows that small house and large family are
   saving energy than the opposite.}},
ISBN = {{978-9944-380-11-9}},
Unique-ID = {{ISI:000339260700051}},
}

@inproceedings{ ISI:000345500506049,
Author = {Lupion, Monica and Alvarez, Inaki and Otero, Pedro and Kuivalainen,
   Reijo and Lantto, Jouni and Hotta, Arto and Hack, Horst},
Editor = {{Dixon, T and Yamaji, K}},
Title = {{30 MWth CIUDEN Oxy-CFB Boiler - First experiences}},
Booktitle = {{GHGT-11}},
Series = {{Energy Procedia}},
Year = {{2013}},
Volume = {{37}},
Pages = {{6179-6188}},
Note = {{International Conference on Greenhouse Gas Technologies (GHGT), Kyoto,
   JAPAN, NOV 18-22, 2012}},
Abstract = {{Global primary energy demand is growing, and is likely to continue
   growing during the next years. Energy projections made by the World
   Energy Council, the International Energy Agency (IEA) and the US Energy
   Information Administration give similar pictures of future energy
   requirements, mainly supplied by fossil fuels. Although it is expected
   that the share of the fossil fuels hi the energy mix will decline in the
   future, the dominant role of fossil fuels will remain for decades to
   come, which entails large emissions of CO2 if new policy measures are
   not endorsed. Carbon Capture and Storage technologies (CCS) have the
   potential to reduce CO2 emissions into the atmosphere, providing by 2050
   up to 20\% of the CO2 reduction required to combat climate change.
   In this context, one of the current European initiatives in terms of
   R\&D\&D on Carbon Capture and Storage (CCS) and Clean Coal technologies
   (CCTs) is the Technology Development Centre for CO2 Capture and Storage,
   or es. CO2 Centre, which is supported by the Spanish Government through
   The Fundacion Ciudad de la Energia. (CIUDEN). CIUDEN is a research and
   development institution created by the Spanish Administration in 2006
   and fully conceived for collaborative technology development on CCS and
   CCTs. The es.CO2 Centre incorporates the world's most advanced equipment
   for the development of capture processes through oxycombustion based on
   two combustion technologies: Pulverized Coal (PC) and Circulating
   Fluidized Bed (CFB).
   Foster Wheeler is the technology provider of the 30 MWth oxy-CFB unit,
   which achieved first fire on coal in September 2011 and underwent
   initial oxy-mode commissioning in December 2011. This CFB unit design
   allows multiple fuels to be tested either under conventional combustion
   with air or under oxy-fuel conditions (Flexi-Burn (R) concept), and
   combines CFB's intrinsic advantages (fuel flexibility and low SOx and
   NOx emissions) with oxygen-firing for CCS.
   This paper focuses on initial operational experiences of CIUDEN's 30MWth
   oxy-CFB facility. During the preliminary tests in spring 2012, and the
   first test campaign in summer 2012, an extensive amount of operational
   data were acquired for four fuels and fuel mixtures. Results from first
   operational experiences are extremely promising. This oxy-CFB
   installation, which is the first of its class, will provide a real basis
   for the design and operation of flexible and competitive oxycombustion
   facilities at demonstration scale. Results achieved here aim to validate
   the design of a future 330 MWe supercritical Oxycombustion Power Station
   (OXY-CFB-300 Compostilla Project) intended to demonstrate CCS technology
   in commercial scale. (C) 2013 The Authors. Published by Elsevier Ltd.
   Open access under CC BY-NC-ND license.}},
DOI = {{10.1016/j.egypro.2013.06.547}},
ISSN = {{1876-6102}},
Unique-ID = {{ISI:000345500506049}},
}

@article{ ISI:000302823000024,
Author = {Atabani, A. E. and Silitonga, A. S. and Badruddin, Irfan Anjum and
   Mahlia, T. M. I. and Masjuki, H. H. and Mekhilef, S.},
Title = {{A comprehensive review on biodiesel as an alternative energy resource
   and its characteristics}},
Journal = {{RENEWABLE \& SUSTAINABLE ENERGY REVIEWS}},
Year = {{2012}},
Volume = {{16}},
Number = {{4}},
Pages = {{2070-2093}},
Month = {{MAY}},
Abstract = {{As the fossil fuels are depleting day by day, there is a need to find
   out an alternative fuel to fulfill the energy demand of the world.
   Biodiesel is one of the best available resources that have come to the
   forefront recently. In this paper, a detailed review has been conducted
   to highlight different related aspects to biodiesel industry. These
   aspects include, biodiesel feedstocks, extraction and production
   methods, properties and qualities of biodiesel, problems and potential
   solutions of using vegetable oil, advantages and disadvantages of
   biodiesel, the economical viability and finally the future of biodiesel.
   The literature reviewed was selective and critical. Highly rated
   journals in scientific indexes were the preferred choice, although other
   non-indexed publications, such as Scientific Research and Essays or some
   internal reports from highly reputed organizations such as International
   Energy Agency (IEA), Energy Information Administration (EIA) and British
   Petroleum (BP) have also been cited. Based on the overview presented, it
   is clear that the search for beneficial biodiesel sources should focus
   on feedstocks that do not compete with food crops, do not lead to
   land-clearing and provide greenhouse-gas reductions. These feedstocks
   include non-edible oils such as Jatropha curcas and Calophyllum
   inophyllum, and more recently microalgae and genetically engineered
   plants such as poplar and switchgrass have emerged to be very promising
   feedstocks for biodiesel production.
   It has been found that feedstock alone represents more than 75\% of the
   overall biodiesel production cost. Therefore, selecting the best
   feedstock is vital to ensure low production cost. It has also been found
   that the continuity in transesterification process is another choice to
   minimize the production cost. Biodiesel is currently not economically
   feasible, and more research and technological development are needed.
   Thus supporting policies are important to promote biodiesel research and
   make their prices competitive with other conventional sources of energy.
   Currently, biodiesel can be more effective if used as a complement to
   other energy sources. (C) 2012 Elsevier Ltd. All rights reserved.}},
DOI = {{10.1016/j.rser.2012.01.003}},
ISSN = {{1364-0321}},
ResearcherID-Numbers = {{Mekhilef, Saad/B-9652-2010
   HAJI HASSAN, MASJUKI/B-8961-2010
   MAGAMI, IRFAN ANJUM /B-8662-2010}},
ORCID-Numbers = {{Mekhilef, Saad/0000-0001-8544-8995
   HAJI HASSAN, MASJUKI/0000-0001-8631-2811
   MAGAMI, IRFAN ANJUM /0000-0002-2247-7999}},
Unique-ID = {{ISI:000302823000024}},
}

@article{ ISI:000298201800012,
Author = {Kang, Ki Sung and Yahashi, Satowa and Matsuda, Kouhei},
Title = {{Central and peripheral effects of ghrelin on energy balance, food intake
   and lipid metabolism in teleost fish}},
Journal = {{PEPTIDES}},
Year = {{2011}},
Volume = {{32}},
Number = {{11, SI}},
Pages = {{2242-2247}},
Month = {{NOV}},
Abstract = {{Ghrelin was first identified and characterized from rat stomach as an
   endogenous ligand for the growth hormone secretagogue receptor. Ghrelin
   and its receptor system are present not only in peripheral tissues such
   as stomach and intestine, but also in the central nervous system of
   mammals. Interestingly, administration of ghrelin induces an orexigenic
   effect and also modifies locomotor activity, suggesting its involvement
   in feeding control and the regulation of energy balance, in addition to
   the regulation of growth hormone release. Information about ghrelin in
   non-mammals, such as teleost fish, has also been increasing, and
   important data have been obtained. An understanding of the evolutionary
   background of the energy regulation system and the central and
   peripheral roles of ghrelin in teleost fish could provide indications as
   to their roles in mammals, particularly humans. In this review, we
   overview the central and peripheral effects of ghrelin on energy
   balance, locomotor activity, and lipid metabolism in teleost fish. (C)
   2011 Elsevier Inc. All rights reserved.}},
DOI = {{10.1016/j.peptides.2011.05.006}},
ISSN = {{0196-9781}},
Unique-ID = {{ISI:000298201800012}},
}

@inproceedings{ ISI:000290422200018,
Author = {Berl, Andreas and de Meer, Hermann},
Editor = {{Eltoweissy, M and Wakamiya, N and Lorenz, P and Freire, MM}},
Title = {{An Energy-Efficient Distributed Office Environment}},
Booktitle = {{2009 FIRST INTERNATIONAL CONFERENCE ON EMERGING NETWORK INTELLIGENCE
   (EMERGING 2009)}},
Year = {{2009}},
Pages = {{117-122}},
Note = {{1st International Conference on Emerging Network Intelligence, Sliema,
   MALTA, OCT 11-16, 2009}},
Abstract = {{Energy ef ciency in the eld of information and communication technology
   becomes increasingly important due to the increase in energy costs and
   the desire to reduce CO2 emissions. Of ce environments of public
   administration and companies promise high potential in terms of energy
   saving. In such environments a high number of hosts are operating on a
   24/7 basis. This paper suggests an Energy-Efficient Distributed Office
   Environment that reduces the number of always-on hosts and raises the
   energy ef ciency within of ce environments. It describes the suggested
   architecture and its key technologies. In addition, it evaluates the
   bene ts of the architecture analytically and illustrates experimental
   results to evaluate resulting overhead.}},
DOI = {{10.1109/EMERGING.2009.13}},
ISBN = {{978-1-4244-5085-5}},
Unique-ID = {{ISI:000290422200018}},
}

@article{ ISI:000246820900013,
Author = {Wilson, James H. and Beyene, Asfaw},
Title = {{California wave energy resource evaluation}},
Journal = {{JOURNAL OF COASTAL RESEARCH}},
Year = {{2007}},
Volume = {{23}},
Number = {{3}},
Pages = {{679-690}},
Month = {{MAY}},
Abstract = {{In this article, a collection of deep water (>100 m) wave records was
   assessed to create a long-term, statistically reliable data set. These
   wave data were derived from buoy data of the Coastal Information Data
   Program (CDIP) at the University of California, San Diego (UCSD),
   Scripps Institute of Oceanography; the National Data Buoy Center (NDBC)
   at the National Oceanic and Atmospheric Administration (NOAA); and other
   sources. From this data set, long-term annual averages and monthly wave
   probability distributions were analyzed for 10 one-degree-latitude bins,
   bounded by the 100-m and 1000-m depth contours seaward of the California
   coast. The probability distributions were used to quantify the potential
   for useful energy extraction from the coastal waves of California.
   Optimal locations for developing wave energy installations are
   specified. South of Point Conception, California, the wave energy
   arriving from North Pacific storms is efficiently blocked by the
   significant change in the California coast orientation south of Point
   Conception and the Channel Islands. The near-coastal Southern California
   (SOCAL) region has a significantly reduced wave resource compared with
   the California coast north of Point Conception.}},
DOI = {{10.2112/04-0240.1}},
ISSN = {{0749-0208}},
Unique-ID = {{ISI:000246820900013}},
}

@article{ ISI:000234659800002,
Author = {Rubio, VC and Sanchez-Vazquez, FJ and Madrid, JA},
Title = {{Oral serotonin administration affects the quantity and the quality of
   macronutrients selection in European sea bass Dicentrarchus labrax L.}},
Journal = {{PHYSIOLOGY \& BEHAVIOR}},
Year = {{2006}},
Volume = {{87}},
Number = {{1}},
Pages = {{7-15}},
Month = {{JAN 30}},
Abstract = {{Telcost fish are able to regulate their energy intake selecting from
   pure macronutrients sources, but the regulatory mechanisms involved in
   macronutrients selection remain unknown. Serotonin (5-HT) reduces food
   intake in mammals and fish and modifies the macronutrients selection
   pattern in mammals; however, no information is available about its role
   on macronturients selection in fish. The aim was to determine the effect
   of orally administered 5-HT (0.1, 0.5 and 2.5 mg kg BW-1) into gelatine
   capsules on the subsequent macronutrient selection of sea bass, using
   for this purpose gelatine capsules including carbohydrates, protein, or
   lipids separately. The voluntary ingested 5-HT was released into the
   plasma of fish, reaching a level two times greater than the controls, 45
   min after the ingestion of a capsule containing 2.5 mg kg BW-1 of 5-HT.
   The indoleamine, at doses of 0. 1, 0.5 and 2.5 mg kg BW-1, produced a
   reduction in total food intake of 31\%, 49\% and 37\%, respectively,
   compared to the baseline, modifying the macronutrient selection pattern.
   The percentage of fat selected was significantly reduced whereas the
   percentage of protein significantly increased after administration of
   highest dose, but no changes were observed in the proportion of
   carbohydrate for any 5-HT doses. In conclusion, oral administration of
   5-HT affected both amount of food intake and pattern of macronutrients
   selected. This is the first evidence supporting a role of 5-HT as a
   neurohumoral mediator involved in macronutrients selection in fish. (c)
   2005 Elsevier Inc. All rights reserved.}},
DOI = {{10.1016/j.physbeh.2005.08.030}},
ISSN = {{0031-9384}},
ResearcherID-Numbers = {{Rubio, Vera Cruz/D-4359-2009
   Sanchez Vazquez, Francisco Javier/}},
ORCID-Numbers = {{Rubio, Vera Cruz/0000-0001-8974-8995
   Sanchez Vazquez, Francisco Javier/0000-0002-2366-9714}},
Unique-ID = {{ISI:000234659800002}},
}

@article{ ISI:000176894300005,
Author = {Morris, SC and Goldstein, GA and Fthenakis, VM},
Title = {{NEMS and MARKAL-MACRO models for energy-environmental-economic analysis:
   A comparison of the electricity and carbon reduction projections}},
Journal = {{ENVIRONMENTAL MODELING \& ASSESSMENT}},
Year = {{2002}},
Volume = {{7}},
Number = {{3}},
Pages = {{207-216}},
Month = {{SEP}},
Abstract = {{The Annual Energy Outlook forecasts published by the United States
   Energy Information Administration (EIA) of the Department of Energy are
   based on results from the National Energy Modeling system (NEMS). This
   paper compares NEMS, which is used only in the U.S., with the U.S.
   version of MARKAL-MACRO (USMM) model, which is used in more than
   thirty-five countries. The two models predict similar results for the
   base 1999 US Annual Energy Outlook (AEO), but their results with carbon
   constraints are quite different. The differences of the models and those
   of their predictions are explained. USMM can be used to provide an
   alternative and complementary approach to projections of renewable
   technologies penetration and their potential in reducing carbon dioxide
   emissions in the USA.}},
DOI = {{10.1023/A:1016332907313}},
ISSN = {{1420-2026}},
Unique-ID = {{ISI:000176894300005}},
}

@article{ ISI:A1995QR24100003,
Author = {ASAKUMA, S and OHYANAGI, M and IWASAKI, T},
Title = {{THE EFFECTS OF ANTIANGINAL DRUGS ON ENERGY-EXPENDITURE DURING EXERCISE
   IN NORMAL SUBJECTS}},
Journal = {{JAPANESE CIRCULATION JOURNAL-ENGLISH EDITION}},
Year = {{1995}},
Volume = {{59}},
Number = {{3}},
Pages = {{137-145}},
Month = {{MAR}},
Abstract = {{The respiratory quotient (RQ = VCO2/VO2) provides important information
   (ie, the ratio of carbohydrate to fat utilization) concerning energy
   expenditure. We studied the effects of various antianginal drugs on
   energy expenditure during steady-state aerobic exercise in 9 healthy
   adult men. The drugs used were propranolol (a non-selective
   beta-blocker), metoprolol (a beta-1 selective blocker), amosulalol (an
   alpha- and beta-blocker), nicardipine (a calcium antagonist) and
   isosorbide dinitrate. Each drug was administered for 2 weeks, followed
   by a 2-week washout period. VO2, VCO2 and RQ were measured with an
   expired gas analyzer during treadmill exercise tests before and during
   the administration of each drug. Two protocols of constant-load exercise
   were performed: Protocol 1 lasted for 10 min at a speed of 5.5 km/h and
   a grade of 0\%, (at a level of about 30\% peak VO2), while Protocol 2
   lasted for 10 min at a speed of 7 km/h and a grade of 0\%, (at a level
   of about 40\% peak VO2) RQ during exercise was significantly increased
   and VO2 was decreased after propranolol, metoprolol and amosulalol (P <
   0.05). Neither nicardipine nor isosorbide dinitrate produced significant
   changes in these values. These data suggest that propranolol, metoprolol
   and amosulalol increase the efficiency of energy expenditure during
   ordinary physical activity by increasing the utilization of carbohydrate
   and by decreasing the utilization of fat.}},
ISSN = {{0047-1828}},
Unique-ID = {{ISI:A1995QR24100003}},
}

@article{ ISI:A1993LC83100005,
Author = {HALE, DR},
Title = {{OBJECTIVE INFORMATION ABOUT ENERGY MODELS}},
Journal = {{GOVERNMENT INFORMATION QUARTERLY}},
Year = {{1993}},
Volume = {{10}},
Number = {{1}},
Pages = {{53-61}},
Abstract = {{This article describes the Energy Information Administration's program
   to develop objective information about its modeling systems without
   hindering model development and applications, and within budget and
   human resource constraints.}},
DOI = {{10.1016/0740-624X(93)90006-L}},
ISSN = {{0740-624X}},
Unique-ID = {{ISI:A1993LC83100005}},
}

@article{ ISI:A1992JQ86600009,
Author = {LIU, BC and TZENG, GH and HSIEH, CT},
Title = {{ENERGY PLANNING AND ENVIRONMENTAL-QUALITY MANAGEMENT - A DECISION
   SUPPORT SYSTEM APPROACH}},
Journal = {{ENERGY ECONOMICS}},
Year = {{1992}},
Volume = {{14}},
Number = {{4}},
Pages = {{302-307}},
Month = {{OCT}},
Abstract = {{This paper describes a computer-based decision support system (DSS) for
   evaluating quality, of life (QOL) improvement in general, and
   technological and environmental impacts of energy planning and
   consumption in particular. Based primarily on information obtained from
   the Environmental Protection Administration and the Energy Committee,
   Ministry of Economic Affairs of ROC, the variations in economic growth
   and overall life quality changes in Taiwan may be quantitatively
   assessed and performance indexes for various socioeconomic, political,
   environmental, energy and technological aspects constructed using
   historical and extrapolated time series data. The interdependent
   relationships and cross-impacts among energy planning, patterns of
   energy production and consumption, and `trade-off' decisions in
   environmental quality management may be objectively tested and analysed.
   This approach is designed to support and enhance strategical
   decision-makers in a more organized and efficient manner for
   semi-structured tasks and/or problem solving, assisted by a micro- or
   personal computer.}},
DOI = {{10.1016/0140-9883(92)90036-D}},
ISSN = {{0140-9883}},
ResearcherID-Numbers = {{Tzeng, Gwo-Hshiung/B-2775-2009}},
ORCID-Numbers = {{Tzeng, Gwo-Hshiung/0000-0003-1856-7497}},
Unique-ID = {{ISI:A1992JQ86600009}},
}

@inproceedings{ ISI:000339125800075,
Author = {Lo, Fa-Sain and Sun, Tao},
Editor = {{Xu, Q and Li, H and Li, Q}},
Title = {{Smart Grid Innovation Strategy for Low-Carbon City Administration}},
Booktitle = {{SUSTAINABLE DEVELOPMENT OF INDUSTRY AND ECONOMY, PTS 1 AND 2}},
Series = {{Advanced Materials Research}},
Year = {{2014}},
Volume = {{869-870}},
Pages = {{393-398}},
Note = {{3rd International Conference on Energy, Environment and Sustainable
   Development (EESD 2013), Shanghai, PEOPLES R CHINA, NOV 12-13, 2013}},
Organization = {{Shanghai Univ Elect Power; Shanghai Normal Univ}},
Abstract = {{Governments and scientists are concerned about the negative impacts of
   climate change on humanity in the foreseeable future, especially for the
   city sustainable development. Smart Grid is an important infrastructure
   service for developing the energy efficiency and low carbon society. The
   reliability and efficiency of our electrical grid can be enhanced by
   implementing smart grid technology; however this would require
   modifications to the current electrical system. The objective of this
   paper is to find out the innovation strategy for future smart grid by
   investigate, analyze and evaluate the related technologies and
   competitive information of different nations and industries. We
   presented the key information about smart grid development in the world.
   We also proposed four practical smart grid innovation strategies and
   innovation model for smart-green city policy making, construction and
   administration.}},
DOI = {{10.4028/www.scientific.net/AMR.869-870.393}},
ISSN = {{1022-6680}},
ISBN = {{978-3-03785-975-9}},
Unique-ID = {{ISI:000339125800075}},
}

@article{ ISI:000307377800020,
Author = {Meehan, Timothy D.},
Title = {{Energetics of thermoregulation by an industrious endotherm}},
Journal = {{AMERICAN JOURNAL OF HUMAN BIOLOGY}},
Year = {{2012}},
Volume = {{24}},
Number = {{5}},
Pages = {{713-715}},
Month = {{SEP-OCT}},
Abstract = {{Objectives: Thermoregulation by modern industrial humans is unique among
   endothermic animals, in that it is largely accomplished by controlling
   the temperature of our external environment. The objective of this study
   was to view the relationship between thermoregulatory energy use and
   environmental temperature in modern humans from the perspective of
   comparative physiology. Methods: Monthly residential energy use
   estimates from the US Energy Information Administration were divided by
   the annual number of American households from the US Census Bureau,
   giving average monthly energy consumption per American household for the
   years 2006 through 2010. Monthly energy consumption was then plotted
   against average monthly temperature across the United States from the
   National Climatic Data Center. Results: The resulting graph bore a
   striking resemblance to a classic Scholander-Irving curve, exhibiting
   clear upper (22 degrees C) and lower (15 degrees C) critical
   temperatures, and an increase in energy use as temperatures extend above
   (90 W degrees C-1 increase) or below (244 W degrees C-1 decrease) those
   critical temperatures. Allometric equations from comparative physiology
   indicate that the energetic costs of our current thermoregulatory habits
   are similar to 30 to 50 times those predicted for an endotherm of our
   size. Conclusions: Modern humans have redefined what it means to be a
   homeothermic endotherm, using large quantities of extrametabolic energy
   to regulate the temperature of our surroundings. Despite this
   sophistication, the signal of our individual physiology is readily
   discernible in national data on energy consumption. Am. J. Hum. Biol.,
   2012. (c) 2012 Wiley Periodicals, Inc.}},
DOI = {{10.1002/ajhb.22278}},
ISSN = {{1042-0533}},
Unique-ID = {{ISI:000307377800020}},
}

@article{ ISI:000298528500001,
Author = {Hamylton, S.},
Title = {{The use of remote sensing and linear wave theory to model local wave
   energy around Alphonse Atoll, Seychelles}},
Journal = {{ESTUARINE COASTAL AND SHELF SCIENCE}},
Year = {{2011}},
Volume = {{95}},
Number = {{4}},
Pages = {{349-358}},
Month = {{DEC 20}},
Abstract = {{This paper demonstrates a practical step-wise method for modelling wave
   energy at the landscape scale using GIS and remote sensing techniques at
   Alphonse Atoll, Seychelles. Inputs are a map of the benthic surface
   (seabed) cover, a detailed bathymetric model derived from remotely
   sensed Compact Airborne Spectrographic Imager (CASI) data and
   information on regional wave heights. Incident energy at the reef crest
   around the atoll perimeter is calculated as a function of its deepwater
   value with wave parameters (significant wave height and period) hindcast
   in the offshore zone using the WaveWatch III application developed by
   the National Oceanographic and Atmospheric Administration. Energy
   modifications are calculated at constant intervals as waves transform
   over the forereef platform along a series of reef profile transects
   running into the atoll centre. Factors for shoaling, refraction and
   frictional attenuation are calculated at each interval for given changes
   in bathymetry and benthic coverage type and a nominal reduction in
   absolute energy is incorporated at the reef crest to account for wave
   breaking. Overall energy estimates are derived for a period of 5 years
   and related to spatial patterning of reef flat surface cover (sand and
   seagrass patches). (C) 2011 Published by Elsevier Ltd.}},
DOI = {{10.1016/j.ecss.2011.08.035}},
ISSN = {{0272-7714}},
EISSN = {{1096-0015}},
Unique-ID = {{ISI:000298528500001}},
}

@inproceedings{ ISI:000297160600277,
Author = {Grassi, Marco and Nucci, Michele and Piazza, Francesco},
Book-Group-Author = {{IEEE}},
Title = {{Towards an ontology framework for intelligent smart home management and
   energy saving}},
Booktitle = {{2011 IEEE INTERNATIONAL SYMPOSIUM ON INDUSTRIAL ELECTRONICS (ISIE)}},
Year = {{2011}},
Note = {{20th IEEE International Symposium on Industrial Electronics (ISIE),
   Gdansk, POLAND, JUN 27-30, 2011}},
Organization = {{Inst Elect \& Elect Engineers (IEEE); IEEE Ind Elect Soc (IES); Gdansk
   Univ Technol}},
Abstract = {{Energetic efficiency has become a mandatory requirement for buildings.
   Several efforts have been done both to reduce energy consumption and to
   promote alternative generation sources. In most of the existing
   proposals these two facets of energy conservation are handled
   singularly. We believe that energy production and consumption need to be
   managed in a unique perspective to enable a more efficient energy
   administration.
   In this paper, we briefly introduce a novel holistic vision for smart
   home environments and present an ontology framework conceived to provide
   the necessary information modelling in its implementation. In
   particular, we focus on two of the composing ontologies that we are
   currently developing for describing devices and power
   generation/consumption, in order to enable intelligent task management
   for energy consumption optimisation.}},
ISBN = {{978-1-4244-9312-8}},
Unique-ID = {{ISI:000297160600277}},
}

@article{ ISI:000075482900004,
Author = {Klas, A},
Title = {{The development of competitiveness factors in the world economy and in
   the Slovak Republic}},
Journal = {{EKONOMICKY CASOPIS}},
Year = {{1998}},
Volume = {{46}},
Number = {{2}},
Pages = {{202-218}},
Abstract = {{The Slovak economy faces the strategic task of transforming its
   technology structure, raising its performance and integrating itself
   into the international division of labour with economically developed
   countries (EDCs). The problem of structure changes is not in trinsic to
   transitional economies only, EDCs meet this problem too. Know-how of
   this development can be instructive along several lines to master the
   changes that face the current economy of the Slovak Republic (SR).
   Since the sixties EDCs have experienced gradual manpower price increase,
   which especially in Western Europe proceeded faster than labour
   productivity increase. That discriminated above all labour intensive
   branches oriented on mass production In the seventies this development
   was aggravated by the steep price increase of raw materials and energy.
   These facts, accompanied by progress in science and technology and a
   drive of newly industrialized countries of south-east Asia with cheap
   manpower, changed the character of the competitive advantage of EDCs. In
   one decade a whole range of production branches went bankrupt, such as
   iron and steel metallurgy, textile production, ship-building etc.
   If price increase and limited natural resources lead on one side to seek
   new economical methods, on the other side the price increase of
   production factors opened the way towards more expensive investment and
   research intensive technologies. Factors based on the progress of
   science and technology became a moving force of a new type of
   competitive advantages. Unlike static factors of comparative advantages,
   which are usually linked to a certain geographical region, dynamic
   factors are characterized by greater mobility and are linked more and
   more to regions rich in science and research potential.
   The result of all this seems to be a high concentration of direct
   foreign investments in EDCs. The share of EDCs in the total inflow of
   direct foreign investments represented 85.4\% in 1980 and till 1992 this
   figure rose up to 88\%. Such a development means a new polarization of
   the world. In the year 1965, the seven wealthiest countries produced
   20-times more than the poorest countries. In the year 1995 this figure
   rose to 39 times.
   All these facts influence foreign trade too. The traditional exchange of
   commodities between autonomous independent firms has widened into
   international exchange within multinational companies. The share of
   intercompany exports in multinational companies USA reaches about 36\%,
   in manufacturing industry even double that figure. Such a change
   markedly narrows transfer channels of modem technologies through
   traditional foreign trade. Under the new conditions multinational
   companies try to gain advantages resulting from the progress in science
   and technology by founding daughter and sister companies of their own,
   and research institutes. In the year 1989 the enterprises of USA, Japan
   and EU placed 40\% of their research centres abroad, compared to only
   12\% in the year 1982. This means that the interest of investors is
   attracted not only by comparative advantages of production conditions,
   but increasingly comparative advantages of the intellectual potential in
   the relevant country.
   The advancing process of globalization, the growing importance of
   innovations and a more severe competition environment significantly
   increased the demand on information volume, its acquirement and
   handling. The share of people employed in information professions
   markedly rose. The transfer of the centre of gravity from physical work
   to brainwork introduced a whole range of new problems. Most important of
   these was the contradiction between labour productivity in information
   professions and in physical work. Solely in the period from 1975 to 1985
   the labour productivity increment in industry was 30 times as big as
   that in administration. The increase of those employed in information
   activities became st great obstacle to total labour productivity growth.
   This discrepancy resulted from the strategic orientation of industrial
   community predominantly oriented on the increase of the physical
   performance of the individual.
   The start of computer technology brought a solution of this
   contradiction. This technology together with telecommunication
   techniques provided material base of post-industrial development now
   designated the information society. In a short time it penetrated into
   all segments of economics and society and accelerated the rate of
   production restructuring in favour of products demanding information
   resources and qualified labour. Table 3 illustrates the development of
   manpower allocation in the USA proportionally by sectors and years, and
   Table 4 presents the share of people employed in information activities
   in the total of the active population proportionally in selected
   countries. The information society today has ceased to be a future
   vision only. It has a definite place in the economies of EDCs, creates
   new branches in the sphere of production and services.
   The changeover of the Slovak economy onto the development path of EDCs
   will not be easy. Foreign trade exchange of SR is still characterized by
   imports and exports of raw materials, fuels and intermediate products.
   Their share in the last three years has even increased. The Slovak
   economy registered an increasing comparative advantage against small
   economically developed countries in the years 1994-1996 only in
   intermediate products and short term consumer goods. The data of Table 6
   show that SR is reaching positive differences in comparative advantages
   in commodity groups demanding simple labour, physical capital and raw
   materials. At the same time the group of products demanding research,
   e.g. higher qualified labour, the negative difference increases (from
   -24.8 up to -30 points). The data of Table 7 witness the fact that SR
   gains comparative advantage against small economically developed
   countries above all in less technology demanding commodities. At the
   same time the share of university students in Slovakia per hundred
   thousand inhabitants is satisfactory, in the middle between developed
   and less developed countries of the EU. Due to worse technology
   equipment, to provide one million USD of GDP needs 4.82 students,
   whereas in economically developed countries one needs only 0.89
   students. it is clear that current technology equipment of production
   substantially reduces the efficiency of university educated
   professionals. Slovakia achieves, in the overall productivity measured
   by GDP per capita, only one third of the productivity currently achieved
   in the EU countries. In the education level SR occupies eleventh place
   among 15 EU countries (Table 9). This disproportion between the
   education level and labour productivity can be explained only by the
   fact that other production factors badly lag behind. One can see,
   therefore, that the factor of education and intellectual potential of SR
   is not lagging behind to such an extent as other production factors and
   has therefore the best chance to become a driving force of future
   development.}},
ISSN = {{0013-3035}},
Unique-ID = {{ISI:000075482900004}},
}

@article{ ISI:A1992JE77300013,
Author = {INABA, J and NISHIMURA, Y and TAKEDA, H and TAKAHASHI, S},
Title = {{PLACENTAL-TRANSFER OF CERIUM IN THE RAT WITH SPECIAL REFERENCE TO ROUTE
   OF ADMINISTRATION}},
Journal = {{RADIATION PROTECTION DOSIMETRY}},
Year = {{1992}},
Volume = {{41}},
Number = {{2-4}},
Pages = {{119-122}},
Note = {{WORKSHOP ON AGE-DEPENDENT FACTORS IN THE BIOKINETICS AND DOSIMETRY OF
   RADIONUCLIDES, SCHLOSS ELMAU, GERMANY, NOV 05-08, 1991}},
Organization = {{COMMISS EUROPEAN COMMUNITIES; US DOE; EUROPEAN LATE EFFECTS PROJECT GRP}},
Abstract = {{The transfer of radiocerium to the fetus in the rat was studied to
   provide quantitative information for the assessment of radiation doses
   to members of the public in connection with environmental problems of
   nuclear energy. Pregnant rats were injected intravenously or given oral
   doses of a single tracer amount of (CeCl3)-Ce-141, and the distribution
   in maternal tissues, the fetus and associated tissues, and neonates was
   determined at different times after administration. Concentrations of
   Ce-141 in the fetus were two or three orders of magnitude lower than
   average maternal whole-body concentrations, while accumulation in fetal
   membranes gave similar values to those for maternal concentrations. The
   results also indicated that continuing transfer of Ce-141 to the fetus
   from maternal deposits led to similar concentrations being maintained at
   different times after administration despite the rapid growth of the
   fetus. Similarly, transfer in milk during suckling maintained
   concentrations in neonates. Concentrations in the fetus and associated
   tissues relative to maternal concentrations were lower after intravenous
   administration than after oral administration.}},
ISSN = {{0144-8420}},
Unique-ID = {{ISI:A1992JE77300013}},
}

@article{ ISI:000352252600033,
Author = {Bjursell, Johan and Gentle, James E. and Wang, George H. K.},
Title = {{Inventory announcements, jump dynamics, volatility and trading volume in
   US energy futures markets}},
Journal = {{ENERGY ECONOMICS}},
Year = {{2015}},
Volume = {{48}},
Pages = {{336-349}},
Month = {{MAR}},
Abstract = {{This paper applies nonparametric methods to identify jumps in daily
   futures prices and intraday jumps surrounding inventory announcements of
   crude oil, heating oil and natural gas contracts traded on the New York
   Mercantile Exchange. The sample period of our intraday data covers
   January 1990 to January 2008. We have obtained several interesting
   empirical results. (1) Large volatility days are often associated with
   large jump components, and large jump components are often associated
   with the Energy Information Administration's inventory announcement
   dates. (2) The volatility jump component is less persistent than the
   continuous sample path component. (3) Volatility and trading volume are
   higher on days with a jump at the inventory announcement than on days
   without a jump at the announcement. Furthermore, the intraday volatility
   returns to normal faster following inventory announcements with jumps
   than after announcements without jumps. (C) 2014 Elsevier B.V. All
   rights reserved.}},
DOI = {{10.1016/j.eneco.2014.11.006}},
ISSN = {{0140-9883}},
EISSN = {{1873-6181}},
Unique-ID = {{ISI:000352252600033}},
}

@inproceedings{ ISI:000296318700037,
Author = {Mares, Valerica and Mares, Marius Daniel},
Book-Group-Author = {{Bucharest Acad Econ Studies}},
Title = {{ETHICS AND RESPONSIBILITY IN IT}},
Booktitle = {{PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ACCOUNTING AND MANAGEMENT
   INFORMATION SYSTEMS (AMIS 2011), 6TH EDITION}},
Year = {{2011}},
Pages = {{580-592}},
Note = {{International Conference on Accounting and Management Information
   Systems (AMIS), Bucharest, ROMANIA, JUN 08-09, 2011}},
Organization = {{Bucharest Acad Econom Studies, Fac Accounting \& Management Informat
   Syst}},
Abstract = {{In this article the authors aim to create a presentation of the triangle
   morals-ethics-responsibility with an accent on the current globalized
   society. Business ethics has to disseminate in all the corners of a
   company, and first of all it has to be understood. Understanding the
   moral criteria of behaviour in business is important because the new
   Organizational structures create new complications, related to
   information flow and information administration inside various
   workgroups and in the entire organization, for which there are no
   traditional precedents.}},
Unique-ID = {{ISI:000296318700037}},
}

@article{ ISI:000324048200019,
Author = {Barkenbus, Jack},
Title = {{Indoor Thermal Comfort: The Behavioral Component}},
Journal = {{SUSTAINABILITY}},
Year = {{2013}},
Volume = {{5}},
Number = {{4}},
Pages = {{1680-1699}},
Month = {{APR}},
Abstract = {{This is a study of how indoor temperature settings have changed over
   time in the United States based on data from the Energy Information
   Administration's, Residential Energy Consumption Survey (RECS). It is
   shown that Americans have moderately raised indoor temperature settings
   during the heating season over the past thirty years. It is also shown
   that most Americans keep their homes relatively cool in the summertime
   and are generally averse to implementing temperature setbacks. It is
   revealed that occupants in lower-income homes tend to set their
   thermostats higher in winter than other income groups, but that the most
   intense cooling tends to take place in both low-income and high-income
   homes. As expected, renters tend to heat and cool more intensively than
   homeowners. Getting Americans to change their temperature settings in
   order to save energy is not easy even though it comes with the promise
   of financial savings. The use of programmable thermostats thus far has
   proved unsuccessful. Greater utilization of social marketing to achieve
   energy savings is suggested, as well as a renewed effort on the part of
   electricity suppliers to work more closely with homeowners as part of
   the rollout of the ``smart grid{''}.}},
DOI = {{10.3390/su5041680}},
ISSN = {{2071-1050}},
Unique-ID = {{ISI:000324048200019}},
}

@inproceedings{ ISI:A1993BA32A00005,
Author = {JANIG, C},
Editor = {{Bonin, HEG}},
Title = {{THE INFORMATION AND COMMUNICATION-SYSTEM OF THE CITY OF UNNA - A
   HIERARCHICAL CLIENT-SERVER NETWORK ARCHITECTURE AS ONE MODULE OF THE
   INFORMATION AND COMMUNICATION-SYSTEM IN THE UNNA MUNICIPAL
   ADMINISTRATION}},
Booktitle = {{SYSTEMS ENGINEERING IN PUBLIC ADMINISTRATION}},
Series = {{IFIP TRANSACTIONS A-COMPUTER SCIENCE AND TECHNOLOGY}},
Year = {{1993}},
Volume = {{36}},
Pages = {{53-81}},
Note = {{IFIP TC8/WG8.5 Working Conference on Systems Engineering in Public
   Administration, LUNEBURG, GERMANY, MAR 03-05, 1993}},
Organization = {{INT FEDERAT INFORMAT PROC, TECH COMM INFORMAT SYST; GERMAN COMP SOC;
   AUSTRIAN COMP SOC; FH NORDOSTNIEDERSACHSEN}},
Abstract = {{The power utility company of the city of Unna in Germany underwent a
   reoganization process in the years 1991-92 as part of a `'planned
   change'' in organization, which involved restructuring it from a classic
   energy supply (and distribution) company to an energy service and
   communication company.
   One building block of this restructuring is the organization as a
   cybernetically-oriented organization structure based on an open,
   distributed and heterogenous `'information and communication
   architecture'' as a network.
   The decentralization of competence and responsibility leads to blurred
   boundaries between areas of responsibility, so that a tension can result
   between the necessary supervision of the `'regulatory density'' on the
   one hand and the innovative - and therefore barely subject to
   supervision - use of computers on the other.}},
ISSN = {{0926-5473}},
ISBN = {{0-444-81560-0}},
Unique-ID = {{ISI:A1993BA32A00005}},
}

@article{ ISI:000356871500081,
Author = {Matschullat, Joerg},
Title = {{Sitting on an almost infinite energy source-Japan's geothermal and
   renewables' potential and reality}},
Journal = {{ENVIRONMENTAL EARTH SCIENCES}},
Year = {{2015}},
Volume = {{74}},
Number = {{2}},
Pages = {{1833-1835}},
Month = {{JUL}},
Abstract = {{According to the US Energy Information Administration, Japan produced in
   2013 only 3 \% of its domestic gas consumption and 0.3 \% of its
   domestic oil consumption. It has emerged as the world's largest importer
   of liquefied natural gas, the second-largest importer of coal and the
   third largest of net oil. For this reason, the exigencies of energy
   supplies in Japan call for durable solutions that are sustainable and
   reliable. The present situation of under developed own energy potential
   contradicts the abundant and inexhaustible sources of renewable energy
   within Japan.}},
DOI = {{10.1007/s12665-015-4226-9}},
ISSN = {{1866-6280}},
EISSN = {{1866-6299}},
Unique-ID = {{ISI:000356871500081}},
}

@article{ ISI:000330310400005,
Author = {Zhao, Mo and Sharma, Anuj and Bernt, Dave G. and Meyer, Joshua A. and
   Dickey, Benjamin and Rosenbaugh, Scott and Jones, Elizabeth and Rilett,
   Laurence},
Title = {{Economic Analysis of Using a Renewable Wind Power System at a Signalized
   Intersection}},
Journal = {{JOURNAL OF INTELLIGENT TRANSPORTATION SYSTEMS}},
Year = {{2013}},
Volume = {{17}},
Number = {{3, SI}},
Pages = {{210-220}},
Abstract = {{The transportation sector consumes about 28\% of the total energy
   expended by all sectors in the United States, according to the U. S.
   Energy Information Administration. This article proposes a renewable
   wind power system (RWPS) as an alternative power source for a signalized
   traffic intersection. The RWPS can be mounted on existing transportation
   infrastructure to provide green energy. Large-scale implementation of
   such a system has the potential to change the role of the public
   right-of-way from an energy consumer to an energy producer. This article
   provides a framework to investigate the physical and economic
   feasibility of installing an RWPS. Methodologies to conduct a structural
   analysis, site selection, and economic analysis are developed. A case
   study for an intersection in Lincoln, Nebraska, is used to demonstrate
   the application of evaluation procedures. The benefits of an RWPS are
   twofold: (a) the power generated by such a system can support the
   operation of traffic signals and any excess power produced can be sold
   back to the power grid; and (b) an RWPS provides a source of backup
   power in case of grid failure and thus increases the traffic network
   reliability. This article presents the methodologies to determine the
   economic value of an RWPS for both cases just described. The costs and
   benefits of providing RWPS are stated in dollar values. The decision to
   install an RWPS at an intersection can be made using a benefit-cost
   ratio. The case study shows that the RWPS is economically feasible at
   the subject intersection. The results also show that intersections with
   frequent power failures will have higher benefit-cost ratios. In the
   event of budget constraints, the methodologies developed in this article
   can be used to prioritize the investments.}},
DOI = {{10.1080/15472450.2012.716641}},
ISSN = {{1547-2450}},
EISSN = {{1547-2442}},
Unique-ID = {{ISI:000330310400005}},
}

@article{ ISI:000305089200015,
Author = {Sharma, Sapna and Ahluwalia, Pardeep Kumar},
Title = {{Diagnosing alternative conceptions of Fermi energy among undergraduate
   students}},
Journal = {{EUROPEAN JOURNAL OF PHYSICS}},
Year = {{2012}},
Volume = {{33}},
Number = {{4}},
Pages = {{883-895}},
Month = {{JUL}},
Abstract = {{Physics education researchers have scientifically established the fact
   that the understanding of new concepts and interpretation of incoming
   information are strongly influenced by the preexisting knowledge and
   beliefs of students, called epistemological beliefs. This can lead to a
   gap between what students actually learn and what the teacher expects
   them to learn. In a classroom, as a teacher, it is desirable that one
   tries to bridge this gap at least on the key concepts of a particular
   field which is being taught. One such key concept which crops up in
   statistical physics/solid-state physics courses, and around which the
   behaviour of materials is described, is Fermi energy (epsilon(F)). In
   this paper, we present the results which emerged about misconceptions on
   Fermi energy in the process of administering a diagnostic tool called
   the Statistical Physics Concept Survey developed by the authors. It
   deals with eight themes of basic importance in learning undergraduate
   solid-state physics and statistical physics. The question items of the
   tool were put through well-established sequential processes: definition
   of themes, Delphi study, interview with students, drafting questions,
   administration, validity and reliability of the tool. The tool was
   administered to a group of undergraduate students and postgraduate
   students, in a pre-test and post-test design. In this paper, we have
   taken one of the themes i.e. Fermi energy of the diagnostic tool for our
   analysis and discussion. Students' responses and reasoning comments
   given during interview were analysed. This analysis helped us to
   identify prevailing misconceptions/learning gaps among students on this
   topic. How spreadsheets can be effectively used to remove the identified
   misconceptions and help appreciate the finer nuances while visualizing
   the behaviour of the system around Fermi energy, normally sidestepped
   both by the teachers and learners, is also presented in this paper.}},
DOI = {{10.1088/0143-0807/33/4/883}},
ISSN = {{0143-0807}},
Unique-ID = {{ISI:000305089200015}},
}

@article{ ISI:000301773500013,
Author = {Suzuki, Yutaka and Song, Sang-Houn and Sato, Katsuyoshi and So,
   Kyoung-Ha and Ardiyanti, Astrid and Kitayama, Shun and Hong, Yeon-Hee
   and Lee, Sung-Dae and Choi, Ki-Choon and Hagino, Akihiko and Katoh,
   Kazuo and Roh, Sang-Gun},
Title = {{Chemerin analog regulates energy metabolism in sheep}},
Journal = {{ANIMAL SCIENCE JOURNAL}},
Year = {{2012}},
Volume = {{83}},
Number = {{3}},
Pages = {{263-267}},
Abstract = {{Accumulating data suggest a relationship between chemerin and energy
   metabolism. Our group previously described gene cloning, expression
   analysis and the regulatory mechanism of chemerin and its own receptor
   in mice and cattle. The objective of the present study was to
   investigate the physiological effect of chemerin on endocrine changes
   and energy metabolism in sheep using a biologically stable chemerin
   analog. The chemerin analog was intravenously administrated (100 or 500
   mu g/head) to sheep, and plasma insulin and metabolites (glucose,
   nonesterified fatty acids (NEFA), triglyceride, total cholesterol and
   high-density lipoprotein (HDL) cholesterol) were analyzed. The chemerin
   analog dramatically increased the insulin levels, and glucose levels
   were decreased. NEFA levels were slightly decreased at 20 min but then
   increased gradually from 60 to 180 min after analog administration. In
   addition, injection of the chemerin analog immediately increased
   triglyceride and total cholesterol but not HDL levels. These results
   suggested that chemerin analog regulated insulin secretion related to
   glucose metabolism and the release of triglycerides in sheep in vivo.
   This study provides new information about endocrine and metabolic
   changes in response to chemerin in sheep.}},
DOI = {{10.1111/j.1740-0929.2011.01002.x}},
ISSN = {{1344-3941}},
Unique-ID = {{ISI:000301773500013}},
}

@article{ ISI:000284987900034,
Author = {Mazhari, Esfandyar and Zhao, Jiayun and Celik, Nurcin and Lee, Seungho
   and Son, Young-Jun and Head, Larry},
Title = {{Hybrid simulation and optimization-based design and operation of
   integrated photovoltaic generation, storage units, and grid}},
Journal = {{SIMULATION MODELLING PRACTICE AND THEORY}},
Year = {{2011}},
Volume = {{19}},
Number = {{1}},
Pages = {{463-481}},
Month = {{JAN}},
Abstract = {{Unlike fossil-fueled generation solar energy resources are
   geographically distributed and highly intermittent which makes their
   direct control extremely difficult and requires storage units as an
   additional concern The goal of this research is to design and develop a
   flexible tool which will allow us to obtain (1) an optimal capacity of
   an integrated photovoltaic (PV) system and storage units and (2) an
   optimal operational decision policy considering the current and future
   market prices of the electricity The proposed tool is based on hybrid
   (system dynamics model and agent-based model) simulation and
   meta-heuristic optimization In particular this tool has been developed
   for three different scenarios (involving different geographical scales)
   where PV-based solar generators storage units
   (compressed-air-energy-storage (CAES) and super-capacitors) and grid are
   used in an integrated manner to supply energy demands Required data has
   been gathered from various sources including NASA and TEP(utility
   company) US Energy Information Administration National Renewable Energy
   Laboratory commercial PV panel manufacturers and publicly available
   reports The constructed tool has been demonstrated to (1) test impacts
   of several factors (e g demand growth efficiencies in PV panel and CAES
   system) on the total cost of the integrated generation and storage
   system and an optimal mixture of PV generation and storage capacity and
   to (2) demonstrate an optimal operational policy (C) 2010 Elsevier B V
   All rights reserved}},
DOI = {{10.1016/j.simpat.2010.08.005}},
ISSN = {{1569-190X}},
Unique-ID = {{ISI:000284987900034}},
}

@inproceedings{ ISI:000273591400071,
Author = {Leng, Hui-wen and Wang, Dong-xing and Li, Yue and Li, Bao-shun},
Editor = {{Luo, Q}},
Title = {{Research on the Experimental Education of Technical Courses in the
   Information Age}},
Booktitle = {{2009 INTERNATIONAL SYMPOSIUM ON INTELLIGENT UBIQUITOUS COMPUTING AND
   EDUCATION}},
Year = {{2009}},
Pages = {{277-280}},
Note = {{International Symposium on Intelligent Ubiquitous Computing and
   Education, Chengdu, PEOPLES R CHINA, MAY 16-17, 2009}},
Organization = {{Intelligent Informat Technol Applicat Res Assoc; Engn Technol Press;
   Wuhan Inst Technol}},
Abstract = {{The advanced technologies in the information age have instilled new
   energy to the experimental education. A new experimental education
   scheme for technical courses has been proposed, including education of
   experiment principles, Web-based presentation of experiment resources,
   preparation of experiments and its examination, virtual experiments and
   their examination, administration of open real experiments, real
   experiments and their examination, and creative experiments. The
   proposed scheme concentrates several advanced techniques of the
   information age, by making full use of their advantages and bypassing
   their disadvantages. By applying the scheme, the experiments in
   technical courses can be carried out with high efficiency, high quality,
   good safety and individualization. Practice has demonstrated that the
   scheme is applicable. Considering its asynchronism, the scheme is
   especially applicable to distance education, lifelong education,
   self-study and individualized education.}},
DOI = {{10.1109/IUCE.2009.30}},
ISBN = {{978-0-7695-3619-4}},
Unique-ID = {{ISI:000273591400071}},
}

@article{ ISI:000252624700008,
Author = {Arnett, Edward B. and Brown, W. Kent and Erickson, Wallace P. and
   Fiedler, Jenny K. and Hamilton, Brenda L. and Henry, Travis H. and Jain,
   Aaftab and Johnson, Gregory D. and Kerns, Jessica and Koford, Rolf R.
   and Nicholson, Charles P. and O'Connell, Timothy J. and Piorkowski,
   Martin D. and Tankersley, Jr., Roger D.},
Title = {{Patterns of bat fatalities at wind energy facilities in North America}},
Journal = {{JOURNAL OF WILDLIFE MANAGEMENT}},
Year = {{2008}},
Volume = {{72}},
Number = {{1}},
Pages = {{61-78}},
Month = {{JAN}},
Abstract = {{Wind has become one of the fastest growing sources of renewable energy
   worldwide, but widespread and often extensive fatalities of bats have
   increased concern regarding the impacts of wind energy development on
   bats and other wildlife. We synthesized available information on
   patterns of bat fatalities from a review of 21 postconstruction fatality
   studies conducted at 19 facilities in 5 United States regions and one
   Canadian province. Dominance of migratory, foliage- and tree-roosting
   lasiurine species (e.g., hoary bat {[}Lasiurus cincreus]) killed by
   turbines was consistent among studies. Bat fatalities, although highly
   variable and periodic, consistently peaked in late summer and fall,
   coinciding with migration of lasiurines and other species. A notable
   exception was documented fatalities of pregnant female Brazilian
   free-tailed bats (Tadarida brasiliensis) in May and June at a facility
   in Oklahoma, USA, and female silver-haired bats (Lasionycteris
   noctivagans) during spring in Tennessee, USA, and Alberta, Canada. Most
   studies reported that fatalities were distributed randomly across
   turbines at a site, although the highest number of fatalities was often
   found near the end Of turbine strings. Two studies conducted
   simultaneously in the same region documented similar timing of
   fatalities between sites, which suggests broader patterns of collisions
   dictated by weather, prey abundance, or other factors. None of the
   studies found differences in bat fatalities between turbines equipped
   with lighting required by the Federal Aviation Administration and
   turbines that were unlit. All studies that addressed relationships
   between bat fatalities and weather patterns found that most bats were
   killed on nights with low wind speed (<6 m/sec) and that fatalities
   increased immediately before and after passage of storm fronts. Weather
   patterns may be predictors of bat activity and fatality; thus,
   mitigation efforts that focus on these high-risk periods could reduce
   bat fatality substantially. We caution that estimates of bat fatality
   are conditioned by length of study and search interval and that they are
   biased in relation to how searcher efficiency, scavenger removal, and
   habitat differences were or were not accounted for. Our review will
   assist managers, biologists, and decision-makers with understanding
   unifying and unique patterns of bat fatality, biases, and limitations of
   existing efforts, and it will aid in designing future research needed to
   develop mitigation strategies for minimizing or eliminating bat fatality
   at wind facilities.}},
DOI = {{10.2193/2007-221}},
ISSN = {{0022-541X}},
ResearcherID-Numbers = {{O'Connell, Timothy/A-2908-2011}},
ORCID-Numbers = {{O'Connell, Timothy/0000-0001-8215-2670}},
Unique-ID = {{ISI:000252624700008}},
}

@article{ ISI:000231025800011,
Author = {Kim, S and Dale, BE},
Title = {{Life cycle inventory information of the United States electricity system}},
Journal = {{INTERNATIONAL JOURNAL OF LIFE CYCLE ASSESSMENT}},
Year = {{2005}},
Volume = {{10}},
Number = {{4}},
Pages = {{294-304}},
Month = {{JUL}},
Abstract = {{Goal and Scope. This study estimates the life cycle inventory (LCI) of
   the electricity system in the United States, including the 10 NERC
   (North American Electric Reliability Council) regions, Alaska, Hawaii,
   off-grid non-utility plants and the US average figures. The greenhouse
   gas emissions associated with the United States electricity system are
   also estimated.
   Methods. The fuel mix of the electricity system based on year 2000 data
   is used. The environmental burdens associated with raw material
   extraction, petroleum oil production and transportation for petroleum
   oil and natural gas to power plants are adopted from the DEAM (TM) LCA
   database. Coal transportation from a mining site to a power plant is
   specified with the data from the Energy Information Administration
   (EIA), which includes the mode of transportation as well as the distance
   traveled. The gate-to-gate environmental burdens associated with
   generating electricity from a fossil-fired power plant are obtained from
   the DEAM (TM) LCA database and the eGRID model developed by the United
   States Environmental Protection Agency. For nuclear power plants and
   hydroelectric power plants, the data from the DEAM (TM) LCA database are
   used.
   Results and Discussion. Selected environmental profiles of the US
   electricity system are presented in the paper version, while the on-line
   version presents the whole LCI data. The overall US electricity system
   in the year 2000 released about 2,654 Tg CO2 eq. of greenhouse gas
   emissions based on 100-year global warming potentials with 193 g CO2 eq.
   MJe(-1) as an weighted average emission rate per one MJ electricity
   generated. Most greenhouse gases are released during combusting fossil
   fuels, accounting for 78-95\% of the total. The greenhouse gas emissions
   released from coal-fired power plants account for 81\% of the total
   greenhouse gas emissions associated with electricity generation, and
   natural gas-fired power plants contribute about 16\% of the total. The
   most significant regions for the total greenhouse gas emissions are the
   SERC (Southeastern Electric Reliability Council) and ECAR (East Central
   Area Reliability Coordination Agreement) regions, which account for 22\%
   and 21\% of the total, respectively. A sensitivity analysis on the
   generation and consumption based calculations indicates that the
   environmental profiles of electricity based on consumption are more
   uncertain than those based on generation unless exchange data from the
   same year are available because the exchange rates (region to region
   import and export of electricity) vary significantly from year to year.
   Conclusions and Outlook. Those who are interested in the LCI data of the
   US electricity system can refer to the on-line version. When the
   inventory data presented in the on-tine version are used in a life cycle
   assessment study, the distribution and transmission losses should be
   taken into account, which is about 9.5\% of the net generation {[}1].
   The comprehensive technical information presented in this study can be
   used in estimating the environmental burdens when new information on the
   regional fuel mix or the upstream processes is available. The exchange
   rates presented in this study also offer useful information in
   consequential LCI studies.}},
DOI = {{10.1065/lca2004.09.176}},
ISSN = {{0948-3349}},
Unique-ID = {{ISI:000231025800011}},
}

@article{ ISI:000229071900001,
Author = {Popovic, V and Duntas, LH},
Title = {{Brain somatic cross-talk: Ghrelin, leptin and ultimate challengers of
   obesity}},
Journal = {{NUTRITIONAL NEUROSCIENCE}},
Year = {{2005}},
Volume = {{8}},
Number = {{1}},
Pages = {{1-5}},
Month = {{FEB}},
Abstract = {{Energy balance is largely regulated by the central nervous system (CNS),
   which senses metabolic status from a wide range of humoral and neural
   signals, and controls energy intake. Accumulating evidence supports the
   model that stimulation of leptin-and ghrelin-responsive pathways,
   including the central melanocortin system, in the hypothalamus,
   contributes to the maintenance of body weight. Ghrelin is the brain-gut
   peptide with growth hormone-releasing and appetite-inducing activities.
   It is mainly secreted from the stomach and acts as an afferent signal to
   the hypothalamus and hindbrain. Leptin, the adipocyte hormone, is
   believed to tonically act as an afferent signal from adipose tissue to
   the brain, in particular hypothalamus, as a part of negative feedback
   loop regulating the size of energy stores and energy balance.
   Dysregulation of these pathways is a marker of changes in energy
   balance. Ghrelin is negatively correlated with weight and obese subjects
   have lower ghrelin levels than lean subjects, consistent with a
   compensatory rather than causal role for ghrelin in obesity. On the
   contrary, circulating leptin levels correlate in proportion to adiposity
   being high in obesity suggesting that human obesity is associated with
   insensitivity to leptin. The leptin resistance in diet-induced obesity
   emphasizes that environmental factors can modulate leptin sensitivity.
   It is speculated that through hypothalamic/pituitary axis ghrelin and
   leptin operate as a metabolic switch. Ghrelin actually transfers
   information from the stomach to the hypothalamus in cooperation with
   leptin and provides calories that growth hormone (GH) needs for growth
   and repair. Pharmacological manipulations of circulating hormone levels
   may work well in ``cheating{''} the brain regarding information from the
   periphery. It might also be necessary to combine two or three agents to
   fight obesity. A combination of drugs that decrease preprandial appetite
   (ghrelin antagonist) and increase post-prandial satiety (gut hormone
   fragment peptide YY 3-36) might have a chance of achieving sustained
   weight loss. The administration of exogenous satiety hormone peptide YY
   3-36 (PYY) may prevent the action of appetite-stimulating hypothalamic
   circuits on the anorexigenic melanocortin pathways.}},
DOI = {{10.1080/10284150400027107}},
ISSN = {{1028-415X}},
Unique-ID = {{ISI:000229071900001}},
}

@inproceedings{ ISI:000189002100169,
Author = {Mozaffari, H},
Book-Group-Author = {{ISHVAC}},
Title = {{Energy reduction in developing countries}},
Booktitle = {{PROCEEDINGS OF THE 4TH INTERNATIONAL SYMPOSIUM ON HEATING, VENTILATING
   AND AIR CONDITIONING, VOLS 1 AND 2}},
Year = {{2003}},
Pages = {{1149-1155}},
Note = {{4th International Symposium on Heating, Ventilating and Air
   Conditioning, BEIJING, PEOPLES R CHINA, OCT 09-11, 2003}},
Organization = {{Tsinghua Univ, Dpet Bldg Sci, Sch Architecture; Natl Nat Sci Fdn China;
   Amer Soc Heating, Refrigerating \& Air Conditioning Engineers; Chartered
   Inst Bldg Serv Engineers; Soc Heating, Air Conditioning \& Sanitary
   Engineers Japan; Scandinavian Federat Heating; Federat European Heating
   \& Air Conditioning Assoc; China Assoc Refrigerat; Chinese Architecture
   Assoc, Comm Heating, Ventilating \& Air Conditioning; Beijing Assoc
   Refrigerat}},
Abstract = {{Due to the rapid growth of the Chinese economy, increased efficiency of
   energy use has become an important element of a strategy to achieve
   sustainable development in the country. According to the Energy
   Information Administration EIA, within the next few decades, China will
   be the world's largest producer of CO2 and in the future, buildings will
   consume up to one-third of the total energy. The aim of this paper is to
   study possible reductions of energy consumption in residential dwellings
   in China. The computer simulations in this paper have been done by
   Simulink, which is based on Matlab. To compare the result, a new
   methodology based on dynamic thermal networks, developed at the
   department of Building Physic in Chalmers University of Technology,
   Gothenburg has been used but not presented in this paper. To calculate
   the time-dependent variation of the heat loss through the construction,
   the outer temperatures are weighed with certain weight factors. By
   studying the weight factors, a clear picture over the dynamic heat flow
   is obtained. The dynamic heat loss of a wall is the sum of absorptive
   and transmittive heat flux {[}1].}},
ISBN = {{7-302-07326-0}},
Unique-ID = {{ISI:000189002100169}},
}

@article{ ISI:A1997YH66000001,
Author = {Huether, G and Zhou, D and Ruther, E},
Title = {{Causes and consequences of the loss of serotonergic presynapses elicited
   by the consumption of 3,4-methylenedioxymethamphetamine (MDMA,
   `'ecstasy'') and its congeners}},
Journal = {{JOURNAL OF NEURAL TRANSMISSION}},
Year = {{1997}},
Volume = {{104}},
Number = {{8-9}},
Pages = {{771-794}},
Abstract = {{The massive and prolonged stimulation of serotonin (5-HT)-release and
   the increased dopaminergic activity are responsible for the acute
   psychomimetic and psychostimulatory effects of
   3,4-methylenedioxymethamphetamine (MDMA, `'ecstasy'') and its congeners.
   In vulnerable subjects, at high doses or repeated use, and under certain
   unfavorable conditions (crowding, high ambient temperature), severe, in
   some cases fatal, averse systemic reactions (hyperthermia,
   serotonin-syndrome) may occur during the first few hours. Animal
   experiments revealed the existence of similar differences in
   vulnerability and similar dose-and context-related influences on; a
   similar sequence of acute responses. The severity of these acute
   systemic responses is closely related to the severity of the long-term
   damage to 5-HT axon terminals caused by the administration of
   substituted amphetamines. Attempts to identify the mechanisms involved
   in this selective degeneration of 5-HT presynapses brought to light a
   multitude of different factors and conditions which either attenuate or
   potentiate the loss of 5-HT terminals caused by MDMA and related
   amphetamine derivatives. These puzzling observations suggest that the
   degeneration of 5-HT presynapses represents only the final step in a
   sequence of events which compromise the ability of 5-HT terminals to
   maintain their functional and structural integrity. The common feature
   of all these events is a profound wastage of energy. Substituted
   amphetamines selectively tax energy metabolism in 5-HT presynapses
   through their ability to exchange with 5-HT and to dissipate
   transmembrane ion gradients. The active carrier systems in the vesicular
   and presynaptic membrane operate at a permanently activated state. The
   resulting energy deficit can no longer adequately restored by the 5-HT
   presynapses when their availability ability of substrates for ATP
   production is additionally reduced by the hyperthermic and other energy
   consuming reactions which are elicited by the systemic administration of
   substituted amphetamines. The exhaustion of energy in 5-HT nerve
   terminals compromise all energy-requiring endogenous mechanisms involved
   in the regulation of transmembrane-ion exchange, internal
   Ca++-homeostasis, prevention of oxidative stress, detoxification, and
   repair. Above a critical threshold the failure of these self-protective
   mechanisms will lead to the degeneration of the 5-HT axon terminals.
   Based on the role of 5-HT as a global modulatory transmitter-system
   involved in the stabilization and integration of impulse flow between
   distributed multifocal neuronal networks, the partial loss of 5-HT
   presynapses must be expected to impair the ability of these networks to
   maintain the integrity of signal flow pattern, and increase the
   likelihood of switching to unstable information processing. Behavioral
   responding may therefore become more dominated by activities generated
   in individual networks, and hitherto `'buffered'' personality traits and
   predisposition may become manifested as defined psychiatric syndromes in
   certain predisposed subjects.}},
DOI = {{10.1007/BF01285547}},
ISSN = {{0300-9564}},
Unique-ID = {{ISI:A1997YH66000001}},
}

@article{ ISI:A1993LC83100002,
Author = {KENT, CA},
Title = {{AN ANALYTICAL HISTORY OF EIA}},
Journal = {{GOVERNMENT INFORMATION QUARTERLY}},
Year = {{1993}},
Volume = {{10}},
Number = {{1}},
Pages = {{3-24}},
Abstract = {{This article traces the development of the Energy Information
   Administration (EIA) from 1974, the inception of its precursor, an
   office within the Federal Energy Administration, to its current form as
   an independent agency within the U.S. Department of Energy (DOE). EIA
   amalgamated the energy-related activities of over 50 separate agencies,
   when it was chartered in DOE in 1977, `'to collect, evaluate, assemble,
   and analyze energy information....'' Six tensions have characterized the
   agency during its history: data quality, the role of modeling,
   confidentiality of data, resources and requirements, the independence of
   EIA, and timeliness vs. accuracy.}},
DOI = {{10.1016/0740-624X(93)90003-I}},
ISSN = {{0740-624X}},
Unique-ID = {{ISI:A1993LC83100002}},
}

@article{ ISI:A1993LC83100004,
Author = {SKINNER, CW},
Title = {{NATIONAL ENERGY MODELING SYSTEM}},
Journal = {{GOVERNMENT INFORMATION QUARTERLY}},
Year = {{1993}},
Volume = {{10}},
Number = {{1}},
Pages = {{41-51}},
Abstract = {{The Energy Information Administration is developing a new National
   Energy Modeling System to provide annual forecasts of energy supply,
   demand, and prices on a regional basis in the United States and, to a
   limited extent, in the rest of the world. The design for the system was
   based on a requirements analysis, a comparison of requirements with
   existing modeling capabilities, and a series of widely circulated issue
   papers defining the choices and tradeoffs for 13 key design decisions,
   An initial prototype of the new NEMS was implemented in late 1992, with
   a more complete, operational version in 1993. NEMS is expected to
   provide EIA and other users with a greatly enhanced ability to
   illustrate quickly and effectively the effects of a wide range of energy
   policy proposals.}},
DOI = {{10.1016/0740-624X(93)90005-K}},
ISSN = {{0740-624X}},
Unique-ID = {{ISI:A1993LC83100004}},
}

@article{ ISI:000359751400010,
Author = {Blandford, Benjamin and Grossardt, Ted and Shouse, Michael and Ripy,
   John},
Title = {{Intermodal Network Model of Coal Distribution in the United States}},
Journal = {{TRANSPORTATION RESEARCH RECORD}},
Year = {{2015}},
Number = {{2479}},
Pages = {{69-77}},
Abstract = {{This paper describes an intermodal network model based on the geographic
   information system for the shipment of coal in the United States. The
   research contributes to a better understanding of a portion of the
   energy transportation system and how rail, water, and highway are
   integrated to deliver energy goods. Coal movements were modeled across
   the network with the Energy Information Administration's 2010 data,
   providing detailed origin, destination, primary mode, and volume
   information for coal movements in the United States. The model
   identifies the optimum routes for coal shipments on the basis of a rate
   structure that accounts for the relative costs of shipping by each of
   the modes. The model results reveal the wide distribution of Powder
   River Basin coal, with a market area that reaches across the West and
   the Midwest. Both Texas and Illinois, the two largest coal consumers by
   state, derive virtually all their coal from the West or from within
   state. Appalachian Basin coal serves domestic and export markets
   primarily in the east and southeastern United States. Only the Ohio
   River provides significant movement of Central Appalachian Basin coal to
   the West and the South. The presented research demonstrates the
   potential for integrated models to accommodate energy-related or similar
   data. The model is a tool freight planners can use to identify energy
   transportation corridors of significance. Results from this model can
   inform efforts related to the Moving Ahead for Progress in the 21st
   Century Act for developing a national freight network and a national
   freight strategic plan.}},
DOI = {{10.3141/2479-09}},
ISSN = {{0361-1981}},
EISSN = {{2169-4052}},
Unique-ID = {{ISI:000359751400010}},
}

@article{ ISI:000339599100017,
Author = {Edefonti, Valeria and Rosato, Valentina and Parpinel, Maria and Nebbia,
   Gabriella and Fiorica, Lorenzo and Fossali, Emilio and Ferraroni, Monica
   and Decarli, Adriano and Agostoni, Carlo},
Title = {{The effect of breakfast composition and energy contribution on cognitive
   and academic performance: a systematic review}},
Journal = {{AMERICAN JOURNAL OF CLINICAL NUTRITION}},
Year = {{2014}},
Volume = {{100}},
Number = {{2}},
Pages = {{626-656}},
Month = {{AUG}},
Abstract = {{Background: Most studies that assess the effects of breakfast on
   subsequent mental abilities compared performance in subjects who had or
   had not consumed this meal. However, characteristics of breakfast itself
   may induce metabolic and hormonal alterations of the gastrointestinal
   tract and potentially modify cognitive performance Moreover, as far as
   the evidence on the positive effects of having breakfast is becoming
   more robust, interest may shift to the specific characteristics of an
   adequate breakfast.
   Objective: The objective was to summarize existing evidence on the role
   of nutrient composition or energy intake at breakfast on the
   accomplishment of school-related tasks and cognition.
   Design: We conducted a systematic review of the literature through the
   Pub Med database.
   Results: From the literature search, we identified 102 articles, 15 of
   which met the inclusion criteria. Of these, 3 studies provided
   information on the relation between cognitive and academic performance
   and energy intake at breakfast, 11 provided the same information for the
   macronutrient composition of breakfast, and 1 investigated both the
   aspects. Eleven studies considered breakfast meals differing in glycemic
   index/load. Selected studies were generally carried out in
   well-nourished children and adults of both sexes from general education.
   They were mostly experimental studies of short duration and had a
   limited number of subjects. Cognitive and academic performance was
   investigated by looking at multiple domains, including memory,
   attention, reasoning, learning, and verbal and math abilities, with a
   variety of test batteries scheduled at different time points in the
   morning. Breakfast options differed in terms of included foods and place
   and time of administration.
   Conclusions: There is insufficient quantity and consistency among
   studies to draw firm conclusions. However, whereas the hypothesis of a
   better and more sustained performance with a breakfast providing >20\%
   daily energy intake still needs substantiation, there does appear to be
   emerging, but still equivocal, evidence that a lower postprandial
   glycemic response is beneficial to cognitive performance.}},
DOI = {{10.3945/jcn.114.083683}},
ISSN = {{0002-9165}},
EISSN = {{1938-3207}},
ResearcherID-Numbers = {{Parpinel, Maria/B-1605-2012
   Agostoni, Carlo/B-3470-2015
   Fossali, Emilio/K-2200-2015
   Ferraroni, Monica/}},
ORCID-Numbers = {{Agostoni, Carlo/0000-0002-5006-0832
   Fossali, Emilio/0000-0002-3197-062X
   Ferraroni, Monica/0000-0002-4542-4996}},
Unique-ID = {{ISI:000339599100017}},
}

@inproceedings{ ISI:000361162400003,
Author = {Wu, Kangqian and Kreith, Frank},
Book-Group-Author = {{ASME}},
Title = {{TRANSITION TO SUSTAINABILITY WITH NATURAL GAS FROM FRACKING}},
Booktitle = {{PROCEEDINGS OF THE ASME 8TH INTERNATIONAL CONFERENCE ON ENERGY
   SUSTAINABILITY, 2014, VOL 2}},
Year = {{2014}},
Note = {{ASME 8th International Conference on Energy Sustainability, Seaport
   World Trade Ctr, Boston, MA, JUN 30-JUL 02, 2014}},
Organization = {{ASME, Adv Energy Syst; ASME, Solar Energy Div}},
Abstract = {{This paper is an analysis of the energy and money needed to construct a
   renewable energy system with the excess energy available from natural
   gas obtained by hydraulic fracturing or ``fracking{''}. Using data from
   the Energy Information Administration regarding the future availability
   of natural gas obtained by fracking and the energy required to build a
   sustainable system consisting of wind power, photo-voltaic energy
   generation and hydraulic storage, a scenario for the construction of a
   sustainable system is generated. Finally, a preliminary financial
   analysis of the cost of the renewable system is made. The analysis
   demonstrates that it is possible to build a sustainable system from the
   excess natural gas obtained by fracking in less than 30 years. After
   that time the energy produced from the renewable system is sufficient to
   replace those parts of the system that have reached their expected life
   and construct new sustainable generation technology as required by
   population growth.}},
Article-Number = {{V002T03A003}},
ISBN = {{978-0-7918-4587-5}},
Unique-ID = {{ISI:000361162400003}},
}

@article{ ISI:000319213900012,
Author = {Wang, Li-Mei and Wang, Yong-Jiu and Cui, Min and Luo, Wen-Juan and Wang,
   Xiao-Ji and Barber, Philip A. and Chen, Zhe-Yu},
Title = {{A dietary polyphenol resveratrol acts to provide neuroprotection in
   recurrent stroke models by regulating AMPK and SIRT1 signaling, thereby
   reducing energy requirements during ischemia}},
Journal = {{EUROPEAN JOURNAL OF NEUROSCIENCE}},
Year = {{2013}},
Volume = {{37}},
Number = {{10}},
Pages = {{1669-1681}},
Month = {{MAY}},
Abstract = {{Polyphenol resveratrol (RSV) has been associated with Silent Information
   Regulator T1 (SIRT1) and AMP-activated protein kinase (AMPK) metabolic
   stress sensors and probably responds to the intracellular energy status.
   Our aim here was to investigate the neuroprotective effects of RSV and
   its association with SIRT1 and AMPK signaling in recurrent ischemia
   models. In this study, elderly male Wistar rats received a combination
   of two mild transient middle cerebral artery occlusions (tMCAOs) as an
   in vivo recurrent ischemic model. Primary cultured cortical neuronal
   cells subjected to combined oxygenglucose deprivation (OGD) were used as
   an in vitro recurrent ischemic model. RSV administration significantly
   reduced infarct volumes, improved behavioral deficits and protected
   neuronal cells from cell death in recurrent ischemic stroke models in
   vivo and in vitro. RSV treatments significantly increased the
   intracellular NAD+/NADH ratio, AMPK and SIRT1 activities, decreased
   energy assumption and restored cell energy ATP level. SIRT1 and AMPK
   inhibitors and specific small interfering RNA (siRNA) for SIRT1 and AMPK
   significantly abrogated the neuroprotection induced by RSV. AMPK-siRNA
   and inhibitor decreased SIRT1 activities; however, SIRT1-siRNA and
   inhibitor had no impact on phospho-AMPK (p-AMPK) levels. These results
   indicated that the neuroprotective effects of RSV increased the
   intracellular NAD+/NADH ratio as well as AMPK and SIRT1 activities,
   thereby reducing energy ATP requirements during ischemia. SIRT1 is a
   downstream target of p-AMPK signaling induced by RSV in the recurrent
   ischemic stroke model.}},
DOI = {{10.1111/ejn.12162}},
ISSN = {{0953-816X}},
Unique-ID = {{ISI:000319213900012}},
}

@article{ ISI:000273985700015,
Author = {Thorsteinsson, Hildigunnur H. and Tester, Jefferson W.},
Title = {{Barriers and enablers to geothermal district heating system development
   in the United States}},
Journal = {{ENERGY POLICY}},
Year = {{2010}},
Volume = {{38}},
Number = {{2}},
Pages = {{803-813}},
Month = {{FEB}},
Abstract = {{According to the US Energy Information Administration, space and hot
   water heating represented about 20\% of total US energy demand in 2006.
   Given that most of this demand is met by burning natural gas, propane,
   and fuel oil, an enormous opportunity exists for directly utilizing
   indigenous geothermal energy as a cleaner, nearly emissions-free
   renewable alternative. Although the US is rich in geothermal energy
   resources, they have been frequently undervalued in America's portfolio
   of options as a means of offsetting fossil fuel emissions while
   providing a local, reliable energy source for communities. Currently,
   there are only 21 operating GDHS in the US with a capacity of about
   100MW thermal. Interviews with current US district heating operators
   were used to collect data on and analyze the development of these
   systems. This article presents the current structure of the US
   regulatory and market environment for GDHS along with a comparative
   study of district heating in Iceland where geothermal energy is
   extensively utilized. It goes on to review the barriers and enablers to
   utilizing geothermal district heating systems (GDHS) in the US for space
   and hot water heating and provides policy recommendations on how to
   advance this energy sector in the US. (C) 2009 Elsevier Ltd. All rights
   reserved.}},
DOI = {{10.1016/j.enpol.2009.10.025}},
ISSN = {{0301-4215}},
Unique-ID = {{ISI:000273985700015}},
}

@article{ ISI:000268162800015,
Author = {Casas-Augustench, P. and Salas-Salvado, J.},
Title = {{Viscosity and flow-rate of three high-energy, high-fibre enteral
   nutrition formulas}},
Journal = {{NUTRICION HOSPITALARIA}},
Year = {{2009}},
Volume = {{24}},
Number = {{4}},
Pages = {{492-497}},
Month = {{JUL-AUG}},
Abstract = {{Introduction: There have been few studies evaluating how the viscosity
   of the enteral nutrition formulas determine the time of nutritional
   administration by gravity and whether viscosity causes tubes to become
   obstructed.
   Objective: To assess how long it takes for three polymeric, hypercaloric
   and fibre-rich enteral nutrition formulas marketed in Europe to pass
   through different nasointestinal tubes by gravity and whether these
   formulas obstruct the tubes.
   Methods: We evaluated the in vitro viscosity of the three formulas using
   a rotational viscometer and by calculating how long these formulas took
   to pass by free fall through the equipment and different calibre tubes.
   We also assessed the possible obstruction of the tubes or the equipment
   after the three formulas had been administered, simulating the
   administration conditions in clinical practice (1,500 ml over 24 h).
   Results: The administration time by gravity of 500 ml of each of the
   formulas studied was closely related to the viscosity determined in
   vitro of each of the formulas used. The larger the internal diameter of
   the tube, the shorter the emptying time by gravity or free fall. The
   possibility of tube obstruction was higher in the case of the two more
   viscous formulas.
   Conclusions: The viscosity of the enteral nutrition formulas should be
   included in the labelling of the product. This information would assist
   the clinician to make decisions about the kind of formula to be used
   with different types and calibres of tube.}},
ISSN = {{0212-1611}},
Unique-ID = {{ISI:000268162800015}},
}

@incollection{ ISI:000270130900015,
Author = {Solmes, Leslie A.},
Book-Author = {{Solmes, LA}},
Title = {{Commitment to Resource Efficiency}},
Booktitle = {{ENERGY EFFICIENCY: REAL TIME ENERGY INFRASTRUCTURE INVESTMENT AND RISK
   MANAGEMENT}},
Year = {{2009}},
Pages = {{169-184}},
Abstract = {{This chapter reinforces the importance of making a commitment to
   establish a uniform language, best practices, and software tools in
   order to compare, measure, and report the financial benefits of energy
   infrastructure investments as well as make them accessible to all
   stakeholders. She states the importance of being able to define the
   opportunity value of new, alternative investment fuels, technologies,
   and implementation strategies in order to make the right investment
   decision regarding the timing, location, and size of the investment.
   The `smart' grid is presented as an exciting IT solution to optimize the
   operation of the US energy systems, but the IT approach needs to be
   expanded to include evaluation and management of energy systems
   infrastructure investments and not just operations.
   The author tells about the Presidential Directives that federal
   government facilities are facing to reduce energy use and invest in
   renewable fuels and uses the example of the Veteran Administration to
   expose the tremendous task of obtaining baseline and on-going
   information to try to meet the directive. Although the federal
   government is providing billions of dollars to support a `smart' grid,
   customers like the VA are left without energy information technology or
   a framework to meet their directives and must find ways to spend their
   own budgets and staff time to try to move forward.
   The author takes apart the title of the book to best expose the policy
   initiatives implied and the real commitment to not just energy, but
   resource efficiency. Key government and business policy initiatives are
   recommended for change.}},
ISBN = {{978-90-481-3320-8}},
Unique-ID = {{ISI:000270130900015}},
}

@article{ ISI:000244170000006,
Author = {Kydes, Andy S.},
Title = {{Impacts of a renewable portfolio generation standard on US energy
   markets}},
Journal = {{ENERGY POLICY}},
Year = {{2007}},
Volume = {{35}},
Number = {{2}},
Pages = {{809-814}},
Month = {{FEB}},
Abstract = {{This paper analyzes the impacts of imposing a Federal 20 percent
   non-hydropower renewable generation portfolio standard (RPS) on US
   energy markets by 2020. The US currently has no RPS requirement although
   some state RPS regulations have been adopted but not uniformly enforced
   (see http://www.eia.doe.gov/oiaf/analysispaper/rps/index.html for a
   recent summary on RPSs in the US). The renewable portfolio standard
   (RPS) requires that 20 percent of the power sold must come from
   qualifying renewable facilities. The analysis of the 20 percent RPS was
   developed by using the December 2001 version of the National Energy
   Modeling System (NEMS) of the Energy Information Administration (EIA)
   and the assumptions and results of the Annual Energy Outlook 2002
   (AEO2002) reference case. 2 A policy that requires a 20 percent
   non-hydro-electric RPS by 2020 appears to be effective in promoting the
   adoption of renewable generation technologies while also reducing
   emissions of nitrogen oxides by 6 percent, mercury by 4 percent and
   carbon dioxide by about 16.5 percent relative to the reference case in
   2020. Electricity prices are expected to rise about 3 percent while the
   cost to the electric power industry could rise between 35 and 60 billion
   dollars (in year 2000 dollars in net present value terms). (c) 2006
   Elsevier Ltd. All rights reserved.}},
DOI = {{10.1016/j.enpol.2006.03.002}},
ISSN = {{0301-4215}},
Unique-ID = {{ISI:000244170000006}},
}

@article{ ISI:000074737700004,
Author = {Moss, MC and Scholey, AB and Wesnes, K},
Title = {{Oxygen administration selectively enhances cognitive performance in
   healthy young adults: a placebo controlled double blind crossover study}},
Journal = {{PSYCHOPHARMACOLOGY}},
Year = {{1998}},
Volume = {{138}},
Number = {{1}},
Pages = {{27-33}},
Month = {{JUL}},
Abstract = {{It was recently demonstrated that oxygen administration can improve
   performance on a simple word recall task in healthy young adults. This
   study was aimed at determining the impact of various durations of oxygen
   administration on a wider range of cognitive measures. This was achieved
   using the Cognitive Drug Research computerised test battery, and
   employing a double-blind, placebo-controlled crossover design. Over a
   period of 7 weeks, 20 participants were trained and subsequently
   assessed on the test battery under several durations of oxygen
   inhalation; air administered in an identical fashion served as a
   control. The results provided support for our earlier work in that
   increases were found in both immediate and delayed word recall. In
   addition, oxygen administration significantly improved performance on
   several measures of attention and vigilance. Simple reaction time,
   choice reaction time, digit vigilance reaction time and picture
   recognition reaction time were improved in a manner which depended on
   the duration of oxygen inspired. With the exception of word recall, no
   significant improvements were found for any measure of accuracy, nor
   were word recognition, digit memory scanning, or spatial memory
   improved. These results are discussed in the context of stages of
   information processing and are consistent with the hypothesis that
   cognitive performance is ``fuel-limited{''} and can be differentially
   augmented by increasing the availability of the brain's metabolic
   resources.}},
DOI = {{10.1007/s002130050641}},
ISSN = {{0033-3158}},
ResearcherID-Numbers = {{Scholey, Andrew/C-5940-2015}},
ORCID-Numbers = {{Scholey, Andrew/0000-0003-4484-5462}},
Unique-ID = {{ISI:000074737700004}},
}

@inproceedings{ ISI:A1996BJ01E00038,
Author = {Rutchik, RH and BradsherFredrick, H},
Book-Group-Author = {{AMER STAT ASSOC}},
Title = {{Maximizing feedback to increase customer use of the energy information
   administration world wide web site}},
Booktitle = {{AMERICAN STATISTICAL ASSOCIATION - 1996 PROCEEDINGS OF THE SECTION ON
   GOVERNMENT STATISTICS}},
Year = {{1996}},
Pages = {{194-199}},
Note = {{Conference of the Section-on-Government-Statistics, at the Annual
   Meeting of the American-Statistical-Association, CHICAGO, IL, AUG 04-08,
   1996}},
Organization = {{Amer Stat Assoc, Sect Govt Stat}},
ISBN = {{1-883276-44-6}},
Unique-ID = {{ISI:A1996BJ01E00038}},
}

@article{ ISI:000335885000014,
Author = {Fenton, Tanis R. and Premji, Shahirose S. and Al-Wassia, Heidi and
   Sauve, Reg S.},
Title = {{Higher versus lower protein intake in formula-fed low birth weight
   infants}},
Journal = {{COCHRANE DATABASE OF SYSTEMATIC REVIEWS}},
Year = {{2014}},
Number = {{4}},
Abstract = {{Background
   The ideal quantity of dietary protein for formula-fed low birth weight
   infants is still amatter of debate. Protein intake must be sufficient to
   achieve normal growth without negative effects such as acidosis, uremia,
   and elevated levels of circulating amino acids.
   Objectives
   To determine whether higher (>= 3.0 g/kg/d) versus lower (< 3.0 g/kg/d)
   protein intake during the initial hospital stay of formula-fed preterm
   infants or low birth weight infants (< 2.5 kilograms) results in
   improved growth and neurodevelopmental outcomes without evidence of
   short-and long-term morbidity.
   To examine the following distinctions in protein intake.
   1. Low protein intake if the amount was less than 3.0 g/kg/d.
   2. High protein intake if the amount was equal to or greater than 3.0
   g/kg/d but less than 4.0 g/kg/d.
   3. Very high protein intake if the amount was equal to or greater than
   4.0 g/kg/d.
   If the reviewed studies combined alterations of protein and energy,
   subgroup analyses were to be carried out for the planned categories of
   protein intake according to the following predefined energy intake
   categories.
   1. Low energy intake: less than 105 kcal/kg/d.
   2. Medium energy intake: greater than or equal to 105 kcal/kg/d and less
   than or equal to 135 kcal/kg/d.
   3. High energy intake: greater than 135 kcal/kg/d. As the Ziegler-Fomon
   reference fetus estimates different protein requirements for infants
   based on birth weight, subgroup analyses were to be undertaken for the
   following birth weight categories.
   1. < 800 grams.
   2. 800 to 1199 grams.
   3. 1200 to 1799 grams.
   4. 1800 to 2499 grams.
   Search methods
   The standard search methods of the Cochrane Neonatal Review Group were
   used. MEDLINE, CINAHL, PubMed, EMBASE, and the Cochrane Central Register
   of Controlled Trials (CENTRAL; The Cochrane Library) were searched.
   Selection criteria
   Randomized controlled trials contrasting levels of formula protein
   intake as low (< 3.0 g/kg/d), high (< 3.0 g/kg/d but < 4.0 g/kg/d), or
   very high (>= 4.0 g/kg/d) in formula-fed hospitalized neonates weighing
   less than 2.5 kilograms were included. Studies were excluded if infants
   received partial parenteral nutrition during the study period or were
   fed formula as a supplement to human milk. Studies in which nutrients
   other than protein also varied were added in a post-facto analysis.
   Data collection and analysis
   The standard methods of the Cochrane Neonatal Review Group were used.
   Main results
   Five studies compared low versus high protein intake. Improved weight
   gain and higher nitrogen accretion were demonstrated in infants
   receiving formula with higher protein content while other nutrients were
   kept constant. No significant differences were seen in rates of
   necrotizing enterocolitis, sepsis, or diarrhea.
   One study compared high versus very high protein intake during and after
   an initial hospital stay. Very high protein intake promoted improved
   gain in length at term, but differences did not remain significant at 12
   weeks corrected age. Three of the 24 infants receiving very high protein
   intake developed uremia.
   A post-facto analysis revealed further improvement in all growth
   parameters in infants receiving formula with higher protein content. No
   significant difference in the concentration of plasma phenylalanine was
   noted between high and low protein intake groups. However, one study
   (Goldman 1969) documented a significantly increased incidence of low
   intelligence quotient (IQ) scores among infants of birth weight less
   than 1300 grams who received a very high protein intake (6 to 7.2 g/kg).
   Authors' conclusions
   Higher protein intake (>= 3.0 g/kg/d but < 4.0 g/kg/d) from formula
   accelerates weight gain. However, limited information is available
   regarding the impact of higher formula protein intake on long-term
   outcomes such as neurodevelopmental abnormalities. Available evidence is
   not adequate to permit specific recommendations regarding the provision
   of very high protein intake (> 4.0 g/kg/d) from formula during the
   initial hospital stay or after discharge.}},
DOI = {{10.1002/14651858.CD003959.pub3}},
Article-Number = {{CD003959}},
ISSN = {{1469-493X}},
EISSN = {{1361-6137}},
ResearcherID-Numbers = {{Al-Wassia, Heidi/C-8863-2015}},
Unique-ID = {{ISI:000335885000014}},
}

@article{ ISI:000328434000017,
Author = {Stevanov, Mirjana and Ostoic, Silvija Krajter and Vuletic, Dijana and
   Orlovic, Sasa},
Title = {{Consultation process on forest biomass and sustainable forest
   management: How knowledge mobilization in the cross-border region of
   Croatia and Serbia worked?}},
Journal = {{PERIODICUM BIOLOGORUM}},
Year = {{2013}},
Volume = {{115}},
Number = {{3}},
Pages = {{435-445}},
Month = {{SEP}},
Abstract = {{Background and purpose: The aim of the paper is to describe and analyse
   the consultation process on forest biomass and sustainable forest
   management in the context of renewable energy. Rather unique for the
   cross-border region of Croatian and Serbia the process was initiated
   within the EU project RoK-FOR {[}1] and based on a `triple helix'
   principle- taking into consideration perspectives of science,
   administration and stakeholders {[}2 in 3]. Achieved body of information
   provides insights into forest-related issues in the context of renewable
   energy in the Western Balkans.
   Materials and methods: The methods and analytical frame used for the
   purpose of this article was proposed by {[}3], focusing on: actors and
   their roles in the process; instruments and tools used in the process of
   gathering information and consultation; and assessing the level of
   interaction among actors during the consultation processes.
   Stakeholders' panel was the main instrument that generated ``body of
   information{''}, whereas structured interviews were used for better
   understanding of actors involved. For understanding administrative and
   legislative framework the whole set of documents and decisions from both
   countries was analysed while observational notes helped to critically
   reflect upon data obtained by stakeholder interviews.
   Results and conclusions: Use of stakeholders' panel as a platform for
   creating a rather robust ``body of information{''} proved to be valuable
   tool in the consultation processes, which resulted in a consensus of
   participating actors on strategic research topics and common recognition
   of major challenges related to forest biomass production and use. An
   overall level of interaction among participants can in both countries be
   classified as of a ``medium intensity{''}, although the ways of
   interaction were somewhat different. The results could serve as inputs
   to national research and/or energy strategies in context of achieving
   renewable energy goals and fulfilment of obligations according to the
   Kyoto Protocol.}},
ISSN = {{0031-5362}},
Unique-ID = {{ISI:000328434000017}},
}

@article{ ISI:000359805300001,
Author = {Omitaomu, Olufemi A. and Singh, Nagendra and Bhaduri, Budhendra L.},
Title = {{Mapping suitability areas for concentrated solar power plants using
   remote sensing data}},
Journal = {{JOURNAL OF APPLIED REMOTE SENSING}},
Year = {{2015}},
Volume = {{9}},
Month = {{JUL 27}},
Abstract = {{The political push to increase power generation from renewable sources,
   such as solar energy, requires knowing the best places to site new solar
   power plants with respect to the applicable regulatory, operational,
   engineering, environmental, and socioeconomic criteria. Therefore, we
   present applications of remote sensing data for mapping suitable areas
   for concentrated solar power (CSP) plants. Our approach uses satellite
   data from National Aeronautical and Space Administration's Global Energy
   and Water Cycle Surface Radiation Budget project at a resolution of 1
   deg for estimating global solar radiation for the study area. Then we
   develop a computational model built on a geographic information system
   (GIS) platform that divides the study area into a grid of cells and
   estimates the site suitability value for each cell by computing a list
   of metrics based on applicable site requirements using GIS data. The
   computed metrics include population density, solar energy potential,
   federal lands, and hazardous facilities. Overall, some 30 GIS datasets
   are used to compute eight metrics. The site suitability value for each
   cell is computed as an algebraic sum of all metrics for the cell with
   the assumption that all metrics have equal weight. Finally, we color
   each cell according to its suitability value. We present results for CSP
   that drives a stream turbine and parabolic mirror connected to a
   Stirling engine. (C) The Authors. Published by SPIE under a Creative
   Commons Attribution 3.0 Unported License.}},
DOI = {{10.1117/1.JRS.9.097697}},
Article-Number = {{097697}},
ISSN = {{1931-3195}},
Unique-ID = {{ISI:000359805300001}},
}

@inproceedings{ ISI:000357980300056,
Author = {Loukas, A. and Tzabiras, J. and Spiliotopoulos, M. and Kokkinos, K. and
   Fafoutis, C. and Mylopoulos, N.},
Editor = {{Hadjimitsis, DG and Themistocleous, K and Michaelides, S and Papadavid, G}},
Title = {{Development of a district information system for water management
   planning and strategic decision making}},
Booktitle = {{THIRD INTERNATIONAL CONFERENCE ON REMOTE SENSING AND GEOINFORMATION OF
   THE ENVIRONMENT (RSCY2015)}},
Series = {{Proceedings of SPIE}},
Year = {{2015}},
Volume = {{9535}},
Note = {{3rd International Conference on Remote Sensing and Geoinformation of the
   Environment (RSCy), Paphos, CYPRUS, MAR 16-19, 2015}},
Organization = {{Cyprus Univ Technol; Cyprus Remote Sensing Soc; European Space Agcy;
   Cyprus Sci \& Tech Chamber; Dept Meteorol; Minist Def; Minist Commun \&
   Works, Dept Elect Commun; Agr Res Inst; Grp Earth Observat; DLR; Hellas
   Sat; Neapolis Univ; Frederick Univ; Intergraph; GeoSystems Hellas; I
   BEC; Si Cluster; Spectra Vista Corp; Agisoft; QuestUAV; SPOLMHK; SODAP;
   Smart Events; Municipal Pafos; Municipal Geroskipou; Pegeia Municipal}},
Abstract = {{The overall objective of this work is the development of a District
   Information System (DIS) which could be used by stakeholders for the
   purposes of a district day-to-day water management as well as for
   planning and strategic decision-making The DIS was developed from a
   GIS-based modeling approach, which integrates a generic crop model and a
   hydraulic model of the transport/distribution system, using land use
   maps generated by Landsat TM imagery. The main sub-objectives are: (i)
   the development of an operational algorithm to retrieve crop
   evapotranspiration from remote sensing data, (ii) the development of an
   information system with friendly user interface for the data base, the
   crop module and the hydraulic module and (iii) the analysis and
   validation of management scenarios from model simulations predicting the
   respective behavior. The Lake Karla watershed is used in this study, but
   the overall methodology could be used as a basis for future analysis
   elsewhere. Surface Energy Balance Algorithm for Land (SEBAL) was used to
   derive monthly actual evapotranspiration (ET) values from Landsat TM
   imagery. Meteorological data from the archives of the Institute for
   Research and Technology, Thessaly (I.RE.TE.TH) has also been used. The
   methodology was developed using high quality Landsat TM images during
   2007 growing season. Monthly ET values are used as an input to CROPWAT
   model. Outputs of CROPWAT model are then used as input for WEAP model.
   The developed scenario is based on the actual situation of the surface
   irrigation network of the Local Administration of Land Reclamation
   (LALR) of Pinios for the year of 2007. The DIS is calibrated with
   observed data of this year and the district parameterization is
   conducted based on the actual operation of the network. The operation of
   the surface irrigation network of Pinios LALR is simulated using
   Technologismiki Works, while the operation of closed pipe irrigation
   network of Lake Karla LALR is simulated using Watercad.Your alternative
   scenarios have been tested with the DIS:
   .Reduction of channel losses
   .Alteration of irrigation methods
   .Introduction of greenhouse cultivation
   .Operation of the future Lake Karla network The results of the
   simulation for the historical period indicate that the water pumped from
   Pinios LALR is not enough to serve irrigation requirements. The spatial
   and temporal variation of the unmet and unsatisfied water demand has
   been estimated. Simulation of the four alternative scenarios indicated
   that the alteration of irrigation methods scenario mainly increases the
   efficiency of the irrigation network.}},
DOI = {{10.1117/12.2193892}},
Article-Number = {{95351L}},
ISSN = {{0277-786X}},
ISBN = {{978-1-62841-700-5}},
Unique-ID = {{ISI:000357980300056}},
}

@article{ ISI:000289428000003,
Author = {Subhedar, Nishikant and Barsagade, Vikas G. and Singru, Praful S. and
   Thim, Lars and Clausen, Jes Thorn},
Title = {{Cocaine- and Amphetamine-Regulated Transcript Peptide (CART) in the
   Telencephalon of the Catfish, Clarias gariepinus: Distribution and
   Response to Fasting, 2-Deoxy-D-glucose, Glucose, Insulin, and Leptin
   Treatments}},
Journal = {{JOURNAL OF COMPARATIVE NEUROLOGY}},
Year = {{2011}},
Volume = {{519}},
Number = {{7}},
Pages = {{1281-1300}},
Month = {{MAY 1}},
Abstract = {{The cocaine- and amphetamine-regulated transcript peptide
   (CART)-containing system in the forebrain of Clarias gariepinus was
   studied with immunocytochemistry. While the immunoreactivity was
   prominently seen in the neurons of the entopeduncular nucleus (EN)
   located in the ventral telencephalon, CART-immunoreactive fibers were
   widely distributed in the dorsal and ventral telencephalon. In view of
   the established role of CART in energy metabolism, we investigated the
   response of the CART immunoreactive system to positive and negative
   nutritional conditions. Neurons of the EN and fibers in the different
   areas of the telencephalon showed significant reduction in CART
   immunoreactivity following 48 hours food deprivation, or 2 hours
   following intracranial administration of 2-deoxy-D-glucose (2DG, 100
   ng/g body weight, a metabolic antagonist of glucose). However,
   intracranial injection of glucose (100 ng/g body weight) resulted in a
   distinct increase in CART immunoreactivity in these components. In
   mammals, insulin and leptin have been recognized as adiposity agents
   that convey peripheral energy status-related information to brain.
   Intracranial administration of insulin (3 mU/fish) and leptin (10 ng/g
   body weight) significantly increased CART immunoreactivity in the EN
   neurons and in the fiber network within 2 hours. Superfusion of the
   EN-containing tissue fragments in the medium enriched in glucose,
   insulin, or leptin evoked a significant increase in CART
   immunoreactivity in the EN neurons, but 2DG reduced the
   immunoreactivity. We suggest that CART-containing neurons of the EN, and
   fibers in the telencephalon, may process the energy status-related
   information and contribute to satiety. J. Comp. Neurol. 519: 1281-1300,
   2011. (C) 2010 Wiley-Liss, Inc.}},
DOI = {{10.1002/cne.22569}},
ISSN = {{0021-9967}},
Unique-ID = {{ISI:000289428000003}},
}

@article{ ISI:000275350300004,
Author = {Frei, Thomas},
Title = {{Economic and social benefits of meteorology and climatology in
   Switzerland}},
Journal = {{METEOROLOGICAL APPLICATIONS}},
Year = {{2010}},
Volume = {{17}},
Number = {{1}},
Pages = {{39-44}},
Month = {{MAR}},
Abstract = {{National Meteorological Services provide meteorological data,
   information. forecasts and various related products, which are Important
   for the smooth functioning of many aspects ill economy, administration
   and society The merit of meteorological services cannot be deduced
   directly from the consumption of services. Rattler, it emerges front the
   improvement of decisions by economic Stakeholders thanks to weather and
   climate information These services are purchased by users in order to be
   able to offer optimally of demand a certain service or. with respect to
   security, these services aim at helping to prevent damage from extreme
   events.
   A rough estimate for a number of selected sectors shows that benefits
   froth weather services in Switzerland ale in the region of hundreds of
   millions Swiss Francs (1 Swiss Franc similar to (sic) 0.66. US\$0.83 as
   at 2008)
   This pilot study shows that it is not possible to estimate ogle single
   figure representing the overall benefit from weather services in a
   country. Concerning the economic sector, a benefit analysis should
   therefore concentrate on those sub-sectors where weather services are
   particularly relevant. i.e agriculture, construction. energy, insurance,
   telecommunication. tourism, transport. logistics and water availability
   Analysis of benefits from climate data is Of particular Interest to
   MeteoSwiss since the Federal Office Is the Main source for climate data
   in Switzerland. Climate data form the basis on which climate change and
   possible climate threats call be detected.
   This Study estimates for the first lime the socio-economic benefits of
   meteorological and climatic information in Switzerland as a small
   developed European country and gives all Outlook of how it further Study
   might be. designed. Copyright (C) 2009 Royal Meteorological Society.}},
DOI = {{10.1002/met.156}},
ISSN = {{1350-4827}},
Unique-ID = {{ISI:000275350300004}},
}

@article{ ISI:000246655900009,
Author = {Polimeni, John M. and Polimeni, Raluca Iorgulescu},
Title = {{Jevons' Paradox and the myth of technological liberation}},
Journal = {{ECOLOGICAL COMPLEXITY}},
Year = {{2006}},
Volume = {{3}},
Number = {{4}},
Pages = {{344-353}},
Month = {{DEC}},
Note = {{Conference on Complexity and Ecological Economics, Liverpool, ENGLAND,
   SEP 11-14, 2005}},
Abstract = {{Natural resource consumption has increased considerably in the past 200
   years despite more efficient technology advancements. This correlation
   between increased natural resource consumption and increased efficiency
   is known as jevons' Paradox. Since all the inputs to economic production
   come from the environment, increased resource consumption and ecosystem
   destruction should be of concern. Furthermore, the expenditure of
   natural resources to provide energy and other consumer goods is an
   irreversible process, worsening the human condition instead of improving
   human welfare as neoclassical theory would have one to believe.
   Therefore, sustainable development policies need to be considered to end
   the continued excess consumption, beyond sustainable levels, of natural
   resources and the potential resulting conflicts. To design
   environmentally sustainable policies, the effect of economic activity,
   of resource utilization, and increased efficiency must be understood. In
   this paper, we attempt to illustrate how human consumption of natural
   resources alters the natural state of the economy and the environment.
   Further, using energy data from the Energy Information Administration we
   develop models that provide some empirical support that jevons' Paradox
   may exist on a macro level. Finally, we examine the resulting policy
   implications and the applications for an ecological economic approach.
   (c) 2007 Elsevier B.V. All rights reserved.}},
DOI = {{10.1016/j.ecocom.2007.02.008}},
ISSN = {{1476-945X}},
Unique-ID = {{ISI:000246655900009}},
}

@article{ ISI:000234668300015,
Author = {Van den Oever, MC and Spijker, S and Li, KW and Jimenez, CR and Koya, E
   and Van der Schors, RC and Gouwenberg, Y and Binnekade, R and De Vries,
   TJ and Schoffelmeer, ANM and Smit, AB},
Title = {{A proteomics approach to identify long-term molecular changes in rat
   medial prefrontal cortex resulting from sucrose self-administration}},
Journal = {{JOURNAL OF PROTEOME RESEARCH}},
Year = {{2006}},
Volume = {{5}},
Number = {{1}},
Pages = {{147-154}},
Month = {{JAN}},
Abstract = {{The medial prefrontal cortex (mPFC) is involved in the processing and
   retrieval of reward-related information. Here, we investigated
   long-lasting changes in protein composition of the mPFC in rats with a
   history of sucrose self-administration. Protein levels were analyzed
   using 2-D PAGE and MALDI-TOF sequencing. From similar to 1500 spots, 28
   regulated proteins were unambiguously identified and were involved in
   cytoskeleton organization, energy metabolism, oxidative stress,
   neurotransmission, and neuronal outgrowth and differentiation. For
   several proteins, this change was also found as a long-lasting
   alteration in gene expression. We show that self-administration of
   sucrose produces long-lasting molecular neuroadaptations in the mPFC
   that may be involved in reward-related information processing.}},
DOI = {{10.1021/pr-050303y}},
ISSN = {{1535-3893}},
EISSN = {{1535-3907}},
ResearcherID-Numbers = {{Smit, August /E-8410-2011
   Spijker, Sabine/F-2300-2011
   De Vries, Taco/B-2831-2014
   van den Oever, Michel/A-2180-2015
   De Vries, Taco/}},
ORCID-Numbers = {{van den Oever, Michel/0000-0001-5523-8612
   De Vries, Taco/0000-0002-0340-4946}},
Unique-ID = {{ISI:000234668300015}},
}

@article{ ISI:000222462700017,
Author = {Harmer, CJ and Shelley, NC and Cowen, PJ and Goodwin, GM},
Title = {{Increased positive versus negative affective perception and memory in
   healthy volunteers following selective serotonin and norepinephrine
   reuptake inhibition}},
Journal = {{AMERICAN JOURNAL OF PSYCHIATRY}},
Year = {{2004}},
Volume = {{161}},
Number = {{7}},
Pages = {{1256-1263}},
Month = {{JUL}},
Abstract = {{Objective: Antidepressants that inhibit the reuptake of serotonin
   (SSRIs) or norepinephrine (SNRIs) are effective in the treatment of
   disorders such as depression and anxiety. Cognitive psychological
   theories emphasize the importance of correcting negative biases of
   information processing in the nonpharmacological treatment of these
   disorders, but it is not known whether antidepressant drugs can directly
   modulate the neural processing of affective information. The present
   study therefore assessed the actions of repeated antidepressant
   administration on perception and memory for positive and negative
   emotional information in healthy volunteers.
   Method: Forty-two male and female volunteers were randomly assigned to 7
   days of double-blind intervention with the SSRI citalopram (20 mg/day),
   the SNRI reboxetine (8 mg/day), or placebo. On the final day, facial
   expression recognition, emotion-potentiated startle response, and memory
   for affect-laden words were assessed. Questionnaires monitoring mood,
   hostility, and anxiety were given before and after treatment.
   Results: In the facial expression recognition task, citalopram and
   reboxetine reduced the identification of the negative facial expressions
   of anger and fear. Citalopram also abolished the increased startle
   response found in the context of negative affective images. Both
   antidepressants increased the relative recall of positive (versus
   negative) emotional material. These changes in emotional processing
   occurred in the absence of significant differences in ratings of mood
   and anxiety. However, reboxetine decreased subjective ratings of
   hostility and elevated energy.
   Conclusions: Short-term administration of two different antidepressant
   types had similar effects on emotion-related tasks in healthy
   volunteers, reducing the processing of negative relative to positive
   emotional material. Such effects of antidepressants may ameliorate the
   negative biases in information processing that characterize mood and
   anxiety disorders. They also suggest a mechanism of action potentially
   compatible with cognitive theories of anxiety and depression.}},
DOI = {{10.1176/appi.ajp.161.7.1256}},
ISSN = {{0002-953X}},
Unique-ID = {{ISI:000222462700017}},
}

@article{ ISI:000188202500003,
Author = {Linn, SC and Zhu, Z},
Title = {{Natural gas prices and the gas storage report: Public news and
   volatility in energy futures markets}},
Journal = {{JOURNAL OF FUTURES MARKETS}},
Year = {{2004}},
Volume = {{24}},
Number = {{3}},
Pages = {{283-313}},
Month = {{MAR}},
Abstract = {{This study examines the short-term volatility of natural gas prices
   through an examination of the intraday prices of the nearby natural gas
   futures contract traded on the New York Mercantile Exchange. The
   influence on volatility of what many regard as a key element of the
   information set influencing the natural gas market is investigated.
   Specifically, we examine the impact on natural gas futures price
   volatility of the Weekly American Gas Storage Survey report compiled and
   issued by the American Gas Association during the period January 1, 1999
   through May 3, 2002 and the subsequent weekly report compiled and issued
   by the U.S. Energy Information Administration after May 6, 2002. We find
   that the weekly gas storage report announcement was responsible for
   considerable volatility at the time of its release and that volatility
   up to 30 minutes following the announcement was also higher than normal.
   Aside from these results, we document pronounced price volatility in
   this market both at the beginning of the day and at the end of the day
   and offer explanations for such behavior. Our results are robust to the
   manner in which the mean percentage change in the futures price is
   estimated and to correlation of these changes both within the day and
   across days. (C) 2004 Wiley Periodicals, Inc.}},
DOI = {{10.1002/fut.10115}},
ISSN = {{0270-7314}},
Unique-ID = {{ISI:000188202500003}},
}

@article{ ISI:000356393000001,
Author = {Chalmeh, Aliasghar and Pourjafar, Mehrdad and Nazifi, Saeed and
   Momenifar, Foroogh and Mohamadi, Mahboobeh},
Title = {{Insulin Resistance in Different Physiological States of High Producing
   Holstein Dairy Cows}},
Journal = {{ACTA SCIENTIAE VETERINARIAE}},
Year = {{2015}},
Volume = {{43}},
Month = {{FEB 6}},
Abstract = {{Background: Alterations in energy demands during different physiological
   states of dairy cows predispose them to metabolic disorders. Insulin as
   a main metabolic hormone has a key role to maintain homeorhesis in dairy
   cows. Insulin resistance phenomenon can expose these animals to
   metabolic dysfunctions. Information regarding insulin resistance at each
   physiological state of high producing dairy cows can assist
   veterinarians to control and prevent the metabolic disorders at herd
   levels.
   Materials, Methods \& Results: This research was carried out at winter
   2014 on 25 multiparous Holstein dairy cows from a high producing
   industrial dairy farm. The total mixed rations were formulated and
   prepared for all animals according to National Research Council (NRC)
   requirements. At this farm, a dry period of 60 days has been considered.
   Milk production was about 10,000 kg for year, an average of 3.6 of milk
   fat \%, and 3.3 of milk protein \%. All the animals were clinically
   healthy and body condition score (BCS) was estimated based on 0 to 5
   system. Cattle were divided into 5 equal groups containing early, mid
   and late lactations, far-off and close-up dry periods. A blood sample
   was taken immediately after catheterization, and dextrose 50\% was
   administered at 500 mg/kg, 10 mL/kg/h, subsequently. Blood samples were
   collected from all cows through the fixed catheter prior to and 1, 2, 3
   and 4 h after dextrose 50\% infusion in plain tubes. After sera
   separation, glucose and insulin were detected in all samples.
   Significant and rapid elevation of serum glucose and insulin
   concentrations were seen in all studied animals at 1st h after dextrose
   administration (P < 0.05). Decreasing the glucose level near to base
   line levels was seen at h 4 in late lactation and far-off dry cows. The
   glucose level at this time was remained significantly higher than h zero
   in other groups (P < 0.05). In early, mid and late lactation and
   close-up dry cows, insulin levels at h 4 were remained significantly
   higher than base line values (P < 0.05).
   Discussion: Cows during the early far-off dry period are experiencing
   relatively low metabolic demands as fetal growth is just beginning to
   accelerate and cows are no longer lactating. Fetal and uterine tissues
   are insulin-independent and so as energy demands increase with days of
   pregnancy, maternal peripheral tissues will become more insulin
   resistant in order to support fetal growth. These changes in the role of
   insulin have effects on energy metabolism in dry cows. Although pregnant
   dairy cows had essentially the same basal insulin levels as the
   lactating and non-pregnant non-lactating dairy cows, the amount of
   insulin secreted during infusion of glucose or propionate was higher in
   pregnant cows than in the lactating and non-pregnant non-lactating cows.
   The significant increasing patterns of insulin and glucose were seen
   after dextrose infusion in early lactation dairy cows ( P < 0.05). In
   the mid-lactation group the glucose at 4th h was significantly remained
   at higher levels than base line values. These findings indicate the
   presence of insulin resistance in early and mid lactation dairy cows. It
   was reported that insulin clearance rates had a tendency to decrease
   during the postpartum period. The reduced clearance of glucose observed
   at post partum was due to a greater degree of insulin resistance which
   gave rise to more pronounced net lipolysis from the adipocytes. These
   qualitative changes in metabolism occurring during lactation are
   necessary to support a homeostatic state. Despite the presence of high
   concentrations of insulin, high levels of glucose were seen in early and
   mid-lactation and close-up dry cows. The insulin resistance was found in
   early and mid lactation and close-up dry cows. It could be concluded
   that high energy demands to lactogenesis and suffering from the negative
   energy balance are the main reasons of insulin resistance in high
   producing Holstein dairy cows.}},
Article-Number = {{1255}},
ISSN = {{1678-0345}},
EISSN = {{1679-9216}},
Unique-ID = {{ISI:000356393000001}},
}

@article{ ISI:000330257800011,
Author = {Piro, G. and Cianci, I. and Grieco, L. A. and Boggia, G. and Camarda, P.},
Title = {{Information centric services in Smart Cities}},
Journal = {{JOURNAL OF SYSTEMS AND SOFTWARE}},
Year = {{2014}},
Volume = {{88}},
Pages = {{169-188}},
Month = {{FEB}},
Abstract = {{A ``Smart City{''} is intended as an urban environment which, supported
   by pervasive ICT systems, is able to offer advanced and innovative
   services to citizens in order to improve the overall quality of their
   life. In this context, the present contribution formulates a pioneering
   proposal, by drawing an advanced information centric platform for
   supporting the typical ICT services of a Smart City. It can easily
   embrace all available and upcoming wireless technologies, while
   enforcing, at the same time, ubiquitous and secure applications in many
   domains, such as, e-government and public administration, intelligent
   transportation systems, public safety, social, health-care, educational,
   building and urban planning, environmental, and energy and water
   management applications. All the details of the proposed approach have
   been carefully described by means of pragmatical use-cases, such as the
   management of administrative procedures, the starting of a new business
   in a given country, the navigation assistance, the signaling of an urban
   accident aimed at improving the public safety, the reservation of a
   medical examination, the remote assistance of patients, and the
   management of waste in a city. This description makes evident the real
   effectiveness of the present proposal in future urban environments. (C)
   2013 Elsevier Inc. All rights reserved.}},
DOI = {{10.1016/j.jss.2013.10.029}},
ISSN = {{0164-1212}},
EISSN = {{1873-1228}},
ORCID-Numbers = {{Piro, Giuseppe/0000-0003-3783-5565}},
Unique-ID = {{ISI:000330257800011}},
}

@article{ ISI:000310006200021,
Author = {Arifin, Darwin and Aston, Victoria J. and Liang, Xinhua and McDaniel,
   Anthony H. and Weimer, Alan W.},
Title = {{CoFe2O4 on a porous Al2O3 nanostructure for solar thermochemical CO2
   splitting}},
Journal = {{ENERGY \& ENVIRONMENTAL SCIENCE}},
Year = {{2012}},
Volume = {{5}},
Number = {{11}},
Pages = {{9438-9443}},
Month = {{NOV}},
Abstract = {{Projected growth in global population and continued industrialization of
   developing countries will increase total world energy consumption by
   50\% between 2008 and 2035 (U.S. Energy Information Administration
   (EIA), International Energy Outlook, DOE/EIA-0484(2011) (Washington, DC,
   September 2011)). This demand for energy will be largely met by burning
   more fossil fuels, thereby increasing anthropogenic carbon in the
   atmosphere and further fuelling geopolitical conflicts over control of
   dwindling energy resources. Recycling CO2 by splitting it in a
   solar-based thermo-chemical process is an attractive solution to both of
   these 21st century problems. In this communication, we examine a novel
   chemistry for a two-step, non-volatile metal oxide CO2 splitting cycle
   that shuttles iron oxidation states (Fe2+/3+) between CoFe2O4 and
   FeAl2O4 spinel compounds within a nano-engineered material. This
   chemistry is dramatically different than current metal oxide cycles that
   exploit oxygen non-stoichiometry in ceria or solid solution behaviour in
   ferrites. The engineered material was prepared using atomic layer
   deposition and maintained structural integrity over 6 heating cycles
   under conditions that mimic a concentrated solar power application,
   namely an oxidation temperature of 1000 degrees C, reduction at 1460
   degrees C, and a heating rate of 16 degrees C s(-1) from low to high
   temperature. Oxygen uptake and release behaviour was similar to that of
   ceria. Raman spectroscopy was used to verify cycle chemistry.}},
DOI = {{10.1039/c2ee22090c}},
ISSN = {{1754-5692}},
Unique-ID = {{ISI:000310006200021}},
}

@article{ ISI:000298674700013,
Author = {Hultman, Nathan and Rebois, Dylan and Scholten, Michael and Ramig,
   Christopher},
Title = {{The greenhouse impact of unconventional gas for electricity generation}},
Journal = {{ENVIRONMENTAL RESEARCH LETTERS}},
Year = {{2011}},
Volume = {{6}},
Number = {{4}},
Month = {{OCT-DEC}},
Abstract = {{New techniques to extract natural gas from unconventional resources have
   become economically competitive over the past several years, leading to
   a rapid and largely unanticipated expansion in natural gas production.
   The US Energy Information Administration projects that unconventional
   gas will supply nearly half of US gas production by 2035. In addition,
   by significantly expanding and diversifying the gas supply
   internationally, the exploitation of new unconventional gas resources
   has the potential to reshape energy policy at national and international
   levels-altering geopolitics and energy security, recasting the economics
   of energy technology investment decisions, and shifting trends in
   greenhouse gas (GHG) emissions. In anticipation of this expansion, one
   of the perceived core advantages of unconventional gas-its relatively
   moderate GHG impact compared to coal-has recently come under scrutiny.
   In this paper, we compare the GHG footprints of conventional natural
   gas, unconventional natural gas (i.e. shale gas that has been produced
   using the process of hydraulic fracturing, or `fracking'), and coal in a
   transparent and consistent way, focusing primarily on the electricity
   generation sector. We show that for electricity generation the GHG
   impacts of shale gas are 11\% higher than those of conventional gas, and
   only 56\% that of coal for standard assumptions.}},
DOI = {{10.1088/1748-9326/6/4/044008}},
Article-Number = {{044008}},
ISSN = {{1748-9326}},
Unique-ID = {{ISI:000298674700013}},
}

@article{ ISI:000274500000009,
Author = {Morrow, W. Ross and Gallagher, Kelly Sims and Collantes, Gustavo and
   Lee, Henry},
Title = {{Analysis of policies to reduce oil consumption and greenhouse-gas
   emissions from the US transportation sector}},
Journal = {{ENERGY POLICY}},
Year = {{2010}},
Volume = {{38}},
Number = {{3}},
Pages = {{1305-1320}},
Month = {{MAR}},
Abstract = {{Even as the US debates an economy-wide CO(2) cap-and-trade policy the
   transportation sector remains a significant oil security and climate
   change concern. Transportation alone consumes the majority of the Us's
   imported oil and produces a third of total US Greenhouse-Gas (GHG)
   emissions. This study examines different sector-specific policy
   scenarios for reducing GHG emissions and oil consumption in the US
   transportation sector under economy-wide CO(2) prices. The 2009 version
   of the Energy Information Administration's (EIA) National Energy
   Modeling System (NEMS), a general equilibrium model of US energy
   markets, enables quantitative estimates of the impact of economy-wide
   CO(2) prices and various transportation-specific policy options. We
   analyze fuel taxes, continued increases in fuel economy standards, and
   purchase tax credits for new vehicle purchases, as well as the impacts
   of combining these policies. All policy scenarios modeled fail to meet
   the Obama administration's goal of reducing GHG emissions 14\% below
   2005 levels by 2020. Purchase tax credits are expensive and ineffective
   at reducing emissions, while the largest reductions in GHG emissions
   result from increasing the cost of driving, thereby damping growth in
   vehicle miles traveled. (C) 2009 Elsevier Ltd. All rights reserved.}},
DOI = {{10.1016/j.enpol.2009.11.006}},
ISSN = {{0301-4215}},
ResearcherID-Numbers = {{Morrow, William/K-8489-2012}},
Unique-ID = {{ISI:000274500000009}},
}

@inproceedings{ ISI:000303172600028,
Author = {Zivic, Natasa and Ruland, Christoph},
Editor = {{Cellary, W and Estevez, E}},
Title = {{Security Architecture of Smart Metering Systems}},
Booktitle = {{SOFTWARE SERVICES FOR E-WORLD}},
Series = {{IFIP Advances in Information and Communication Technology}},
Year = {{2010}},
Volume = {{341}},
Pages = {{249-259}},
Note = {{10th IFIP WG 6 11 Conference on e-Business, e-Services, and e-Society,
   I3E 2010, Buenos Aires, ARGENTINA, NOV 03-05, 2010}},
Organization = {{Natl Ind Promot Agcy; IDRC CRDI; Agencia}},
Abstract = {{The main goals of smart metering are the reduction of costs, energy and
   CO2 by the provision of actual metering information to the providers and
   the customer. They allow for flexible possibilities to influence the
   customers' energy consumption behavior and to adapt dynamically the
   power generation and distribution to the requested energy by smart
   grids. Metering devices are under control of governmental organizations,
   which are responsible for the permanent correct delivery of metering
   data. The governmental organizations accept online metering,
   administration and even software download of regulated software only, if
   strong, lawful security requirements are fulfilled. This paper describes
   such a security system. It considers not only the security mechanisms of
   the metering devices, but also of the complete system hierarchy, which
   is planned for the communication system of smart metering. It supports
   also new use cases, which are caused by the liberalization of the energy
   and metering services markets.}},
ISSN = {{1868-4238}},
ISBN = {{978-3-642-16282-4}},
Unique-ID = {{ISI:000303172600028}},
}

@article{ ISI:000226935700012,
Author = {Gonzalez-Diaz, H and Aguero, G and Cabrera, MA and Molina, R and
   Santana, L and Uriarte, E and Delogu, G and Castanedo, N},
Title = {{Unified Markov thermodynamics based on stochastic forms to classify
   drugs considering molecular structure, partition system, and biological
   species: distribution of the antimicrobial G1 on rat tissues}},
Journal = {{BIOORGANIC \& MEDICINAL CHEMISTRY LETTERS}},
Year = {{2005}},
Volume = {{15}},
Number = {{3}},
Pages = {{551-557}},
Month = {{FEB 1}},
Abstract = {{To date, molecular descriptors do not commonly account for important
   information beyond chemical structure. The present work, attempts to
   extend, in this sense, the stochastic molecular descriptors
   (Gonzalez-Diaz, H. et al., J. Mol. Mod. 2002 8 237), incorporating
   information about the specific biphasic partition system, the biological
   species, and chemical structure inside the molecular descriptors.
   Consequently, MARCH-INSIDE molecular descriptors may be identified with
   time-dependent thermodynamic parameters (entropy and mean free energy)
   of partition process. A classification function was developed to
   classify data of 423 drugs and up to 14 different partition systems at
   the same time. The model has shown a high overall accuracy of 92.1\%
   (293 out of 318 cases) in training series and 90\% (36 out of 40 cases)
   in predicting ones. Finally, we illustrate the use of the model by
   predicting a high probability (\%) for G1 (a novel antibacterial drug)
   to undergo partition on different biotic systems (rat organs): liver
   (97.7), spleen (97.5), lung (97.4), and adipose tissue (97.6). These
   theoretical results coincide with herein reported steady state plasma
   concentrations (c) and partition coefficients (P) in liver (c = 42.25
   +/- 7.86/P = 4.75), spleen (11.47 +/- 4.43/P = 1.29), lung (17.04 +/-
   3.58/P = 1.91), and adipose tissue (28.19 +/- 11.82/P = 3.17). All
   values were relative to C-14-labeled-radioactive-G I in plasma (c = 8.9
   +/- 3.05) after 3 h of oral administration. In closing, the present
   stochastic forms derive average thermodynamic parameters fitting on a
   more clearly physicochemical framework with respect to classic
   vector-matrix-vector forms, which include, as particular cases,
   quadratic forms such as Wiener index, Randic invariants, Zagreb
   descriptors, Harary index, Balaban index, and Marrero-Ponce quadratic
   molecular indices. (C) 2004 Elsevier Ltd. All rights reserved.}},
DOI = {{10.1016/j.bmcl.2004.11.059}},
ISSN = {{0960-894X}},
ResearcherID-Numbers = {{Uriarte, Eugenio/F-5691-2012
   Santana , Lourdes /L-2981-2014
   Cabrera-Perez, Miguel Angel/H-2683-2015
   Gonzalez-Diaz, Humberto/A-6785-2012}},
ORCID-Numbers = {{Uriarte, Eugenio/0000-0001-6218-2899
   Santana , Lourdes /0000-0001-6056-8253
   Cabrera-Perez, Miguel Angel/0000-0001-5897-2230
   Gonzalez-Diaz, Humberto/0000-0002-9392-2797}},
Unique-ID = {{ISI:000226935700012}},
}

@article{ ISI:000185193400015,
Author = {Nygren, J and Thorell, A and Ljungqvist, O},
Title = {{New developments facilitating nutritional intake after gastrointestinal
   surgery}},
Journal = {{CURRENT OPINION IN CLINICAL NUTRITION AND METABOLIC CARE}},
Year = {{2003}},
Volume = {{6}},
Number = {{5}},
Pages = {{593-597}},
Month = {{SEP}},
Abstract = {{Purpose of review Conventional perioperative care includes a period of
   semistarvation before bowel function returns and adequate oral intake is
   allowed. It has been clearly shown that there is no need for restriction
   in oral intake after, at least lower, gastrointestinal surgery, and that
   early oral feeding does not increase the risk for dehiscense of the
   anastomosis. In contrast, early feeding reduces postoperative
   complications. Even if early oral intake is allowed, however, it is
   common that side effects such as nausea and vomiting prevent patients
   from reaching the target energy intakes. Thus, developing routines and
   treatments that promote sufficient early oral intake after surgery and
   maintain adequate energy intake in the postoperative period are probably
   of great importance for the outcome from surgery.
   Recent findings There are a number of factors which may facilitate early
   oral intake after gastrointestinal surgery including effective pain
   relief using epidural anaesthesia while avoiding opioids, minimizing
   sodium and fluid administration perioperatively and substantially
   reducing preoperative fasting. In addition, sufficient preoperative
   information, intensive mobilization, energy-dense hospital food and oral
   supplements may all contribute to improved energy intake after surgery.
   Summary In general, there is a great need for randomized controlled
   trials examining factors important for the regulation of oral intake
   after surgery and also the effects of early oral intake after upper
   gastrointestinal surgery. Future areas of research may also include
   regulation of appetite and use of peripherally acting opioid
   antagonists.}},
DOI = {{10.1097/01.mco.000087975.83880.1d}},
ISSN = {{1363-1950}},
Unique-ID = {{ISI:000185193400015}},
}

@article{ ISI:000333487300008,
Author = {Chiou-Wei, Song-Zan and Linn, Scott C. and Zhu, Zhen},
Title = {{The response of US natural gas futures and spot prices to storage change
   surprises: Fundamental information and the effect of escalating physical
   gas production}},
Journal = {{JOURNAL OF INTERNATIONAL MONEY AND FINANCE}},
Year = {{2014}},
Volume = {{42}},
Number = {{SI}},
Pages = {{156-173}},
Month = {{APR}},
Abstract = {{We study the behavior of U.S. natural gas futures and spot prices on and
   around the weekly announcements by the U.S. Energy Information
   Administration of the amount of natural gas in storage. We identify an
   inverse empirical relation between changes in futures prices and
   surprises in the change in natural gas in storage and that this relation
   is not driven by the absolute size of the surprise. The evidence also
   indicates prices react first in the futures market for natural gas with
   that information then flowing to the spot market. Post 2005,
   corresponding to a period of significant increases in the production of
   natural gas in the United States, the response of prices to storage
   surprises was larger in absolute value. No evidence is found of
   economically meaningful reactions to the surprise other than on the date
   the storage news is released. The results demonstrate the importance of
   fundamental information in the formation of natural gas prices. (C) 2013
   Elsevier Ltd. All rights reserved.}},
DOI = {{10.1016/j.jimonfin.2013.08.009}},
ISSN = {{0261-5606}},
EISSN = {{1873-0639}},
Unique-ID = {{ISI:000333487300008}},
}

@article{ ISI:000328095000050,
Author = {Ray, Charles D. and Ma, Li and Wilson, Thomas and Wilson, Daniel and
   McCreery, Lew and Wiedenbeck, Janice K.},
Title = {{Biomass boiler conversion potential in the eastern United States}},
Journal = {{RENEWABLE ENERGY}},
Year = {{2014}},
Volume = {{62}},
Pages = {{439-453}},
Month = {{FEB}},
Abstract = {{The U.S. is the world's leading consumer of primary energy. A large
   fraction of this energy is used in boiler installations to generate
   steam and hot water for heating applications. It is estimated there are
   total 163,000 industrial and commercial boilers in use in the United
   States of all sizes.
   This paper characterizes the commercial and industrial boilers in the 37
   states of the Midwest, Northeast, and Southern regions of the U.S. in
   term of number of units, unit capacity, aggregate capacity, and fuel
   type. A methodology is developed for evaluating and ranking the
   potential for converting from existing fossil-fuel boilers to biomass
   boilers in these states.
   In total, 3495 oil and coal boiler units in industrial and commercial
   buildings, and 1067 major wood energy facilities in the 37 eastern
   states were identified. These represent a subset of existing and
   potential conversions from fossil fuels to woody biomass. Based on this
   sample and energy consumption data from the Energy Information
   Administration (EIA), we estimate that there are currently 31,776 oil,
   coal, and propane boiler units over 0.5 MMBtus/hour capacity in these 37
   states, representing a total energy consumption of 1.7 quadrillion Btus,
   or roughly the equivalent of 287 million barrels of oil. Were these
   units all converted to woody biomass fuel, they would consume a total of
   121 million dry tons of wood per year, about three times the most recent
   US DOE estimates of woody biomass availability in those regions. Since
   only the most economical conversions typically occur, the reality of
   woody biomass market availability combined with thermal fossil-fuel
   consumption patterns suggests that roughly one-third of all potential
   projects could be achieved under sustainable utilization of existing
   biomass feedstocks in the three regions.
   Analysis of the results indicates that a targeted response to
   wood-conversion initiatives will yield the most successful program of
   fossil-fuel replacement in thermal applications. A ranking index
   developed in this study through analysis of existing boiler
   installations and availability of wood feedstocks suggests that the top
   ten states in the eastern United States on which to focus future
   messaging, feasibility studies, and policy development for potential
   woody biomass conversions are:
   1. Maine, 2. Texas, 3. New York, 4. Florida, 5. Georgia, 6. Alabama, 7.
   South Carolina, 8. North Carolina, 9. Arkansas, 10. Pennsylvania. (C)
   2013 Elsevier Ltd. All rights reserved.}},
DOI = {{10.1016/j.renene.2013.07.019}},
ISSN = {{0960-1481}},
Unique-ID = {{ISI:000328095000050}},
}

@inproceedings{ ISI:000353637100063,
Author = {Roscia, Mariacristina and Longo, Michela and Lazaroiu, George Cristian},
Book-Group-Author = {{IEEE}},
Title = {{Smart City By Multi-Agent Systems}},
Booktitle = {{2013 INTERNATIONAL CONFERENCE ON RENEWABLE ENERGY RESEARCH AND
   APPLICATIONS (ICRERA)}},
Series = {{International Conference on Renewable Energy Research and Applications}},
Year = {{2013}},
Pages = {{371-376}},
Note = {{International Conference on Renewable Energy Research and Applications
   (ICRERA), Madrid, SPAIN, OCT 20-23, 2013}},
Organization = {{Int Journal Renewable Energy Res; Comillas Pontif Univ; IEEE; IEEE Power
   Elect Soc; IEEE Ind Applicat Soc; IBERDROLA; KBSoftware; Asociac
   Ingenieros ICAI; IEEE Secc Espana; IEEE Spanish Power Elect Ind Elect
   Joint Chapter; Univ Deusto; iMS; bime; Fraunhofer; INESCTEC; Aalborg
   Univ; CARTIF; EiC; European Commiss \& Inst Elect Informat \& Commun
   Engineers Japan; Natl Assoc Spanish ICAI Engineers}},
Abstract = {{The current economic crisis, combined with growing citizen expectations,
   is placing increasing pressure on European cities to provide better and
   more efficient infrastructures and services, often for less cost. This
   trend has contributed to the growing popularity and use of the term
   `Smart City' {[}1]. The Smart City, represent a new way of thinking
   about urban space by shaping a model that integrates Green Energy
   Sources and Systems (GESSs), energy efficiency, sustainable mobility,
   protection of the environment and economic sustainability, that
   represent the goals for future developments. Smart cities are made by a
   high level of Information and Communication Technology-ICT-structures
   able to transmit energy, information flows multidirectional and connect
   a different sector that include mobility, energy, social, economy. Into
   Smart Cities transport systems are sustainable, smart grids are enhanced
   to ensure greater integration capabilities of production plants from
   renewable sources, public lighting is efficient, the buildings are
   equipped with sensors and devices aimed at rationalizing consumption
   energy and create greater awareness on the part of citizens, with the
   aim of improving the quality of life of people through a new governance
   of public administration capable of managing this innovation and
   cultural change. However, while wishing the transformation of cities in
   smart systems, have not defined models infrastructure, that allow
   different subsets to communicate and interact, in order to make the
   concrete realization of a smart city. The objective of this paper is to
   discuss a model of Smart City with a multi-agent systems and Internet of
   things, that provides intelligence to a city, as basic infrastructure
   for a definition of a model repeatable and exportable, so as advocated
   by the European Community, that is allocating considerable funds
   (Horizon 2020) for the creation of Smart City.}},
ISSN = {{2377-6897}},
ISBN = {{978-1-4799-1464-7}},
ResearcherID-Numbers = {{Lazaroiu, George Cristian/A-8153-2012
   Longo, Michela/}},
ORCID-Numbers = {{Lazaroiu, George Cristian/0000-0002-6749-5891
   Longo, Michela/0000-0002-3780-4980}},
Unique-ID = {{ISI:000353637100063}},
}

@article{ ISI:000299644400002,
Author = {Lent, Janice},
Title = {{Estimating an energy consumer price index from establishment survey data}},
Journal = {{MONTHLY LABOR REVIEW}},
Year = {{2011}},
Volume = {{134}},
Number = {{12}},
Pages = {{13-28}},
Month = {{DEC}},
Abstract = {{Residential price and consumption estimates from the Energy Information
   Administration's establishment surveys can be used to estimate a
   consumer price index for energy at national and State levels; at the
   national level, the index is comparable to the energy component of the
   BLS Chained CPI and is more timely}},
ISSN = {{0098-1818}},
Unique-ID = {{ISI:000299644400002}},
}

@inproceedings{ ISI:000317042600036,
Author = {Baba, J. S. and Bale, B. A. and Allegood, M. S.},
Book-Group-Author = {{IEEE}},
Title = {{Development of Radionuclide Based Instrumentation for the Quantitative
   Study of Plant Physiology}},
Booktitle = {{2011 FUTURE OF INSTRUMENTATION INTERNATIONAL WORKSHOP (FIIW)}},
Year = {{2011}},
Note = {{Future of Instrumentation International Workshop (FIIW), Oak Ridge Natl
   Lab, Oak Ridge, TN, NOV 07-08, 2011}},
Organization = {{IEEE; ISA}},
Abstract = {{Renewable biofuels are primary research targets as sources for
   sustainable, net-zero-carbon, alternative energy. In this vein, we are
   developing an imaging device for whole plant measurement of vascular and
   metabolic processes. It will provide new information geared towards
   increasing the output of biofuels and the resilience of plant feedstock.
   Single Photon Emission Computer Tomography (SPECT) is a commonly used
   medical imaging technique capable of creating three dimensional images
   as well as time-lapsed, four dimensional images. SPECT relies upon the
   administration of radionuclides that emit photons at discrete energies.
   Establishing uptake and detectable emission threshold levels of
   delivered activity to a SPECT imaging subject is essential for
   successful quantitative studies. We present application of radionuclide
   based uptake and decay measurement of the commonly used medical isotope,
   Tc-99m, to the quantitative study of Populus deltoids physiology for the
   purposes of developing this species as a lignocellulose based biofuel
   feedstock.}},
ISBN = {{978-1-4673-5835-4}},
Unique-ID = {{ISI:000317042600036}},
}

@article{ ISI:000263403900003,
Author = {Bilgili, M. and Sahin, B.},
Title = {{Investigation of Wind Energy Density in the Southern and Southwestern
   Region of Turkey}},
Journal = {{JOURNAL OF ENERGY ENGINEERING-ASCE}},
Year = {{2009}},
Volume = {{135}},
Number = {{1}},
Pages = {{12-20}},
Month = {{MAR}},
Abstract = {{In this study, wind energy density in the southern and southwestern
   region of Turkey was investigated by using the Weibull and Rayleigh
   probability density functions, and the wind atlas analysis and
   application program (WAsP). Hourly wind speeds and directions collected
   by the General Directorate of Electrical Power Resources Survey
   Administration were used. Before the construction of the wind turbine
   generator in these locations, several fundamental properties of the site
   such as wind behavior, availability, continuity, and probability should
   be carried out in order to provide the necessary information to the
   potential investors about cost and economical aspects of planning the
   wind energy project. The dominant wind direction, probability
   distribution, Weibull parameters, mean wind speed and power potential of
   all stations were determined by the Weibull and Rayleigh models, and the
   WAsP program. The results obtained with these models were compared with
   the measured data. Finally, it is found that these regions have a
   reasonable wind power potential and they are suitable for planting wind
   energy turbines. However, Belen is the most promising and convenient
   site for production of electricity from wind power.}},
DOI = {{10.1061/(ASCE)0733-9402(2009)135:1(12)}},
ISSN = {{0733-9402}},
Unique-ID = {{ISI:000263403900003}},
}

@article{ ISI:000240200700029,
Author = {Silvestri, Elena and Moreno, Maria and Schiavo, Luigi and de lange,
   Pieter and Lombardi, Assunta and Chambery, Angela and Parente, Augusto
   and Lanni, Antonia and Goglia, Fernando},
Title = {{A proteomics approach to identify protein expression changes in rat
   liver following administration of 3,5,3'-Triiodo-(L)-thyronine}},
Journal = {{JOURNAL OF PROTEOME RESEARCH}},
Year = {{2006}},
Volume = {{5}},
Number = {{9}},
Pages = {{2317-2327}},
Month = {{SEP 1}},
Abstract = {{We analyzed whole cell protein content of rat liver following T3
   administration. Fourteen differentially expressed proteins were
   unambiguously identified and were involved in substrates and lipid
   metabolism, energy metabolism, detoxification of cytotoxic products,
   calcium homeostasis, amino acid catabolism, and the urea cycle. This
   study represents the first systematic identification of T3-induced
   changes in liver protein expression profile and provides novel
   information at the molecular, cellular, and tissue level of T3 action.}},
DOI = {{10.1021/pr0601411}},
ISSN = {{1535-3893}},
ORCID-Numbers = {{GOGLIA, Fernando/0000-0003-0468-9645
   Chambery, Angela/0000-0002-5136-0941}},
Unique-ID = {{ISI:000240200700029}},
}

@article{ ISI:000237430000010,
Author = {Ma, J and Wang, YP and Chen, SY and Liu, PX and Liu, LQ},
Title = {{Insights into correlation between satellite infrared information and
   fault activities}},
Journal = {{PROGRESS IN NATURAL SCIENCE}},
Year = {{2006}},
Volume = {{16}},
Number = {{4}},
Pages = {{394-402}},
Month = {{APR}},
Abstract = {{Tectonic activities are accompanied with material movement and energy
   transfer, which definitely change the state of thermal radiation on the
   ground. Thus it is possible to infer present-day tectonic activities
   based on variations of the thermal radiation state on the ground. The
   received satellite infrared information is, however, likely influenced
   by many kinds of factors. Therefore, the first problem that needs to be
   solved is to extract information on tectonic activities and eliminate
   effects of external (non-tectonic) factors. In this study, we firstly
   make a review of the current studies on this subject, and then present
   the technical approach and our research goal. Using the data of 20 years
   from the infrared hand of the satellite of National Oceanic and
   Atmospheric Administration (NOAA) and the method we have developed, we
   investigate fault activities in western China. The results show that the
   areas with high residual values of land surface brightness temperature
   (LSBT), which is presumably related to faultings in space, accord
   usually with the locations of followed major earthquakes. The times of
   their value growing are also roughly consistent with the beginning of
   active periods of earthquakes. The low frequency component fields of the
   LSBT, acquired from wavelet analysis, exhibit well the spatial
   distributions of active faults. The ``heat penetrability index{''} (HPI)
   related with enhancement of subsurface thermal information has been
   expressed well for the backgrounds of accelerated tectonic motions, and
   some correlations exist between HPI and the local faulting and
   seismicity. This study provides a new approach to study temporal-spatial
   evolution of recent activities of faults and their interactions.}},
DOI = {{10.1080/10020070612330010}},
ISSN = {{1002-0071}},
Unique-ID = {{ISI:000237430000010}},
}

@inproceedings{ ISI:000187500300037,
Author = {Guttromson, RT and Chassin, DP and Widergren, SE},
Book-Group-Author = {{IEEE
   IEEE}},
Title = {{Residential energy resource models for distribution feeder simulation}},
Booktitle = {{2003 IEEE POWER ENGINEERING SOCIETY GENERAL MEETING, VOLS 1-4,
   CONFERENCE PROCEEDINGS}},
Year = {{2003}},
Pages = {{108-113}},
Note = {{IEEE-Power-Engineering-Society General Meeting, TORONTO, CANADA, JUL
   13-17, 2003}},
Organization = {{IEEE Power Engn Soc}},
Abstract = {{Advances in information technology, ubiquitous communications, and
   distributed generation and storage reveal new opportunities for the
   participation of demand-side resources in balancing the physical and
   economic operation of electric power systems. To better understand the
   potential impact of this participation, accurate, detailed energy
   resource models are necessary at the distribution feeder level. This
   presentation describes a detailed approach to residential energy
   resource modeling that preserves the individual characteristics of major
   residential appliances and human behavior patterns so that their
   contribution to energy efficiency schemes and intelligent demand
   curtailment algorithms is properly portrayed. These models are derived
   from previous analyses of residential and commercial building systems
   supported by data collected from the End-Use Load and Consumer
   Assessment Program (ELCAP) undertaken by the Bonneville Power
   Administration from 1983 to 1990. Preliminary results of using these
   models in distribution system simulations indicate that non-obvious,
   complex behavior patterns can emerge when consumers are confronted with
   varying price signals.}},
DOI = {{10.1109/PES.2003.1267145}},
ISBN = {{0-7803-7989-6}},
Unique-ID = {{ISI:000187500300037}},
}

@article{ ISI:000090100500008,
Author = {Magni, P and Motta, M and Martini, L},
Title = {{Leptin: a possible link between food intake, energy expenditure, and
   reproductive function}},
Journal = {{REGULATORY PEPTIDES}},
Year = {{2000}},
Volume = {{92}},
Number = {{1-3, SI}},
Pages = {{51-56}},
Month = {{AUG 25}},
Abstract = {{Several regulatory substances participate in the regulation of both food
   intake/energy metabolism and reproduction in mammals. Most of these
   neuropeptides originate and act in the central nervous system, mainly at
   specific hypothalamic areas. Leptin represents a signal integrating all
   these functions, but originating from the periphery (adipose tissue) and
   carrying information mainly to central structures. Observations in
   rodent models of leptin deficiency have suggested that leptin
   participates;in the control of reproduction, in conjunction with that of
   food intake and energy expenditure. Indeed, leptin administration
   resulted in the restoration of normal body weight, food intake, and
   fertility in the ob mouse, lacking circulating leptin. Specific targets
   of leptin. in the hypothalamus are neurons expressing neuropeptide Y,
   proopiomelanocortin and gonadotropin-releasing hormone, but the presence
   of leptin receptors in peripheral reproductive structures suggests that
   leptin might also act at these sites. Human obesity is often associated
   with reproductive disturbances. The situation in humans is more complex
   than in the animal models of leptin deficit and the presence of leptin
   resistance in these subjects is suggested. In conclusion, leptin fits
   many requirements for a molecule linking the regulation of energy
   balance and the control of reproduction. (C) 2000 Elsevier Science B.V.
   All rights reserved.}},
DOI = {{10.1016/S0167-0115(00)00149-X}},
ISSN = {{0167-0115}},
Unique-ID = {{ISI:000090100500008}},
}

@inproceedings{ ISI:000083950700008,
Author = {Beller, DE and Sailor, WC and Venneri, F},
Book-Group-Author = {{NEA
   NEA}},
Title = {{A closed ThUOX fuel cycle for LWRs with ADTT (ATW) backend for the
   21(st) century}},
Booktitle = {{BACK-END OF THE FUEL CYCLE IN A 1000 GWE NUCLEAR SCENARIO}},
Series = {{OECD PROCEEDINGS}},
Year = {{1999}},
Pages = {{91-104}},
Note = {{Workshop on Back-End of the Fuel Cycle in a 1000 GWE Nuclear Scenario,
   AVIGNON, FRANCE, OCT 06-07, 1998}},
Abstract = {{A future nuclear energy scenario with a closed, thorium-uranium-oxide
   (ThUOX) fuel cycle and new light water reactors (TULWRs) supported by
   Accelerator Transmutation of Waste (ATW) systems could provide several
   improvements beyond today's once-through, UO2-fueled nuclear technology.
   A deployment scenario with TULWRs plus ATWs to burn the actinides
   produced by these LWRs and to close the back-end of the ThUOX fuel cycle
   was modeled to satisfy a U.S. demand that increases linearly from 80 GWe
   in 2020 to 200 GWe by 2100. During the first 20 years of the scenario
   (2000-2020), nuclear energy production in the U.S. declines from today's
   100 GWe to about 80 GWe, in accordance with forecasts of the U.S. DOE's
   Energy Information Administration. No new nuclear systems are added
   during this declining nuclear energy period, and all existing LWRs are
   shut down by 2045. Beginning in 2020, ATWs that transmute the actinides
   from existing LWRs are deployed, along with TULWRs and additional ATWs
   with a support ratio of 1 ATW to 7 TULWRs to meet the energy demand
   scenario. A final mix of 174 GWe from TULWRs and 26 GWe from ATWs
   provides the 200 GWe demand in 2100. Compared to a once-through LWR
   scenario that meets the same energy demand,the TULWR/ATW concept could
   result in the following improvements:
   depletion of natural uranium resources would be reduced by 50 percent;
   inventories of Pu which may result in weapons proliferation,will be
   reduced in quantity by more than 98 percent and in quality because of
   higher neutron emissions and 50 times the alpha-decay heating of
   weapons-grade plutonium;
   actinides (and possibly fission products) for final disposal in nuclear
   waste would be substantially reduced; and
   the cost of fuel and the fuel cycle may be 20-30\% less than the
   once-through UO2 fuel cycle.}},
ISBN = {{92-64-17116-9}},
Unique-ID = {{ISI:000083950700008}},
}

@article{ ISI:A1995TH91600011,
Author = {LARSON, SM},
Title = {{IMPROVING THE BALANCE BETWEEN TREATMENT AND DIAGNOSIS - A ROLE FOR
   RADIOIMMUNODETECTION}},
Journal = {{CANCER RESEARCH}},
Year = {{1995}},
Volume = {{55}},
Number = {{23, S}},
Pages = {{S5756-S5758}},
Month = {{DEC 1}},
Note = {{5th Conference on Radioimmunodetection and Radioimmunotherapy of Cancer,
   PRINCETON, NJ, OCT 06-08, 1994}},
Organization = {{Ctr Molec Med \& Immunol; Garden State Canc Ctr}},
Abstract = {{Despite major advances in diagnostic testing, including the introduction
   and widespread availability of high-resolution computed tomography (CT)
   and magnetic resonance imaging, inadequate diagnostic information still
   interferes with proper management of many patients with cancers, This is
   particularly true for recurrent colorectal cancer, for example. In the
   course of this symposium, significant advances have been reported which
   are likely to improve management of this clinical situation, In-111,
   oncoscint for colorectal and ovarian cancer imaging, has been approved
   for single use only, and is a product licensed by the Food and Drug
   Administration. It has been shown to be significantly more effective
   than CT for detecting the presence of disease that is confined to the
   abdomen outside the liver, This agent is very useful in a limited role.
   A larger opportunity awaits other preparations reported at this
   conference, especially Tc-99m-labeled Immu-4 carcinoembryonic antigen,
   which is significantly better than CT for determining resectability of
   recurrent cancer (T, Behr st al., Cancer Res, 55 (Suppl,): 5777s-5785s,
   1995), The Tc-99m-labeled compound preparations offer the advantages of
   low immunogenicity, excellent imaging energies of Tc-99m, and
   `'same-day'' imaging.
   Even the most effective cancer treatment such as surgical resection, if
   applied to a patient who basically does not need it, can be a needless
   expense and a trauma to the patient, To date, our emphasis in oncology
   research has been heavily weighted toward developing new therapies, The
   success of radioimmunodetection is one indication of why it is time for
   a paradigm shift, during which we can move toward a more balanced
   program that emphasizes both diagnosis and therapy, To achieve this we
   must urge research institutions such as the National Cancer Institute
   and American Cancer Society to make major investments in the diagnostic
   aspects of cancer care, With the knowledge base that we have now, we can
   make improvements in patient care by emphasizing development of improved
   diagnostic methods and support for cost-effectiveness studies for
   developed methods, in order that currently available treatments can be
   more intelligently applied.}},
ISSN = {{0008-5472}},
Unique-ID = {{ISI:A1995TH91600011}},
}

@article{ ISI:000285908000001,
Author = {Guogis, Arvydas},
Title = {{To refrain from capitalism or to improve it? The importance of equity
   during crisis}},
Journal = {{FILOSOFIJA-SOCIOLOGIJA}},
Year = {{2010}},
Volume = {{21}},
Number = {{2}},
Pages = {{83-91}},
Abstract = {{The article deals with the last decades' shift of the Western world to
   liberal capitalism values when the significance of privatization,
   liberalization, globalization and New Public Management has sufficiently
   risen. Earlier, such rather specific regions as the Nordic countries,
   Latin America, Eastern and Southern Asia had introduced many elements
   similar to the Anglo-Saxon experience. Many Eastern European countries,
   upon rejecting totalitarian regimes, in fact without compromises have
   chosen the path of Western liberal capitalism, although this way was
   hindered by communist heritage, corruption and clientelism. However, not
   everybody in the world agreed with such a change of the economic-social
   paradigm. Mostly in the West, the intellectual critics of the system
   appeared, representing modern economic, political, social and
   cultural-philosophical theories. The economic crisis of 2008-2010 shook
   the world and promoted a radical criticism of capitalism. One of such
   critics is the Italian left-wing sociologist Franco Berardi (Bifo) who
   considers the contemporary economic system as dead and only artificially
   stimulated. The real values, according to E Berardi, must be not
   economic consumption and alienated work for satisfying one's needs, but
   spiritual and emotional values which can direct psychic energy towards
   the joy of life autonomous from capitalism. F. Berardi contrasts
   autonomy with the whole exhausted contemporary capitalist system which,
   in his opinion, does not have possibilities to expand.
   The article deals with the issue of refraining from capitalism which,
   according to the author, is not fruitful, because it is possible to
   ``improve{''} capitalism by imposing more equity (social justice). The
   author sees the biggest problem in society's division into ``winners{''}
   and ``loosers{''} who have no relations at all. Capitalism creates not
   only globalization, which is useful to the ``winners{''}, but also its
   antipode - glocalization - which imprisons a large part of population in
   geographically restricted social ghettos because of income, education,
   competence, age differences, illnesses and disability. The system's
   efficiency criterion, besides the well-known 3-E conception, should be
   the fourth E (equity), when it is necessary to pay attention to the
   problems of marginal groups. In order to reach social justice, it is
   necessary to implement new methods of social sciences, such as
   participatory research and benchmarking research. It is necessary to
   improve methods of public administration, first of all social
   administration methods, in order to provide efficiency for the benefit
   of social reintegration. It is necessary to diminish public
   administration ``transaction costs{''} and ``asymmetrical
   information{''}. Not only the well-known New Public Management methods,
   such as ``quality management{''} or clients' satisfaction surveys, but
   also less known methods such as global budgeting or priority planning
   should be used. New Public Management should be expanded or timely
   changed by New Governance values which supplement or change economic
   calculation by civil participation, democracy, active non-governmental
   activities, transparency and absence of corruption, diminishing of
   social exclusion.}},
ISSN = {{0235-7186}},
Unique-ID = {{ISI:000285908000001}},
}

@article{ ISI:000220131600017,
Author = {Tachibana, T and Saito, S and Tomonaga, S and Takagi, T and Saito, ES
   and Nakanishi, T and Koutoku, T and Tsukada, A and Ohkubo, T and
   Boswell, T and Furuse, M},
Title = {{Effect of central administration of prolactin-releasing peptide on
   feeding in chicks}},
Journal = {{PHYSIOLOGY \& BEHAVIOR}},
Year = {{2004}},
Volume = {{80}},
Number = {{5}},
Pages = {{713-719}},
Month = {{FEB}},
Abstract = {{Prolactin-releasing peptide (PrRP) is one of the inhibitory factors in
   feeding regulation of mammals. However, no information is available for
   avian species. The present study was done to clarify the effect of
   intracerebroventricular (ICV) injection of PrRP on feeding in chicks.
   Firstly, we found that ICV injection of PrRP (94-1500 pmol)
   significantly increased food intake in chicks. The result was completely
   different from those obtained in mammals. The orexigenic effect of PrRP
   was significantly weaker than that of neuropeptide Y (NPY), a potent
   orexigenic peptide, on an equimolar basis. The orexigenic effect of NPY
   was further enhanced with coinjection of PrRP. These results suggest the
   existence of a novel orexigenic mechanism in the chick brain, which
   might differ from NPY-involved feeding regulatory pathway. In addition,
   ICV injection of PrRP significantly decreased the rectal temperature,
   but the effect was weaker than that of NPY, suggesting that PrRP may
   inhibit energy expenditure in chicks. Taken together, we showed here
   that PrRP may be involved in the regulation of both feeding behavior and
   energy metabolism in the chick brain. (C) 2004 Elsevier Inc. All rights
   reserved.}},
DOI = {{10.1016/j.physbeh.2003.12.005}},
ISSN = {{0031-9384}},
ORCID-Numbers = {{Tomonaga, Shozo/0000-0003-0888-1407}},
Unique-ID = {{ISI:000220131600017}},
}

@article{ ISI:000358458100015,
Author = {Torres, Pamela and Blackhurst, Michael and Bouhou, Nour},
Title = {{Cross comparison of empirical and simulated models for calculating
   residential electricity consumption}},
Journal = {{ENERGY AND BUILDINGS}},
Year = {{2015}},
Volume = {{102}},
Pages = {{163-171}},
Month = {{SEP 1}},
Abstract = {{The U.S. Energy Information Administration's Residential Energy
   Consumption Survey (RECS) provides electricity end-use estimates derived
   from disaggregating total household consumption. However, the accuracy
   of the EIA's disaggregation method is unclear, thus potentially
   producing erroneous end-use estimates and affecting respective decision
   support. In order to test the EIA's disaggregation methods, we perform
   parallel empirical analysis of residential cooling demands on two
   household samples located in Texas: an estimated sample (RECS) and a
   sample where air conditioning branch circuits are directly metered.
   Results indicate statistically significant differences between data
   sources; with the RECS sample possibly underestimating cooling demands.
   Results further indicate that models developed using observed end-use
   consumption are more robust, demonstrating statistically significant
   predictors that do not significantly correlate with end-use estimates
   from the RECS sample. We find that accounting for seasonality increases
   predicted R-2 values and reduces overestimation of statistical
   significance. Finally, the observed model indicates that window area and
   orientation are statistically significant predictors of cooling loads,
   which are parameters not surveyed in RECS. We then provide policy
   recommendations to improve end-use estimates, including integrating
   select utility-funded audit data into disaggregation methods. (c) 2015
   Elsevier B.V. All rights reserved.}},
DOI = {{10.1016/j.enbuild.2015.05.015}},
ISSN = {{0378-7788}},
EISSN = {{1872-6178}},
Unique-ID = {{ISI:000358458100015}},
}

@article{ ISI:000324787700009,
Author = {Parece, Tammy Erlene and Younos, Tamim and Grossman, Lawrence S. and
   Geller, E. Scott},
Title = {{A study of environmentally relevant behavior in university residence
   halls}},
Journal = {{INTERNATIONAL JOURNAL OF SUSTAINABILITY IN HIGHER EDUCATION}},
Year = {{2013}},
Volume = {{14}},
Number = {{4}},
Pages = {{466-481}},
Abstract = {{Purpose - This paper aims to report on a study promoting energy
   conservation on Virginia Tech's campus. It explores whether the behavior
   of students living in university residence halls would change when
   various electricity conservation strategies are introduced.
   Design/methodology/approach - Intervention strategies, including
   educational media, information, and voluntary resource-conservation
   activities, were applied at varying levels of intensity across five
   study groups over two semesters in 2009. Additional questions explore
   whether one particular strategy would produce higher consumption
   reductions, and whether combining strategies would produce more
   consumption reductions than individual techniques.
   Findings - The findings revealed that on a campus where environmentally
   sustainability is foremost in the minds of students and administration,
   asking students to take action to reduce their consumption resulted in
   positive consumption reductions, even in the control group. Additive
   strategies did not produce higher reductions.
   Social implications - Reducing natural resource consumption in the USA
   is essential to promote worldwide sustainability. This study shows that,
   even when people see no financial incentive to reduce consumption,
   consumption reductions can be achieved.
   Originality/value - Numerous studies have been completed since the 1970s
   in households across the world to promote environmentally relevant
   behavior (ERB). Sustainability action plans are being implemented on
   university campuses, but literature on promoting ERB in students
   residing on university campuses is sparse. This study provides
   information and a format for colleges/universities worldwide to promote
   ERB on their campuses.}},
DOI = {{10.1108/IJSHE-01-2012-0008}},
ISSN = {{1467-6370}},
Unique-ID = {{ISI:000324787700009}},
}

@article{ ISI:000293429700022,
Author = {Feng, Jianghua and Liu, Huili and Bhakoo, Kishore K. and Lu, Lehui and
   Chen, Zhong},
Title = {{A metabonomic analysis of organ specific response to USPIO
   administration}},
Journal = {{BIOMATERIALS}},
Year = {{2011}},
Volume = {{32}},
Number = {{27}},
Pages = {{6558-6569}},
Month = {{SEP}},
Abstract = {{As ultrasmall superparamagnetic particles of iron oxides (USPIO) have
   been widely used in clinical medicine as MRI contrast agents, hence
   their potential toxicity and adverse effects following administration
   have attracted particular attention. In the present study, high
   resolution magic-angle-spinning (1)H NMR spectroscopy coupled with
   multivariate statistical analysis was used to directly determine the
   metabolic consequences of specific-tissues, including kidney, liver and
   spleen following the intravenous administration of USPIO. Alterations of
   renal, hepatic and splenic function were reflected by changes in a
   number of metabolic pathways including small molecules involved in
   energy, lipid, glucose, and amino acids metabolism. The toxicological
   potential and metabolic fate of USPIO seems to be linked to their
   surface chemistry and particle size. Hierarchical principal component
   analysis was used to explore the multidimensional metabolic
   relationships between various biological matrices such as kidney, liver,
   spleen, plasma and urine. Information on the involvement of USPIO in
   transportation, absorption, biotransformation, biodistribution and
   secretion was derived from metabolic correlation analysis between
   different organs and biofluids. Such a metabonomic strategy provides
   methodology for investigating the potential adverse biological effects
   of similar nanoparticles on the environmental and human health and
   assessing the drug interventions on the targeted organ. (C) 2011
   Elsevier Ltd. All rights reserved.}},
DOI = {{10.1016/j.biomaterials.2011.05.035}},
ISSN = {{0142-9612}},
ResearcherID-Numbers = {{SKL, PCOSS/D-4395-2013}},
Unique-ID = {{ISI:000293429700022}},
}

@article{ ISI:000340212400012,
Author = {Nakamachi, Tomoya and Shibata, Haruki and Sakashita, Atsushi and Iinuma,
   Naoto and Wada, Kohei and Konno, Norifumi and Matsuda, Kouhei},
Title = {{Orexin A enhances locomotor activity and induces anxiogenic-like action
   in the goldfish, Carassius auratus}},
Journal = {{HORMONES AND BEHAVIOR}},
Year = {{2014}},
Volume = {{66}},
Number = {{2}},
Pages = {{317-323}},
Month = {{JUL}},
Abstract = {{Orexin acts as an orexigenic factor for the regulation of appetite and
   rhythmicity in rodents. In goldfish, intracerebroventricular (ICV)
   administration of orexin A has been shown to affect not only food
   intake, but also locomotor activity. However, as there is still no
   information regarding the effect of orexin A on emotional behavior in
   goldfish, we investigated the effect of orexin A on psychomotor activity
   in this species. Intracerebroventricular administration of synthetic
   orexin A at 2 and 4 pmol/g body weight (BW) enhanced locomotor activity,
   and this enhancement by orexin A at 4 pmol/g BW was attenuated by
   treatment with the orexin receptor 1 antagonist, SB334867, at 10 pmol/g
   BW. Since intact goldfish prefer a black to a white background area, or
   the lower to the upper area of a tank, we used two types of preference
   tests (black/white and upper/lower tests) for measuring anxiety-like
   behavior in goldfish. Intracerebroventricular administration of orexin A
   at 4 pmol/g BW shortened the time spent in the white background area,
   and increased the time taken to move from the lower to the upper area.
   This action of orexin A mimicked that of the central-type benzodiazepine
   receptor inverse agonist, FG-7142 (an anxiogenic agent), at 4 pmol/g BW.
   The anxiogenic-like effect of orexin A was abolished by treatment with
   SB334867 at 10 pmol/g BW. These results indicate that orexin A potently
   affects psychomotor activity in goldfish. (C) 2014 Elsevier Inc. All
   rights reserved.}},
DOI = {{10.1016/j.yhbeh.2014.06.004}},
ISSN = {{0018-506X}},
EISSN = {{1095-6867}},
Unique-ID = {{ISI:000340212400012}},
}

@inproceedings{ ISI:000302565000008,
Author = {Akers, Walter J. and Solomon, Metasebya and Sudlow, Gail P. and Berezin,
   Mikhail and Achilefu, Samuel},
Editor = {{Achilefu, S and Raghavachari, R}},
Title = {{Time-domain imaging with quench-based fluorescent contrast agents}},
Booktitle = {{REPORTERS, MARKERS, DYES, NANOPARTICLES, AND MOLECULAR PROBES FOR
   BIOMEDICAL APPLICATIONS IV}},
Series = {{Proceedings of SPIE}},
Year = {{2012}},
Volume = {{8233}},
Note = {{Conference on Reporters, Markers, Dyes, Nanoparticles, and Molecular
   Probes for Biomedical Applications IV, San Francisco, CA, JAN 23-25,
   2012}},
Organization = {{SPIE}},
Abstract = {{Quench-based probes utilize unique characteristics of fluorescence
   resonance energy transfer (FRET) to enhance contrast upon de-quenching.
   This mechanism has been used in a variety of molecular probes for
   imaging of cancer related enzyme activity such as matrix
   metalloproteinases, cathepsins and caspases. While non-fluorescent upon
   administration, fluorescence can be restored by separation of donor and
   acceptor, resulting in higher intensity in the presence of activator.
   Along with decreased quantum yield, FRET also results in altered
   fluorescence lifetime. Time-domain imaging can further enhance contrast
   and information yield from quench-based probes. We present in vivo
   time-domain imaging for detecting activation of quench-based probes.
   Quench-based probes utilize unique characteristics of fluorescence
   resonance energy transfer (FRET) to enhance contrast upon de-quenching.
   This mechanism has been used in a variety of molecular probes for
   imaging of cancer related enzyme activity such as matrix
   metalloproteinases, cathepsins and caspases. While non-fluorescent upon
   administration, fluorescence can be restored by separation of donor and
   acceptor, resulting in higher intensity in the presence of activator.
   Along with decreased quantum yield, FRET also results in altered
   fluorescence lifetime. Time-domain imaging can further enhance contrast
   and information yield from quench-based probes. We present in vivo
   time-domain imaging for detecting activation of quench-based probes.
   Time-domain diffuse optical imaging was performed to assess the FRET and
   quenching in living mice with orthotopic breast cancer. Tumor contrast
   enhancement was accompanied by increased fluorescence lifetime after
   administration of quenched probes selective for matrix
   metalloproteinases while no significant change was observed for
   non-quenched probes for integrin receptors. These results demonstrate
   the utility of time-domain imaging for detection of cancer-related
   enzyme activity in vivo.}},
DOI = {{10.1117/12.915917}},
Article-Number = {{82330G}},
ISSN = {{0277-786X}},
ISBN = {{978-0-8194-8876-3}},
ORCID-Numbers = {{Achilefu, Samuel/0000-0002-3133-6717
   Akers, Walter/0000-0002-9697-7654}},
Unique-ID = {{ISI:000302565000008}},
}

@inproceedings{ ISI:000282107600424,
Author = {Fan, Xiumin and Zhu, Minghua and Zhang, Xi and He, Qichang and Rovetta,
   Alberto},
Book-Group-Author = {{IEEE}},
Title = {{Solid Waste Collection Optimization Considering Energy Utilization for
   Large City Area}},
Booktitle = {{PROCEEDINGS OF 2010 INTERNATIONAL CONFERENCE ON LOGISTICS SYSTEMS AND
   INTELLIGENT MANAGEMENT, VOLS 1-3}},
Year = {{2010}},
Pages = {{1905-1909}},
Note = {{International Conference on Logistics Systems and Intelligent
   Management, Harbin, PEOPLES R CHINA, JAN 09-10, 2010}},
Organization = {{Harbin Univ Commerce; China Soc Comod Sci, IEEE Harbin Sect}},
Abstract = {{Waste management is a significant issue in the world, which is of vital
   importance to global environmental. Three strategies for truck
   scheduling and path optimization of waste collection are provided. For
   an improvement waste processing strategy which not only cares about the
   weight and volume, this paper presented a model for optimizing municipal
   solid waste management considering energy utilization. A genetic
   algorithm and simulate algorithm integrated method was adopted to
   optimize the collection route. To better help administration department
   manage its solid waste, a GIS based decision support system was
   developed. The proposed approach is verified through a case study of
   Pudong. The results show the method is effective for solid waste
   collection and transport from the energy utilization improvement point
   of view.}},
ISBN = {{978-1-4244-7328-1}},
ResearcherID-Numbers = {{CHAI, CINDY /B-6685-2010}},
Unique-ID = {{ISI:000282107600424}},
}

@article{ ISI:000274067000004,
Author = {Li, Zhuoran and Li, Gang and Qin, Pei},
Title = {{The prediction of ecological potential for developing salt-tolerant oil
   plants on coastal saline land in Sheyang Saltern, China}},
Journal = {{ECOLOGICAL ENGINEERING}},
Year = {{2010}},
Volume = {{36}},
Number = {{1}},
Pages = {{27-35}},
Month = {{JAN}},
Abstract = {{The current energy crisis is a worldwide problem. and developing energy
   from biomass is considered an effective partial solution. Sheyang
   Saltern is located in a coastal area in East China. The administration
   of saltern cooperated with our Halophyte Research Lab to create a
   Five-year Plan of Biomass Energy on Saline Land. In this plan, 3330 ha
   of salt-tolerant oil plants will be planted on the coastal saline land
   in Sheyang Saltern, including 2664 ha of Ricinus communis and 666 ha of
   Kosteletzkya virginica (L.) presl. These plants will produce biomass
   energy from land that is not fit for common crops, and thus this plan
   will not affect crop production. Moreover. the biomass of plants will be
   fully utilized in a hierarchical way, guided by an ecological
   engineering design. Thus, more outputs and more profits will be gained
   by applying this plan. This study uses the emergy analysis to predict
   and analyze the saltern ecosystem's ecological potential and compare it
   with an existing system founded in 2007, a 33.3 ha field of the two
   plants in the saltern. Four main emergy indices of the two ecosystems,
   EYR, EIR, ELR and ESI, are calculated and compared. To better show the
   system's ecological potential, we establish a new emergy index-potential
   yield ratio (PYR). PYR is designed to measure artificial ecosystems'
   potential output capacity. It reflects a system's potential to transform
   stored emergy into output emergy using ecological engineering
   technology. The value of the predicted system's PYR is as great as 225,
   indicating that the system has a bright future to develop salt-tolerant
   oil plants. The system's future ecological potential and additional ways
   to utilize the two plants - the use of ricin and tuberous roots, etc.
   are also discussed in this paper. Our results will be helpful to the
   government's policy making. and provides useful information for
   enterprises. (c) 2009 Elsevier B.V. All rights reserved.}},
DOI = {{10.1016/j.ecoleng.2009.09.006}},
ISSN = {{0925-8574}},
Unique-ID = {{ISI:000274067000004}},
}

@article{ ISI:000270563300002,
Author = {Arvanitis, C. D. and Speller, R.},
Title = {{Quantitative contrast-enhanced mammography for contrast medium kinetics
   studies}},
Journal = {{PHYSICS IN MEDICINE AND BIOLOGY}},
Year = {{2009}},
Volume = {{54}},
Number = {{20}},
Pages = {{6041-6064}},
Month = {{OCT 21}},
Abstract = {{Quantitative contrast-enhanced mammography, based on a dual-energy
   approach, aims to extract quantitative and temporal information of the
   tumour enhancement after administration of iodinated vascular contrast
   media. Simulations using analytical expressions and optimization of
   critical parameters essential for the development of quantitative
   contrast-enhanced mammography are presented. The procedure has been
   experimentally evaluated using a tissue-equivalent phantom and an
   amorphous silicon active matrix flat panel imager. The x-ray beams were
   produced by a tungsten target tube and spectrally shaped using readily
   available materials. Measurement of iodine projected thickness in mg
   cm(-2) has been performed. The effect of beam hardening does not
   introduce nonlinearities in the measurement of iodine projected
   thickness for values of thicknesses found in clinical investigations.
   However, scattered radiation introduces significant deviations from
   slope equal to unity when compared with the actual iodine projected
   thickness. Scatter correction before the analysis of the dual-energy
   images provides accurate iodine projected thickness measurements. At
   10\% of the exposure used in clinical mammography, signal-to-noise
   ratios in excess of 5 were achieved for iodine projected thicknesses
   less than 3 mg cm(-2) within a 4 cm thick phantom. For the extraction of
   temporal information, a limited number of low-dose images were used with
   the phantom incorporating a flow of iodinated contrast medium. The
   results suggest that spatial and temporal information of iodinated
   contrast media can be used to indirectly measure the tumour microvessel
   density and determine its uptake and washout from breast tumours. The
   proposed method can significantly improve tumour detection in dense
   breasts. Its application to perform in situ x-ray biopsy and assessment
   of the oncolytic effect of anticancer agents is foreseeable.}},
DOI = {{10.1088/0031-9155/54/20/002}},
ISSN = {{0031-9155}},
Unique-ID = {{ISI:000270563300002}},
}

@article{ ISI:000235088600005,
Author = {Geelissen, SME and Swennen, Q and Van der Geyten, S and Kuhn, ER and
   Kaiya, H and Kangawa, K and Decuypere, E and Buyse, J and Darras, VM},
Title = {{Peripheral ghrelin reduces food intake and respiratory quotient in
   chicken}},
Journal = {{DOMESTIC ANIMAL ENDOCRINOLOGY}},
Year = {{2006}},
Volume = {{30}},
Number = {{2}},
Pages = {{108-116}},
Month = {{FEB}},
Abstract = {{Ghrelin injection, either centrally or peripherally strongly stimulates
   feeding in human and rodents. In contrast, centrally injected ghrelin
   inhibits food intake in neonatal chickens. No information is available
   about the mechanism and its relationship with energy homeostasis in
   chicken. Since ghrelin is predominantly produced in the stomach, we
   investigated the effect of peripherally injected ghrelin (1 nmol/100g
   body weight) on food intake and energy expenditure as measured in
   respiratory cells by indirect calorimetry for 24 h in one-week-old
   chickens. Plasma glucose, triglycerides, free fatty acids, total protein
   and T-3 were measured in a separate experiment until 60 min after
   injection. Food intake decreased until at least I h after intravenous
   ghrelin administration. The respiratory quotient (RQ) in
   ghrelin-injected chickens was reduced until 14h after administration
   whereas plasma glucose and triglycerides concentrations were not
   altered. Free fatty acids and total protein levels also remained
   unchanged. Ghrelin did not influence heat production and this was
   supported by the absence of changes in plasma T3 levels when compared to
   the control values.
   In conclusion, peripheral ghrelin reduces food intake as well as RQ and
   might influence the type of substrate (macronutrient) that is used as
   metabolic fuel. (c) 2005 Elsevier Inc. All rights reserved.}},
DOI = {{10.1016/j.domaniend.2005.06.005}},
ISSN = {{0739-7240}},
Unique-ID = {{ISI:000235088600005}},
}

@article{ ISI:000178807200003,
Author = {Brzica, D},
Title = {{Institutional framework in the period before Slovakia's European Union
   accession}},
Journal = {{EKONOMICKY CASOPIS}},
Year = {{2002}},
Volume = {{50}},
Number = {{4}},
Pages = {{605-619}},
Abstract = {{Adequate institutional structure is a precondition for EU membership. As
   the reference date for accession is 2004, all relevant acquis should be
   implemented until the end of this year and so is expected adequate
   strengthening of capacities. In the accession process framework are
   specified another priorities (e.g. harmonization of legal system),
   measures for implementation and conditions for providing support.
   However, adaptation depends also on transparency of decision-making, law
   enforcement and elimination of corruption. Reform of public
   administration, made through decentralization, is based on operation of
   state administration and regional self-government and on changing
   competencies with the aim to reduce expenditures and improve services.
   Respected in this process are principles of subsidiarity and competitive
   environment.
   In general, there has been a strengthening of the system of governmental
   management bodies like, e.g., Custom directorate of the Slovak republic.
   In the case of public finance the gradual reductions of subsidies is the
   basic principle to be followed in the next future and market functioning
   should be improved via financial control over enterprises. Economic
   policy priorities have shifted from liberalization and privatization
   towards structural changes in corporate law. The amendment should
   increase transparency of ownership and business relations and,
   therefore, lead to a better corporate governance. Mentioned briefly are
   survey results on increasing ownership concentration of the biggest
   shareholders. Among central issues is also formation of competitive
   environment. Following acts on state assistance and on protection of
   economic competition, expected is approval of legal regulations allowing
   to provide group exceptions from prohibition of agreements limiting
   competition for certain agreements.
   Despite the fact that, as mentioned above, the state enforces liberal
   model of the economy based on transparency of business environment it
   also aims to develop some industries or branches to make Slovak
   industrial structure more similar to that of EU countries. Such changes
   should lead towards higher intra-industry trade, a feature typical for
   developed economics. Accepted concept of state science and technology
   policy, supporting participation in EU framework programs, faces problem
   with inadequate funding.
   In corporate law an amended bankruptcy act has enforced position of
   creditors which should speed-up corporate restructuring and recovery.
   Being aware of the positive role of foreign investment, the state
   promotes their inflows using certain policy measures like tax holiday
   etc. As a potential positive by-product of ending privatization is
   considered the possibility that completion of privatization could
   eliminate chances for corruption in state administration.
   Some changes have indirect impact on corporate costs or production.
   Poorly performing healthcare sector increases illness rates of workforce
   and problems in education sector negatively affects qualification of
   labor force. It is necessary, according to policymakers, to reform
   social system by changing the system of pension and social insurance and
   social aid. Reform of healthcare should guarantee transition towards
   predominantly ambulant form of care and decentralization of the whole
   system. Elementary healthcare insurance should be extended by
   supplementary insurance and optional commercial insurance schemes.
   In environmental protection the main principles are those related to
   sustainable development. National environmental action program SR II has
   originated and the realization of this policy is conditioned by
   introduction of environmental taxes, management and audit. Projected are
   also monitoring and information systems. Key role in the process of EU
   programs and implemented should be the administrative structure at NUTS
   11 level. Improvement of technical preparation of projects financed from
   EU structural funds is needed.
   In the area of free movement of goods it is necessary implement
   operational directives related to technical requirements for products.
   Act oil public procurement has already been implemented to a substantial
   degree acquis but real use has remained a problem. Legal changes should
   be followed by building of administrative capacities. One example is the
   need for coordination of the control of adjustment process in the area
   of Slovak technical norms in non-harmonized area.
   As general requirement, it is necessary to implement numerous laws in
   individual chapters in the whole EU directives agenda. Labor Code and
   laws oil state and public services, in the chapter of social policy and
   employment, were implemented recently but the remaining problem is
   flexibility, of labor market. Approval of the law oil network industries
   regulation, creation of regulatory office and removal of price
   distortions had prepared conditions for successful restructuring of
   energy industry. Passed was the law on emergency petrol reserves and
   petrol products and amended was the law oil state tangible reserves.
   Enforced will be the capacity of the Off ice for regulation of network
   industries due to the preparation of secondary legislature in this area.
   In a preliminary concluded chapter Protection of consumer and health
   remaining directives should be implemented, c. g., marking of consumer
   products with price tags.. and legislature regulating market
   supervision. Passed was also a custom act. full harmonized should be the
   scheme of General systcru of preferences (until 2004) and passcd should
   be all act on Export-import Bank of the SR. In preparatory stage is a
   new information society strategy.
   Progress in transposition of accession chapters is the subject of EC
   evaluations. Report on Preparedness (2001) positively evaluates number
   of measures already made. It states that progress has been reached in
   the areas of structure and functioning of administration, justice,
   legislature of internal market, corporate law and competition. Progress
   has to be made in agriculture sector and in enforcing of administrative
   capacities (e. g., management and control of EC funds). Improvement has
   been expected especially in the area of corporate law, competition,
   social policy and employment. Comparison of candidate countries made on
   the basis,of convergence indicator DCEI (DGZ Deka Bank) shows that the
   Slovak republic still lacks behind other candidate partners. However, in
   the area of institutional convergence is its evaluation better than is
   the total country rating. Evaluations have informative purpose only but
   for accession decisions one should look also oil non-economic (political
   and strategic) dimensions.}},
ISSN = {{0013-3035}},
Unique-ID = {{ISI:000178807200003}},
}

@article{ ISI:000167166400005,
Author = {Cullen, MJ and Ling, N and Foster, AC and Pelleymounter, MA},
Title = {{Urocortin, corticotropin releasing factor-2 receptors and energy balance}},
Journal = {{ENDOCRINOLOGY}},
Year = {{2001}},
Volume = {{142}},
Number = {{3}},
Pages = {{992-999}},
Month = {{MAR}},
Abstract = {{Although there is considerable information regarding the role of brain
   CRF in energy balance, relatively little is known about the role of
   urocortin (UCN), which is an equally potent anorexic agent. Therefore,
   the effects of intracerebroventricular (icv) administration of UCN
   (0.01-1 nmol/day) on food intake and body weight were assessed over a
   period of 13 days and compared with data from CRF-infused counterparts.
   Although both peptides dose dependently reduced food intake and weight
   gain, the effects of CRF were much greater in magnitude than those of
   UCN, particularly on body weight. Pair-feeding studies suggested that,
   while the effects of CRF on body weight could not be completely
   explained by appetite suppression, the effects of UCN appeared to be due
   to its initial impact on food intake. CRF increased brown adipose fat
   pad and adrenal weights, whereas it reduced thymus and spleen weights.
   CRF also increased serum corticosterone, triglyceride, FFA, and
   cholesterol levels, whereas it reduced glucose. UCN did not produce any
   consistent changes in any of these indices of sympathetic nervous system
   activation. Concurrent administration of the CRF2-selective antagonist,
   antisauvagine-30 (ASV-30) (30 nmol/day) completely reversed or
   attenuated the effects of UCN and CRF(1 nmol/day) on food intake and
   body weight. ASV-80 did not significantly attenuate any of the above
   CRF-induced changes in tissue weights or serum chemistry. These data
   suggest that the central CRF2 receptor may primarily mediate the
   anorexic, but not the metabolic effects of CRF.}},
DOI = {{10.1210/en.142.3.992}},
ISSN = {{0013-7227}},
Unique-ID = {{ISI:000167166400005}},
}

@inproceedings{ ISI:000089398700283,
Author = {Hawke, S},
Book-Group-Author = {{IEEE
   IEEE}},
Title = {{Pacific Northwest - Politics trumps technology}},
Booktitle = {{2000 IEEE POWER ENGINEERING SOCIETY SUMMER MEETING, CONFERENCE
   PROCEEDINGS, VOLS 1-4}},
Year = {{2000}},
Pages = {{1458-1460}},
Note = {{IEEE Power-Engineering-Society Summer Meeting, SEATTLE, WA, JUL 16-20,
   2000}},
Organization = {{Power Engn Soc; IEEE}},
Abstract = {{Let's begin by painting the transmission landscape in the Pacific
   Northwest. We have a system with a peak load of 34,000 MW in the summer
   and 42,000 MW in the winter, that includes 24,000 miles of facilities at
   230 kV and above in the states of Washington, Oregon, Idaho, Montana,
   Northern Nevada, and a portion of British Columbia and Alberta in
   Canada. Dominated by the Columbia River System, the area has been the
   low-cost region for electricity in the country for decades. In the
   1940's and 1950's, aluminum plants located throughout the region in
   support of the war effort, and these large loads continue through today
   to have a significant impact on the Northwest energy picture. Special
   contracts and historical claims to low-cost power were the norm until
   thermal plants were needed to meet growth in the 50's and 60's. Now the
   rights to the hydro-based power continue to be negotiated as separate
   economic and political commodities independent of the physical realities
   of power flow. Huge capital investments by regional power groups in the
   WPPSS nuclear plants led to one of the largest defaults in the country
   in the 70's and 80's, and current billing and cost recovery mechanisms
   still spread these costs across Northwest customers. The Bonneville
   Power administration is responsible for the distribution of power from
   federal dams in the region, and as such, owns 80\% of the bulk power
   transmission facilities. It's Ditmer Control Center in Vancouver,
   Washington acts as the region's technical hub for information exchange
   and it's investments in capital and O \& M dwarf the other Northwest
   owners. With its' recent construction of fiber systems, it has now begun
   competing with private investments in the communication bandwidth arena.
   The area also has eight major IOU's and 125 publics, muni's, and coops.
   Surplus energy is sold to California and the Southwest via the AC and DC
   intertie with a combined capacity of 7900 MW North to South. 4800 MW of
   this capacity is on the AC intertie, and the remaining 3100 on the DC.
   South to North ratings are in the 6800 range with the AC intertie taking
   the de-rating.
   The technology of die Northwest is not particularly unique when
   considered on an international scale. The large North to South power
   exchanges over long distances result in operating nomograms in response
   to stability limitations. Two significant regional outages in the 1990's
   have resulted in much tighter coordination on planning and reliability
   issues, and the dramatic increase in commerce over the system mimics the
   activity seen around the U.S. Both DC and AC interties and the support
   of the Federal Government through Bonneville Power Administration, have
   produced leading edge technology developments over the years and some of
   the world's top transmission engineers have received their knowledge and
   expertise on the Northwest system. Thermal and voltage limit problems
   are not nearly as significant as those in the East, and very little
   congestion occurs.
   The politics of the Pacific especially unique. The multiple use
   characteristics of irrigation, generation, recreation, flood control,
   transportation, and other commerce of the hydro system has produced a
   dynamic tension among stakeholders over the years that continues
   unabated today.
   Environmental issues surrounding the dramatic reduction in salmon over
   the past decades are currently leading to considerations to breach dams
   on the Snake River. The water management practices in the spring to
   spill water to enhance fish survival carry price tags in the hundreds of
   millions of dollars. Unique payment packages surrounding the debt
   associated with the WPPSS nuclear power plants entangle most regional
   participants, not only economically, but politically as well. State
   politics defending low-cost power fi om decade's old public preference
   clause lead to bitter discussion on cross border worth of citizens. The
   State of Washington's high representation of PUD's and coops, and it's
   national delegation's political strength in the Washington DC lead to a
   decision process that goes from Olympia, to the National Senate, to the
   Department of Energy, to BPA, and back to the Northwest, on issues that
   don't get resolved satisfactorily in an Olympia to SPA path. Differences
   among IOU's from the ``defend the vertically integrated monopoly{''}
   ethic to the ``unbundle and compete{''} ethic, lead to the complete
   realignment of special interest groups around issues far different than
   the historic allegiance to stockholders. The purchase of PGE by Enron
   and the purchase of PacifiCorp by Scottish Power were the first such
   purchases in the Northwest, and the commercial and international
   viewpoints are often at odds with the current wave of open access retail
   and RTO's in the United States on both ends of the spectrum-too fast and
   too slow. hundreds payment
   And now enter stage right, FERC Order 2000 on the heels of FERC Order
   888 and 889. The variety of responses around the United States is
   reflecting the entire spectrum of self-interests, and this is just the
   beginning. Based on a voluntary compliance policy, the order requires
   the now familiar minimum characteristic of independence, scope acid
   regional configuration, operational authority, and short-term
   reliability, and the minimum functions of tariff administration and
   design, congestion management, parallel path flow, ancillary services,
   OASIS/TTC/ATC, marker monitoring, planning and expansion, and
   interregional coordination.
   With the monolithic California ISO and PX to the South, and with the
   dominant BPA in the North providing the organizational bookends in the
   West, the five most important transmission issues in the region will
   clearly involve them. But just as true is that the five most important
   issues in April of 2000 will not be the five most important issues in
   July of 2000. The speed of evolution or revolution continues to
   increase, and meetings which were monthly, are now weekly or daily. So
   the difference in issues between now and the summer will be, by itself,
   instructive as to both the process and content as we move forward.}},
ISBN = {{0-7803-6420-1}},
Unique-ID = {{ISI:000089398700283}},
}

@article{ ISI:000082184200004,
Author = {Barb, CR and Barrett, JB and Kraeling, RR and Rampacek, GB},
Title = {{Role of leptin in modulating neuroendocrine function: A metabolic link
   between the brain-pituitary and adipose tissue}},
Journal = {{REPRODUCTION IN DOMESTIC ANIMALS}},
Year = {{1999}},
Volume = {{34}},
Number = {{3-4}},
Pages = {{111-125}},
Month = {{AUG}},
Abstract = {{The recently discovered 16 kD protein, leptin, consists of 146 amino
   acids, is synthesized and secreted by adipose tissue, and impacts feed
   intake and the neuroendocrine-axis. Leptin was first identified as the
   gene product found deficient in the obese ob/ob mouse. Leptin, in the
   rodent, serves as a circulating signal of nutritional status and plays a
   pivotal role in regulation of body weight, energy expenditure, growth,
   and reproduction. Information regarding the effect of nutrition on serum
   leptin concentrations and subsequent luteinizing hormone (LH) and growth
   hormone (GH) secretion in domestic animals is limited. In the pig, serum
   leptin concentrations decreased by hr 24 of a 28 hr fast with no change
   in subcutaneous back fat thickness. However, plasma glucose and serum
   insulin concentrations were lower in fasted animals compared to fed
   controls. To examine the effects of metabolic fuel restriction on LH, GH
   and leptin secretion, ovariectomized (OVX) prepuberal gilts were treated
   with 2-deoxy-D-glucose (2DG), a competitive inhibitor of glycolysis.
   Mean serum GH concentrations increased and LH pulse frequency decreased
   after i.v. administration of 300 mg/kg body weight of 2DG. However,
   serum leptin concentrations were not changed by 2DG treatment. These
   results demonstrate that the effects of acute energy deprivation on LH
   and GH secretion are independent of changes in serum leptin
   concentrations. Serum leptin concentrations increased with age in the
   intact prepuberal gilt. Ln addition, estradiol-induced leptin mRNA
   expression was age and weight dependent in the OVX prepuberal gilt. This
   increase occurred at the time of expected puberty in intact
   contemporaries and was associated with greater LH secretion. These data
   suggest that leptin may serve as a signal for the onset of puberty.
   Moreover, leptin receptor mRNA was localized in the hypothalamus and
   anterior pituitary of the pig, suggesting that leptin could act at the
   brain and(or) pituitary to regulate LH and GH secretion. In addition,
   leptin stimulated GnRH release from hypothalamic tissue in vitro.
   Studies with pig anterior pituitary cells in culture demonstrated that
   leptin treatment enhanced basal LH and GH secretion and suppressed
   gonadotropin releasing hormone (GnRH) and growth hormone releasing
   hormone (GHRH) induced increase in LH and GH secretion. Furthermore,
   intracerebroventricular (ICV) administration of leptin suppressed feed
   intake and stimulated GH but failed to alter LH secretion in the intact
   prepuberal gilt. Hypothalamic neuropeptide Y (NPY) is responsive to
   changes in energy balance and serum leptin concentrations in rodents.
   ICV administration of NPY suppressed LH secretion and increased GH
   secretion in the OVX pig. Thus, leptin/NPY may be an important link
   between metabolic status, the neuroendocrine system, growth, and
   reproductive processes.}},
DOI = {{10.1111/j.1439-0531.1999.tb01228.x}},
ISSN = {{0936-6768}},
Unique-ID = {{ISI:000082184200004}},
}

@article{ ISI:A1994PF76800001,
Author = {FERENC, K},
Title = {{DIAGNOSIS AND TREATMENT OF HEPATIC DISEASES OF DOGS - COMPILATORY
   ACCOUNT}},
Journal = {{MAGYAR ALLATORVOSOK LAPJA}},
Year = {{1994}},
Volume = {{49}},
Number = {{8}},
Pages = {{453-459}},
Month = {{AUG}},
Abstract = {{Diagnosis:  Hepatic diseases of dogs can practically not be diagnosd
   with certainty by physical examination methods, especially in the early
   or subclinical stage of the diseases.  Instrumental complementary
   examinations - X-ray, ultrasonography, laparoscopy - give information
   about the morphological changes.  Pathological changes in the hepatic
   function can be detected by chemical laboratory methods.
   Increase of the total bilirubin level of blood plasma indicates a
   subclinical icterus.  Of the hepatic enzymes, the activity of liver
   specific ALT increases even in case of mild hepatic changes.  AP is less
   liver specific, however it is also positive in case of chronic processes
   and portocaval shunt.  Increase of GLDH occurs in case of hepatic tissue
   destruction.  Activity of GGT increases in case of cholestasis and
   cholangitis.  Of the examinations of hepatic functions, the
   bromsulphalein test is reliable.  Increase of total bile acid level
   indicates specifically and unanimously the deterioration of the
   excreting and conjugating possibility of liver.  The ammonia tolerance
   test serves, first of all for the diagnosis of portocaval shunts.
   The simultaneous determination of ALT, AP and total bilirubin level is
   advisable:  when none of the levels increases above the physiological
   limit value, it is highly probable that the dog does not suffer from any
   hepatopathy.
   Treatment:  In case of an acute hepatic disease, elimination of the
   cause of disease, keeping alive the patient up to the start of hepatic
   regeneration by symptomatic treatment and promotion of regeneration are
   the main goals.  In case of chronic hepatopathies, it is necessary to
   endeavor to inhibit the deterioration of the progress of disease, to
   diminish the consequences of the deficit in the hepatic function.  In
   case of complex hepatoprotective therapy, a special care should be taken
   of the prevention of physical loading of patients.  It should also be
   stopped the administration of the formerly given, negligible
   medicaments.  Diet of the hepatopaths is a feed rich in energy, poor in
   protein and fat, and contains easily digestible carbohydrates.  In the
   field of medication, the administration of isotonic salines, as well as
   glucose infusions should be emphasized.  Parenteral administration of
   larger amounts of glucose (1 to 2 g/body-mass kg/day) serves also for
   energy substitution.
   Parenteral antibiotic treatment is useful for the thinning of the
   hepatic bacterial flora while the oral application of the intestinal
   bacteria.  Supplementation of vitamins B is an obligate part of
   medication; it is also often necessary to give vitamin K.  The
   administration of glutaminic acid + arginin infusion can be used for the
   treatment of hepatic coma, while lactulose syrup in case of acute
   hepatopathies.  Glucocorticoids can be applied as antiphlogistic, for
   the prevention of shock and as roborant.  The carefulness is reasonable
   because they can cause a steroidhepatopathy.
   Lipotropic medicaments, liver extracts do not belong to the effective
   medicaments in case of hepatic diseases of dogs.}},
ISSN = {{0025-004X}},
Unique-ID = {{ISI:A1994PF76800001}},
}

@article{ ISI:A1993LW01600003,
Author = {GEY, FC},
Title = {{INFORMATION DISTRIBUTION PRACTICES OF FEDERAL STATISTICAL AGENCIES - THE
   CENSUS BUREAU EXAMPLE}},
Journal = {{GOVERNMENT INFORMATION QUARTERLY}},
Year = {{1993}},
Volume = {{10}},
Number = {{3}},
Pages = {{319-330}},
Abstract = {{U.S. government agencies collect statistical data either under a
   Constitutional mandate (as in the case of the decennial census) or by
   legislative mandate or administrative decree. The preeminent example is
   the Bureau of the Census which, for the 1990 decennial census, collected
   and distributed some 50 gigabytes (the equivalent of over 100 CD-ROMs)
   of data, if digitized map boundaries are included. Some major agencies
   producing public statistics include the Bureau of Labor Statistics,
   Social Security Administration, Bureau of Economic Analysis, Energy
   Information Administration, Departments of Education and Agriculture,
   and National Center for Health Statistics. The pricing and distribution
   practices of these agencies vary widely, with some agencies encouraging
   widespread distribution of data and others looking on distribution to
   the public as not within their mandate. This article elucidates issues
   of reasonable distribution policies and adaptation to technological
   change of such agencies by focusing on the distribution activities, both
   currently and historically, of the Bureau of the Census.}},
DOI = {{10.1016/0740-624X(93)90016-S}},
ISSN = {{0740-624X}},
Unique-ID = {{ISI:A1993LW01600003}},
}

@article{ ISI:000352217000005,
Author = {Alcaraz, Raul and Martinez, Arturo and Rieta, Jose J.},
Title = {{Role of the P-wave high frequency energy and duration as noninvasive
   cardiovascular predictors of paroxysmal atrial fibrillation}},
Journal = {{COMPUTER METHODS AND PROGRAMS IN BIOMEDICINE}},
Year = {{2015}},
Volume = {{119}},
Number = {{2}},
Pages = {{110-119}},
Month = {{APR}},
Abstract = {{A normal cardiac activation starts in the sinoatrial node and then
   spreads throughout the atrial myocardium, thus defining the P-wave of
   the electrocardiogram. However, when the onset of paroxysmal atrial
   fibrillation (PAF) approximates, a highly disturbed electrical activity
   occurs within the atria, thus provoking fragmented and eventually longer
   P-waves. Although this altered atrial conduction has been successfully
   quantified just before PAF onset from the signal-averaged P-wave
   spectral analysis, its evolution during the hours preceding the
   arrhythmia has not been assessed yet. This work focuses on quantifying
   the P-wave spectral content variability over the 2 h preceding PAF onset
   with the aim of anticipating as much as possible the arrhythmic episode
   envision. For that purpose, the time course of several metrics
   estimating absolute energy and ratios of high- to low-frequency power in
   different bands between 20 and 200 Hz has been computed from the P-wave
   autoregressive spectral estimation. All the analyzed metrics showed an
   increasing variability trend as PAF onset approximated, providing the
   P-wave high-frequency energy (between 80 and 150 Hz) a diagnostic
   accuracy around 80\% to discern between healthy subjects, patients far
   from PAF and patients less than 1 h close to a PAF episode. This
   discriminant power was similar to that provided by the most classical
   time-domain approach, i.e., the P-wave duration. Furthermore, the linear
   combination of both metrics improved the diagnostic accuracy up to
   88.07\%, thus constituting a reliable noninvasive harbinger of PAF onset
   with a reasonable anticipation. The information provided by this
   methodology could be very useful in clinical practice either to optimize
   the antiarrhythmic treatment in patients at high-risk of PAF onset and
   to limit drug administration in low risk patients. (C) 2015 Elsevier
   Ireland Ltd. All rights reserved.}},
DOI = {{10.1016/j.cmpb.2015.01.006}},
ISSN = {{0169-2607}},
EISSN = {{1872-7565}},
Unique-ID = {{ISI:000352217000005}},
}

@article{ ISI:000333753300004,
Author = {Desrois, Martine and Kober, Frank and Lan, Carole and Dalmasso,
   Christiane and Cole, Mark and Clarke, Kieran and Cozzone, Patrick J. and
   Bernard, Monique},
Title = {{Effect of isoproterenol on myocardial perfusion, function, energy
   metabolism and nitric oxide pathway in the rat heart -a longitudinal MR
   study}},
Journal = {{NMR IN BIOMEDICINE}},
Year = {{2014}},
Volume = {{27}},
Number = {{5}},
Pages = {{529-538}},
Month = {{MAY}},
Abstract = {{The chronic administration of the -adrenoreceptor agonist isoproterenol
   (IsoP) is used in animals to study the mechanisms of cardiac hypertrophy
   and failure associated with a sustained increase in circulating
   catecholamines. Time-dependent changes in myocardial blood flow (MBF),
   morphological and functional parameters were assessed in rats in vivo
   using multimodal cardiac MRI. Energy metabolism, oxidative stress and
   the nitric oxide (NO) pathway were evaluated in isolated perfused rat
   hearts following 7 days of treatment. Male Wistar rats were infused for
   7 days with IsoP or vehicle using osmotic pumps. Cine-MRI and arterial
   spin labeling were used to determine left ventricular morphology,
   function and MBF at days 1, 2 and 7 after pump implantation. Isolated
   hearts were then perfused, and high-energy phosphate compounds and
   intracellular pH were followed using P-31 MRS with simultaneous
   measurement of contractile function. Total creatine and malondialdehyde
   (MDA) contents were measured by high-performance liquid chromatography.
   The NO pathway was evaluated by NO synthase isoform expression and total
   nitrate concentration (NOx). In IsoP-treated rats, left ventricular mass
   was increased at day 1 and maintained. Wall thickness was increased with
   a peak at day 2 and a tendency to return to baseline values at day 7.
   MBF was markedly increased at day 1 and returned to normal values
   between days 1 and 2. The rate-pressure product and
   phosphocreatine/adenosine triphosphate ratio in perfused hearts were
   reduced. MDA, endothelial NO synthase expression and NOx were increased.
   Sustained high cardiac function and normal MBF after 24 h of IsoP
   infusion indicate imbalance between functional demand and blood flow,
   leading to morphological changes. After 1 week, cardiac hypertrophy and
   decreased function were associated with impaired phosphocreatine,
   increased oxidative stress and up-regulation of the NO pathway. These
   results provide supplemental information on the evolution of the
   different contributing factors leading to morphological and functional
   changes in this model of cardiac hypertrophy and failure. Copyright (c)
   2014 John Wiley \& Sons, Ltd.}},
DOI = {{10.1002/nbm.3088}},
ISSN = {{0952-3480}},
EISSN = {{1099-1492}},
Unique-ID = {{ISI:000333753300004}},
}

@inproceedings{ ISI:000349875400039,
Author = {Clark, Corrie and Harto, Christopher},
Book-Group-Author = {{ASME}},
Title = {{LIFECYCLE WATER CONSUMPTION OF GEOTHERMAL POWER SYSTEMS}},
Booktitle = {{PROCEEDINGS OF THE ASME POWER CONFERENCE, 2013, VOL 2}},
Year = {{2014}},
Note = {{ASME Power Conference 2013, Boston, MA, JUL 29-AUG 01, 2013}},
Organization = {{ASME, Power Div}},
Abstract = {{Previous assessments of the sustainability of geothermal energy have
   focused on resource management and associated environmental impacts
   during plant operations. Within these constraints, studies have shown
   that overall emissions, water consumption, and land use for geothermal
   electricity production have a smaller impact than traditional base-load
   electricity generation technologies. According to the Energy Information
   Administration (ETA) of the U.S. Department of Energy (DOE), geothermal
   energy generation in the United States is projected to increase nearly
   threefold, from 2.37 GW to 6.30 GW, by 2035 (ETA 2012). With this
   potential for significant growth in geothermal electricity production,
   there is a need to improve understanding of the environmental impacts
   across the life cycle of geothermal energy production systems.
   This paper assesses the use of freshwater in construction, drilling, and
   production activities of various geothermal power plants. Four
   geothermal technologies were evaluated: air-cooled enhanced geothermal
   systems (EGSs), air-cooled hydrothermal binary systems,
   evaporative-cooled hydrothermal flash systems, and air-cooled
   geopressured systems that coproduce natural gas. The impacts associated
   with these power plant scenarios are compared to those from other
   electricity generating technologies as part of a larger effort to
   compare the lifecycle impacts of geothermal electricity generation to
   other power generation technologies.}},
Article-Number = {{V002T10A002}},
ISBN = {{978-0-7918-5606-2}},
Unique-ID = {{ISI:000349875400039}},
}

@article{ ISI:000294645500005,
Author = {Lupion, M. and Nauarrete, B. and Otero, P. and Cortes, V. J.},
Title = {{Experimental programme in CIUDEN's CO2 capture technology development
   plant for power generation}},
Journal = {{CHEMICAL ENGINEERING RESEARCH \& DESIGN}},
Year = {{2011}},
Volume = {{89}},
Number = {{9, SI}},
Pages = {{1494-1500}},
Month = {{SEP}},
Abstract = {{Energy projections made by the World Energy Council, the International
   Energy Agency (LEA) and the US Energy Information Administration give
   similar pictures of the dominant role of fossil fuel in the future
   primary energy global demand and the necessity of incorporating CCS
   Technologies as part of the portfolio of solutions to reach the target
   world emission reduction in the coming years. Without CCS, CO2 emission
   levels by 2050 are expected to increase by 70\%.
   One of the most relevant initiatives for the deployment of CCS
   technologies is promoted by the Spanish Government through the
   institution Fundacion Ciudad de la Energia (CIUDEN).
   CIUDEN is developing a complete programme focusing on the development of
   CCT and CCS technologies in Europe. CIUDEN's CO2 capture programme
   includes the construction and operation of a Technology Development
   Plant (TDP) in NW Spain (El Bierzo). The construction of the
   installation started in November 2008 and incorporates the following
   technologies: fuel preparation system, pulverised coal boiler (20 MWth),
   circulating fluidized bed boiler (30 MWth), biomass gasifier (3 MWth),
   flue gas cleaning train for NOx dust and SOx, and CO2 processing unit.
   This paper describes CIUDEN's TDP for CO2 capture, focusing on the
   particularities of the installation and design, and especially on the PC
   unit and equipment required for its operation. The experimental
   programme currently under way is also described.
   Results are expected to be an extraordinary advance in the development
   and strengthening of CCT and CCS technologies, particularly
   oxycombustion. (C) 2010 The Institution of Chemical Engineers. Published
   by Elsevier B.V. All rights reserved.}},
DOI = {{10.1016/j.cherd.2010.10.017}},
ISSN = {{0263-8762}},
ResearcherID-Numbers = {{Lupion, Monica/L-8430-2014
   Navarrete Rubia, Benito/}},
ORCID-Numbers = {{Lupion, Monica/0000-0002-7365-9565
   Navarrete Rubia, Benito/0000-0003-0742-7878}},
Unique-ID = {{ISI:000294645500005}},
}

@article{ ISI:000286551900002,
Author = {Legge, M. and Jones, L. M. and McLeod, B. J.},
Title = {{Energy substrate utilization in the common brushtailed possum
   (Trichosurus vulpecula) using intravenous tolerance tests}},
Journal = {{COMPARATIVE BIOCHEMISTRY AND PHYSIOLOGY B-BIOCHEMISTRY \& MOLECULAR
   BIOLOGY}},
Year = {{2011}},
Volume = {{158}},
Number = {{2}},
Pages = {{132-135}},
Month = {{FEB}},
Abstract = {{The aim of this study was to investigate the energy substrate
   requirements of the common brushtailed possum (Trichosurus vulpecula)
   using intravenous tolerance tests for glucose, alanine, and propionate
   in five adult male and female animals under standardized conditions.
   Significant differences (p<0.01) were observed for fasting blood glucose
   values between males (6.3 +/- 0.16 mmol L(-1)) and females (4.8 +/- 0.13
   mmol L(-1)), and males had a significantly (p<0.001) increased response
   to glucose. All animals returned to fasting glucose levels within 120
   min after the glucose challenge. No significant change in blood glucose
   levels was observed for either the alanine or propionate tolerance tests
   (p>0.05). However, following propionate administration, there was a
   highly significant (p<0.001) decrease in blood lactate concentrations
   over 120 min. There was no evidence of ketone formation using
   beta-hydroxybutyrate as a biomarker during any of the tests, indicating
   that there was no significant switch to lipolysis. In conclusion, the
   study provides new information on energy substrate utilization in this
   species and has identified that a gluconeogenic response normally
   identified in other species is not apparent in the common brushtailed
   possum. (C) 2010 Elsevier Inc. All rights reserved.}},
DOI = {{10.1016/j.cbpb.2010.10.007}},
ISSN = {{1096-4959}},
Unique-ID = {{ISI:000286551900002}},
}

@inproceedings{ ISI:000299096403140,
Author = {Li Guangyu and Zhou Kefa and Sun Li and Wang Jinlin and Wang Qianfeng},
Editor = {{Zhou, X}},
Title = {{Regional Eco-Environmental Information Service System Based on Open
   Source Projects}},
Booktitle = {{2011 INTERNATIONAL CONFERENCE ON ENERGY AND ENVIRONMENTAL SCIENCE-ICEES
   2011}},
Series = {{Energy Procedia}},
Year = {{2011}},
Volume = {{11}},
Pages = {{3892-3898}},
Note = {{International Conference on Energy and Environmental Science (ICEES),
   Singapore, SINGAPORE, OCT, 2011}},
Organization = {{Singapore Inst Electron}},
Abstract = {{In arid area of western China, due to harsh natural conditions,
   ecosystems are less stable and easily affected by human activities. In
   recent decades, significant amount of research on the impact of human
   activity on environmental change in arid areas have been done. Though no
   particular conclusions were drawn, a number of eco-environmental data
   were accumulated. For lack of effective means of sharing, these data
   exit in form of ``Information Island{''}. To use the data more
   efficiently, a WebGIS prototype for regional eco-environment service
   system is constructed using open source software such as PostgreSQL,
   PostGIS, GeoServer, OpenLayers and etc. Implementation techniques,
   system function and key procedures were also described. This system, of
   high practical value, will be able to provide the public, scientists,
   and administration with convenient and rapid access to eco-environmental
   information. (C) 2011 Published by Elsevier Ltd. Selection and/or
   peer-review under responsibility of the Organizers of 2011 International
   Conference on Energy and Environmental Science.}},
DOI = {{10.1016/j.egypro.2011.10.774}},
ISSN = {{1876-6102}},
Unique-ID = {{ISI:000299096403140}},
}

@article{ ISI:000255222800012,
Author = {Gupta, Pawan and Patadia, Falguni and Christopher, Sundar A.},
Title = {{Multisensor data product fusion for aerosol research}},
Journal = {{IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING}},
Year = {{2008}},
Volume = {{46}},
Number = {{5}},
Pages = {{1407-1415}},
Month = {{MAY}},
Abstract = {{Combining data sets from multiple satellite sensors is a powerful method
   for studying Earth-atmosphere problems. By fusing data, we can utilize
   the strengths of the individual sensors that may not be otherwise
   possible. In this paper, we provide the framework for combining level 2
   data products, using data from three sensors aboard the National
   Aeronautics and Space Administration (NASA)'s Terra satellite. These
   data include top-of-the-atmosphere (TOA) radiative energy fluxes
   obtained from the Clouds and the Earth's Radiant Energy System (CERES),
   aerosol optical thickness from the multispectral Moderate Resolution
   Imaging Spectroradiometer (MODIS), and aerosol properties from the
   Multi-angle Imaging SpectroRadiometer (MISR). The CERES Single Scanner
   Footprint (SSF) contains the pixel level CERES TOA fluxes and the level
   2 MODIS aerosol data. We specifically focus upon fusing the CERES SSF
   with the MISR aerosol products. Although this project was undertaken
   specifically to address aerosol research, the methods employed for
   fusing data products can be used for other problems requiring
   synergistic data sets. We present selected case studies over different
   aerosol regimes and indicate that multisensor information provides
   value-added information for aerosol research that is not available from
   a single sensor.}},
DOI = {{10.1109/TGRS.2008.916087}},
ISSN = {{0196-2892}},
ResearcherID-Numbers = {{Gupta, Pawan/F-3624-2011
   Christopher, Sundar/E-6781-2011}},
Unique-ID = {{ISI:000255222800012}},
}

@inproceedings{ ISI:000256952700048,
Author = {Pichugina, Y. L. and Banta, R. M. and Kelley, N. D. and Brewer, W. A.
   and Sandberg, S. P. and Machol, J. L. and Jonkman, B. J.},
Editor = {{Mann, J and Bingol, F and Courtney, M and Jorgensen, HE and Lindelow, P and Mikkelsen, T and Pena, A and Sjoholm, M and Wagner, R}},
Title = {{Remote sensing of the nocturnal boundary layer for Wind Energy
   applications}},
Booktitle = {{14TH INTERNATIONAL SYMPOSIUM FOR THE ADVANCEMENT OF BOUNDARY LAYER
   REMOTE SENSING}},
Series = {{IOP Conference Series Earth and Environmental Science}},
Year = {{2008}},
Volume = {{1}},
Pages = {{U387-U396}},
Note = {{14th International Symposium for the Advancement of Boundary Layer
   Remote Sensing, Tech Univ Denmark, Copenhagen, DENMARK, JUN 23-25, 2008}},
Abstract = {{The fine temporal and spatial resolution of Doppler lidar observations
   has been highly effective in the study of wind and turbulence dynamic in
   the nocturnal boundary layer during Lamar Low-Level Project in 2003. The
   High-Resolution Doppler Lidar (HRDL), designed and developed at the
   National Oceanic and Atmospheric Administration (NOAA) Earth System
   Research Laboratory (ESRL), measures range-resolved profiles of line-of
   sight (LOS) Doppler velocity and aerosol backscatter with a pulse
   repetition frequency of 200 Hz, velocity precision about 10 cm s(-1),
   and a very narrow beam width. The majority of the lidar-measured wind
   speed and variance profiles were derived using a vertical-scan mode and
   the application of a vertical binning technique. The profile data were
   used to calculate quantities important for wind energy applications,
   including turbulence intensity, wind and directional shear through the
   layer of the turbine rotor. Profiles of all quantities show a strong
   variation with height. The mean wind fields, the turbulence, and
   turbulence intensities show a good agreement with sonic anemometer sodar
   high confidence (high SNR) measurements. The ability of HRDL to provide
   continuous information about wind and turbulence conditions at the
   turbine height and above the range of the tower measurements made HRDL
   as a powerful instrument for studies of the nighttime boundary layer
   features. Such information is needed as turbine rotors continue to rise
   higher into the boundary layer.}},
ISSN = {{1755-1307}},
ResearcherID-Numbers = {{Sandberg, Scott/I-4875-2013}},
Unique-ID = {{ISI:000256952700048}},
}

@article{ ISI:000242033900069,
Author = {Wong-Parodi, Gabrielle and Dale, Larry and Lekov, Alex},
Title = {{Comparing price forecast accuracy of natural gas models and futures
   markets}},
Journal = {{ENERGY POLICY}},
Year = {{2006}},
Volume = {{34}},
Number = {{18}},
Pages = {{4115-4122}},
Month = {{DEC}},
Abstract = {{The purpose of this article is to compare the accuracy of forecasts for
   natural gas prices as reported by the Energy Information
   Administration's short-term energy outlook (STEO) and the futures market
   for the period from 1998 to 2004. The analysis tabulates the existing
   data and develops a statistical comparison of the error between STEO and
   US wellhead natural gas prices and between Henry Hub and US wellhead
   spot prices. The results indicate that, on average, Henry Hub is a
   slightly better predictor of natural gas prices with an average error of
   -0.52 and a standard deviation of 1.25 than STEO with an average error
   of -0.83 and a standard deviation of 1.34. In addition. the results
   reveal that during the 13-24 months of the 2-year ahead forecast, STEO
   is a biased predictor of natural gas prices. This analysis suggests that
   as the futures market continues to report longer forward prices
   (currently out to 5 years), it may be of interest to economic modelers
   to compare the accuracy of their models to the futures market. The
   authors would especially like to thank Doug Hale of the Energy
   Information Administration for supporting and reviewing this work.
   Published by Elsevier Ltd.}},
DOI = {{10.1016/j.enpol.2005.08.013}},
ISSN = {{0301-4215}},
Unique-ID = {{ISI:000242033900069}},
}

@article{ ISI:000240087400014,
Author = {Cummings, David E.},
Title = {{Ghrelin and the short- and long-term regulation of appetite and body
   weight}},
Journal = {{PHYSIOLOGY \& BEHAVIOR}},
Year = {{2006}},
Volume = {{89}},
Number = {{1}},
Pages = {{71-84}},
Month = {{AUG 30}},
Note = {{3rd Food Summit Meeting on Making Sense of Food, Wageningen,
   NETHERLANDS, DEC, 2005}},
Organization = {{Wageningen Ctr Food Sci}},
Abstract = {{Ghrelin, an acylated upper gastrointestinal peptide, is the only known
   orexigenic hormone. Considerable evidence implicates ghrelin in mealtime
   hunger and meal initiation. Circulating levels decrease with feeding and
   increase before meals, achieving concentrations sufficient to stimulate
   hunger and food intake. Preprandial ghrelin surges occur before every
   meal on various fixed feeding schedules and also among individuals
   initiating meals voluntarily without time- or food-related cues. Ghrelin
   injections stimulate food intake rapidly and transiently, primarily by
   increasing appetitive feeding behaviors and the number of meals.
   Preprandial ghrelin surges are probably triggered by sympathetic nervous
   output. Postprandial suppression is not mediated by nutrients in the
   stomach or duodenum, where most ghrelin is produced. Rather, it results
   from post-ingestive increases in lower intestinal osmolarity
   (information probably relayed to the foregut via enteric nervous
   signaling), as well as from insulin surges. Consequently, ingested
   lipids suppress ghrelin poorly compared with other macronutrients.
   Beyond a probable role in meal initiation, ghrelin also fulfills
   established criteria for an adiposity-related hormone involved in
   long-term body-weight regulation. Ghrelin levels circulate in relation
   to energy stores and manifest compensatory changes in response to
   body-weight alterations. Ghrelin crosses the bloodbrain barrier and
   stimulates food intake by acting on several classical body-weight
   regulatory centers, including the hypothalamus, hindbrain, and
   mesolimbic reward system. Chronic ghrelin administration increases body
   weight via diverse, concerted actions on food intake, energy
   expenditure, and fuel utilization. Congenital ablation of the ghrelin or
   ghrelin-receptor gene causes resistance to diet-induced obesity, and
   pharmacologic ghrelin blockade reduces food intake and body weight.
   Ghrelin levels are high in Prader-Willi syndrome and low after gastric
   bypass surgery, possibly contributing to body-weight alterations in
   these settings. Extant evidence favors roles for ghrelin in both
   short-term meal initiation and long-term energy homeostasis, making it
   an attractive target for drugs to treat obesity and/or wasting
   disorders. (c) 2006 Elsevier Inc. All rights reserved.}},
DOI = {{10.1016/j.physbeh.2006.05.022}},
ISSN = {{0031-9384}},
Unique-ID = {{ISI:000240087400014}},
}

@article{ ISI:000203004800003,
Author = {Haq, Zia and Easterly, James L.},
Title = {{Agricultural residue availability in the United States}},
Journal = {{APPLIED BIOCHEMISTRY AND BIOTECHNOLOGY}},
Year = {{2006}},
Volume = {{129}},
Number = {{1-3}},
Pages = {{3-21}},
Month = {{MAR}},
Abstract = {{The National Energy Modeling System (NEMS) is used by the Energy
   Information Administration (EIA) to forecast US energy production,
   consumption, and price trends for a 25-yr-time horizon. Biomass is one
   of the technologies within NEMS, which plays a key role in several
   scenarios. An endogenously determined biomass supply schedule is used to
   derive the price-quantity relationship of biomass. There are four
   components to the NEMS biomass supply schedule including: agricultural
   residues, energy crops, forestry residues, and urban wood waste/mill
   residues. The EIA's Annual Energy Outlook 2005 includes updated
   estimates of the agricultural residue portion of the biomass supply
   schedule. The changes from previous agricultural residue supply
   estimates include: revised assumptions concerning corn stover and wheat
   straw residue availabilities, inclusion of non-corn and non-wheat
   agricultural residues ( such as barley, rice straw, and sugarcane
   bagasse), and the implementation of assumptions concerning increases in
   no-till farming. This article will discuss the impact of these changes
   on the supply schedule.}},
DOI = {{10.1385/ABAB:129:1:3}},
ISSN = {{0273-2289}},
Unique-ID = {{ISI:000203004800003}},
}

@article{ ISI:000234053500032,
Author = {Yi, CX and van der Vliet, J and Dai, JP and Yin, GF and Ru, LQ and
   Buijs, RM},
Title = {{Ventromedial arcuate nucleus communicates peripheral metabolic
   information to the suprachiasmatic nucleus}},
Journal = {{ENDOCRINOLOGY}},
Year = {{2006}},
Volume = {{147}},
Number = {{1}},
Pages = {{283-294}},
Month = {{JAN}},
Abstract = {{The arcuate nucleus (ARC) is crucial for the maintenance of energy
   homeostasis as an integrator of long- and short-term hunger and satiety
   signals. The expression of receptors for metabolic hormones, such as
   insulin, leptin, and ghrelin, allows ARC to sense information from the
   periphery and signal it to the central nervous system. The ventromedial
   ARC (vmARC) mainly comprises orexigenic neuropeptide agouti-related
   peptide and neuropeptide Y neurons, which are sensitive to circulating
   signals. To investigate neural connections of vmARC within the central
   nervous system, we injected the neuronal tracer cholera toxin B into
   vmARC. Due to variation of injection sites, tracer was also injected
   into the subependymal layer of the median eminence (seME), which showed
   similar projection patterns as the vmARC. We propose that the vmARC
   forms a complex with the seME, their reciprocal connections with
   viscerosensory areas in brain stem, and other circumventricular organs,
   suggesting the exchange of metabolic and circulating information. For
   the first time, the vmARC-seME was shown to have reciprocal interaction
   with the suprachiasmatic nucleus (SCN). Activation of vmARC neurons by
   systemic administration of the ghrelin mimetic GH-releasing peptide-6
   combined with SCN tracing showed vmARC neurons to transmit feeding
   related signals to the SCN. The functionality of this pathway was
   demonstrated by systemic injection of GH-releasing peptide-6, which
   induced Fos in the vmARC and resulted in a reduction of about 40\% of
   early daytime Fos immunoreactivity in the SCN. This observation suggests
   an anatomical and functional pathway for peripheral hormonal feedback to
   the hypothalamus, which may serve to modulate the activity of the SCN.}},
DOI = {{10.1210/en.2005-1051}},
ISSN = {{0013-7227}},
ResearcherID-Numbers = {{Yi, Chun-Xia/G-3667-2012}},
Unique-ID = {{ISI:000234053500032}},
}

@article{ ISI:000220477000034,
Author = {Divan, D and Luckjiff, GA and Brumsickle, WE and Freeborg, J and
   Bhadkamkar, A},
Title = {{A grid information resource for nationwide real-time power monitoring}},
Journal = {{IEEE TRANSACTIONS ON INDUSTRY APPLICATIONS}},
Year = {{2004}},
Volume = {{40}},
Number = {{2}},
Pages = {{699-705}},
Month = {{MAR-APR}},
Note = {{Annual Meeting of the Industry-Applications-Society, PITTSBURGH, PA, OCT
   13-18, 2002}},
Organization = {{Ind Applicat Soc}},
Abstract = {{A significant barrier to improving the power quality at industrial
   facilities is the lack of contemporaneous and historical power quality
   and reliability data. A new Web-enabled near-real-time power quality and
   reliability monitoring system, termed I-Grid, has been developed to
   provide such information on a nationwide basis. The ultralow-cost
   sensors record power events and send event data via the Internet to the
   system database servers using an internal modem. Data display, e-mail
   event notification, site administration, and summary reporting of the
   data are achieved via a Web browser. In cooperation with the U.S.
   Department of Energy, the Electric Power Research Institute, and leading
   utilities and manufacturers, the deployment of these sensors has begun,
   with a target deployment of 50 000 monitors across the U.S. and Canada
   over the next 2-4 years. This paper discusses the implementation of this
   grid information resource, and discusses data captured by the network
   since early monitors were deployed in 2001.}},
DOI = {{10.1109/TIA.2004.824503}},
ISSN = {{0093-9994}},
Unique-ID = {{ISI:000220477000034}},
}

@inproceedings{ ISI:000188096400002,
Author = {Saricks, C and Vyas, AD and Stodolsky, F and Maples, JD},
Book-Group-Author = {{TRB
   TRB}},
Title = {{Fuel consumption of heavy-duty trucks - Potential effect of future
   technologies for improving energy efficiency and emissions}},
Booktitle = {{ENERGY, AIR QUALITY, AND FUELS 2003: ENERGY AND ENVIRONMENT}},
Series = {{TRANSPORTATION RESEARCH RECORD}},
Year = {{2003}},
Number = {{1842}},
Pages = {{9-19}},
Note = {{82nd Annual Meeting of the Transportation-Research-Board, WASHINGTON,
   D.C., JAN 12-16, 2003}},
Organization = {{Transportat Res Board; US Dept Transportat; Bur Transportat Stat; Fed
   Aviat Adm; Fed Highway Adm; Fed Motor Carrier Safety Adm; Fed Railroad
   Adm; Fed Transit Adm; Natl Highway Traff Safety Adm; Res \& Special
   Programs Adm; NASA; USA Corps Engineers; US Coast Guard; US DOE; US EPA}},
Abstract = {{The results of an analysis of heavy-duty truck (Classes 2b through 8)
   technologies conducted to support the Energy Information
   Administration's long-term projections for energy use are summarized.
   Several technology options that have the potential to improve the fuel
   economy and emissions characteristics of heavy-duty trucks are included
   in the analysis. The technologies are grouped as those that enhance fuel
   economy and those that improve emissions. Each technology's potential
   impact on the fuel economy of heavy-duty trucks is estimated. A rough
   cost projection is also presented. The extent of technology penetration
   is estimated on the basis of truck data analyses and technical judgment.}},
ISSN = {{0361-1981}},
ISBN = {{0-309-08575-6}},
Unique-ID = {{ISI:000188096400002}},
}

@article{ ISI:000173859000007,
Author = {Rohatgi, US and Jo, JH and Lee, JC and Bari, RA},
Title = {{Impact of the nuclear option on the environment and the economy}},
Journal = {{NUCLEAR TECHNOLOGY}},
Year = {{2002}},
Volume = {{137}},
Number = {{3}},
Pages = {{252-264}},
Month = {{MAR}},
Abstract = {{The impact of the nuclear option in the national energy outlook on the
   environment and the U.S. economy is analyzed with the MARKAL-MACRO
   energy systems computer code. The base case projection by the U.S.
   Energy Information Administration is the starting point for this study.
   The possibility of license renewal of the current fleet of U.S. nuclear
   power plants is considered as well as the introduction of
   cost-competitive advanced light water reactors. Electricity energy
   sector projections for fossil fuel plants, renewable energy sources, and
   nuclear power plants are analyzed on a least cost basis. The impact of
   constraints on the emissions of greenhouse gases is included in the
   analysis. It is found that it would be economically favorable to
   introduce as many as 300 additional nuclear power plants in the United
   States by the year 2025 to meet emission constraints of limiting
   emission to the 1990 level in the years beyond 2010.}},
ISSN = {{0029-5450}},
Unique-ID = {{ISI:000173859000007}},
}

@article{ ISI:000077675200006,
Author = {Harper, EJ},
Title = {{Changing perspectives on aging and energy requirements: Aging, body
   weight and body composition in humans, dogs and cats}},
Journal = {{JOURNAL OF NUTRITION}},
Year = {{1998}},
Volume = {{128}},
Number = {{12, S}},
Pages = {{2627S-2631S}},
Month = {{DEC}},
Note = {{Waltham International Symposium on Pet Nutrition and Health in the 21st
   Century, ORLANDO, FLORIDA, MAY 26-29, 1997}},
Abstract = {{The drivers of the age-related decline in maintenance energy requirement
   in humans are primarily reduced physical activity and a decrease in
   basal metabolic rate, which is largely driven by changes in body
   composition. Most studies indicate that there is a significant loss of
   lean body mass and a concomitant increase in fat mass with advancing
   age. The causal factors appear to be changes in physical activity and a
   reduction in the activity of growth hormone. Sustained physical activity
   and/or administration of growth hormone have been shown to offset
   age-related changes in lean:fat ratios in humans and in rats. Very
   little information is available on dogs, but current data suggest that
   aging is accompanied by a decrease in lean:fat ratios. The rate and
   extent of change is similar to that observed in aging humans and it is
   assumed that the same causal factors are responsible. On this basis, it
   is likely that basal metabolic rate declines in older dogs. New evidence
   suggests that the situation is very different in cats, with no apparent
   change in lean:fat ratios with advancing age. This is probably related
   to constant activity levels throughout life and suggests that basal
   metabolic rate probably does not decrease as cats age. On the basis of
   this evidence, there is no reason to reduce energy provision to the
   majority of older cats.}},
ISSN = {{0022-3166}},
Unique-ID = {{ISI:000077675200006}},
}

@article{ ISI:000076302800004,
Author = {Edwards, C and Rousso, A and Merrill, P and Wagner, E},
Title = {{Cool code: Federal tax incentives to mitigate global warming}},
Journal = {{NATIONAL TAX JOURNAL}},
Year = {{1998}},
Volume = {{51}},
Number = {{3}},
Pages = {{465-483}},
Month = {{SEP}},
Note = {{Symposium on What Do We Mean By Taxpayer Relief, WASHINGTON, D.C., MAY
   18-19, 1997}},
Abstract = {{The Clinton Administration's fiscal year 1999 budget marks a revival of
   interest in using the federal income tax Code to influence energy
   demand. In the 1970s, Congress enacted tax incentives for energy
   conservation and alternative fuels. Now, the threat of global warming
   has again focused attention on energy use. This paper evaluates the
   proposed federal tax incentives to mitigate global warming, concluding
   that most of the government's funding for energy conservation,
   alternative fuels, and other global warming mitigation related
   expenditures is through the tax Code, rather than direct spending
   programs. The tax incentives in the Administration's budget proposal are
   best viewed as demonstration projects designed to provide information
   about the commercial potential of certain technologies, not a least cost
   method of reducing greenhouse gas emissions.}},
ISSN = {{0028-0283}},
Unique-ID = {{ISI:000076302800004}},
}

@article{ ISI:000073096800004,
Author = {Aldrich, D},
Title = {{Partners on the net: FDLP partnering to coordinate remote access to
   Internet-based government information}},
Journal = {{GOVERNMENT INFORMATION QUARTERLY}},
Year = {{1998}},
Volume = {{15}},
Number = {{1}},
Pages = {{27-38}},
Abstract = {{In June 1996, the Government Printing Office (GPO) published a plan for
   its transition to a more electronic Federal Depository Library Program
   (FDLP). This plan assumes that federal information policy requires that
   the FDLP provide permanent public access to remotely-accessible
   electronic government information products and indicates that such
   access will be provided through a network of partnerships comprised of
   the GPO, the National Archives and Records Administration (NARA),
   federal agencies, and FDLP libraries. GPO has established its first
   library partnership in this FDLP network with the University of Chicago
   at Illinois' Richard J. Daley Library and the Department of State (DOS)
   to ensure that DOS materials will be available for permanent public
   access through the FDLP. To extend the partnership network to publishing
   agencies, a partnership has been arranged with the Department of Energy
   (DOE) to ensure direct FDLP access to technical reports maintained on a
   DOE World Wide Web site.}},
DOI = {{10.1016/S0740-624X(98)90013-2}},
ISSN = {{0740-624X}},
Unique-ID = {{ISI:000073096800004}},
}

@article{ ISI:A1996UD15900005,
Author = {Bonjour, JP and Schurch, MA and Rizzoli, R},
Title = {{Nutritional aspects of hip fractures}},
Journal = {{BONE}},
Year = {{1996}},
Volume = {{18}},
Number = {{3, S}},
Pages = {{S139-S144}},
Month = {{MAR}},
Note = {{3rd International Conference on Osteoporosis, PARIS, FRANCE, OCT   20,
   1995}},
Organization = {{Hlth Council Osteoporosis}},
Abstract = {{Prevalence of malnutrition, particularly undernutrition, increases with
   advancing age, and patients with hip fracture are often particularly
   malnourished and/or undernourished. Deficiency in both micronutrients
   and macronutrients appears to be strongly implicated in the pathogenesis
   and the consequences of hip fracture in osteoporotic elderly. Such
   deficiencies can accelerate age-dependent bone loss, increase the
   propensity to fall by impairing movement coordination, and affect
   protective mechanisms that reduce the impact of falling. With respect to
   micronutrients, the most documented information concerns calcium and
   vitamin D. Studies conducted in the elderly have shown that
   administration of calcium and vitamin D can reduce femoral bone loss
   and, in institutionalized patients, lower the incidence of hip fracture,
   Besides hypovitaminosis D, deficiency in vitamin K has been suggested to
   contribute to bone fragility in patients sustaining hip fracture. As far
   as macronutrients are concerned, low protein intake appears to play a
   distinct detrimental role in the causes and complications of hip
   fracture. In a recent survey in hospitalized elderly patients, reduced
   protein intake was associated with lower femoral neck bone mineral
   density (BMD) and poor physical performance. This observation is in
   keeping with several studies in which a state of energy-protein
   malnutrition was documented in elderly patients with hip fracture. In
   these patients, in whom we detected very low femoral neck bone mineral
   density at the level of the proximal femur, the self-selected intake of
   protein and energy was insufficient during their hospital stay.
   Interestingly, the clinical outcome after hip fracture was significantly
   improved by daily oral nutritional supplement normalizing the protein
   intake, documented as a reduction in both complication rate and median
   duration of hospital stay. Further studies showed that normalization of
   the protein intake, independently of that of energy, calcium, and
   vitamin D, was responsible for this more favorable outcome, Preliminary
   data suggest that protein supplementation may also reduce further bone
   loss in elderly patients having sustained hip fracture. Increasing the
   protein intake from low to normal could act through an increase in the
   plasma level of IGF-I, a growth factor that exerts a positive effect on
   bone mass and that has been found to decrease with aging.}},
DOI = {{10.1016/8756-3282(95)00494-7}},
ISSN = {{8756-3282}},
Unique-ID = {{ISI:A1996UD15900005}},
}

@article{ ISI:A1994NH18200023,
Author = {NEHLIG, A},
Title = {{EFFECTS OF RESPIRATORY STIMULANTS ON CEREBRAL METABOLISM AND BLOOD-FLOW}},
Journal = {{BIOLOGY OF THE NEONATE}},
Year = {{1994}},
Volume = {{65}},
Number = {{3-4}},
Pages = {{258-264}},
Month = {{MAR-APR}},
Note = {{Research Colloquium on Control of Breathing during Development: Apnea of
   the Newborn and in Sudden Infant Death Syndrome, NANCY PONT MOUSSON,
   FRANCE, SEP 07-09, 1992}},
Organization = {{INSERM; NIH NICHHHD}},
Abstract = {{The cerebral metabolic and circulatory effects of the two main classes
   of respiratory stimulants used in the apnea of the newborn and premature
   infant, i.e. methylxanthines and doxapram, have not been studied in
   great detail. In adult animals and humans, methylxanthines widely
   increase cerebral metabolic rates and simultaneously decrease cerebral
   blood flow levels. Thus, these compounds are able to reset the level of
   coupling between cerebral blood flow and energy metabolism inducing a
   relative hypoperfusion at a constant metabolic rate. In neonates,
   methylxanthines induce no change in cerebral blood flow as long as the
   drop in pCO(2) related to drug administration is prevented. Information
   on doxapram effects on cerebral blood flow and metabolism is very scarse
   and limited to adult animals. Doxapram does not induce any change in
   cerebral energy metabolism and transiently decreases cerebral blood
   flow. In conclusion, it seems that the use of methylxanthines in apneic
   newborn infants fulfils a good margin of safety with respect to cerebral
   blood flow as long as no other pathology such as marked hypoxia or
   seizures is present. The use of doxapram also seems to stay in a good
   margin of safety in terms of cerebral blood flow and energy metabolism
   but many more studies are necessary to better understand the effects of
   this respiratory stimulant on cerebral functional activity.}},
ISSN = {{0006-3126}},
ResearcherID-Numbers = {{BauschBecker, Nikolaus/H-5273-2011}},
Unique-ID = {{ISI:A1994NH18200023}},
}

@inproceedings{ ISI:A1994BD83U00008,
Author = {RUTCHIK, RH},
Book-Group-Author = {{AMER STAT ASSOC}},
Title = {{Energy information administration guidelines for statistical graphs}},
Booktitle = {{AMERICAN STATISTICAL ASSOCIATION - 1994 PROCEEDINGS OF THE SECTION ON
   STATISTICAL GRAPHICS}},
Year = {{1994}},
Pages = {{48-53}},
Note = {{Annual Meeting of the American-Statistical-Association,
   Section-on-Statistical-Graphics, TORONTO, CANADA, AUG 13-18, 1994}},
Organization = {{Amer Stat Assoc, Sect Stat Graph}},
ISBN = {{1-883276-08-X}},
Unique-ID = {{ISI:A1994BD83U00008}},
}

@article{ ISI:A1994QC23500005,
Author = {SUTHERLAND, RJ},
Title = {{INCOME-DISTRIBUTION EFFECTS OF ELECTRIC UTILITY DSM PROGRAMS}},
Journal = {{ENERGY JOURNAL}},
Year = {{1994}},
Volume = {{15}},
Number = {{4}},
Pages = {{103-118}},
Abstract = {{This paper uses the Residential Energy Consumption Survey undertaken by
   the Energy Information Administration in 1990 to estimate the
   statistical association between household income and participation in
   electric utility energy conservation programs and the association
   between participation and the electricity consumption. The results
   indicate that utility rebates, energy audits, load management programs
   and other conservation measures tend to be undertaken at greater
   frequency by high income households than by low income households.
   Participants in conservation programs tend to occupy relatively new and
   energy efficient residences and undertake conservation measures other
   than utility programs, which suggests that utility sponsored programs
   are substitutes for other conservation investments. Electricity
   consumption during 1990 is not significantly less for households
   participating in utility programs than for nonparticipants, which also
   implies that utility conservation programs are displacing other
   conservation investments. Apparently, utility programs are not avoiding
   the costs of new construction and instead are transferring wealth,
   particularly to high income participating households.}},
ISSN = {{0195-6574}},
Unique-ID = {{ISI:A1994QC23500005}},
}

@article{ ISI:A1991GC27600014,
Author = {BIER, DM},
Title = {{GROWTH-HORMONE AND INSULIN-LIKE GROWTH FACTOR-I - NUTRITIONAL
   PATHOPHYSIOLOGY AND THERAPEUTIC POTENTIAL}},
Journal = {{ACTA PAEDIATRICA SCANDINAVICA}},
Year = {{1991}},
Number = {{374}},
Pages = {{119-128}},
Note = {{MILUPA NUTRITION WORKSHOP : PREVENTION AND TREATMENT OF PRIMARY
   MALNUTRITION IN DEVELOPING AND INDUSTRIALIZED COUNTRIES, CAIRO, EGYPT,
   FEB 18-20, 1990}},
Abstract = {{The growth hormone-insulin-like growth factor I axis has been
   appreciated for more than 30 years and the effects of malnutrition on
   this axis for more than 20 years. Over the last decade, advances in
   molecular biology have permitted enhanced understanding of feedback
   regulation between growth hormone and IGF-I at the gene level, including
   limited information on nutritional influences. Similarly, the
   availability of recombinant human growth hormone has allowed controlled
   clinical studies demonstrating its net anabolic actions at hypocaloric
   dietary energy intake levels and its ability to enhance height velocity
   in children with various causes of diminished growth. Although
   investigational use of recombinant IGF-I in humans has been limited, its
   actions are likely to complement those of growth hormone during periods
   of profound dietary energy deficit. From the information presented, two
   hypotheses are developed. First, recombinant IGF-I administration will
   enhance substrate anabolic events during the acutely malnourished state
   when dietary intake is severely limited. Second, administration of
   recombinant human growth hormone will accelerate protein anabolism and
   catch-up growth during the period of recovery from protein-energy
   malnutrition. Given current clinical investigational tools and the
   availability of both recombinantly-produced hormones, these are testable
   hypotheses.}},
ISSN = {{0001-656X}},
Unique-ID = {{ISI:A1991GC27600014}},
}

@article{ ISI:000353008300017,
Author = {Sanchez-Garcia, Sandra and Canga, Elena and Tolosana, Eduardo and
   Majada, Juan},
Title = {{A spatial analysis of woodfuel based on WISDOM GIS methodology:
   Multiscale approach in Northern Spain}},
Journal = {{APPLIED ENERGY}},
Year = {{2015}},
Volume = {{144}},
Pages = {{193-203}},
Month = {{APR 15}},
Abstract = {{Given the complexity of generating energy from biomass, the need has
   arisen for support tools to assist in balancing energy and forestry
   policies which are sufficiently flexible to address the issues of
   planning and management at small and large scales.
   The present study aims to adapt WISDOM GIS methodology for application
   in the autonomous region of Asturias (Northern Spain) and thereby, by
   creating a geodatabase, to contribute to a support tool for
   investigating the potential of woodfuel. This will aid the public
   administration by providing information on woodfuel supply and demand at
   the regional, municipality and site-specific level, and thus assist in
   decision making in terms of formulating new energy strategies.
   In terms of supply (t year(-1)), in this work, woodfuel from forest area
   is defined as the crown fraction only (branches and leaves), although in
   the case of Eucalyptus spp., bark is also included as it is remains
   on-site following extraction of eucalypts for the pulp industry.
   Non-Forest Direct Supply was calculated on the basis of the relevant
   categories from an agricultural land use inventory and average woodfuel
   productivity. In addition, physical and legal constraints related to
   accessibility of the woodfuel were considered, the former applying
   restriction filters with values weighted depending on the interaction
   between slope map, road networks and centres of population, and the
   latter considering legal limitations in protected areas. In addition,
   unused waste from the wood processing industry was included. To
   calculate total woodfuel demand (t year-1) for energy generation (heat
   and electricity), both the residential and industrial sector were taken
   into account.
   All data was georeferenced through Geographic Information Systems
   (GISs), which allow operations between raster maps to be performed to
   generate numeric and spatial results focusing on logistics and biomass
   strategies, depending on the inputs data and scale employed for each
   scenario considered. In addition, the application of the methodology at
   the site-specific level illustrates the practical implementation at the
   small scale of the geodatabase created, by evaluating the woodfuel
   available to feed, in case 1, a wood-fired power plant in a specific
   proposed location and, in case 2, this plant combined with a second
   plant in a different municipality, both cases also taking into
   consideration industrial demand. (C) 2015 Elsevier Ltd. All rights
   reserved.}},
DOI = {{10.1016/j.apenergy.2015.01.099}},
ISSN = {{0306-2619}},
EISSN = {{1872-9118}},
Unique-ID = {{ISI:000353008300017}},
}

@article{ ISI:000346138100002,
Author = {Von Grafenstein, Susanne and Fuchs, Julian E. and Huber, Markus M. and
   Bassi, Andrea and Lacetera, Alessandra and Ruzsanyi, Veronika and
   Troppmair, Jakob and Amann, Anton and Liedl, Klaus R.},
Title = {{Precursors for cytochrome P450 profiling breath tests from an in silico
   screening approach}},
Journal = {{JOURNAL OF BREATH RESEARCH}},
Year = {{2014}},
Volume = {{8}},
Number = {{4}},
Month = {{DEC}},
Abstract = {{The family of cytochrome P450 enzymes (CYPs) is a major player in the
   metabolism of drugs and xenobiotics. Genetic polymorphisms and
   transcriptional regulation give a complex patient-individual CYP
   activity profile for each human being. Therefore, personalized medicine
   demands easy and non-invasive measurement of the CYP phenotype. Breath
   tests detect volatile organic compounds (VOCs) in the patients' exhaled
   air after administration of a precursor molecule. CYP breath tests
   established for individual CYP isoforms are based on the detection of
   (CO2)-C-13 or (CO2)-C-14 originating from CYP-catalyzed oxidative
   degradation reactions of isotopically labeled precursors.
   We present an in silico work-flow aiming at the identification of novel
   precursor molecules, likely to result in VOCs other than CO2 upon
   oxidative degradation as we aim at label-free precursor molecules. The
   ligand-based work-flow comprises five parts: (1) CYP profiling was
   encoded as a decision tree based on 2D molecular descriptors derived
   from established models in the literature and validated against publicly
   available data extracted from the DrugBank. (2) Likely sites of
   metabolism were identified by reactivity and accessibility estimation
   for abstractable hydrogen radical. (3) Oxidative degradation reactions
   (O- and N-dealkylations) were found to be most promising in the release
   of VOCs. Thus, the CYP-catalyzed oxidative degradation reaction was
   encoded as SMIRKS (a programming language style to implement reactions
   based on the SMARTS description) to enumerate possible reaction
   products. (4) A quantitative structure property relation (QSPR) model
   aiming to predict the Henry constant H was derived from data for 488
   organic compounds and identifies potentially VOCs amongst CYP reaction
   products. (5) A blacklist of naturally occurring breath components was
   implemented to identify marker molecules allowing straightforward
   detection within the exhaled air.
   Evident oxidative degradation reactions served as test case for the
   screening approach. Comparisons to metabolism data from literature
   support the results' plausibility. Thus, a large scale screening for
   potential novel breath test precursor using the presented five stage
   work-flow is promising.}},
DOI = {{10.1088/1752-7155/8/4/046001}},
Article-Number = {{UNSP 046001}},
ISSN = {{1752-7155}},
EISSN = {{1752-7163}},
ResearcherID-Numbers = {{Liedl, Klaus/F-3099-2015}},
ORCID-Numbers = {{Liedl, Klaus/0000-0002-0985-2299}},
Unique-ID = {{ISI:000346138100002}},
}

@article{ ISI:000290181000003,
Author = {El Ouahrani, Abdeltif and Molero Mesa, Joaquin and Merzouki,
   Abderrahmane},
Title = {{Anthropogenic CO2 emissions from fossil fuels Trends and drivers in the
   Mediterranean region}},
Journal = {{INTERNATIONAL JOURNAL OF CLIMATE CHANGE STRATEGIES AND MANAGEMENT}},
Year = {{2011}},
Volume = {{3}},
Number = {{1}},
Pages = {{16-28}},
Abstract = {{Purpose - This paper aims to highlight the drivers and trends of carbon
   dioxide (CO2) emissions from fossil fuels of 21 Mediterranean countries,
   and suggest some policy recommendations to help mitigate them and
   fostering energy partnership within the studied area.
   Design/methodology/approach - Simplified Kaya identity was used to
   analyse the drivers and trends of CO2 emission from fossil fuels. Data
   used were retrieved from the US Energy Information Administration and
   Carbon Dioxide Information Analysis Centre. The analysis considers
   Northern rim countries and Southern-Eastern rim countries (SERCs) as
   separate groups, as well as all together.
   Findings - The total fossil fuel emissions between 1980 and 2005, the
   emissions growth rate in 1980s, 1990s, and 2000-2006 were assessed. The
   findings put emphasis on the drivers and trends of fuel emissions
   considering per capita emission, gross domestic product and carbon
   intensity.
   Originality/value - Despite their low contribution to global
   andiropogenic CO2 emissions (similar to 7 percent), the growing energy
   demands in the Mediterranean countries especially in the SERCs shows
   that there is an urgent and tremendous effort that needs to be addressed
   at national and regional levels in order to slow down the increasing
   emissions without impacting the development growth. This paper puts
   special emphasis on the importance of regional energy and
   climate-related frameworks as a systematic approach to endure the
   impacts of climate change through sustainable ways.}},
DOI = {{10.1108/17568691111107925}},
ISSN = {{1756-8692}},
Unique-ID = {{ISI:000290181000003}},
}

@article{ ISI:A1996VV18600005,
Author = {Crowley, B},
Title = {{Site of the month: Energy information administration}},
Journal = {{HYDROCARBON PROCESSING}},
Year = {{1996}},
Volume = {{75}},
Number = {{11}},
Pages = {{23}},
Month = {{NOV}},
ISSN = {{0018-8190}},
Unique-ID = {{ISI:A1996VV18600005}},
}

@article{ ISI:A1994NR70300017,
Author = {KENT, CA},
Title = {{MODEL EVALUATION AT THE ENERGY INFORMATION ADMINISTRATION - COMMENT}},
Journal = {{INTERFACES}},
Year = {{1994}},
Volume = {{24}},
Number = {{3}},
Pages = {{138}},
Month = {{MAY-JUN}},
ISSN = {{0092-2102}},
Unique-ID = {{ISI:A1994NR70300017}},
}

@article{ ISI:A1993LC83100001,
Author = {WEINER, JH},
Title = {{SYMPOSIUM ISSUE ON THE ENERGY INFORMATION ADMINISTRATION - FOREWORD}},
Journal = {{GOVERNMENT INFORMATION QUARTERLY}},
Year = {{1993}},
Volume = {{10}},
Number = {{1}},
Pages = {{1}},
DOI = {{10.1016/0740-624X(93)90002-H}},
ISSN = {{0740-624X}},
Unique-ID = {{ISI:A1993LC83100001}},
}

@article{ ISI:A1984TR61200005,
Author = {FARMER, RD and HARRIS, CM and MURPHY, FH and DAMUTH, RJ},
Title = {{THE OUTER CONTINENTAL-SHELF OIL AND GAS-SUPPLY MODEL OF THE ENERGY
   INFORMATION ADMINISTRATION}},
Journal = {{EUROPEAN JOURNAL OF OPERATIONAL RESEARCH}},
Year = {{1984}},
Volume = {{18}},
Number = {{2}},
Pages = {{184-197}},
DOI = {{10.1016/0377-2217(84)90184-X}},
ISSN = {{0377-2217}},
Unique-ID = {{ISI:A1984TR61200005}},
}

@article{ ISI:A1978FG65100012,
Author = {HOGARTY, TF},
Title = {{UNITED-STATES ENERGY INFORMATION ADMINISTRATION AND COAL DATA}},
Journal = {{ENERGY POLICY}},
Year = {{1978}},
Volume = {{6}},
Number = {{2}},
Pages = {{168-169}},
DOI = {{10.1016/0301-4215(78)90041-1}},
ISSN = {{0301-4215}},
Unique-ID = {{ISI:A1978FG65100012}},
}

@article{ ISI:A1977DU64300002,
Author = {GOODSELL, CT},
Title = {{INFORMATION-ENERGY MODEL AND COMPARATIVE ADMINISTRATION}},
Journal = {{ADMINISTRATION \& SOCIETY}},
Year = {{1977}},
Volume = {{9}},
Number = {{2}},
Pages = {{159-168}},
DOI = {{10.1177/009539977700900202}},
ISSN = {{0095-3997}},
Unique-ID = {{ISI:A1977DU64300002}},
}

@article{ ISI:000317547100017,
Author = {Miliutenko, Sofia and Bjorklund, Anna and Carlsson, Annica},
Title = {{Opportunities for environmentally improved asphalt recycling: the
   example of Sweden}},
Journal = {{JOURNAL OF CLEANER PRODUCTION}},
Year = {{2013}},
Volume = {{43}},
Pages = {{156-165}},
Month = {{MAR}},
Abstract = {{Asphalt waste from State roads in Sweden is usually recycled in order to
   preserve natural resources and reduce the burden on landfill. However,
   there appears to be a knowledge gap regarding the methods of asphalt
   recycling used by municipalities and private owners in Sweden. There is
   also a lack of knowledge regarding best practice from a life cycle
   environmental point of view. This study identified and evaluated
   potential ways of improving the life cycle environmental performance of
   asphalt recycling in Sweden. Data and information about the current
   situation of asphalt recycling in Sweden were collected through
   reviewing the literature and through interviews. It was observed that
   asphalt recycling practices were different for all three groups of road
   owners: the State, represented by the Swedish Transport Administration
   (STA), municipalities and industry. Life Cycle Assessment (LCA)
   methodology was used to identify processes within asphalt recycling and
   reuse that contribute a significant share of the total environmental
   impact (hotspots), and to compare the life cycle environmental
   performance of the main techniques used for asphalt recycling and reuse
   in Sweden: hot in-plant, hot in-place and reuse as an unbound material.
   The results showed that hot in-place recycling gave slightly more global
   warming potential (GWP) and cumulative energy demand (CED) savings than
   hot in-plant recycling. There were no savings of GWP and small savings
   of CED during asphalt reuse. It was concluded that asphalt recycling is
   environmentally preferable to asphalt reuse. However each method of
   asphalt recycling can provide different benefits, so possibilities exist
   for improving the environmental performance of the processes involved.
   These possibilities were subdivided into logistic, technical and
   organisational. (C) 2013 Elsevier Ltd. All rights reserved.}},
DOI = {{10.1016/j.jclepro.2012.12.040}},
ISSN = {{0959-6526}},
Unique-ID = {{ISI:000317547100017}},
}

@inproceedings{ ISI:000349067200079,
Author = {Musat, Cosmin Constantin and Rusu, Georgiana},
Book-Group-Author = {{SGEM}},
Title = {{ACTUAL TRENDS REGARDING THE USAGE OF 3D CADASTRE FOR AN EFFICIENT
   ADMINISTRATION}},
Booktitle = {{GEOCONFERENCE ON INFORMATICS, GEOINFORMATICS AND REMOTE SENSING -
   CONFERENCE PROCEEDINGS, VOL I}},
Series = {{International Multidisciplinary Scientific GeoConference-SGEM}},
Year = {{2013}},
Pages = {{613-620}},
Note = {{13th International Multidisciplinary Scientific Geoconference, SGEM
   2013, Albena, BULGARIA, JUN 16-22, 2013}},
Abstract = {{The concept of ``property{''} emerged from the human need to satisfy
   their necessities and the need for safety. In the context of constantly
   changing contemporary society it can be distinguished the urgent need to
   organize a unitary system of all data related to real-estate properties
   across the country. The importance of this paper is given by the fact
   that this issue has not been solved yet, although it has been a subject
   of great interest over the last years.
   Geographic Information Systems is a technique increasingly used in the
   contemporary world, both in theoretical research and in many practical
   activities. Currently, the main GIS applications are used in the
   following fields: natural resources, energy, transports, business,
   public safety. Many GIS technologies have played an important role in
   the private sector in areas such as marketing, retail industry,
   transport, real estate, property development. The paper presents the
   utility of using 3D technologies and techniques in real-estate cadastre
   and its application for an efficient public administration. The modern
   world representations need the third dimension for a better
   understanding of reality. The 3D technology can be used for representing
   building complexes, subsurface infrastructure objects, soil pollution,
   archaeological sites and monuments. {[}1]}},
ISSN = {{1314-2704}},
ISBN = {{978-954-91818-9-0}},
Unique-ID = {{ISI:000349067200079}},
}

@article{ ISI:000297280500002,
Author = {Minnis, Patrick and Sun-Mack, Szedung and Young, David F. and Heck,
   Patrick W. and Garber, Donald P. and Chen, Yan and Spangenberg, Douglas
   A. and Arduini, Robert F. and Trepte, Qing Z. and Smith, Jr., William L.
   and Ayers, J. Kirk and Gibson, Sharon C. and Miller, Walter F. and Hong,
   Gang and Chakrapani, Venkatesan and Takano, Yoshihide and Liou, Kuo-Nan
   and Xie, Yu and Yang, Ping},
Title = {{CERES Edition-2 Cloud Property Retrievals Using TRMM VIRS and Terra and
   Aqua MODIS Data-Part I: Algorithms}},
Journal = {{IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING}},
Year = {{2011}},
Volume = {{49}},
Number = {{11, 2}},
Pages = {{4374-4400}},
Month = {{NOV}},
Abstract = {{The National Aeronautics and Space Administration's Clouds and the
   Earth's Radiant Energy System (CERES) Project was designed to improve
   our understanding of the relationship between clouds and solar and
   longwave radiation. This is achieved using satellite broad-band
   instruments to map the top-of-atmosphere radiation fields with
   coincident data from satellite narrow-band imagers employed to retrieve
   the properties of clouds associated with those fields. This paper
   documents the CERES Edition-2 cloud property retrieval system used to
   analyze data from the Tropical Rainfall Measuring Mission Visible and
   Infrared Scanner and by the MODerate-resolution Imaging Spectrometer
   instruments on board the Terra and Aqua satellites covering the period
   1998 through 2007. Two daytime retrieval methods are explained: the
   Visible Infrared Shortwave-infrared Split-window Technique for snow-free
   surfaces and the Shortwave-infrared Infrared Near-infrared Technique for
   snow or ice-covered surfaces. The Shortwave-infrared Infrared
   Split-window Technique is used for all surfaces at night. These methods,
   along with the ancillary data and empirical parameterizations of cloud
   thickness, are used to derive cloud boundaries, phase, optical depth,
   effective particle size, and condensed/frozen water path at both pixel
   and CERES footprint levels. Additional information is presented,
   detailing the potential effects of satellite calibration differences,
   highlighting methods to compensate for spectral differences and correct
   for atmospheric absorption and emissivity, and discussing known errors
   in the code. Because a consistent set of algorithms, auxiliary input,
   and calibrations across platforms are used, instrument and
   algorithm-induced changes in the data record are minimized. This
   facilitates the use of the CERES data products for studying
   climate-scale trends.}},
DOI = {{10.1109/TGRS.2011.2144601}},
ISSN = {{0196-2892}},
ResearcherID-Numbers = {{Yang, Ping/B-4590-2011
   Hong, Gang/A-2323-2012
   Minnis, Patrick/G-1902-2010
   Garber, Donald/D-7427-2015}},
Unique-ID = {{ISI:000297280500002}},
}

@article{ ISI:000278136900039,
Author = {Gardiner, James V. and Campbell, Daniel and Patterson, Michael and Kent,
   Aysha and Ghatei, Mohammed A. and Bloom, Stephen R. and Bewick, Gavin A.},
Title = {{The Hyperphagic Effect of Ghrelin Is Inhibited in Mice by a Diet High in
   Fat}},
Journal = {{GASTROENTEROLOGY}},
Year = {{2010}},
Volume = {{138}},
Number = {{7}},
Pages = {{2468-U338}},
Month = {{JUN}},
Abstract = {{BACKGROUND \& AIMS: Ghrelin is the only peripheral hormone known to
   increase food intake. It is released from the stomach and is thought to
   function as a signal of energy deficit and a meal initiator. We
   generated transgenic mice in which levels of bioactive ghrelin are
   increased in the stomach and circulation. These mice, as expected, are
   hyperphagic and glucose intolerant. We investigated whether exposure to
   a high-fat diet (HFD) would exacerbate this phenotype. METHODS: We
   investigated the effect of HFD on energy and glucose homeostasis in
   ghrelin transgenic mice. We determined dietary preference; expression of
   hypothalamic neuropeptides that control food intake; and, using
   fast-performance liquid chromatography, the circulating forms of
   ghrelin. We measured food intake during continuous administration of
   ghrelin in wild-type mice fed either regular chow or an HFD. RESULTS:
   Ghrelin transgenic mice were resistant to diet-induced obesity because
   of their reduced food intake. This was not caused by alterations to food
   preference, hypothalamic signaling of neuropeptides that control food
   intake, or the form of circulating acylated ghrelin. Long-term
   administration of ghrelin to wild-type mice failed to increase ingestion
   of an HFD but, as expected, increased intake of regular chow.
   CONCLUSIONS: This is the first report that diets high in fat inhibit the
   hyperphagic effect of ghrelin; these findings indicate that features of
   the diet are important determinants of ghrelin's function. This
   information is important for the development of anti-obesity drugs that
   target ghrelin signaling.}},
DOI = {{10.1053/j.gastro.2010.02.012}},
ISSN = {{0016-5085}},
ORCID-Numbers = {{Gardiner, James/0000-0001-9357-1387}},
Unique-ID = {{ISI:000278136900039}},
}

@article{ ISI:000279415600016,
Author = {Lyras, Dimitrios N. and Kazakos, Konstantinos and Verettas, Dionysios
   and Chronopoulos, Efstathios and Folaranmi, Semiu and Agrogiannis,
   George},
Title = {{Effect of combined administration of Transforming Growth Factor-b1 and
   Insulin-like Growth Factor I on the mechanical properties of a patellar
   tendon defect model in rabbits}},
Journal = {{ACTA ORTHOPAEDICA BELGICA}},
Year = {{2010}},
Volume = {{76}},
Number = {{3}},
Pages = {{380-386}},
Month = {{JUN}},
Abstract = {{The aim of this study was to test the hypothesis that combined
   administration of TGF-b1 and IGF-I in a patellar tendon defect model
   could enhance the mechanical properties of the healed tendon. Twenty
   four New Zealand white rabbits were used for this purpose. In each
   animal, the right knee was used for the application of the growth
   factors, whereas the left knee served as an untreated control. The
   growth factors were mixed with fibrin sealant as a delivery vehicle. Two
   groups of rabbits were sacrificed after 2 weeks and 6 weeks
   respectively. Application of the growth factors resulted in a
   significant increase in force at failure, ultimate stress, stiffness,
   and energy uptake at 2 weeks, whereas none of the parameters revealed
   any significant difference between the two groups at 6 weeks. This study
   provides valuable information on the effect of the two growth factors on
   this patellar tendon defect model.}},
ISSN = {{0001-6462}},
Unique-ID = {{ISI:000279415600016}},
}

@article{ ISI:A1993MD96300017,
Author = {ASHER, GW and FISHER, MW and FENNESSY, PF and SUTTIE, JM and WEBSTER, JR},
Title = {{MANIPULATION OF REPRODUCTIVE SEASONALITY OF FARMED RED DEER
   (CERVUS-ELAPHUS) AND FALLOW DEER (DAMA-DAMA) BY STRATEGIC ADMINISTRATION
   OF EXOGENOUS MELATONIN}},
Journal = {{ANIMAL REPRODUCTION SCIENCE}},
Year = {{1993}},
Volume = {{33}},
Number = {{1-4}},
Pages = {{267-287}},
Month = {{OCT}},
Abstract = {{There is often a poor synchrony between the high energy demands of
   lactation in summer and the peak of pasture production and quality
   occurring in spring for red deer (Cervus elaphus) and fallow deer (Dama
   dama) farmed under pastoral conditions in temperate climates.
   Considerable research within the last decade has investigated either
   daily administration or constant infusion of exogenous melatonin in
   order to advance the breeding season and hence the seasonal pattern of
   births of farmed deer and, therefore, align lactation and feed
   production. Melatonin is the hormone involved in the transduction of
   photoperiodic information to the endocrine system leading to precise
   timing of reproduction.
   Owing to the absence of pregnancy and lactation, the pubertal hind/doe
   provides the simplest model for exogenously controlling the seasonality
   of oestrus, ovulation and conception. All forms of exogenous melatonin
   delivery initiated in summer (10-12 months of age) are effective in
   advancing the onset of puberty. However, the degree of advancement
   relative to control females has been highly variable, reflecting a wide
   range of treatment protocols. The most significant variables appear to
   be the time of onset of treatment and the degree of social interaction
   between treated and control animals. Initiation of treatments less than
   100 days after the winter solstice are likely to delay puberty by
   impinging upon a possible photoperiod entrainment period. Initiation of
   treatments more than 100 days after the solstice advances puberty, with
   progressively later initiation dates generally resulting in smaller
   degrees of advancement. Melatonin-treated red deer hinds and stags
   appear to influence the timing of puberty of contiguous control hinds.
   The maximum degree of puberty advancement so far achieved by melatonin
   treatment has been 54 days for red deer and 56 days for fallow deer.
   In adult female deer, lactation does not appear to markedly influence
   the degree of phase shifting by melatonin treatment. However, because
   melatonin treatment initiated before the end of pregnancy, 140-170 days
   after the winter solstice, may prevent lactogenesis, the use of
   melatonin is contra-indicated during pregnancy. Treatment initiation
   after the onset of lactation does not appear to influence milk yields,
   as evidenced by calf/fawn growth rates.
   Treatment of adult male red and fallow deer during summer advances all
   aspects of reproductive seasonality. Coincident treatment of males and
   females appears to result in coincident early rutting and oestrous
   activity, leading to high conception rates. Long-term consequences of
   treatment of red deer stags include early sexual quiescence and
   occasional expression of transient testicular cycles, with
   re-synchronisation of treated and control stags occurring 14-15 months
   after the initiation of treatment. However, initiation of treatment of
   red deer stags less than 50 days after the winter solstice delays sexual
   quiescence and sexual recrudescence, indicating that increasing
   photoperiod in early spring is important in the entrainment process.
   While seasonal birth/lactation patterns for red and fallow deer can be
   advanced by exogenous melatonin treatment, research is needed to
   elucidate the actual effects on overall productivity, particularly in
   relation to calf/fawn growth rates and the impact of precocious puberty
   in early-born animals.}},
DOI = {{10.1016/0378-4320(93)90119-C}},
ISSN = {{0378-4320}},
Unique-ID = {{ISI:A1993MD96300017}},
}

@article{ ISI:000357545400015,
Author = {Zhang, Xiaotong and Liang, Shunlin and Wild, Martin and Jiang, Bo},
Title = {{Analysis of surface incident shortwave radiation from four satellite
   products}},
Journal = {{REMOTE SENSING OF ENVIRONMENT}},
Year = {{2015}},
Volume = {{165}},
Pages = {{186-202}},
Month = {{AUG}},
Abstract = {{Incident solar radiation (R-s) over the Earth's surface is important for
   studying our climate and environment Global observation networks have
   been established, but many land surfaces are under-represented.
   Satellite remote sensing is the only way to estimate R-s at both global
   and regional scales. Many efforts have been made to evaluate the
   accuracy of current R-s products generated from satellite observations,
   but only a limited amount of ground measurements was generally used and
   the individual satellite products were used for analyzing R-s
   variability. In this study, four satellite estimates of R-s, including
   the Global Energy and Water Cycle Experiment - Surface Radiation Budget
   (GEWEX-SRB V3.0), the International Satellite Cloud Climatology Project
   - Flux Data (ISCCP-FD), the University of Maryland (UMD)/Shortwave
   Radiation Budget (SRB) (UMD-SRB V3.33) product, and the Earth's Radiant
   Energy System (CERES) EBAF, were evaluated using comprehensive ground
   measurements at 1151 sites around the world from the Global Energy
   Balance Archive (GEBA) and the China Meteorological Administration
   (CMA). It was found that these satellite estimates of R-s agree better
   with surface measurements at monthly than at daily time scale and can
   capture the seasonal variation of R-s very well, but these satellite
   products overestimated R-s by approximately 10w m(-2). The mean bias and
   the root mean square error (RMSE) of the monthly mean estimates from
   these four data sets were 10.2 w m(-2) and 24.8 w m(-2) respectively.
   The global annual mean values of R-s were 186.7 w m(-2), 185.4 w m(-2),
   and 188.6 w m(-2) for CERES-EBAF, ISCCP-FD, and GEWEX-SRB V3.0
   respectively. The averaged global annual mean R-s value from
   ground-measured-calibrated three satellite derived R-s products was
   180.6 w m(-2), which is smaller than that estimated from individual
   satellite-derived products. The CERES-EBAF product shows the best
   accuracy among these four data sets, which indicates that including more
   accurate cloud information from active instruments can improve the
   accuracy of R-s. These satellite products show different temporal
   trends. Both GEWEX-SRB V3.0 and ISCCP-FD showed similar trends at the
   global scale but with different magnitudes. A significant dimming was
   found between 1984 and 1991, followed by brightening from 1992 to 2000,
   and then by a significant dimming over 2001-2007. The CERES-EBAF product
   showed a brightening trend, but not significantly since 2000. The
   variability from satellite estimates at pixel level was also analyzed.
   The results are comparable with previous studies based on observed R-s
   at the surface for specific regions, although some inconsistencies still
   exist and the magnitudes of the variations should be further quantified.
   We also found that clouds contribute more to the long-term variations of
   R-s derived from satellite observations than aerosols. (C) 2015 Elsevier
   Inc. All rights reserved.}},
DOI = {{10.1016/j.rse2015.05.015}},
ISSN = {{0034-4257}},
EISSN = {{1879-0704}},
ResearcherID-Numbers = {{liang, shunlin/C-2809-2015
   Wild, Martin/J-8977-2012}},
Unique-ID = {{ISI:000357545400015}},
}

@article{ ISI:000320905500002,
Author = {Sacchelli, Sandro and Fagarazzi, Claudio and Bernetti, Iacopo},
Title = {{Economic evaluation of forest biomass production in central Italy: A
   scenario assessment based on spatial analysis tool}},
Journal = {{BIOMASS \& BIOENERGY}},
Year = {{2013}},
Volume = {{53}},
Number = {{SI}},
Pages = {{1-10}},
Month = {{JUN}},
Abstract = {{A spatial analysis tool, a Decision Support (DS) model able to support
   decision-making processes related to forestry energy planning has been
   developed using ecological and economic parameters. In this paper, the
   relative performance of different forest energy chains were compared by
   using metrics such as net revenue from forest processes, break-even
   prices of wood fuels, and the price elasticity of the bioenergy supply.
   Working with different scenarios at a spatial level, the DS model can
   evaluate innovative technologies and traditional forest harvest and
   logistical chains across a range of products, such as firewood and
   woodchips. The spatial analysis lends itself easily to an analysis of
   the political and administrative constraints with respect to levels of
   administration and regional variables.
   As expected, applying the tool to the Tuscany region in Italy shows that
   local characteristics and the species composition of an area influence
   the economic outcome of different harvest and logistical chains. In
   particular, mixed species Mediterranean forests appear to be suitable
   for the implementation of innovative bioenergy production processes,
   such as Whole Tree Chipping. (C) 2012 Elsevier Ltd. All rights reserved.}},
DOI = {{10.1016/j.biombioe.2012.11.026}},
ISSN = {{0961-9534}},
ORCID-Numbers = {{SACCHELLI, SANDRO/0000-0002-7031-1125}},
Unique-ID = {{ISI:000320905500002}},
}

@article{ ISI:000274774000021,
Author = {Lady, George M.},
Title = {{Evaluating long term forecasts}},
Journal = {{ENERGY ECONOMICS}},
Year = {{2010}},
Volume = {{32}},
Number = {{2}},
Pages = {{450-457}},
Month = {{MAR}},
Abstract = {{The U.S. Department of Energy's Energy Information Administration (EIA),
   and its predecessor organizations, has published projections of U.S.
   energy production, consumption, distribution and prices annually for
   over 30 years. A natural issue to raise in evaluating the projections is
   an assessment of their accuracy compared to eventual outcomes. A related
   issue is the determination of the sources of ``error{''} in the
   projections that are due to differences between the actual versus
   realized values of the associated assumptions. One way to do this would
   be to run the computer-based model from which the projections are
   derived at the time the projected values are realized, using actual
   rather than assumed values for model assumptions; and, compare these
   results to the original projections. For long term forecasts, this
   approach would require that the model's software and hardware
   configuration be archived and available for many years, possibly
   decades, into the future. Such archival creates many practical problems:
   and, in general, it is not being done. This paper reports on an
   alternative approach for evaluating the projections. In the alternative
   approach, the model is run many times for cases in which important
   assumptions are changed individually and in combinations. A database is
   assembled from the solutions and a regression analysis is conducted for
   each important projected variable with the associated assumptions chosen
   as exogenous variables. When actual data are eventually available, the
   regression results are then used to estimate the sources of the
   differences in the projections of the endogenous variables compared to
   their eventual outcomes. The results presented here are for residential
   and commercial sector natural gas and electricity consumption. (C) 2009
   Elsevier B.V. All rights reserved.}},
DOI = {{10.1016/j.eneco.2009.10.006}},
ISSN = {{0140-9883}},
Unique-ID = {{ISI:000274774000021}},
}

@inproceedings{ ISI:000258370000030,
Author = {Moraru, S-A. and Bujdei, C. and Pelcz, A. and Vulpe, C. and Sisak, Fr.
   and Perniu, L.},
Editor = {{Cernat, M}},
Title = {{Monitoring of energy consumption in industrial environment using
   integrated software system}},
Booktitle = {{OPTIM 2008: PROCEEDINGS OF THE 11TH INTERNATIONAL CONFERENCE ON
   OPTIMIZATION OF ELECTRICAL AND ELECTRONIC EQUIPMENT, VOL III}},
Year = {{2008}},
Pages = {{173-178}},
Note = {{11th International Conference on Optimization of Electrical and
   Electronic Equipment, Brasov, ROMANIA, MAY 22-23, 2008}},
Abstract = {{Today many industrial facilities have a lot of industrial control
   software systems used in various ways. These systems work in all kinds
   of architectures, starting from the simple ``one application on one
   computer attached to a process{''} to more complex systems such as
   client-server-database, multi-tier applications, etc. Being provided by
   different vendors, there is a problem of managing the applications,
   developed using various technologies and running on different
   environments, implying administration problems and many security
   aspects. The information is spread into many places, this making it
   difficult to have a global view on the enterprise's resources. The
   solution is to have a single software system which to provide
   functionality for all the enterprise, into a unified manner. Our
   distributed software applications architecture comes to deal with the
   problems presented above. The system has three main levels of
   application:
   - The data source, having two main parts: software applications that
   communicate with the equipment and a connector to the system.
   - The server, gathering all the data from the data sources, processing
   and storing it into the database.
   - The client applications, including the interface of the system with
   the user. The technology used for developing this system is
   web-oriented.}},
Unique-ID = {{ISI:000258370000030}},
}

@article{ ISI:000081443500001,
Author = {Greene, DL and Kahn, JR and Gibson, RC},
Title = {{Fuel economy rebound effect for US household vehicles}},
Journal = {{ENERGY JOURNAL}},
Year = {{1999}},
Volume = {{20}},
Number = {{3}},
Pages = {{1-31}},
Abstract = {{This paper presents an econometric estimation of the ``rebound
   effect{''} for household vehicle travel in the United States based on
   analysis of survey data collected by the Energy Information
   Administration (EIA) at approximately three-year intervals over a
   15-year period. The rebound effect measures the tendency to ``take
   back{''} potential energy savings from fuel economy improvements as
   increased travel. Vehicle use models were estimated for one-, two-,
   three-, four-, and five-vehicle households. The results confirm recent
   estimates based on national or state-level data: a long-run ``take
   back{''} of about 20 percent of potential energy savings. Consumer
   responses to changes in fuel economy or fuel price per gallon appear to
   be equal and opposite in sign. Recognizing the interdependencies among
   miles of travel, fuel economy and price is key to obtaining meaningful
   results.}},
ISSN = {{0195-6574}},
Unique-ID = {{ISI:000081443500001}},
}

@inproceedings{ ISI:000359869000051,
Author = {Dhivya, P. and Karthik, S. and Kalaikumaran, T.},
Editor = {{Nagaveni, N and Renuga, R and Kunthavai, A and Sangeetha, M and Ramraj, T}},
Title = {{SOA based Secure Data Transmission over CMEA Protocol in MANET}},
Booktitle = {{GRAPH ALGORITHMS, HIGH PERFORMANCE IMPLEMENTATIONS AND ITS APPLICATIONS
   (ICGHIA 2014)}},
Series = {{Procedia Computer Science}},
Year = {{2015}},
Volume = {{47}},
Pages = {{434-440}},
Note = {{International conference on Graph Algorithms, High Performance
   Implementations and its Applications (ICGHIA), Coimbatore Inst Technol
   Campus, Coimbatore, INDIA, DEC 17-19, 2014}},
Organization = {{Bergen Univ Coll}},
Abstract = {{Mobile Adhoc Networks is a self organizing network composed of mobile
   terminals connected by wireless links. Adhoc Networks are created
   dynamically without any preexisting network infrastructure Ad-hoc
   networks are very useful in situations like emergency search and reuse
   operations and meetings where people want to quickly share information.
   This network does not have any central administration, hence there are
   no designated routes, all the nodes can serve as routers for each other,
   and data packets are forwarded from node to node to node in multi hop
   fashion. Cluster based Mobility and Energy Aware (CMEA) routing
   protocols is used to find the reliable route in a cluster networks. The
   clustered network avoids path breaks and long path delay. When applying
   the energy and mobility aware metric over clustered network gives
   reliable route between Source and Destination. Service Oriented
   Architecture (SOA) is an evolution of past platforms, preserving
   successful characteristics of traditional architectures and bringing
   with it distinct principles that follow service orientation in support
   service oriented enterprise. It forces the network to improve the
   reliability, security, integrity etc. By applying the proposed XML
   technique for encrypting the secure data improves the content delivery
   over the CMEA network. Therefore SOA based secure data transmission over
   the reliable route improves the network performance. (C) 2015 The
   Authors. Published by Elsevier B.V. This is an open access article under
   the CC BY-NC-ND license
   (http://creativecommons.org/licenses/by-nc-nd/4.0/).}},
DOI = {{10.1016/j.procs.2015.03.227}},
ISSN = {{1877-0509}},
Unique-ID = {{ISI:000359869000051}},
}

@article{ ISI:000326770300107,
Author = {Gius, Mark},
Title = {{Regulatory restrictions and energy: The impact of the Jones Act on spot
   gasoline prices}},
Journal = {{ENERGY POLICY}},
Year = {{2013}},
Volume = {{62}},
Pages = {{1058-1063}},
Month = {{NOV}},
Abstract = {{The purpose of the present study is to estimate the effects of the Jones
   Act on spot gasoline prices. Although the Jones Act pertains to the
   domestic shipment of all types of goods, the present study will only
   focus on gasoline. The present study will use data obtained from the
   Energy Information Administration in order to determine if the price of
   gasoline declined during Jones Act waiver periods. Looking at daily
   prices, the results regarding the effects of the Jones Act on spot
   gasoline prices are mixed. When using a t-test, the results indicated
   either that there was no significant difference or that prices were
   actually higher during the waiver periods. When using a first-order
   autoregressive model, it was found that prices were lower during the
   2005 waiver period but higher during the 2012 waiver. Given these
   inconclusive results, it is not possible to conclude that the Jones Act
   restrictions contribute to higher gasoline prices. (C) 2013 Elsevier
   Ltd. All rights reserved.}},
DOI = {{10.1016/j.enpol.2013.07.086}},
ISSN = {{0301-4215}},
EISSN = {{1873-6777}},
Unique-ID = {{ISI:000326770300107}},
}

@article{ ISI:000314281400005,
Author = {Roycroft, Trevor R.},
Title = {{Empirical study of broadband adoption using data from the 2009
   Residential Energy Consumption Survey}},
Journal = {{JOURNAL OF REGULATORY ECONOMICS}},
Year = {{2013}},
Volume = {{43}},
Number = {{2}},
Pages = {{214-228}},
Month = {{APR}},
Abstract = {{Using 2009 data from the U.S. Energy Information Administration, a study
   of factors that influence broadband adoption is conducted. The data set
   includes previously studied demographic factors, as well as records
   associated with the household's use of computers, television, pay
   television services, and broadband. Analysis of the data indicate that,
   when controlling for a number of demographic factors, the purchase of
   television services is positively correlated with broadband adoption,
   with consumers who purchase either cable or satellite television service
   adopting broadband at a higher rate than those who utilize over-the-air
   television services. The results suggest that consumers who prefer
   over-the-air television services may face a more substantial hurdle in
   broadband adoption, one that might be lowered through the availability
   of affordable stand-alone broadband services.}},
DOI = {{10.1007/s11149-012-9207-2}},
ISSN = {{0922-680X}},
Unique-ID = {{ISI:000314281400005}},
}

@article{ ISI:000316239900011,
Author = {Schwarzkopf, Tina M. and Horn, Tobias and Lang, Dorothee and Klein,
   Jochen},
Title = {{Blood gases and energy metabolites in mouse blood before and after
   cerebral ischemia: the effects of anesthetics}},
Journal = {{EXPERIMENTAL BIOLOGY AND MEDICINE}},
Year = {{2013}},
Volume = {{238}},
Number = {{1}},
Pages = {{84-89}},
Month = {{JAN}},
Abstract = {{The levels of blood gases and energy metabolites strongly influence the
   outcome of animal experiments, for example in experimental stroke
   research. While mice have become prominent animal models for cerebral
   ischemia, little information is available on the effects of anesthetic
   drugs on blood parameters such as blood gases, glucose and lactate in
   this species. In this work, we collected arterial and venous blood
   samples from female CD-1 mice before and after cerebral ischemia induced
   by middle cerebral artery occlusion (MCAO), and we tested the influence
   of different anesthetic drugs. We found that all of the injectable
   anesthetics tested (ketamine/xylazine, chloral hydrate, propofol and
   pentobarbital) caused a decrease in blood pH and partial pressure of
   oxygen (pO(2)) and an increase of partial pressure of carbon dioxide
   (pCO(2)), indicating respiratory depression. This was not observed with
   inhalable anesthetics such as isoflurane, sevoflurane and halothane.
   Significant and up to two-fold increases of blood glucose concentration
   were observed under isoflurane, halothane, ketamine/xylazine, chloral
   hydrate, and propofol anesthesia. Lactate concentration rose
   significantly by 2-3-fold during inhalation of isoflurane and halothane
   treatment, but decreased by more than 50\% after administration of
   pentobarbital. Permanent cerebral ischemia induced respiratory acidosis
   (low pH and pO(2), high pCO(2)) which was most prominent after 24 h.
   Postsurgical treatment with Ringer-lactate solution (1 mL,
   intraperitoneal) caused a recovery of blood gases to basal levels after
   24 h. Use of isoflurane for surgery caused a minor increase of blood
   glucose concentrations after one hour, but a strong increase of blood
   lactate. In contrast, anesthesia with pentobarbital did not affect
   glucose concentration but strongly reduced blood lactate concentrations
   one hour after surgery. All values recovered at three hours after MCAO.
   In conclusion, anesthetic drugs have a strong influence on murine blood
   parameters, which should be taken into account in experiments in mice.}},
DOI = {{10.1258/ebm.2012.012261}},
ISSN = {{1535-3702}},
ResearcherID-Numbers = {{Klein, Jochen/B-9730-2008
   Fachbereich14, Dekanat/C-8553-2015}},
ORCID-Numbers = {{Klein, Jochen/0000-0001-6971-3381
   }},
Unique-ID = {{ISI:000316239900011}},
}

@article{ ISI:000298645200008,
Author = {Suenram-Lea, Sandra I. and Owen-Lynch, Jane and Robinson, Sarita J. and
   Jones, Emma and Hu, Henglong},
Title = {{The effect of energy drinks on cortisol levels, cognition and mood
   during a fire-fighting exercise}},
Journal = {{PSYCHOPHARMACOLOGY}},
Year = {{2012}},
Volume = {{219}},
Number = {{1}},
Pages = {{83-97}},
Month = {{JAN}},
Abstract = {{Acute stress has been associated with changes in cognitive performance
   and mood, and these have been in part associated with stress-related
   increased release of cortisol. Both glucose and caffeine consumed in
   isolation have been shown to moderate cortisol response and affect
   cognitive performance and affect mood; however, there has been very
   little research into their behavioural and physiological effects when
   taken in combination. The aim of this study was to assess the effect of
   the two substances in combinationunder stressful and physically
   demanding conditions (fire-fighting training) on cognition, mood and
   cortisol release.
   Using a double-blind, mixed measures design, 81 participants were
   administered a 330-ml drink containing either (1) 50 g glucose and 40 mg
   caffeine, (2) 10.25 g of fructose/glucose and 80 mg caffeine or a
   placebo drink and tested across a range of cognitive tasks, mood and
   physiological measures.
   The results showed an increase in grip strength and improved memory
   performance after ingestion of the drink containing 50 g glucose and 40
   mg caffeine, and both active drinks resulted in improved performance on
   the information-processing task compared to the placebo. In terms of
   mood effects, the drink containing 50 g glucose and 40 mg caffeine led
   to a reduction in anxiety and significantly reduced self-reported levels
   of stress following the fire-fighter training.
   Based on the results of this study, in situations of stress combined
   with physical performance, administration of an energy drink containing
   glucose and caffeine might be an easy to implement and cost effective
   way to maintain mental performance levels and to ameliorate the negative
   effects of stress on mood.}},
DOI = {{10.1007/s00213-011-2379-0}},
ISSN = {{0033-3158}},
EISSN = {{1432-2072}},
ORCID-Numbers = {{Owen-Lynch, Penelope Jane/0000-0002-5928-2327}},
Unique-ID = {{ISI:000298645200008}},
}

@article{ ISI:000295753000054,
Author = {Chandel, Munish K. and Pratson, Lincoln F. and Jackson, Robert B.},
Title = {{The potential impacts of climate-change policy on freshwater use in
   thermoelectric power generation}},
Journal = {{ENERGY POLICY}},
Year = {{2011}},
Volume = {{39}},
Number = {{10}},
Pages = {{6234-6242}},
Month = {{OCT}},
Abstract = {{Climate change policy involving a price on carbon would change the mix
   of power plants and the amount of water they withdraw and consume to
   generate electricity. We analyze what these changes could entail for
   electricity generation in the United States under four climate policy
   scenarios that involve different costs for emitting CO2 and different
   technology options for reducing emissions out to the year 2030. The
   potential impacts of the scenarios on the U.S. electric system are
   modeled using a modified version of the U.S. National Energy Modeling
   System and water-use factors for thermoelectric power plants derived
   from electric utility data compiled by the U.S. Energy Information
   Administration. Under all the climate-policy scenarios, freshwater
   withdrawals decline 2-14\% relative to a business-as-usual (BAU)
   scenario of no U.S. climate policy. Furthermore, water use decreases as
   the price on CO2 under the climate policies increases. At relatively
   high carbon prices ( > \$50/tonne CO2), however, retrofitting coal
   plants to capture CO2 increases freshwater consumption compared to BAU
   in 2030. Our analysis suggests that climate policies and a carbon price
   will reduce both electricity generation and freshwater withdrawals
   compared to BAU unless a substantial number of coal plants are
   retrofitted to capture CO2. (C) 2011 Elsevier Ltd. All rights reserved.}},
DOI = {{10.1016/j.enpol.2011.07.022}},
ISSN = {{0301-4215}},
EISSN = {{1873-6777}},
Unique-ID = {{ISI:000295753000054}},
}

@inproceedings{ ISI:000276074404046,
Author = {Geisbrecht, Rodney and Dipietro, Phil},
Editor = {{Gale, J and Herzog, H and Braitsch, J}},
Title = {{Evaluating options for US coal fired power plants in the face of
   uncertainties and greenhouse gas caps: the economics of refurbishing,
   retrofitting, and repowering}},
Booktitle = {{GREENHOUSE GAS CONTROL TECHNOLOGIES 9}},
Series = {{Energy Procedia}},
Year = {{2009}},
Volume = {{1}},
Number = {{1}},
Pages = {{4347-4354}},
Note = {{9th International Conference on Greenhouse Gas Control Technologies,
   Washington, DC, NOV 16-20, 2008}},
Abstract = {{Facing a cost for emitting carbon dioxide, U.S. entities that own
   coal-fired power plants have a number of options to pursue as
   alternatives to retiring the plant and investing in a new one with lower
   carbon emissions. These include: (1) continuing to operate business as
   usual and obtaining emission allowances as needed, (2) switching to or
   cofiring low carbon fuels, (3) retrofitting with carbon capture and
   sequestration (CCS), (4) repowering with an advanced coal technology
   incorporating CCS, and (5) refurbishing to improve plant efficiency in
   combination with any of the previous options. Markets for refurbishing,
   retrofitting, and repowering were assessed using data bases of existing
   coal fired power plants along with the Energy Information
   Administration's (EIA) National Energy Modeling System (NEMS) code,
   which was modified to undertake an integrated analysis of how retrofit
   and repowering options would compete with other options for managing the
   fleet of coal fired power plants. Sensitivities with respect to key
   uncertainties are presented, including carbon values, natural gas
   prices, CCS incentives, and system-wide cost effectiveness of
   refurbishing in conjunction with retrofitting or repowering.
   The indicated market for coal fired power plants that could be
   retrofitted with near commercial CCS technology under carbon cost
   scenarios ranging from 45 - 60 \$/MTCO2e (metric ton CO2 equivalent) is
   on the order of 100 GW. A similar market is apparent for repowering, but
   with technologies that are as yet not commercialized. Below 30
   \$/MTCO2e, CCS technologies would not deploy without incentives. While
   refurbishing can extend the market for either retrofitting or
   repowering, its impact will depend on the extent to which efficiency as
   well as other cost related factors can be collectively upgraded. (C)
   2008 Elsevier Ltd. All rights reserved.}},
DOI = {{10.1016/j.egypro.2009.02.248}},
ISSN = {{1876-6102}},
Unique-ID = {{ISI:000276074404046}},
}

@article{ ISI:000265271300003,
Author = {Sahin, Besir and Bilgili, Mehmet},
Title = {{Wind Characteristics and Energy Potential in Belen-Hatay, Turkey}},
Journal = {{INTERNATIONAL JOURNAL OF GREEN ENERGY}},
Year = {{2009}},
Volume = {{6}},
Number = {{2}},
Pages = {{157-172}},
Abstract = {{In this study, wind characteristics in the Belen-Hatay province situated
   in southern Turkey were investigated by using the Wind Atlas Analysis
   and Application Program (WAsP) for future wind power generation
   projects. Hourly wind speeds and directions between the years 2004 and
   2005 were collected by the General Directorate of Electrical Power
   Resources Survey Administration (EIEI). Before the construction of the
   wind turbine generator in Belen-Hatay province, several fundamental
   properties of the site such as wind behavior, availability, continuity,
   and probability were carried out in order to provide the necessary
   information to the potential investors about cost and economical aspects
   of the planning wind energy project. The dominant wind directions,
   probability distributions, Weibull parameters, mean wind speeds, and
   power potentials were determined according to the wind directions,
   years, seasons, months, and hours of day, separately. Finally, at a 10 m
   height above ground level, mean wind speed and power potential of the
   site were found to be 7.0 m/s and 378 W/m2, respectively.}},
DOI = {{10.1080/15435070902784947}},
Article-Number = {{PII 910298333}},
ISSN = {{1543-5075}},
Unique-ID = {{ISI:000265271300003}},
}

@article{ ISI:000255251800006,
Author = {Gatti, Jozeti Barbutti and Queiroz, Guilherme de Castilho and Correa
   Garcia, Eloisa Elena},
Title = {{Recycling of aluminum can in terms of life cycle inventory (LCI)}},
Journal = {{INTERNATIONAL JOURNAL OF LIFE CYCLE ASSESSMENT}},
Year = {{2008}},
Volume = {{13}},
Number = {{3}},
Pages = {{219-225}},
Month = {{MAY}},
Abstract = {{Background, Aims and Scope. Life Cycle Assessment is a technique for
   evaluating the environmental performance of a given product by:
   identifying and quantifying the energy and raw materials used in its
   manufacturing process, as well as the emissions of pollutants to water,
   soil, and air inherent in this production, use and disposal, and
   evaluating the environmental impact associated with the use of energy
   and materials and the emissions of pollutants, thus identifying
   opportunities to improve the system in order to optimize the
   environmental performance of the product. CETEA (Packaging Technology
   Center) has conducted a Life Cycle Assessment - LCA study of aluminum
   can with emphasis in life cycle inventory, collecting data for the
   reference years 2000-2002. The goal of this paper is to present part of
   this complete study, focusing the influence of aluminum recycling rate
   on the Life Cycle Inventory (LCI) of aluminum beverage cans in Brazil.
   Methods. The adopted methodology was based on the recommendations of
   SETAC - Society of Environmental Toxicology and Chemistry and the ISO
   14040 Standard, approved by the Sub-Committee 05 of the Environmental
   Administration Technical Committee, TC-207, from ISO - INTERNATIONAL
   ORGANIZATION FOR STANDARDIZATION {[}1,2]. Data storage and modeling were
   performed by employing the PIRA Environmental Management System - PEMS
   {[}3].
   Results. Taking into account the impact categories adopted in this
   study, it has been shown that recycling helps to improve the aluminum
   can environmental profile measured as LCI data.
   Discussion. For the transformed aluminum products, the recycling rate
   affects the values of the environmental parameters inventoried, but not
   in the same proportion, since the contribution of other stages of the
   product system life cycle and the recycling process remain unchanged,
   including the yield of this process. In general, the recycling balance
   is always positive due to the importance of the stages that precede the
   packaging production and the problem of increasing the municipal waste
   volume.
   Conclusions. The advantages of the recycling are obviously concentrated
   on the inventoried parameters related to the primary aluminum production
   and to the package disposal. The verified benefits of the recycling
   increase with the recycling rate enhancement. However, the effects on
   the inventory do not have the same magnitude of the recycling rate. This
   happens due to the relative contributions of the other life cycle
   stages, such as the transportation and sheet or can production. In
   agreement with the presented results, it is possible to conclude that
   the aluminum can recycling reduces part of the consumption of natural
   resources and the emissions associated to the stages previous to the
   production of the packaging. The parameters specifically related to the
   stage of aluminum production suffer reduction directly proportional to
   the increase of the recycling rate. In this way, all of the efforts made
   to increase the recycling rate will have a positive contribution to the
   LCI of the aluminum can.
   Recommendations. It is worth pointing out that LCA studies are iterative
   and dynamic. The data can always be refined, substituted or complemented
   with updated information in order to improve the representativeness of
   the analyzed sector.
   Perspectives. From this study, the aluminum sector in Brazil is able to
   quantify the benefits of future actions for environmental improvement of
   the Brazilian aluminum industry, as well as to contribute technically to
   Environmental Labeling initiatives regarding aluminum products..}},
DOI = {{10.1065/Ica2006.12.370}},
ISSN = {{0948-3349}},
Unique-ID = {{ISI:000255251800006}},
}

@inproceedings{ ISI:000288141000072,
Author = {Bai, Yun and Mao, Baohua and Ding, Yong and Zhou, Fangming and Jia,
   Wenzheng},
Editor = {{Mao, BH and Tian, ZZ and Huang, H and Gao, Z}},
Book-Group-Author = {{ASCE}},
Title = {{An Onboard Optimal Control System for Freight Trains}},
Booktitle = {{TRAFFIC AND TRANSPORTATION STUDIES}},
Year = {{2008}},
Pages = {{770-783}},
Note = {{6th International Conference on Traffic and Transportation Studies,
   Beijing Jiaotong Univ, Nanning, PEOPLES R CHINA, AUG 05-07, 2008}},
Organization = {{Syst Engn Soc China; Amer Soc Civil Engn; Beijing Jiaotong Univ; Inst
   Transportat Engn; Lanzhou Jiaotong Univ; State Key Lab Rail Traff
   Control \& Safety; Beijing Transportat Res Ctr; Japan Soc Civil Engn;
   Hong Kong Soc Transportat Studies; Inst Highways \& Transportat}},
Abstract = {{This thesis aims to probe into optimal control approaches for freight
   train by giving priority to the objective of minimizing energy
   consumption, which is also expected to design the algorithm for optimal
   real-time control of freight train based on the handle control of the
   locomotive, and develop a set of guiding devices applicable to optimal
   control of train under different signal systems and railway conditions.
   The guiding devices is capable of conducting dynamic collection of train
   running information to proceed with the online design of guiding
   proposal for optimal control applicable to the current running
   environment. According to the results of test carried out at the section
   between Changanji-Dagudian under the governance of Shanghai Railway
   Administration, the guiding devices can reduce the energy consumption
   and delays while ensuring the safe and smooth running.}},
ISBN = {{978-0-7844-0995-4}},
Unique-ID = {{ISI:000288141000072}},
}

@article{ ISI:000253702500004,
Author = {Aylon, Sergio Lopez and Ruiz, Ali Haddou},
Title = {{Design of regulatory bodies in Mexico}},
Journal = {{GESTION Y POLITICA PUBLICA}},
Year = {{2007}},
Volume = {{16}},
Number = {{1}},
Pages = {{101-145}},
Note = {{10th International Congress of
   Centro-Latinoamericano-de-Administracion-Para-el-Desarrollo (CLAD),
   Santiago, CHILE, OCT 18-21, 2005}},
Organization = {{Centro Latinoamer Adm Para Desarrollo}},
Abstract = {{Although regulatory authorities have always been a part of the
   institutional makeup of Mexican public administration, the idea of
   independent regulatory authorities was introduced only in the early
   90's, when the process of economic reform was well underway. These
   independent regulatory authorities can be grouped into two broad
   categories. The first includes typical sectoral regulatory entities
   (e.g. energy and telecommunications). The second category comprises
   independent agencies created to anchor continuous horizontal reform
   processes, such as competition and access to information. Based upon the
   Mexican regulatory authorities' experience, this paper proposes a
   framework for the analysis of accountability mechanisms of independent
   regulators. An important lesson from this review is that the use of
   mechanisms such as access to information and regulatory impact analysis,
   enforced by other independent regulatory agencies, strengthen the
   horizontal accountability of sectoral regulatory authorities and reduces
   the risk of capture.}},
ISSN = {{1405-1079}},
Unique-ID = {{ISI:000253702500004}},
}

@inproceedings{ ISI:000254030000024,
Author = {Li, Ye},
Book-Group-Author = {{IEEE}},
Title = {{Scenario-based analysis on the impacts of plug-in hybrid electric
   vehicles' (PHEV) penetration into the transportation sector}},
Booktitle = {{2007 IEEE INTERNATIONAL SYMPOSIUM ON TECHNOLOGY AND SOCIETY}},
Series = {{IEEE International Symposium on Technology and Society}},
Year = {{2007}},
Pages = {{145-150}},
Note = {{IEEE International Symposium on Technology and Society, Las Vegas, NV,
   JUN 01-02, 2007}},
Organization = {{IEEE}},
Abstract = {{With the improved awareness of negative environmental impact from
   traditional automobile fuel consumption and the fluctuating increase of
   gas price, fuel demand and supply in the transportation sector and
   strategies of securing it has gained governmental and public attentions.
   Plug-In Hybrid Electric Vehicles (PREP), as an alternative to the
   conventional vehicles, become appealing. A PHEV is a hybrid electric
   vehicle with sufficient battery to support its daily travel and an
   internal combustion engine to allow overtime travel, which is expected
   to help reduce obnoxious chemicals emission and oil dependency caused by
   the usage of conventional vehicles.
   In this paper, we employed the National Energy Modeling System (NEMS)
   developed by the Energy Information Administration (EIA) to study the
   impact from PHEV penetration into the transportation sector on the
   future electric generation capacity expansion in the United States.
   Arbitrary penetration trajectories of PHEVs for light duty vehicles
   (i.e., cars, pickup trucks, SUVs) were postulated that started
   penetration in 2006 and projected 110 million PHEV vehicles till 2030.
   It shows that large volume of PHEV penetration can reduce most negative
   impacts.}},
DOI = {{10.1109/AOE.2007.4410732}},
ISBN = {{978-1-4244-0586-2}},
Unique-ID = {{ISI:000254030000024}},
}

@article{ ISI:A1991FM50900014,
Author = {VINA, JR and SALUS, JE and DEJOSEPH, MR and PALLARDO, F and TOWFIGHI, J
   and HAWKINS, RA},
Title = {{BRAIN ENERGY-CONSUMPTION IN ETHANOL-TREATED, LONG-EVANS RATS}},
Journal = {{JOURNAL OF NUTRITION}},
Year = {{1991}},
Volume = {{121}},
Number = {{6}},
Pages = {{879-886}},
Month = {{JUN}},
Abstract = {{The cerebral metabolic rate of glucose utilization (CMR(Gic)) was
   measured in rats fed liquid diets containing ethanol for 8 wk, after
   removal of ethanol from the diet and after acute ethanol intoxication. 
   Control rats were pair fed the liquid diets containing isoenergetic
   amounts of dextrin-maltose.  Quantitative autogradiography using
   {[}6-C-14]glucose measured CMR(Gic) at the level of individual
   structures.  Digital image techniques created stereograms of brain
   energy consumption from the autoradiographs.  These techniques provided
   information about CMR(Gic) throughout the brain.  Rats given the ethanol
   liquid diet drank constantly throughout the day and night. 
   Neuropathological examination of brain revealed no abnormalities from
   ethanol consumption.  Acute ethanol administration to control rats
   produced a decrease in CMR(Gic) throughout the brain that was most
   prominent in structures concerning auditory, visual, memory and motor
   functions.  Chronic ethanol consumption did not reduce CMR(Gic) to the
   same degree as acute ethanol intoxication; in fact, it affected only a
   few structures.  The removal of ethanol from chronic ethanol-treated
   rats for a period of 18 h caused CMR(Gic) to rise above control values
   throughout the brain.  However, there were no seizures or other evidence
   of brain dysfunction.}},
ISSN = {{0022-3166}},
Unique-ID = {{ISI:A1991FM50900014}},
}

@inproceedings{ ISI:000337104400023,
Author = {Difiglio, Carmine and Wanner, Brent},
Editor = {{Ragaini, R}},
Title = {{ECONOMICS OF NUCLEAR POWER IN LIBERALIZED POWER MARKETS}},
Booktitle = {{INTERNATIONAL SEMINAR ON NUCLEAR WAR AND PLANETARY EMERGENCIES: 45TH
   SESSION}},
Series = {{Science and Culture Series: Nuclear Strategy and Peace Technology}},
Year = {{2013}},
Pages = {{271-287}},
Note = {{45th International Seminar on Nuclear War and Planetary Emergencies,
   Erice, ITALY, AUG 19-24, 2012}},
Organization = {{E Majorana Ctr Sci Culture}},
Abstract = {{Projections of electricity markets such as the International Energy
   Agency's (IEA) World Energy Outlook (WEO) or the Energy Information
   Administration's (EIA) Annual Energy Outlook (AEO) rely on estimated
   levelized costs for nuclear power and other power generation
   technologies. These levelized cost estimates show nuclear to be a very
   competitive power generating technology in most regions of the world.
   This paper analyzes unpublished data from the 2011 WEO to assess the
   competitiveness of nuclear power in liberalized and non-competitive
   power markets. We consider alternative estimates of nuclear capital
   costs (Risk Scenario) that might well be considered before investing in
   nuclear power in competitive markets without government guarantees. The
   Risk Scenario also assumes lower natural gas prices that could result
   from higher shale gas recovery in the United States and new shale gas
   development in Europe. The Risk Scenario causes the relative cost
   difference of nuclear power vs. natural gas to change by 5 cents/kWhr.
   Instead of nuclear power holding a competitive advantage over natural
   gas, in the Risk Scenario, natural gas gains a competitive advantage
   over nuclear power, even if a \$50/ton CO(2)e charge is assessed.
   The analysis suggests that nuclear power plants will not be built in
   liberalized power markets without government guarantees. If nuclear
   power plants built with government support or those built by state-owned
   power industries prove that nuclear power plants can be reliably built
   at a competitive cost, power plant economics will be a significant
   positive factor for the nuclear industry, especially taking into
   consideration national commitments to reduce greenhouse gas (GHG)
   emissions. If costs continue to increase over the estimates being used
   by the IEA and EIA, power-plant economics become a significant negative
   factor for the nuclear industry that may not be offset by pricing CO2
   emissions.
   These findings do not apply to reactor projects in many Asian countries.
   Nuclear power is estimated to enjoy a more favorable cost advantage than
   in the United States, Europe or Japan. In addition, private financing is
   less important in many Asian countries and delays due to licensing
   problems are less likely. Given the high electricity demand growth
   expected in Asia, more competitive costs, and government support, it is
   not surprising that over 60\% of currently-planned nuclear reactors are
   in Asia.}},
ISBN = {{978-981-4531-77-1}},
Unique-ID = {{ISI:000337104400023}},
}

@article{ ISI:000293810700021,
Author = {Ames, Mark},
Title = {{CBECS in Jeopardy?}},
Journal = {{ASHRAE JOURNAL}},
Year = {{2011}},
Volume = {{53}},
Number = {{8}},
Pages = {{80}},
Month = {{AUG}},
Abstract = {{Funding for the 2011 edition of the Commercial Buildings Energy
   Consumption Survey (CBECS) may be in jeopardy for the coming fiscal year
   as a result of report language inserted into the House Energy and Water
   funding bill for fiscal year 2012 that places severe restrictions on
   funding for federal energy consumption surveys administered by the
   Energy Information Administration (EIA), which includes CBECS.}},
ISSN = {{0001-2491}},
Unique-ID = {{ISI:000293810700021}},
}

@article{ ISI:000250314200003,
Author = {Cicas, Gyorgyi and Hendrickson, Chris T. and Horvath, Arpad and
   Matthews, H. Scott},
Title = {{A regional version of a US economic input-output life-cycle assessment
   model}},
Journal = {{INTERNATIONAL JOURNAL OF LIFE CYCLE ASSESSMENT}},
Year = {{2007}},
Volume = {{12}},
Number = {{6}},
Pages = {{365-372}},
Month = {{SEP}},
Abstract = {{Background, Aims and Scope. Life cycle assessment models typically use
   product-specific, plant-level or national aggregate data. However, many
   decisions by regional policy makers would be better informed by local or
   regional aggregate data. This research is intended to construct and
   apply a regional US economic input-output analysis-based life cycle
   assessment (REIO-LCA) model based upon publicly available datasets. The
   model uses Gross State Product (GSP) estimates to calculate regional
   economic multipliers and then link them to regional electricity and fuel
   use, and air emission factors. Target audiences are governmental
   decision makers, industry experts and researchers concerned,with the
   regional economic and environmental effects of public and private
   decisions.
   Methods. A regional version of the existing US EIO-LCA model was
   developed using-regional economic multipliers and state environmental
   data. The national model is based on the US 491 by 491 economic
   input-output model, and uses sectoral energy consumption and emission
   factors to approximate the environmental effects of production and
   services. The proportion of the regional value added (Gross State
   Product) to the national value added for each sector was used to develop
   economic multipliers to allocate the output of industries to individual
   states and multi-state regions. Inter-sectoral transaction matrices were
   constructed for eight regions. Regional environmental emission and
   resource use factors were formed based upon publicly available data of
   the US Environmental Protection Agency (EPA) and Department of Energy.
   The Toxics Release Inventory include facility location parameters,
   enabling the estimation of sectoral toxic emissions for the regions. The
   national electricity and fuel use, air pollutants (CO, NOx, PM10, SO2
   and VOC) and greenhouse gas emissions used by the EIO-LCA model were
   proportioned based upon state totals for each sector.
   Results. A regional economic input-output model was created for US
   regions; and sectoral energy use and environmental emission factors were
   estimated for Pennsylvania, the Far West (Alaska, California, Hawaii,
   Nevada, Oregon and Washington) and the Mideast (Delaware, District of
   Columbia, Maryland, New Jersey, New York and Pennsylvania) economic
   areas. The use of the framework for regional IO-LCA model is
   demonstrated through two case studies.
   Discussion. As a validation exercise, the regional outputs of petroleum
   refineries were calculated using the regional input-output matrices and
   the outcomes were compared to the Energy Information Administration's
   (EIA) Petroleum State Profile data. The model results show that
   approximately 70\% of the total national sectoral production takes place
   in three regions, i.e., South West, South East and Far West, which
   corresponds with the EIA statistics. The REIO-LCA model constructed for
   the Far West is used to conduct a second case study estimating the
   annual toxic air emissions of power plants in the region in 2003. The
   results are evaluated by comparison to data provided by the US EPA. The
   estimated pollutions do not differ significantly from those presented in
   the Toxics Release Inventory reports.
   Conclusions. The usefulness of IO LCA models can be improved through the
   incorporation of local economic and environmental characteristics. Wiht
   the lack of US regional sectoral data, the allocation of national
   industrial production to regions can provide a framework to create
   smaller scale IO models. The results of case studies support the
   assumption that the GSP multipliers may be used to allocate the sectoral
   production to the regions, and show that the framework IO LCA model
   provides a reasonable approximation of supply chain economic activities
   and environmental effects caused by production and services.
   Recommendations and Perspectives. The quality of data, e.g., age and
   level of aggregation, and the assumed linearity between sectoral outputs
   and environmental emissions represent the main sources of uncertainty in
   the model. The results show that the GSP estimates are appropriate to
   construct a framework for a regional economic input-output and
   environmental assessment model. However, further research is recommended
   to construct more specific state-level input-output matrices
   incorporating interstate commodity flows, and state environmental
   factors in order to mitigate the parameter uncertainties. Further, the
   model might be improved by updating it regularly, as more recent data
   become available.}},
DOI = {{10.1065/lca2007.04.318}},
ISSN = {{0948-3349}},
ORCID-Numbers = {{Hendrickson, Chris/0000-0002-9812-3580}},
Unique-ID = {{ISI:000250314200003}},
}

@article{ ISI:000242175900001,
Author = {Meijer, Y. J. and Swart, D. P. J. and Baier, F. and Bhartia, P. K. and
   Bodeker, G. E. and Casadio, S. and Chance, K. and Del Frate, F. and
   Erbertseder, T. and Felder, M. D. and Flynn, L. E. and Godin-Beekmann,
   S. and Hansen, G. and Hasekamp, O. P. and Kaifel, A. and Kelder, H. M.
   and Kerridge, B. J. and Lambert, J. -C. and Landgraf, J. and Latter, B.
   and Liu, X. and McDermid, I. S. and Pachepsky, Y. and Rozanov, V. and
   Siddans, R. and Tellmann, S. and van der A, R. J. and van Oss, R. F. and
   Weber, M. and Zehner, C.},
Title = {{Evaluation of Global Ozone Monitoring Experiment (GOME) ozone profiles
   from nine different algorithms}},
Journal = {{JOURNAL OF GEOPHYSICAL RESEARCH-ATMOSPHERES}},
Year = {{2006}},
Volume = {{111}},
Number = {{D21}},
Month = {{NOV 15}},
Abstract = {{{[}1] An evaluation is made of ozone profiles retrieved from
   measurements of the nadir-viewing Global Ozone Monitoring Experiment
   (GOME) instrument. Currently, four different approaches are used to
   retrieve ozone profile information from GOME measurements, which differ
   in the use of external information and a priori constraints. In total
   nine different algorithms will be evaluated exploiting the optimal
   estimation ( Royal Netherlands Meteorological Institute, Rutherford
   Appleton Laboratory, University of Bremen, National Oceanic and
   Atmospheric Administration, Smithsonian Astrophysical Observatory),
   Phillips-Tikhonov regularization ( Space Research Organization
   Netherlands), neural network ( Center for Solar Energy and Hydrogen
   Research, Tor Vergata University), and data assimilation ( German
   Aerospace Center) approaches. Analysis tools are used to interpret data
   sets that provide averaging kernels. In the interpretation of these
   data, the focus is on the vertical resolution, the indicative altitude
   of the retrieved value, and the fraction of a priori information. The
   evaluation is completed with a comparison of the results to lidar data
   from the Network for Detection of Stratospheric Change stations in
   Andoya ( Norway), Observatoire Haute Provence ( France), Mauna Loa (
   Hawaii), Lauder ( New Zealand), and Dumont d'Urville ( Antarctic) for
   the years 1997 - 1999. In total, the comparison involves nearly 1000
   ozone profiles and allows the analysis of GOME data measured in
   different global regions and hence observational circumstances. The main
   conclusion of this paper is that unambiguous information on the ozone
   profile can at best be retrieved in the altitude range 15 - 48 km with a
   vertical resolution of 10 to 15 km, precision of 5 - 10\%, and a bias up
   to 5\% or 20\% depending on the success of recalibration of the input
   spectra. The sensitivity of retrievals to ozone at lower altitudes
   varies from scheme to scheme and includes significant influence from a
   priori assumptions.}},
DOI = {{10.1029/2005JD006778}},
Article-Number = {{D21306}},
ISSN = {{2169-897X}},
ResearcherID-Numbers = {{Flynn, Lawrence/B-6321-2009
   Weber, Mark/F-1409-2011
   Del Frate, Fabio/G-1413-2013
   Liu, Xiong/P-7186-2014
   Chance, Kelly/}},
ORCID-Numbers = {{Flynn, Lawrence/0000-0001-6856-2614
   Weber, Mark/0000-0001-8217-5450
   Liu, Xiong/0000-0003-2939-574X
   Chance, Kelly/0000-0002-7339-7577}},
Unique-ID = {{ISI:000242175900001}},
}

@article{ ISI:000181665500002,
Author = {Salem, JA},
Title = {{Public and private sector interests in e-government: a look at the DOE's
   PubSCIENCE}},
Journal = {{GOVERNMENT INFORMATION QUARTERLY}},
Year = {{2003}},
Volume = {{20}},
Number = {{1}},
Pages = {{13-27}},
Abstract = {{As the federal government offers more online services and information to
   an increasingly connected America, public awareness and use are
   increasing as well. While federal agencies take advantage of information
   technology to provide services and information, some representatives of
   the computer, software, and communications industries occasionally raise
   concerns over the presence of the federal government in the emerging
   e-commerce market and in the market for commercial information
   providers. This debate follows a decade-long trend toward privatization
   of government functions as part of the Clinton Administration's push to
   reinvent government. The development of e-government is further
   complicated by a lack of clarity and consistency in policy and
   oversight. This paper explores the controversy surrounding the
   PubSCIENCE initiative from the Department of Energy to outline the
   issues involved in defining the boundaries between e-government and
   e-commerce in such a way that cooperation is developed and competition
   is avoided. (C) 2003 Elsevier Science Inc. All rights reserved.}},
DOI = {{10.1016/S0740-624X(02)00133-8}},
Article-Number = {{PII S0740-624X(02)00133-8}},
ISSN = {{0740-624X}},
Unique-ID = {{ISI:000181665500002}},
}

@article{ ISI:000089451700002,
Author = {Shepherd, GW and Kahler, RJ and Cross, J},
Title = {{Crane fatalities - a taxonomic analysis}},
Journal = {{SAFETY SCIENCE}},
Year = {{2000}},
Volume = {{36}},
Number = {{2}},
Pages = {{83-93}},
Month = {{NOV}},
Abstract = {{It should not be necessary for each generation to rediscover principles
   of safety which the generation before already discovered. We must learn
   from the experience of others rather than learn the hard way. We must
   pass onto the next generation a record of what we have learnt. Jessie C.
   Ducommun
   Cranes are remarkable and invaluable tools for hoisting and carrying:
   Like all other tools they have significantly increased humans' capacity
   to work; they marshal far more energy than can human or animal muscle.
   However, the large quantities of energy involved and the
   human-crane-environment interactions required result in there being a
   high potential for damage to occur to people and equipment. The current
   situation is that similar serious crane occurrences continue to
   repeatedly recur, albeit separated in terms of time and space. As a
   result, crane fatalities can be considered as endemic, at least; many
   would suggest epidemic. To gain sufficient insight into the aetiology of
   crane-related damage, and establish key focus areas for future control,
   there is a need to establish the pattern of crane-related damaging
   occurrences. To achieve this for fatalities, an approach was made to the
   US Occupational Safety and Health Administration (OSHA), which provided
   over 500 crane fatality narratives for the years 1985-1945. This
   information was scientifically organised using the taxonomic process
   involving observation, description and classification of the data into
   groups. The pattern is presented along with discussion regarding the
   application and limitations of the information. The data are intended to
   add to the information base of crane designers, owners and users in
   order to challenge the status quo and generate effective change for the
   future. (C) 2000 Elsevier Science Ltd. All rights reserved.}},
DOI = {{10.1016/S0925-7535(00)00017-5}},
ISSN = {{0925-7535}},
Unique-ID = {{ISI:000089451700002}},
}

@inproceedings{ ISI:000088061300007,
Author = {Kashiwagi, D},
Editor = {{Walsh, KD}},
Title = {{Artificial intelligent performance based procurement system}},
Booktitle = {{CONSTRUCTION CONGRESS VI, PROCEEDING: BUILDING TOGETHER FOR A BETTER
   TOMORROW IN AN INCREASINGLY COMPLEX WORLD}},
Year = {{2000}},
Pages = {{49-58}},
Note = {{6th Construction Congress on Building Together for a Better Tomorrow in
   an Increasingly Complex World, ORLANDO, FL, FEB 20-22, 2000}},
Organization = {{Construct Div Amer Soc Civil Engineers; Univ Florida, ME Rinker Sch
   Construct; Int Council Bldg Res Studies \& Documentat}},
Abstract = {{A new Performance Based Information System (PBIS)/Performance Based
   Procurement System (PBPS) is under development and testing. It harnesses
   the technological advancement of computer technology, information
   technology, and artificial intelligence. It is based on Information
   Measurement Theory (IMT). The research effort has been ongoing for the
   last five years, resulting in over \$2.5 million research and 150 tests
   in the private and public sectors. Current research partners include the
   states of Utah and Hawaii, the Federal Aviation Administration (FAA),
   United Air Lines, Peco Energy, the Sheet Metal and Air Conditioning
   National Association (SMACNA) and construction contractors and material
   manufacturers. The current and future deliverables of the research
   include unique ``genetic performance bar codes{''} for constructors and
   construction systems, an unbiased, artificially intelligent decision
   maker for identification of value, a(1)nd an information system that
   will replace minimum standards in all ``noncommodity{''} or ``risk{''}
   areas of construction.}},
ISBN = {{0-7844-0475-5}},
Unique-ID = {{ISI:000088061300007}},
}

@inproceedings{ ISI:000088388600178,
Author = {Overbye, TJ and Hale, DR and Leckey, T and Weber, JD},
Book-Group-Author = {{IEEE
   IEEE
   IEEE}},
Title = {{Assessment of transmission constraint costs: Northeast US case study}},
Booktitle = {{2000 IEEE POWER ENGINEERING SOCIETY WINTER MEETING - VOLS 1-4,
   CONFERENCE PROCEEDINGS}},
Year = {{2000}},
Pages = {{903-908}},
Note = {{2000 Winter Meeting of the IEEE Power Engineering-Society, SINGAPORE,
   SINGAPORE, JAN 23-27, 2000}},
Organization = {{IEEE Power Engn Soc; IEEE Networking World}},
Abstract = {{This paper provides a methodology to examine the impact of transmission
   constraints on the efficient operation of large scale power markets. The
   Northeast U.S, is presented as a case study. A system model was first
   constructed using the publicly available U.S. Federal Energy Regulatory
   Commission (FERC) Form 715 filings to provide a detailed representation
   of the transmission system. FERC Form 1 data and information from the
   U.S. Energy Information Administration's (EIA) National Energy Modeling
   System model were used to represent generator costs. An optimal power
   flow (OPF) was then used to optimally dispatch a large system consisting
   of the New England Region (NEPOOL), New York (NYPP), and the NERC MAAC
   and ECAR regions, both under base case and modified conditions. Using
   the OFF results, the costs associated with transmission constraints are
   determined. Finally, given the large amount of data generated by these
   studies, methods for the efficient visualization of the results are also
   discussed.}},
ISBN = {{0-7803-5935-6}},
Unique-ID = {{ISI:000088388600178}},
}

@article{ ISI:000077381500009,
Author = {Smith, LL},
Title = {{Estimating US uranium reserves}},
Journal = {{JOM-JOURNAL OF THE MINERALS METALS \& MATERIALS SOCIETY}},
Year = {{1998}},
Volume = {{50}},
Number = {{12}},
Pages = {{41-43}},
Month = {{DEC}},
Abstract = {{This article presents information on the Energy Information
   Administration's (U.S. Department of Energy) annual estimates of U.S.
   uranium reserves. Encompassed is information for year-end 1997's uranium
   reserves, which were estimated by employing numerous resources.}},
DOI = {{10.1007/s11837-998-0306-6}},
ISSN = {{1047-4838}},
Unique-ID = {{ISI:000077381500009}},
}

@inproceedings{ ISI:000073814100039,
Author = {Sick, G and Allen, D and McGee, BD and Walker, R},
Book-Group-Author = {{INT EROSION CONTROL ASSOC}},
Title = {{One government - Getting the most for your resource management dollar}},
Booktitle = {{PROCEEDINGS OF CONFERENCE 29 - INTERNATIONAL EROSION CONTROL ASSOCIATION}},
Series = {{INTERNATIONAL EROSION CONTROL ASSOCIATION - PROCEEDINGS OF CONFERENCE}},
Year = {{1998}},
Volume = {{29}},
Pages = {{493-496}},
Note = {{Conference 29 of the International-Erosion-Control-Association on
   Winning Solutions for Risky Problems, RENO, NV, FEB 16-20, 1998}},
Organization = {{Int Eros Control Assoc}},
Abstract = {{Long before ``government reinvention{''} became the mission of the
   Clinton administration many federal agencies had found ways to work with
   each other to accomplish day to day tasks as well as special projects.
   Cooperation was not uncommon!
   In South Carolina at the Savannah River Site, a Department of Energy
   facility, and at Fort Jackson, a Department of Defense facility, there
   are long-standing, model programs for collaboration. These programs
   demonstrate the efficiencies of interagency resource management and
   should be implemented at other federal facilities.
   The longest term of these arrangements is between the USDA Forest
   Service and the Department of Energy at the Savannah River Site. The
   original agreement, signed in 1952, charged the Forest Service with
   reforesting the mostly open 80,000 hectare site. Since 1952 the
   agreement has evolved to comprehensive natural resource management
   including erosion control, research, timber harvest, education,
   threatened and endangered species management and other activities.
   Also at the Savannah River Site the USDA Soil Conservation Service (now
   NRCS) entered into an agreement with the Department of Energy to conduct
   an inventory and prepare the soil survey. This agreement too has
   continuously evolved, and now includes responsibility for inventories,
   field assistance, erosion control, and storm water management.
   At Fort Jackson (21,000 hectares) the USDA Natural Resources
   Conservation Service and USDA Forest Service are providing daily support
   to the Army. The NRCS began working on critically eroding areas of the
   fort in 1991, and has now extended its agreement with the Army
   indefinitely. For about the same period the Forest Service has assisted
   with prescribed burning and endangered species management.
   The Departments of Energy and Defense are tapping the most experienced
   natural resource management agencies in federal government for quality
   personnel rather than developing their own.
   Both Fort Jackson and the Savannah River Site are undergoing mission
   changes and modernization. Each covers a large land base rich in natural
   resources. The potential environmental effects from day-to-day
   operations as well as modernization are substantial. Through these
   cooperative arrangements the managing agencies are able to obtain expert
   guidance for environmental controls on new projects as well as project
   design and implementation for sediment and erosion control.
   These ``on-loan{''} employees have their parent organizations to support
   them when needed. They also learn new management objectives and
   approaches from their host agency. We believe these types of
   arrangements are under-utilized; that there are many opportunities for
   further collaboration.
   This poster displays information about the history of this
   collaboration, lists some representative program and project costs, and
   displays successful project implementation.}},
ISSN = {{1092-2806}},
Unique-ID = {{ISI:000073814100039}},
}

@article{ ISI:A1997YB39400002,
Author = {Kim, YO and Palmer, RN},
Title = {{Value of seasonal flow forecasts in Bayesian Stochastic Programming}},
Journal = {{JOURNAL OF WATER RESOURCES PLANNING AND MANAGEMENT-ASCE}},
Year = {{1997}},
Volume = {{123}},
Number = {{6}},
Pages = {{327-335}},
Month = {{NOV-DEC}},
Abstract = {{This paper presents a Bayesian Stochastic Dynamic Programming (BSDP)
   model to investigate the value of seasonal flow forecasts in hydropower
   generation. The proposed BSDP framework generates monthly operating
   policies for the Skagit Hydropower System (SHS), which supplies energy
   to the Seattle metropolitan area. The objective function maximizes the
   total benefits resulting from energy produced by the SHS and its
   interchange with the Bonneville Power Administration. The BSDP-derived
   operating policies for the SHS are simulated using historical monthly
   inflows, as well as seasonal flow forecasts during 60 years from January
   1929 through December 1988. Performance of the BSDP model is compared
   with alternative stochastic dynamic programming models. To illustrate
   the potential advantage of using the seasonal how forecasts and other
   hydrologic information, the sensitivity of SHS operation is evaluated by
   varying (1) the reservoir capacity; (2) the energy demand; and (3) the
   energy price. The simulation results demonstrate that including the
   seasonal forecasts is beneficial to SHS operation.}},
DOI = {{10.1061/(ASCE)0733-9496(1997)123:6(327)}},
ISSN = {{0733-9496}},
ResearcherID-Numbers = {{Palmer, Richard/K-4432-2013}},
ORCID-Numbers = {{Palmer, Richard/0000-0002-7338-0468}},
Unique-ID = {{ISI:A1997YB39400002}},
}

@article{ ISI:000180875100028,
Author = {Noethlings, U and Hoffmann, K and Bergmann, MM and Boeing, H},
Title = {{Portion size adds limited information on variance in food intake of
   participants in the EPIC-Potsdam Study}},
Journal = {{JOURNAL OF NUTRITION}},
Year = {{2003}},
Volume = {{133}},
Number = {{2}},
Pages = {{510-515}},
Month = {{FEB}},
Abstract = {{Food-frequency questionnaire (FFQ) data should reflect interindividual
   variation and therefore measure variance in intake among populations. We
   conducted this analysis to evaluate the. relevance of separate portion
   size questions to the interindividual variation in food intake. The
   contribution of portion size questions to the variance in food intake
   was quantified and compared with the variance when group-specific
   portion sizes would be assigned, using 26,764 FFQ of the European
   Investigation into Cancer and Nutrition (EPIC)Potsdam Study. Groups were
   defined according to gender, age (<50y, greater than or equal to50y) or
   body mass index (BMI) (<26 kg/m(2), greater than or equal to26 kg/m(2)).
   The FFQ inquired about both consumption frequency and portion size.
   Linear regression models for each food item were fit with intake (g/d)
   as dependent variables and frequency of intake as independent variables.
   The mean coefficient of determination (R-2) for the different food items
   explained by frequency only Was 84.0\% (71.2-95.7\%). The R-2 for
   gender-, age- and BMI-specific frequencies of intake did not markedly
   alter the overall results. We conclude that the omission of individual
   portion size information would probably result in a notable reduction of
   interindividual variance. However, to reduce the respondents' burden and
   to increase data completeness in self-administration in large
   epidemiologic studies, the assignment of a constant portion size seems
   to be adequate. The variance was not increased markedly when constant
   gender-, age- and BMI-specific portion sizes were applied, thus
   supporting the assignment of an overall portion size.}},
ISSN = {{0022-3166}},
ResearcherID-Numbers = {{Nothlings, Ute/B-2713-2010}},
Unique-ID = {{ISI:000180875100028}},
}

@article{ ISI:000341230000016,
Author = {Gravier, Julien and Sancey, Lucie and Hirsjaervi, Samuli and Rustique,
   Emilie and Passirani, Catherine and Benoit, Jean-Pierre and Coll,
   Jean-Luc and Texier, Isabelle},
Title = {{FRET Imaging Approaches for in Vitro and in Vivo Characterization of
   Synthetic Lipid Nanoparticles}},
Journal = {{MOLECULAR PHARMACEUTICS}},
Year = {{2014}},
Volume = {{11}},
Number = {{9}},
Pages = {{3133-3144}},
Month = {{SEP}},
Abstract = {{DiI and DiD, two fluorophores able to interact by FRET (Forster
   resonance energy transfer), were coencapsulated in the core of lipid
   nanocapsules (LNCs) and nanoemulsions (LNEs), lipophilic reservoirs for
   the delivery of drugs. The ability of FRET imaging to provide
   information on the kinetics of dissociation of the nanopartides in the
   presence of bovine serum albumin (BSA) or whole serum, or after
   incubation with cancer cells, and after systemic administration in
   tumor-bearing mice, was studied. Both microscopic and macroscopic
   imaging was performed to determine the behavior of the nanostructures in
   a biological environment. When 2 mg/mL FRET LNEs or LNCs were dispersed
   in buffer, in the presence of unloaded nanoparticles, BSA, or in whole
   serum, the presence of serum was the most active in destroying the
   particles. This occurred immediately with a diminution of 20\% of FRET,
   then slowly, ending up with still 30\% intact nanoparticles at 24 h.
   LNCs were internalized rapidly in cultured cells with the FRET signal
   decreasing within the first minutes of incubation, and then a plateau
   was reached and LNCs remained intact during 3 h. In contrast, LNEs were
   poorly internalized and were rapidly dissociated after internalization.
   Following their iv injection, LNCs appeared very stable in subcutaneous
   tumors implanted in mice. Intact particles were found using microscopic
   FRET determination on tumor sections 24 h after injection, that
   correlated well with the 8\% calculated noninvasively on live animals.
   FRET investigations showed the potential to determine valid and reliable
   information about in vitro and in vivo behavior of nanoparticles.}},
DOI = {{10.1021/mp500329z}},
ISSN = {{1543-8384}},
ResearcherID-Numbers = {{PASSIRANI, Catherine/K-4379-2015
   Benoit, Jean-Pierre/K-4387-2015}},
Unique-ID = {{ISI:000341230000016}},
}

@article{ ISI:000333538100039,
Author = {Wang, Yanwei and Yu, F. Richard and Tang, Helen and Huang, Minyi},
Title = {{A Mean Field Game Theoretic Approach for Security Enhancements in Mobile
   Ad hoc Networks}},
Journal = {{IEEE TRANSACTIONS ON WIRELESS COMMUNICATIONS}},
Year = {{2014}},
Volume = {{13}},
Number = {{3}},
Pages = {{1616-1627}},
Month = {{MAR}},
Abstract = {{Game theory can provide a useful tool to study the security problem in
   mobile ad hoc networks (MANETs). Most of existing works on applying game
   theories to security only consider two players in the security game
   model: an attacker and a defender. While this assumption may be valid
   for a network with centralized administration, it is not realistic in
   MANETs, where centralized administration is not available. In this
   paper, using recent advances in mean field game theory, we propose a
   novel game theoretic approach with multiple players for security in
   MANETs. The mean field game theory provides a powerful mathematical tool
   for problems with a large number of players. The proposed scheme can
   enable an individual node in MANETs to make strategic security defence
   decisions without centralized administration. In addition, since
   security defence mechanisms consume precious system resources (e. g.,
   energy), the proposed scheme considers not only the security requirement
   of MANETs but also the system resources. Moreover, each node in the
   proposed scheme only needs to know its own state information and the
   aggregate effect of the other nodes in the MANET. Therefore, the
   proposed scheme is a fully distributed scheme. Simulation results are
   presented to illustrate the effectiveness of the proposed scheme.}},
DOI = {{10.1109/TWC.2013.122313.131118}},
ISSN = {{1536-1276}},
EISSN = {{1558-2248}},
Unique-ID = {{ISI:000333538100039}},
}

@article{ ISI:000330926200048,
Author = {Griessinger, Christoph M. and Kehlbach, Rainer and Bukala, Daniel and
   Wiehr, Stefan and Bantleon, Ruediger and Cay, Funda and Schmid, Andreas
   and Braumueller, Heidi and Fehrenbacher, Birgit and Schaller, Martin and
   Eichner, Martin and Sutcliffe, Julie L. and Ehrlichmann, Walter and
   Eibl, Oliver and Reischl, Gerald and Cherry, Simon R. and Roecken,
   Martin and Pichler, Bernd J. and Kneilling, Manfred},
Title = {{In Vivo Tracking of Th1 Cells by PET Reveals Quantitative and Temporal
   Distribution and Specific Homing in Lymphatic Tissue}},
Journal = {{JOURNAL OF NUCLEAR MEDICINE}},
Year = {{2014}},
Volume = {{55}},
Number = {{2}},
Pages = {{301-307}},
Month = {{FEB}},
Abstract = {{Although T cells can be labeled for noninvasive in vivo imaging, little
   is known about the impact of such labeling on T-cell function, and most
   imaging methods do not provide holistic information about trafficking
   kinetics, homing sites, or quantification. Methods: We developed
   protocols that minimize the inhibitory effects of
   Cu-64-pyruvaldehyde-bis(N4-methylthiosemicarbazone) (Cu-64-PTSM)
   labeling on T-cell function and permit the homing patterns of T cells to
   be followed by PET. Thus, we labeled ovalbumin (OVA) T-cell receptor
   transgenic interferon (IFN)-gamma-producing CD4(+) T (Th1) cells with
   0.7-2.2 MBq of Cu-64-PTSM and analyzed cell viability, IFN-gamma
   production, proliferation, apoptosis, and DNA double-strand breaks and
   identified intracellular Cu-64 accumulation sites by energy dispersive
   x-ray analysis. To elucidate the fate of Th1 cell homing by PET, 107
   Cu-64-OVA-Th1 cells were injected intraperitoneally or intravenously
   into healthy mice. To test the functional capacities of Cu-64-OVA-Th1
   cells during experimental OVA-induced airway hyperreactivity, we
   injected 10(7) Cu-64-OVA-Th1 cells intraperitoneally into OVA-immunized
   or nonimmunized healthy mice, which were challenged with OVA peptide or
   phosphate-buffered saline or remained untreated. In vivo PET
   investigations were followed by biodistribution, autoradiography, and
   fluorescence-activated cell sorting analysis. Results: PET revealed
   unexpected homing patterns depending on the mode of T-cell
   administration. Within 20 min after intraperitoneal administration,
   Cu-64-OVA-Th1 cells homed to the perithymic lymph nodes (LNs) of naive
   mice. Interestingly, intravenously administered Cu-64-OVA-Th1 cells
   homed predominantly into the lung and spleen but not into the perithymic
   LNs. The accumulation of Cu-64-OVA-Th1 cells in the pulmonary LNs (6.8
   +/- 1.1 percentage injected dose per cubic centimeter {[}\%ID/cm(3)]) 24
   h after injection was highest in the OVA-immunized and OVA-challenged
   OVA airway hyperreactivity-diseased littermates 24 h after
   intraperitoneal administration and lowest in the untreated littermates
   (3.7 +/- 0.4 \%ID/cm(3)). As expected, Cu-64-OVA-Th1 cells also
   accumulated significantly in the pulmonary LNs of nonimmunized
   OVA-challenged animals (6.1 +/- 0.5 \%ID/cm(3)) when compared with
   phosphate-buffered saline-challenged animals (4.6 +/- 0.5 \%ID/cm(3)).
   Conclusion: Our protocol permits the detection of Th1 cells in single
   LNs and enables temporal in vivo monitoring of T-cell homing over 48 h.
   This work enables future applications for Cu-64-PTSM-labeled T cells in
   clinical trials and novel therapy concepts focusing on T-cell-based
   immunotherapies of autoimmune diseases or cancer.}},
DOI = {{10.2967/jnumed.113.126318}},
ISSN = {{0161-5505}},
EISSN = {{1535-5667}},
ResearcherID-Numbers = {{Pichler, Bernd/B-4483-2012}},
Unique-ID = {{ISI:000330926200048}},
}

@article{ ISI:000330079300005,
Author = {Bergman, Marcelo and Gabriel Cafferata, Fernando},
Title = {{Sub-National Justice Prosecution in Mexico: Fiscal Spending and Efficacy
   of State Prosecution Offices}},
Journal = {{GESTION Y POLITICA PUBLICA}},
Year = {{2013}},
Number = {{2}},
Pages = {{157-194}},
Abstract = {{This paper analyzes state criminal prosecution in Mexico. After
   collecting original data for spending and administration for each D.A.
   office over a span of six years, we examine the economic rationality and
   the efficacy of procurement of justice. We use accessed public data as
   well as information obtained from special requests to states for the
   years 2003-2008. The three most relevant findings are: First, the level
   of efficacy of states in justice prosecution is good, but they are
   extremely inefficient and barely effective. Second, for the large
   majority of states there is not economies of scale nor reductions of
   marginality costs in criminal prosecution. Third, state attorneys
   offices spend more energy and resources to solve petty crime cases than
   serious crimes.}},
ISSN = {{1405-1079}},
Unique-ID = {{ISI:000330079300005}},
}

@incollection{ ISI:000283191100011,
Author = {Phillips, Tamara J. and Pastor, Raul and Scibelli, Angela C. and Reed,
   Cheryl and Tarragon, Ernesto},
Editor = {{Raber, J}},
Title = {{Behavioral Sensitization to Addictive Drugs: Clinical Relevance and
   Methodological Aspects}},
Booktitle = {{ANIMAL MODELS OF BEHAVIORAL ANALYSIS}},
Series = {{Neuromethods}},
Year = {{2011}},
Volume = {{50}},
Pages = {{267-305}},
Abstract = {{Sensitization to the locomotor stimulant effects of abused drugs
   provides 3 behavioral measure thought to reflect underlying neural
   adaptations to repeated drug exposure. Neurochemical measures have
   provided information about the specific neural systems impacted and
   altered by repeated drug exposure. In pre-clinical studies, sensitized
   animals exhibit facilitated acquisition of drug self-administration and
   preference for cues associated with past drug experiences. This has
   suggested a role for sensitization in the development of drug abuse and
   in relapse. In humans, self-reports of sensitized vigor and energy
   levels have been described that may relate to the more direct
   measurements of locomotor sensitization in animals. Described in this
   chapter are methods used to measure psychomotor sensitization in mice,
   which are partially dependent upon the drug under investigation. The
   advantages to the use of mice in pre-clinical research are (1) that they
   readily sensitize to all drugs of abuse, (2) many methods have been
   developed for studying other aspects of their behavior that may be
   related to sensitization, and (3) they are an excellent species for
   genetic investigations aimed at determining susceptibility to behavioral
   sensitization and thus neuroadaptations related to drug abuse. Factors
   to consider when designing a study of drug-induced psychomotor
   sensitization include dose, number or treatments, frequency or interval
   between treatments and challenge, and duration of testing. First, a
   measure of baseline level of activity should be obtained, followed by
   measurement of the initial drug effect, measures of the change in
   initial effect with repeated administration, and a subsequent measure of
   baseline to see how it may have changed after repeated drug testing.
   Depending upon the goal of the research, a drug withdrawal period may be
   desirable, followed by another drug challenge to determine whether
   sensitization is still present. Such a withdrawal or ``incubation{''}
   period has been instated to allow for the establishment of long-term
   central nervous system changes that may accompany sensitization in
   studies of mechanism. The recommended frequency of dosing is dependent
   upon characteristics of the drug, particularly its clearance rate. More
   intermittent schedules of administration are particularly important for
   inducing robust sensitization to classical psychostimulant drugs like
   cocaine and methamphetamine. The recommended duration of:testing is
   influenced by the duration of drug effect, but data should be collected
   in isolated time units so that the time response curve can be examined.
   Finally, associative conditioning and stress-related factors can have
   large impacts on sensitization and should be carefully considered in all
   aspects of the research design, including whether drug treatment is
   linked to the test environment or not, density of housing, and specifics
   of handling.}},
DOI = {{10.1007/978-1-60761-883-6\_11}},
ISSN = {{0893-2336}},
ISBN = {{978-1-60761-882-9}},
Unique-ID = {{ISI:000283191100011}},
}

@article{ ISI:000274375500019,
Author = {Pirnik, Zdeno and Maixnerova, Jana and Matyskova, Resha and Koutova,
   Darja and Zelezna, Blanka and Maletinska, Lenka and Kiss, Alexander},
Title = {{Effect of anorexinergic peptides, cholecystokinin (CCK) and cocaine and
   amphetamine regulated transcript (CART) peptide, on the activity of
   neurons in hypothalamic structures of C57Bl/6 mice involved in the food
   intake regulation}},
Journal = {{PEPTIDES}},
Year = {{2010}},
Volume = {{31}},
Number = {{1}},
Pages = {{139-144}},
Month = {{JAN}},
Abstract = {{The hypothalamus plays an important role in food Consumption, receiving
   information about energy balance via hormonal, metabolic, and neural
   inputs. Its neurons produce neuropeptides influencing energy balance.
   Especially important to regulation of food consumption are certain
   hypothalamic structures, including the arcuate (ARC) and ventromedial
   (VMN) nuclei and the lateral hypothalamic area (LHA). We determined the
   impact of cholecystokinin (CCK) and cocaine and amphetamine regulated
   transcript (CART) peptide, on activity of ARC and VMN neurons and
   hypocretin (Hcrt) synthesizing neurons in LHA. ARC is an integrative
   nucleus regulating food consumption, VMN is considered to be a satiety
   centre, and LHA a hunger sensing centre. After overnight fasting, male
   C57Bl/6 mice received intraperitoneal injection of (i.p.) saline (SAL)
   or CCK (4 mu g/kg) or intracerebroventricular injection of (i.c.v.) CART
   peptide (0.1 mu g/mice) or CCK (i.p.) followed by CART peptide (i.c.v.)
   5 min later. Sixty minutes later, the presence of Fos or Fos/Hcrt
   immunostaining indicated activity of ARC and VMN neurons, as well as of
   Hcrt cells in LHA. CCK alone did not influence neuronal activity in any
   of the nuclei studied. CART peptide Stimulated neurons in ARC and VMN (p
   < 0.01) but decreased Hcrt neuronal activity in LHA (p < 0.05).
   Co-administration of both peptides synergistically stimulated ARC
   neurons (p < 0.01) and asynergistically inhibited LHA Hcrt neurons (p <
   0.01). Results indicate that CCK may modify the effect of CART peptide
   and thus substantially influence activity of neurons in hypothalamic
   structures involved in regulation of food intake. (C) 2009 Elsevier Inc.
   All rights reserved.}},
DOI = {{10.1016/j.peptides.2009.09.035}},
ISSN = {{0196-9781}},
ResearcherID-Numbers = {{Pirnik, Zdenko/G-5758-2014}},
Unique-ID = {{ISI:000274375500019}},
}

@article{ ISI:000275828200008,
Author = {Tanaka, Miyako and Suganami, Takayoshi and Sugita, Satoshi and Shimoda,
   Yuri and Kasahara, Masato and Aoe, Seiichiro and Takeya, Motohiro and
   Takeda, Shu and Kamei, Yasutomi and Ogawa, Yoshihiro},
Title = {{Role of Central Leptin Signaling in Renal Macrophage Infiltration}},
Journal = {{ENDOCRINE JOURNAL}},
Year = {{2010}},
Volume = {{57}},
Number = {{1}},
Pages = {{61-72}},
Month = {{JAN}},
Abstract = {{Monocytes/macrophages are key mediators of wound repair, tissue
   remodeling, and inflammation. However, the molecular mechanisms
   underlying macrophage recruitment to the site of inflammation is not
   fully understood. Leptin acts directly on the hypothalamus, thereby
   regulating food intake and energy expenditure. The leptin receptor, a
   single transmembrane protein that belongs to the gp130 family of
   cytokine receptor superfamily, is expressed not only in the hypothalamus
   but in a variety of peripheral tissues, suggesting the role of leptin as
   a pro-inflammatory adipocytokine in peripheral tissues. Here, we show
   that deficiency of leptin signaling reduces renal macrophage
   infiltration after unilateral ureteral obstruction (UUO). Bone marrow
   transplantation studies using leptin signaling-deficient db/db mice
   revealed that leptin signaling in bone marrow cells may not play a major
   role in the UUO-induced renal macrophage infiltration. Interestingly,
   central leptin administration reverses the otherwise reduced UUO-induced
   renal macrophage infiltration in leptin-deficient ob/ob mice. This is
   effectively abolished by central co-administration of SHU9119, a
   melanocortin-3 receptor/melanocortin-4 receptor antagonist. This study
   demonstrates that central leptin administration in ob/ob mice
   accelerates renal macrophage infiltration through the melanocortin
   system, thereby suggesting that the central nervous system, which is
   inherent to integrate information from throughout the organism, is able
   to control peripheral inflammation.}},
ISSN = {{0918-8959}},
Unique-ID = {{ISI:000275828200008}},
}

@inproceedings{ ISI:000263415000047,
Author = {Marza, Bogdan},
Book-Group-Author = {{UNIV SIBIU, LUCIAN BLAGA}},
Title = {{THE APPROACH OF THE DIAGNOSIS AND THE VALUATION FROM THE POINT OF VIEW
   OF THE MODERN ORGANIZATION MANAGEMENT}},
Booktitle = {{ROMANIA WITHIN THE EU: OPPORTUNITIES, REQUIREMENTS AND PERSPECTIVES, VOL
   II}},
Year = {{2007}},
Pages = {{250-253}},
Note = {{International Economic Conference, Univ Sibiu, Lucian Blaga, Fac Econ
   Sci, Sibiu, ROMANIA, MAY, 2007}},
Abstract = {{To be manager means, first, the management of the complex process of
   obtaining and administration the value of the modem organization. To
   accomplish this thing, to a high qualitative level, the manager must
   understand the general mechanism but also the private process us through
   their mediation the present potential in the natural environment, in
   society and economy, under the shape of substance, energy, information,
   is changing in value and it is preserved in products and favors.
   Second, the manager must be a correct mediator, between the social,
   economical, and natural process us which are employed in the mechanism
   of obtaining the value. An unfair behavior can disturb the respective
   mechanism and also the whole natural and social gearing existence of the
   mankind.
   Finally, the management must administrate efficiently and firmly the
   obtained value for distributing it to the beneficiary from the economy,
   society and environment, with the thought to the future developing of
   the system that participates to the value mechanism.
   More, related to the financial management, the manager's responsibility
   is raised by the fact that all his activity is developing with the
   value: obtaining, sizing, distribution, transmitting by the money,
   commendation, control, increasing through the direct and indirect
   administration of the process us geared in the mechanism of the
   obtaining and administration of the value.}},
ISBN = {{978-973-739-443-9}},
Unique-ID = {{ISI:000263415000047}},
}

@article{ ISI:000084510800001,
Author = {Sakurai, Y and Ochiai, M and Funabiki, T},
Title = {{Assessment of in vivo glucose kinetics using stable isotope tracers to
   determine their alteration in humans during critical illness}},
Journal = {{SURGERY TODAY-THE JAPANESE JOURNAL OF SURGERY}},
Year = {{2000}},
Volume = {{30}},
Number = {{1}},
Pages = {{1-10}},
Abstract = {{Glucose plays a central role in energy metabolism, and alterations in
   its utilization have been reported under a variety of physiological and
   pathological conditions. The extent and direction of its changes provide
   useful information to promote the understanding of pathophysiology. The
   regulation of in vivo glucose kinetics is important because it is
   closely linked to energy production and the control of amino acid and
   protein metabolism. Although alterations in glucose kinetics have been
   demonstrated in critically ill patients, the mechanisms responsible are
   not well understood. The measurement of glucose kinetics in humans using
   stable isotopic glucose tracers provides a better understanding of the
   responses to nutritional support in these patients. While tracer methods
   have been used to quantitatively measure in vivo kinetics in patients
   with a variety of critical illnesses as well as in normal volunteers
   during fasting and exercise in European countries and the United States,
   they have not received the same attention in Japan. Stable isotopic
   glucose tracers can be safely given to humans since they are themselves
   naturally occurring substances, accounting for a small percentage of the
   total, depending on the isotopic species. The intravenous administration
   of a glucose tracer allows quantitative assessment of in vivo glucose
   kinetics under a variety of conditions. This method has wide potential
   for obtaining kinetic data on all aspects of in vivo glucose metabolism,
   with major advantages for conducting metabolic studies in humans.}},
ISSN = {{0941-1291}},
Unique-ID = {{ISI:000084510800001}},
}

@article{ ISI:000352449700002,
Author = {Delacruz, Anthony and Arauz, Gabrielle and Curley, Tracy and Lindo,
   Amabella and Jensen, Trine},
Title = {{Nursing Management of Patients With Castration-Resistant Prostate Cancer
   Undergoing Radium-223 Dichloride Treatment}},
Journal = {{CLINICAL JOURNAL OF ONCOLOGY NURSING}},
Year = {{2015}},
Volume = {{19}},
Number = {{2}},
Pages = {{E31-E35}},
Month = {{APR}},
Abstract = {{Background: Radium-223 dichloride, or radium-223, is a first-in-class
   alpha emitter that selectively targets bone metastases with high-energy,
   short-range alpha particles and is approved for the treatment of
   patients with castration-resistant prostate cancer (CRPC), symptomatic
   bone metastases, and no known visceral metastatic disease. Nurses are
   essential in educating patients about radium-223.
   Objectives: This article provides oncology nurses with information from
   the randomized phase III Alpharadin in Symptomatic Prostate Cancer
   (ALSYMPCA) trial, as well as important handling, administration, and
   safety details unique to radium-223.
   Methods: Data from the ALSYMPCA trial and related published information
   on radium-223 were reviewed.
   Findings: Radium-223 is the only alpha-emitting radiopharmaceutical that
   has been shown to improve overall survival in patients with CRPC, as
   demonstrated in the ALSYMPCA trial. In addition, radium-223 delays time
   to first symptomatic skeletal event, and it is well tolerated with a low
   incidence of myelosuppression and gastrointestinal adverse events.
   Delivered on an outpatient basis, radium-223 requires universal
   precautions for handling and administration. Because of the potential
   for additive myelosuppression, the concomitant use of radium-223 with
   chemotherapy, other systemic radioisotopes, or hemibody external
   radiation therapy is not recommended.}},
DOI = {{10.1188/15.CJON.E31-E35}},
ISSN = {{1092-1095}},
EISSN = {{1538-067X}},
Unique-ID = {{ISI:000352449700002}},
}

@inproceedings{ ISI:000361486900055,
Author = {Kumara, I. N. S. and Ariastina, W. G. and Sukerayasa, I. W. and
   Giriantari, I. A. D.},
Book-Group-Author = {{IEEE}},
Title = {{On the Potential and Progress of Renewable Electricity Generation in
   Bali}},
Booktitle = {{2014 6TH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY AND
   ELECTRICAL ENGINEERING (ICITEE)}},
Year = {{2014}},
Pages = {{307-312}},
Note = {{6th International Conference on Information Technology and Electrical
   Engineering (ICITEE), Yogyakarta, INDONESIA, OCT 07-08, 2014}},
Abstract = {{Indonesian National Energy Policy states that renewable electricity
   generation shall contribute to around 10\% of national grid by 2025.
   Currently, Indonesian grid capacity is just over 43 GW and estimated to
   reach over 65 GW by 2025 hence renewable generation target is around 6.5
   GW. Indonesia is an archipelago country with over 13,700 islands
   stretches from east to west over three time zones. Renewable generation
   should be developed over 34 provincial regions by utilizing local
   resources. Bali is small island and one of provincial administration
   with nearly four million population and land area of 5,600 square
   kilometer. As of 2013, its electrification ratio has reached 98\% Its
   power system is supported by 759.5 MW generating capacity but with peak
   load already at 730 MW. Bali does not have conventional resources hence
   all fossil-based fuels are sourced externally. Fortunately, Bali has
   various renewable resources that can be harnessed for electricity
   generation. Renewable resources available on the island are micro hydro,
   wind, photovoltaic, biomass, and also geothermal. This paper provides
   updated information on the potential and progress of renewable
   generation of the island. As of 2014, total renewable generation plants
   has reached 7 MW. The plants comprises of 2.1 MW photovoltaic, 736 kW
   wind power, 45 kW micro hydro, and 4.174 MW waste-to-electricity plants.
   The renewable generation contributes to around 1\% of Bali's total power
   capacity.}},
ISBN = {{978-1-4799-5303-5}},
Unique-ID = {{ISI:000361486900055}},
}

@inproceedings{ ISI:000333160300001,
Author = {Nordman, Bruce and Christensen, Ken},
Book-Group-Author = {{IEEE}},
Title = {{Local Power Distribution with Nanogrids}},
Booktitle = {{2013 INTERNATIONAL GREEN COMPUTING CONFERENCE (IGCC)}},
Year = {{2013}},
Note = {{International Green Computing Conference (IGCC), Washington State Univ,
   Arlington, VA, JUN 27-29, 2013}},
Organization = {{Univ Texas Arlington}},
Abstract = {{Matching electricity demand to supply will be a growing challenge in the
   future. We argue for the need for further research into local power
   distribution with a focus on ``nanogrids{''}. We define a nanogrid as a
   small electricity domain with distinct voltage, price, reliability,
   quality, and administration. We seek to improve upon existing nanogrids
   (such as USB and PoE) by the addition of electricity price information
   to enable power distribution to be managed in a distributed bottom-up
   and fair manner to optimally match demand to supply, and to more easily
   and efficiently integrate local generation and storage. This approach,
   modeled on Internet principles, offers the possibility of moving to a
   less reliable utility grid, providing quality and reliability at the
   edge, and saving capital and energy. We illustrate the operation of a
   simple nanogrid driven by rules governing controller and load behavior
   in response to varying electricity availability from a renewable source.}},
ISBN = {{978-1-4799-0623-9}},
Unique-ID = {{ISI:000333160300001}},
}

@article{ ISI:000308044600002,
Author = {Heiss, Christian and Govindarajan, Parameswari and Schlewitz, Gudrun and
   Hemdan, Nasr Y. A. and Schliefke, Nathalie and Alt, Volker and Thormann,
   Ulrich and Lips, Katrin Susanne and Wenisch, Sabine and Langheinrich,
   Alexander C. and Zahner, Daniel and Schnettler, Reinhard},
Title = {{Induction of osteoporosis with its influence on osteoporotic
   determinants and their interrelationships in rats by DEXA}},
Journal = {{MEDICAL SCIENCE MONITOR}},
Year = {{2012}},
Volume = {{18}},
Number = {{6}},
Pages = {{BR199-BR207}},
Month = {{JUN}},
Abstract = {{Background: As women are the population most affected by multifactorial
   osteoporosis, research is focused on unraveling the underlying mechanism
   of osteoporosis induction in rats by combining ovariectomy (OVX) either
   with calcium, phosphorus, vitamin C and vitamin D2/D3 deficiency, or by
   administration of glucocorticoid (dexamethasone).
   Material/Methods: Different skeletal sites of sham, OVX-Diet and
   OVX-Steroid rats were analyzed by Dual Energy X-ray Absorptiometry
   (DEXA) at varied time points of 0, 4 and 12 weeks to determine and
   compare the osteoporotic factors such as bone mineral density (BMD),
   bone mineral content (MAC), area, body weight and percent fat among
   different groups and time points. Comparative analysis and
   interrelationships among osteoporotic determinants by regression
   analysis were also determined.
   Results: T scores were below-2.5 in OVX-Diet rats at 4 and 12 weeks
   post-OVX. OVX-diet rats revealed pronounced osteoporotic status with
   reduced BMD and BMC than the steroid counterparts, with the spine and
   pelvis as the most affected skeletal sites. Increase in percent fat was
   observed irrespective of the osteoporosis inducers applied. Comparative
   analysis and interrelationships between osteoporotic determinants that
   are rarely studied in animals indicate the necessity to analyze BMC and
   area along with BMD in obtaining meaningful information leading to
   proper prediction of probability of osteoporotic fractures.
   Conclusion: Enhanced osteoporotic effect observed in OVX-Diet rats
   indicates that estrogen dysregulation combined with diet treatment
   induces and enhances osteoporosis with time when compared to the steroid
   group. Comparative and regression analysis indicates the need to
   determine BMC along with BMD and area in osteoporotic determination.}},
ISSN = {{1234-1010}},
Unique-ID = {{ISI:000308044600002}},
}

@inproceedings{ ISI:000312369900060,
Author = {Liu Jinhua and Zheng Xinqi},
Editor = {{Ma, M}},
Title = {{A Spatial-EF and Econometrics Model Integrated Approach to Explore Land
   Use Sustainable Forecast Model-in Case of Shandong Province}},
Booktitle = {{2011 INTERNATIONAL CONFERENCE OF ENVIRONMENTAL SCIENCE AND ENGINEERING,
   VOL 12, PT A}},
Series = {{Procedia Environmental Sciences}},
Year = {{2012}},
Volume = {{12}},
Number = {{A}},
Pages = {{413-420}},
Note = {{International Conference on Environment Science and Engineering (ICESE),
   Bali Island, INDONESIA, APR 01-03, 2011}},
Organization = {{CBEES; IEEE}},
Abstract = {{This paper constructed land use sustainable forecast model, which was
   based on spatial ecological footprint and econometrics model, to find an
   effective approach and technique for land use sustainable forecast.
   What's the spatial ecological footprint(S-EF)? The paper firstly
   answered the question, namely the improved and expanded EF based on GIS.
   Then S-EF and econometrics model, such as GM(1,1), regression model were
   integrated to build the forecast model. As follows, the Shandong's land
   use sustainable was forecasted by the above model, and the future will
   not be optimistic. The conflict between supply and demand of fossil
   energy land becomes more evident based on the time and spatial
   information diagram. In general, this model can be used to forecast the
   land use sustainable from time to space and was tested effectively; the
   forecast result may offer datum which are beneficial for land
   administrators to make land use planning and land administration. (C)
   2011 Published by Elsevier Ltd. Selection and/or peer-review under
   responsibility of National University of Singapore.}},
DOI = {{10.1016/j.proenv.2012.01.298}},
ISSN = {{1878-0296}},
Unique-ID = {{ISI:000312369900060}},
}

@article{ ISI:000289345900005,
Author = {MacGillivray, James and Hicks, Gregory T. and Adams, Steve and Barnett,
   Sue and Bobrick, Bryan and Graham, David and Royce, Morgan and Weber,
   Rick and Miller, Greg and Wernicke, James},
Title = {{PROSPECTING FOR SILVER STRIKING PLATINUM: Our First LEED Project}},
Journal = {{JOURNAL OF GREEN BUILDING}},
Year = {{2010}},
Volume = {{5}},
Number = {{4}},
Pages = {{78-90}},
Abstract = {{Prospecting demands positive future orientation, hope, sometimes not
   even knowing what it is you might discover. We were hopeful prospectors
   on our first LEED project, not exactly sure what we might strike. We
   sought silver sustainability for the University of New Mexico (UNM)
   College of Education Building (COE); what we discovered was even more
   precious and rare, platinum. Getting there entailed chipping away at
   each sustainable LEED credit until we hit pay dirt, the first
   publicly-funded and second LEED Platinum building in New Mexico.
   Gregory T. Hicks \& Associates P. C. Architects was contracted by UNM to
   design a LEED Silver Certified building for its new COE Administration
   and Classroom Building, Phase 1. All new, state-funded buildings in New
   Mexico must achieve a minimum LEED Silver certification as mandated by
   Governor's Executive Order. Two of our staff, Jim MacGillivray and Jay
   Davis, are LEED APs, and our Principal, Gregory T. Hicks, has taken
   several USGBC courses, but this being our first LEED project, we
   participated in additional study in LEED certification and sustainable
   design. We also hired an experienced sustainable design specialist to
   serve as our LEED AP, our lead prospector, Susan Barnett.
   Not knowing how easy or difficult it might be to achieve LEED Silver,
   the prudent approach was to strive for as many points as possible, so
   that if we lost a few points along the way we would still fulfill the
   obligations of our contract. UNM COE and other UNM staff championed this
   approach. Our initial strategy targeted LEED credits with minimal cost,
   those almost free, logical modifications that improve sustainability.
   Next, we focused on achieving four ``Innovation in Design{''} credits,
   searching for ideas that would involve minor costs or creative design
   endeavor. UNM COE committed to a photovoltaic system for educational and
   research purposes as well as to purchase a renewable energy certificate.
   Our initial venture targeted up to 48 possible points, comfortably
   within Gold territory.
   We submitted our project to USGBC for design review as the project went
   out to bid. The design review denied a few points in some areas, but
   serendipitously awarded a few extra points in other areas. UNM COE
   supported the prospects of achieving Gold so we provided additional
   information to successfully appeal denied credits, which brought us back
   up to a potential of 48 points, assuming targeted points were awarded
   during the construction review. At this point we knew we would certainly
   achieve Silver, possibly Gold.
   Midway through construction, the COE Dean, Richard Howell, and COE Chief
   of Staff, Diane Gwinn, asked us if there might be a way to earn just 4
   or more points to reach the 52 required for LEED Platinum. Steve Chavez,
   UNM Project Manager, strongly championed this effort. This seemed
   difficult, if not impossible at this juncture in the project, but we met
   with COE, UNM engineers, design engineers, LEED AP, and the contractor
   to brainstorm possibilities. We came up with eight possibilities, but
   not all were affordable, practical, or supported, so we whittled the
   eight down to five, but just before the construction review we lost one
   of the five, so we tried for four.
   When the USGBC completed their construction review, we learned we had
   scored 52 points awarded LEED Platinum certification. Partnership of UNM
   COE, architect, engineers, LEED APs, and contractor created this success
   through a relentless ``can-do{''} attitude throughout the project, plus
   some luck. Boring down deeply, we sought Silver and struck Platinum.
   This narrative is organized according to the USGBC LEED credit rating
   system and highlights the sustainable accomplishments of the project
   along with lessons learned.}},
DOI = {{10.3992/jgb.5.4.78}},
ISSN = {{1552-6100}},
Unique-ID = {{ISI:000289345900005}},
}

@article{ ISI:000273168400007,
Author = {Yoshikawa, Shinichi and Murata, Ryo and Shida, Shigenari and Uwai, Koji
   and Suzuki, Tsuneyoshi and Katsumata, Shunji and Takeshita, Mitsuhiro},
Title = {{Evaluation of Correlation between Dissolution Rates of Loxoprofen
   Tablets and Their Surface Morphology Observed by Scanning Electron
   Microscope and Atomic Force Microscope}},
Journal = {{CHEMICAL \& PHARMACEUTICAL BULLETIN}},
Year = {{2010}},
Volume = {{58}},
Number = {{1}},
Pages = {{34-37}},
Month = {{JAN}},
Abstract = {{We observed the surface morphological structures of 60mg tablets of
   Loxonin (R), Loxot (R), and Lobu (R) using scanning electron microscope
   (SEM) and atomic force microscope (AFM) to evaluate the dissolution
   rates. We found a significant difference among the initial dissolution
   rates of the three kinds of loxoprofen sodium tablets. Petal forms of
   different sizes were commonly observed on the surface of the Loxonin (R)
   and Loxot (R) tablets in which loxoprofen sodium was confirmed by
   measuring the energy-dispersible X-ray (EDX) spectrum of NaK alpha using
   SEM. However, a petal form was not observed on the surface of the Lobu
   (R) tablet, indicating differences among the drug production processes.
   Surface area and particle size of the principal ingredient in tablets
   are important factors for dissolution rate. The mean size of the
   smallest fine particles constituting each tablet was also determined
   with AFM. There was a correlation between the initial dissolution rate
   and the mean size of the smallest particles in each tablet. Visualizing
   tablet surface morphology using SEM and AFM provides information on the
   drug production processes and initial dissolution rate, and is
   associated with the time course of pharmacological activities after
   tablet administration.}},
ISSN = {{0009-2363}},
Unique-ID = {{ISI:000273168400007}},
}

@inproceedings{ ISI:000274566400028,
Author = {Gaur, Pradeep Kumar and Dhaliwal, B. S. and Seehra, Ameeta},
Book-Group-Author = {{IEEE}},
Title = {{Analysis of Power Saving Multicasting Routing Applications for Mica2
   Motes-An event based MATLAB Implementation}},
Booktitle = {{2009 INTERNATIONAL CONFERENCE ON MULTIMEDIA, SIGNAL PROCESSING AND
   COMMUNICATION TECHNOLOGIES}},
Year = {{2009}},
Pages = {{109-112}},
Note = {{International Conference on Multimedia, Signal Processing and
   Communication Technologies, Aligarh, INDIA, MAR 14-16, 2009}},
Abstract = {{The adhoc networks are considered to be infrastructure less networks
   therefore the scarcity of resources (i.e. Bandwidth and Energy) are the
   main issues requiring attention. In this paper the routing
   applications/algorithms for optimizing battery life time are analyzed
   while taking into account the highly unreliable real time behavior of
   mica2 motes. Routing applications are run in Matlab based probabilistic
   event driven platform having layered architecture for power centric
   radio model. Although the adhoc networks have dynamic topology and are
   randomly placed in specified environments, radio motes are placed in a
   two-dimentional virtual grid for simulating the flow of packet
   information in a multicasting source-destination domain. Power Efficient
   Wireless Adhoc Networks have their applications in military (spying,
   battlefield surveillance), environmental (forest fire and flood
   detection, seismic structure response and bio-complexity), health (drug
   administration in hospitals) set ups.}},
DOI = {{10.1109/MSPCT.2009.5164186}},
ISBN = {{978-1-4244-3603-3}},
Unique-ID = {{ISI:000274566400028}},
}

@inproceedings{ ISI:000268927100222,
Author = {Hartwell, William T. and Shafer, David S.},
Book-Group-Author = {{ASME}},
Title = {{THE COMMUNITY ENVIRONMENTAL MONITORING PROGRAM: A MODEL FOR STAKEHOLDER
   INVOLVEMENT IN ENVIRONMENTAL MONITORING}},
Booktitle = {{ICEM2007: PROCEEDINGS OF THE 11TH INTERNATIONAL CONFERENCE ON
   ENVIRONMENTAL REMEDIATION AND RADIOACTIVE WASTE MANAGEMENT, PTS A AND B}},
Year = {{2009}},
Pages = {{1461-1464}},
Note = {{11th International Conference on Environmental Remediation and
   Radioactive Waste Management, Bruges, BELGIUM, SEP 02-06, 2007}},
Abstract = {{Since 1981, the Community Environmental Monitoring Program (CEMP) has
   involved stakeholders directly in its daily operation and data
   collection, as well as in dissemination of information on radiological
   surveillance in communities surrounding the Nevada Test Site (NTS), the
   primary location where the United States (US) conducted nuclear testing
   until 1992.The CEMP is funded by the US Department of Energy's National
   Nuclear Security Administration, and is administered by the Desert
   Research Institute (DRI) of the Nevada System of Higher Education.
   The CEMP provides training workshops for stakeholders involved in the
   program, and educational outreach to address public concerns about
   health risk and environmental impacts from past and ongoing NTS
   activities. The network includes 29 monitoring stations located across
   an approximately 160,000 km(2) area of Nevada, Utah and California in
   the southwestern US. The principal radiological instruments are
   pressurized ion chambers for measuring gamma radiation, and particulate
   air samplers, primarily for alpha/beta detection. Stations also employ a
   full suite of meteorological instruments, allowing for improved
   interpretation of the effects of meteorological events on background
   radiation levels. Station sensors are wired to state-of-the-art
   dataloggers that are capable of several weeks of on-site data storage,
   and that work in tandem with a communications system that integrates DSL
   and wireless internet, land line and cellular phone, and satellite
   technologies for data transfer. Data are managed through a platform
   maintained by the Western Regional Climate Center (WRCC) that DRI
   operates for the U.S. National Oceanic and Atmospheric Administration.
   The WRCC platform allows for near real-time upload and display of
   current monitoring information in tabular and graphical formats on a
   public web site. Archival data for each station are also available
   on-line, providing the ability to perform trending analyses or calculate
   site-specific exposure rates. This configuration also allows for remote
   programming and troubleshooting of sensors.
   Involvement of stakeholders in the monitoring process provides a number
   of benefits, including increased public confidence in monitoring
   results, as well as decreasing costs by more than 50 percent from when
   the program was managed entirely by U.S. federal employees.
   Additionally, the CEMP provides an ideal platform for testing new
   environmental sensors.}},
ISBN = {{978-0-7918-4339-0}},
Unique-ID = {{ISI:000268927100222}},
}

@article{ ISI:000250978000009,
Author = {Diekmann, Felix and Bick, Ulrich},
Title = {{Tomosynthesis and contrast-enhanced digital mammography: recent advances
   in digital mammography}},
Journal = {{EUROPEAN RADIOLOGY}},
Year = {{2007}},
Volume = {{17}},
Number = {{12}},
Pages = {{3086-3092}},
Month = {{DEC}},
Abstract = {{Digital mammography is more and more replacing conventional mammography.
   Initial concerns about an inferior image quality of digital mammography
   have been largely overcome and recent studies even show digital
   mammography to be superior in women with dense breasts, while at the
   same time reducing radiation exposure. Nevertheless, an important
   limitation of digital mammography remains: namely, the fact that
   summation may obscure lesions in dense breast tissue. However, digital
   mammography offers the option of so-called advanced applications, and
   two of these, contrast-enhanced mammography and tomosynthesis, are
   promising candidates for improving the detection of breast lesions
   otherwise obscured by the summation of dense tissue. Two techniques of
   contrast-enhanced mammography are available: temporal subtraction of
   images acquired before and after contrast administration and the
   so-called dual-energy technique, which means that pairs of
   low/high-energy images acquired after contrast administration are
   subtracted. Tomosynthesis on the other hand provides three-dimensional
   information on the breast. The images are acquired with different
   angulations of the X-ray tube while the object or detector is static.
   Various reconstruction algorithms can then be applied to the set of
   typically nine to 28 source images to reconstruct 1-mm slices with a
   reduced risk of obscuring pathology. Combinations of both advanced
   applications have only been investigated in individual experimental
   studies; more advanced software algorithms and CAD systems are still in
   their infancy and have only undergone preliminary clinical evaluation.}},
DOI = {{10.1007/s00330-007-0715-x}},
ISSN = {{0938-7994}},
ResearcherID-Numbers = {{Bick, Ulrich/C-1448-2009}},
ORCID-Numbers = {{Bick, Ulrich/0000-0002-7254-8572}},
Unique-ID = {{ISI:000250978000009}},
}

@article{ ISI:000239033300028,
Author = {Paues, J. and Mackerlova, L. and Blomqvist, A.},
Title = {{Expression of melanocortin-4 receptor by rat parabrachial neurons
   responsive to immune and aversive stimuli}},
Journal = {{NEUROSCIENCE}},
Year = {{2006}},
Volume = {{141}},
Number = {{1}},
Pages = {{287-297}},
Abstract = {{The pontine parabrachial nucleus is a major relay area for visceral and
   other interoceptive information, and has been implicated in mechanisms
   underlying anorexia and food aversion during disease. Thus,
   physiological studies have shown that peripheral immune stimuli, as well
   as the administration of aversive substances such as lithium chloride,
   evoke a prominent Fos-expression in the lateral parabrachial nucleus and
   behavioral experiments have demonstrated that this structure is critical
   for the acquisition of conditioned taste aversion. The present study
   examined in rats the relationship between parabrachial neurons activated
   by systemic administration of bacterial cell-wall lipopolysaccharide or
   lithium chloride and the melanocortin system, a major regulator of
   feeding and energy homeostasis that also has been implicated in aversive
   behavior. Dual-labeling in situ hybridization showed melanocortin-4
   receptor expression on neurons in the external lateral parabrachial
   subnucleus that displayed lipopolysaccharide- or lithium
   chloride-induced expression of c-fos mRNA. Melanocortin-4 receptor mRNA
   was also co-expressed with mRNA for calcitonin gene-related peptide in
   this subnucleus. Taken together with previous observations showing that
   calcitonin gene-related peptide expressing neurons in the external
   lateral parabrachial subnucleus are activated by peripheral immune
   challenge, that lipopolysaccharide-activated external lateral
   parabrachial subnucleus neurons project to the amygdala, and that the
   amygdala-projecting neurons in the external lateral parabrachial
   subnucleus are calcitonin gene-related peptide-positive, the present
   findings suggest the presence of a melanocortin-regulated calcitonin
   gene-related peptide-positive pathway from the external lateral
   parabrachial subnucleus to the amygdala that relays information of
   importance to fore-brain responses to certain aspects of sickness
   behavior. These observations may thus help explain how melanocortins can
   reduce feeding and influence conditioned taste aversion during
   inflammation and other disease conditions. (c) 2006 IBRO. Published by
   Elsevier Ltd. All rights reserved.}},
DOI = {{10.1016/j.neuroscience.2006.03.041}},
ISSN = {{0306-4522}},
ORCID-Numbers = {{Blomqvist, Anders/0000-0002-6928-4473}},
Unique-ID = {{ISI:000239033300028}},
}

@inproceedings{ ISI:000229929500092,
Author = {Chen, B and Jing, ZX and Smith, A},
Editor = {{Flynn, MJ}},
Title = {{Contrast-enhanced digital mammography (CEDM): Imaging modeling, computer
   simulations, and phantom study}},
Booktitle = {{Medical Imaging 2005: Physics of Medical Imaging, Pts 1 and 2}},
Series = {{PROCEEDINGS OF THE SOCIETY OF PHOTO-OPTICAL INSTRUMENTATION ENGINEERS
   (SPIE)}},
Year = {{2005}},
Volume = {{5745}},
Number = {{1-2}},
Pages = {{877-888}},
Note = {{Medical Imaging 2005 Conference, San Diego, CA, FEB 15-17, 2005}},
Organization = {{SPIE}},
Abstract = {{Contrast enhanced digital mammography (CEDM), which is based upon the
   analysis of a series of x-ray projection images acquired before/after
   the administration of contrast agents, may provide physicians critical
   physiologic and morphologic information of breast lesions to determine
   the malignancy of lesions. This paper proposes to combine the kinetic
   analysis (KA) of contrast agent uptake/washout process and the
   dual-energy (DE) contrast enhancement together to formulate a hybrid
   contrast enhanced breast-imaging framework. The quantitative
   characteristics of materials and imaging components in the x-ray imaging
   chain, including x-ray tube (tungsten) spectrum, filter, breast
   tissues/lesions, contrast agents (non-ionized iodine solution), and
   selenium detector, were systematically modeled. The
   contrast-noise-ration (CNR) of iodinated lesions and mean absorbed
   glandular dose were estimated mathematically. The x-ray techniques
   optimization was conducted through a series of computer simulations to
   find the optimal tube voltage, filter thickness, and exposure levels for
   various breast thicknesses, breast density, and detectable contrast
   agent concentration levels in terms of detection efficiency (CNR2/dose).
   A phantom study was performed on a modified Selenia full field digital
   mammography system to verify the simulated results. The dose level was
   comparable to the dose in diagnostic mode (less than 4 mGy for an
   average 4.2 cm compressed breast). The results from the computer
   simulations and phantom study are being used to optimize an ongoing
   clinical study.}},
DOI = {{10.1117/12.595747}},
ISSN = {{0277-786X}},
ISBN = {{0-8194-5719-1}},
Unique-ID = {{ISI:000229929500092}},
}

@article{ ISI:000223762000012,
Author = {Hara, M and Bindokas, V and Lopez, JP and Kaihara, K and Landa, LR and
   Harbeck, M and Roe, MW},
Title = {{Imaging endoplasmic reticulum calcium with a fluorescent biosensor in
   transgenic mice}},
Journal = {{AMERICAN JOURNAL OF PHYSIOLOGY-CELL PHYSIOLOGY}},
Year = {{2004}},
Volume = {{287}},
Number = {{4}},
Pages = {{C932-C938}},
Month = {{OCT}},
Abstract = {{The use of biosynthetic fluorescent sensors is an important new approach
   for imaging Ca2+ in cells. Genetically encoded indicators based on green
   fluorescent protein, calmodulin, and fluorescence resonance energy
   transfer ( FRET) have been utilized to measure Ca2+ in nonmammalian
   transgenic organisms and provide information about the organization and
   regulation of Ca2+ signaling events in vivo. However, expression of
   biosynthetic FRET-based Ca2+ indicators in transgenic mammals has proven
   to be problematic. Here, we report transgenic expression of an
   endoplasmic reticulum (ER) Ca2+ biosensor in mouse pancreas. We targeted
   expression of a yellow cameleon3.3er (YC3.3er) transgene with mouse
   insulin I promoter. YC3.3er protein expression was limited to pancreatic
   beta-cells within islets of Langerhans and absent in the exocrine
   pancreas and other tissues. Animals developed and matured normally;
   sensor expression was unaffected by age. Glucose tolerance in transgenic
   mice was also unaffected, indicating the transgenic biosensor did not
   impair endocrine pancreas function. ER Ca2+ responses after
   administration of thapsigargin, carbachol, and glucose were measured in
   individual beta-cells of intact islets using confocal microscopy and
   confirmed the function of the biosensor. We conclude that controlling
   transgene transcription with a cell-specific promoter permits transgenic
   expression of FRET-based Ca2+ sensors in mammals and that this approach
   will facilitate real-time optical imaging of signal transduction events
   in living tissues.}},
DOI = {{10.1152/ajpcell.00151.2004}},
ISSN = {{0363-6143}},
Unique-ID = {{ISI:000223762000012}},
}

@article{ ISI:000185122300005,
Author = {Taylor, RM and Preedy, VR and Baker, AJ and Grimble, G},
Title = {{Nutritional support in critically ill children}},
Journal = {{CLINICAL NUTRITION}},
Year = {{2003}},
Volume = {{22}},
Number = {{4}},
Pages = {{365-369}},
Month = {{AUG}},
Abstract = {{Background \& aims: Enteral nutrition is the feeding method of choice
   during critical illness, but in some cases as few as 25\% are fed
   appropriately. The aim was to retrospectively review the administration
   of nutrition to critically ill children.
   Methods:The notes of 95 children over the age of 1 year who were in PICU
   greater than or equal to 3 days were reviewed and information related to
   the delivery of nutrition was obtained.
   Results: Fifty-nine per cent were fed within 24 h of admission. Enteral
   nutrition was administered 54\% of the time, 10\% required parenteral
   nutrition and 9.5\% received no nutritional support. Children only
   received a median 58.8 (range 0277)\% of their energy requirements,
   which could not be optimised until the 10th intensive care day. Energy
   intake was greater when supplemented with parenteral nutrition.
   Parenteral nutrition administration was interrupted 3 times while
   enteral nutrition was stopped 264 times, mainly to allow other clinical
   procedures to take place. For 75\% of the study time, children had
   abnormal bowel patterns. Seventy-nine per cent were constipated for 3-21
   days and 43\% had diarrhoea of unknown aetiology.
   Conclusion:This was a retrospective study to describe the efficiency of
   nutritional support in critically ill children. We have shown that it is
   possible to administer enteral nutrition safely. However, the difference
   between desirable intake and actual intake achieved suggests that a more
   pro-active approach should be adopted. (C) 2003 Elsevier Science Ltd.
   All rights reserved.}},
DOI = {{10.1016/S0261-5614(03)00033-5}},
ISSN = {{0261-5614}},
Unique-ID = {{ISI:000185122300005}},
}

@article{ ISI:000361256000043,
Author = {Fagiani, M. and Squartini, S. and Gabrielli, L. and Spinsante, S. and
   Piazza, F.},
Title = {{A review of datasets and load forecasting techniques for smart natural
   gas and water grids: Analysis and experiments}},
Journal = {{NEUROCOMPUTING}},
Year = {{2015}},
Volume = {{170}},
Pages = {{448-465}},
Month = {{DEC 25}},
Note = {{Computational Energy Management in Smart Grids Workshop (CEMiSG),
   Beijing, PEOPLES R CHINA, JUL 08-09, 2014}},
Abstract = {{In this paper, experiments concerning the prediction of water and
   natural gas consumption are presented, focusing on how to exploit data
   heterogeneity to get a reliable outcome. Prior to this, an up-to-date
   state-of-the-art review on the available datasets and forecasting
   techniques of water and natural gas consumption, is conducted. A
   collection of techniques (Artificial Neural Networks, Deep Belief
   Networks, Echo State Networks, Support Vector Regression, Genetic
   Programming and Extended Kalman Filter-Genetic Programming), partially
   selected from the state-of-the-art ones, are evaluated using the few
   publicly available datasets. The tests are performed according to two
   key aspects: homogeneous evaluation criteria and application of
   heterogeneous data. Experiments with heterogeneous data obtained
   combining multiple types of resources (water, gas, energy and
   temperature), aimed to short-term prediction, have been possible using
   the Almanac of Minutely Power dataset (AMPds). On the contrary, the
   Energy Information Administration (E.I.A.) data are used for long-term
   prediction combining gas and temperature information. At the end, the
   selected approaches have been evaluated using the sole Tehran water
   consumption for long-term forecasts (thanks to the full availability of
   the dataset). The AMPds and E.I.A. natural gas results show a
   correlation with temperature, that produce a performance improvement.
   The ANN and SVR approaches achieved good performance for both
   long/short-term predictions, while the EKF-GP showed good outcomes with
   the E.I.A. datasets. Finally, it is the authors purpose to create a
   valid starting point for future works that aim to develop innovative
   forecasting approaches, providing a fair comparison among different
   computational intelligence and machine learning techniques. (C) 2015
   Elsevier B.V. All rights reserved.}},
DOI = {{10.1016/j.neucom.2015.04.098}},
ISSN = {{0925-2312}},
EISSN = {{1872-8286}},
Unique-ID = {{ISI:000361256000043}},
}

@article{ ISI:000361256900030,
Author = {Lu, Pei-Jia and Huang, Shou-Chieh and Chen, Yu-Pen and Chiueh, Lih-Ching
   and Shih, Daniel Yang-Chih},
Title = {{Analysis of titanium dioxide and zinc oxide nanoparticles in cosmetics}},
Journal = {{JOURNAL OF FOOD AND DRUG ANALYSIS}},
Year = {{2015}},
Volume = {{23}},
Number = {{3}},
Pages = {{587-594}},
Month = {{SEP}},
Abstract = {{There have been rapid increases in consumer products containing
   nanomaterials, raising concerns over the impact of nanoparticles (NPs)
   to humankind and the environment, but little information has been
   published about mineral filters in commercial sunscreens. It is urgent
   to develop methods to characterize the nanomaterials in products.
   Titanium dioxide (TiO2) and zinc oxide (ZnO) NPs in unmodified
   commercial sunscreens were characterized by laser scanning confocal
   microscopy, atomic force microscopy, X-ray diffraction (XRD), and
   transmission electron microscopy (TEM). The results showed that laser
   scanning confocal microscopy evaluated primary particle aggregates and
   dispersions but could not size NPs because of the diffraction limited
   resolution of optical microscopy (200 nm). Atomic force microscopy
   measurements required a pretreatment of the sunscreens or further
   calibration in phase analysis, but could not provide their elemental
   composition of commercial sunscreens. While XRD gave particle size and
   crystal information without a pretreatment of sunscreen, TEM analysis
   required dilution and dispersion of the commercial sunscreens before
   imaging. When coupled with energy-dispersive X-ray spectroscopy, TEM
   afforded particle size information and compositional analysis. XRD
   characterization of six commercial sunscreens labeled as nanoparticles
   revealed that three samples contained TiO2 NPs, among which two listed
   ZnO and TiO2, and displayed average particle sizes of 15 nm, 21 nm, and
   78 nm. However, no nanosized ZnO particles were found in any of the
   samples by XRD. In general, TEM can resolve nanomaterials that exhibit
   one or more dimensions between 1 nm and 100 nm, allowing the
   identification of ZnO and TiO2 NPs in all six sunscreens and ZnO/TiO2
   mixtures in two of the samples. Overall, the combination of XRD and TEM
   was suitable for analyzing ZnO and TiO2 NPs in commercial sunscreens.
   Copyright (c) 2015, Food and Drug Administration, Taiwan. Published by
   Elsevier Taiwan LLC. All rights reserved.}},
DOI = {{10.1016/j.jfda.2015.02.009}},
ISSN = {{1021-9498}},
Unique-ID = {{ISI:000361256900030}},
}

@article{ ISI:000362309800007,
Author = {Stutte, Gary W.},
Title = {{Commercial Transition to LEDs: A Pathway to High-value Products}},
Journal = {{HORTSCIENCE}},
Year = {{2015}},
Volume = {{50}},
Number = {{9}},
Pages = {{1297-1300}},
Month = {{SEP}},
Abstract = {{The use of light-emitting diodes (LEDs) to support plant growth is a
   radical departure from use of gas-discharge lamps, which were developed
   in mid-19th and widely adopted by the industry during the 20th century.
   Initial investigation by the National Aeronautics and Space
   Administration (NASA) in the late 1980s on the use of LEDs to grow plant
   in space is resulting in an industry-wide transition from gas discharge
   to solid-state lighting systems. This global transformation is given
   urgency by national policies to reduce energy consumption and being
   facilitated by ready access to information on LEDs. The combination of
   research, government policy, and information technology has resulted in
   an exponential increase in research into the use and application of LED
   technology in horticulture. Commercial horticulture has identified the
   opportunities provided by LEDs to optimize light spectra to promote
   growth, regulate morphology, increase nutrient content, and reduce
   operating costs. LED-light technology is enabling the development of
   innovative lighting systems, and is being incorporated into large-scale
   plant factories for the production of edible, ornamental, and medicinal
   plants. An overview of prevalence of readily accessible information on
   LEDs and implications for future adoption in horticulture is discussed.}},
ISSN = {{0018-5345}},
EISSN = {{2327-9834}},
Unique-ID = {{ISI:000362309800007}},
}

@article{ ISI:000353233100009,
Author = {Kranz, Stefan and Huebsch, Marie and Guellmar, Andre and Voelpel, Andrea
   and Tonndorf-Martini, Silke and Sigusch, Bernd W.},
Title = {{Antibacterial Photodynamic Treatment of Periodontopathogenic Bacteria
   With Indocyanine Green and Near-Infrared Laser Light Enhanced by Trolox
   (TM)}},
Journal = {{LASERS IN SURGERY AND MEDICINE}},
Year = {{2015}},
Volume = {{47}},
Number = {{4}},
Pages = {{350-360}},
Month = {{APR}},
Abstract = {{Background and Objectives: It has been shown that certain vitamins can
   significantly enhance the effect of photodynamic anti-tumor therapy.
   Unfortunately, there is no sufficient information available about the
   impact of those antioxidants on antimicrobial Photodynamic Therapy
   (aPDT). The present study is aimed at investigating the antimicrobial
   effect of the dye indocyanine green (ICG) in the presence of Trolox
   (TM), a vitamin E analogue, upon irradiation with near-infrared (NIR)
   laser light (808 nm) on the gramnegative periodontopathogenic bacteria
   Aggregatibacter actinomycetemcomitans (A. a.), Porphyromonas gingivalis
   (P.g.) and Fusobacterium nucleatum (F.n.).
   Methods: Bacteria solved in PBS were incubated with ICG (50-500 mu g/ml)
   in the presence and absence of Trolox (TM) (2 mM). Irradiation was
   performed after 10 minutes of dark-incubation with NIR-laser-light
   (25-100 J/cm(2), 810 nm). During treatment, temperature was also
   recorded inside the bacterial solutions. The treated suspensions were
   serial diluted and plated onto blood agar plates. After anaerobe
   cultivation for 5 days the colony-forming units (CFU/ml) were
   determined.
   Results: The antibacterial effect was ICG-concentration and exposure
   dependent. It was found that high ICG-concentrations and light fluence
   rates caused bacterial reduction due to hyperthermia. Where low
   ICG-concentrations (<250 mu g/ml) and fluence rates only induced minor
   regression, additional Trolox (TM)-administration significantly enhanced
   the photodynamic effect. While treatment of A. a. (250 mu g/ml ICG, 100
   J/cm(2)) without Trolox (TM) caused no bacterial reduction, additional
   administration led to total eradication. In the presence of Trolox (TM)
   reduction to one-fifth of the original ICG-concentration (50 mu g/ml)
   still induced total suppression of P.g. and F.n. at identical fluence
   (100 J/cm(2)). Treatment with ICG, NIR-light or Trolox (TM) alone showed
   no remarkable bactericidal effect. Application of high
   ICG-concentrations (500 mu g/ml) and exposure values (100 J/cm(2))
   caused peak temperatures of 64.53 degrees C.
   Conclusions: The results clearly show that Trolox (TM) significantly
   enhanced the antibacterial effect of ICG upon irradiation with
   NIR-laser-light. Additional administration of Trolox (TM) may also
   increase the efficiency of other aPDT systems. Lasers Surg. Med.
   47:350-360, 2015. (C) 2015 Wiley Periodicals, Inc.}},
DOI = {{10.1002/lsm.22336}},
ISSN = {{0196-8092}},
EISSN = {{1096-9101}},
Unique-ID = {{ISI:000353233100009}},
}

@article{ ISI:000334897700030,
Author = {Fortunato, B. and Torresi, M. and Deramo, A.},
Title = {{Modeling, performance analysis and economic feasibility of a
   mirror-augmented photovoltaic system}},
Journal = {{ENERGY CONVERSION AND MANAGEMENT}},
Year = {{2014}},
Volume = {{80}},
Pages = {{276-286}},
Month = {{APR}},
Abstract = {{In the last years, solar photovoltaic (PV) systems have had great
   impetus with research and demonstration projects, both in Italy and
   other European countries. The main problems with solar PV are the cost
   of solar electricity, which is still higher compared with other
   renewables (such as wind or biomass), due to the cost of
   semi-conductors, and the low conversion efficiency. However, PV panel
   prices are rapidly decreasing benefiting from favorable economies of
   scale. For instance, according to the Energy Information Administration
   (ETA) the US average levelized costs for plants entering service in the
   2018 should be 144.3\$/MW h for solar PV, whereas 111.0\$/MW h for
   biomass and 86.6\$/MW h for wind (Levelized Cost of New Generation
   Resources in the Annual Energy Outlook, 2013). In order to increase the
   electric yield of PV modules (which can be even doubled with respect to
   constant tilt configurations), without significantly increasing the
   system costs, it was decided to consider the addition of inclined
   mirrors at both sides of the PV modules, so as to deflect more solar
   rays towards them, as in Mirror-Augmented Photovoltaic (MAPV) systems.
   The system preserves its constructive simplicity with commercial flat PV
   modules even though dual axis tracker must be implemented, since MAPV
   systems harness mainly the direct radiation. The performance analysis of
   MAPV systems starts from the calculation of the global irradiation on
   the surface of the PV module which is a sum of the direct sunlight on it
   and the irradiation reflected by the mirrors. A mathematical model of a
   MAPV system is presented, which takes into account not only the increase
   of direct (or beam) radiation, due to the mirrors, but also the
   reduction of both the diffuse and reflected radiations due to the
   shadowing effect of the flat mirrors. In particular, under an isotropic
   sky assumption, a simplified analytical expression, applicable in the
   case of MAPV systems, for the sky-view factor has been developed. The
   deterioration in the performance of the PV system as a result of the
   increasing cell temperature with radiation augmentation due to mirrors
   has been also evaluated. Moreover, in order to provide a more realistic
   view of the process, the energy analysis is accompanied by the exergy
   analysis. Finally, in order to analyse the economics of MAPV systems,
   Net Present Value, Discounted Payback Period, Internal Rate of Return
   and Life-Cycle Costs, have been considered and compared with both a
   constant tilt building-integrated photovoltaic (BIPV) system and a
   system with a dual axis tracker. (C) 2014 Elsevier Ltd. All rights
   reserved.}},
DOI = {{10.1016/j.enconman.2013.12.074}},
ISSN = {{0196-8904}},
EISSN = {{1879-2227}},
ORCID-Numbers = {{Torresi, Marco/0000-0001-8507-2713}},
Unique-ID = {{ISI:000334897700030}},
}

@article{ ISI:000331715400006,
Author = {Gong, Yanling and Xu, Luo and Guo, Feifei and Pang, Mingjie and Shi,
   Zhenyan and Gao, Shengli and Sun, Xiangrong},
Title = {{Effects of ghrelin on gastric distension sensitive neurons and gastric
   motility in the lateral septum and arcuate nucleus regulation}},
Journal = {{JOURNAL OF GASTROENTEROLOGY}},
Year = {{2014}},
Volume = {{49}},
Number = {{2}},
Pages = {{219-230}},
Month = {{FEB}},
Abstract = {{Ghrelin is an endogenous ligand for the growth hormone secretagogue
   receptor (GHS-R) and a peptide hormone that promotes food intake and
   gastric motility. Our aims are to explore the effects of ghrelin on
   gastric distension (GD) sensitive neurons in the lateral septum, and the
   possible regulation of gastric motility by ghrelin through the
   hypothalamic arcuate nucleus (ARC).
   Single-unit discharges were recorded, extracellularly, and the gastric
   motility was monitored by the administration of ghrelin in the lateral
   septum. The projection of nerve fiber and expression of ghrelin were
   observed by retrograde tracer and fluo-immunohistochemistry staining.
   The expression of GHS-R and ghrelin was determined by real-time
   polymerase chain reaction and western blotting analysis.
   There were GD neurons in the lateral septum. The administration of
   ghrelin could excite both GD-excitatory (GD-E) and GD-inhibitory (GD-I)
   neurons in the lateral septum. Gastric motility was significantly
   enhanced by the administration of ghrelin in the lateral septum in a
   dose-dependent manner. Pretreatment with {[}d-Lys-3]-GHRP-6, however,
   could completely abolish the ghrelin-induced effects. Electrical
   stimulation of the ARC could significantly excite the response of GD
   neurons to ghrelin, increase ghrelin protein expression in the lateral
   septum and promote gastric motility. Nevertheless, these effects could
   be mitigated by pretreatment of {[}d-Lys-3]-GHRP-6. Electrical lesion of
   the lateral septum resulted in decreased gastric motility. The GHS-R and
   Ghrelin/FG-double labeled neurons were observed in the lateral septum
   and ARC, respectively.
   It is suggested that the lateral septum may receive afferent information
   from the gastrointestinal tract and promote gastric motility. Ghrelin
   plays an important role in promoting gastric motility in the lateral
   septum. The ARC may be involved in the regulation of the lateral
   septum's influence on gastric motility.}},
DOI = {{10.1007/s00535-013-0789-y}},
ISSN = {{0944-1174}},
EISSN = {{1435-5922}},
Unique-ID = {{ISI:000331715400006}},
}

@article{ ISI:000346110900003,
Author = {Pandey, Chandra Lal},
Title = {{The limits of climate change agreements: from past to present}},
Journal = {{INTERNATIONAL JOURNAL OF CLIMATE CHANGE STRATEGIES AND MANAGEMENT}},
Year = {{2014}},
Volume = {{6}},
Number = {{4}},
Pages = {{376-390}},
Abstract = {{Purpose - This paper aims to show why very little progress was made in
   arresting climate change. Managing climate change is one of the greatest
   challenges humanity has encountered in the 21st century. Responding to
   this greatest challenge, the United Nations has organized numerous
   climate change conferences. Four agreements (United Nations Framework
   Convention on Climate Change {[}UNFCCC], Kyoto, Copenhagen and Doha)
   have emerged in the process of developing a potential international
   climate change policy but failed to produce any ambitious agreement to
   arrest climate change.
   Design/methodology/approach - The pledges made by Conferences of the
   Parties (COPs) to reduce the greenhouse gases (GHGs) are contextualized
   with the ever increasing emissions of GHGs by exploring the databases of
   UNFCCC, International Energy Agency (IEA), Energy Information
   Administration (EIA) and the Netherlands Energy Assessment Agency (NEAA)
   for this study.
   Findings - However, GHGs have continued to rise and no globally binding
   agreement is seen to be forthcoming. Quantified targets to address the
   problem have yet to be agreed while major emitters remain free riders.
   This paper argues that the state-centric negotiating framework and the
   principles of the climate change negotiations were the main reasons for
   the inadequate outcomes leading to the continuing rise in emissions.
   Originality/value - This is an original research. It has presented the
   overview of climate change agreements, finds the problems and presents a
   way forward. The research is useful for governments of the world,
   climate negotiators, students of climate change, researchers, NGO
   communities and every single human being who understands that managing
   climate change is not only complex but also extensive.}},
DOI = {{10.1108/IJCCSM-03-2013-0026}},
ISSN = {{1756-8692}},
EISSN = {{1756-8706}},
Unique-ID = {{ISI:000346110900003}},
}

@inproceedings{ ISI:000350965100038,
Author = {Chiroma, Haruna and Abdulkareem, Sameem and Abubakar, Adamu and Zeki,
   Akram and Gital, Abdulsalam Ya'u},
Book-Group-Author = {{IEEE}},
Title = {{Intelligent System for Predicting the Price of Natural Gas Based on
   Non-Oil Commodities}},
Booktitle = {{2013 IEEE SYMPOSIUM ON INDUSTRIAL ELECTRONICS \& APPLICATIONS (ISIEA
   2013)}},
Series = {{IEEE Symposium on Industrial Electronics and Applications}},
Year = {{2013}},
Pages = {{200-205}},
Note = {{IEEE Symposium on Industrial Electronics and Applications (ISIEA),
   Kuching, PEOPLES R CHINA, SEP 22-25, 2013}},
Organization = {{IEEE; IEEE Malaysia Ind Elect Ind Applicat Soc Joint Chapter}},
Abstract = {{We present a preliminary investigation into a novel approach to natural
   gas prediction. Experimental data were extracted from the Energy
   Information Administration of the US Department of Energy. The datasets
   were pre-processed and used to build a feed-forward neural network
   intelligent system for predicting natural gas prices based on gold,
   silver, soy and copper. The validation of the intelligent system
   indicated a Regression (R) = 0.79972 when the reserved datasets were
   tested on the intelligent system. Natural gas prices can be predicted
   using non-oil commodities as independent variables. With little
   additional information, the proposed design can be used to construct
   intelligent decision support systems to support decision making in the
   government and private sector.}},
ISSN = {{2373-5384}},
ORCID-Numbers = {{Chiroma, Haruna/0000-0003-3446-4316}},
Unique-ID = {{ISI:000350965100038}},
}

@article{ ISI:000323103900017,
Author = {Xing, J. and Pleim, J. and Mathur, R. and Pouliot, G. and Hogrefe, C.
   and Gan, C. -M. and Wei, C.},
Title = {{Historical gaseous and primary aerosol emissions in the United States
   from 1990 to 2010}},
Journal = {{ATMOSPHERIC CHEMISTRY AND PHYSICS}},
Year = {{2013}},
Volume = {{13}},
Number = {{15}},
Pages = {{7531-7549}},
Abstract = {{An accurate description of emissions is crucial for model simulations to
   reproduce and interpret observed phenomena over extended time periods.
   In this study, we used an approach based on activity data to develop a
   consistent series of spatially resolved emissions in the United States
   from 1990 to 2010. The state-level anthropogenic emissions of SO2, NOx,
   CO, NMVOC (non-methane volatile organic compounds), NH3, PM10 and PM2.5
   for a total of 49 sectors were estimated based on several long-term
   databases containing information about activities and emission controls.
   Activity data for energy-related stationary sources were derived from
   the State Energy Data System. Corresponding emission factors reflecting
   implemented emission controls were calculated back from the National
   Emissions Inventory (NEI) for seven years (i.e., 1990, 1995, 1996, 1999,
   2001, 2002 and 2005), and constrained by the AP-42 (US EPA's Compilation
   of Air Pollutant Emissions Factors) dataset. Activity data for mobile
   sources including different types of highway vehicles and non-highway
   equipment were obtained from highway statistics reported by the Federal
   Highway Administration. The trends in emission factors for highway
   mobile source were informed by the 2011 National Transportation
   Statistics. Emissions for all non-energy-related sources were either
   scaled by the growth ratio of activity indicators or adjusted based on
   the NEI trends report.
   Because of the strengthened control efforts, particularly for the power
   sector and mobile sources, emissions of all pollutants except NH3 were
   reduced by half over the last two decades. The emission trends developed
   in this study are comparable with the NEI trend report and EDGAR
   (Emissions Database for Global Atmospheric Research) data, but better
   constrained by trends in activity data. Reductions in SO2, NOx, CO and
   EC (speciation of PM2.5 by SMOKE, Sparse Matrix Operator Kernel
   Emissions) emissions agree well with the observed changes in ambient
   SO2, NO2, CO and EC concentrations, suggesting that the various controls
   on emissions implemented over the last two decades are well represented
   in the emission inventories developed in this study. These inventories
   were processed by SMOKE and are now ready to be used for regional
   chemistry transport model simulations over the 1990-2010 period.}},
DOI = {{10.5194/acp-13-7531-2013}},
ISSN = {{1680-7316}},
ResearcherID-Numbers = {{Pouliot, George/E-9332-2012
   wei, chao/E-4379-2011
   xing, jia/O-1784-2014}},
ORCID-Numbers = {{Pouliot, George/0000-0003-3406-4814
   }},
Unique-ID = {{ISI:000323103900017}},
}

@article{ ISI:000307799400010,
Author = {Wilson, Jefferson R. and Arnold, Paul M. and Singh, Anoushka and
   Kalsi-Ryan, Sukhvinder and Fehlings, Michael G.},
Title = {{Clinical prediction model for acute inpatient complications after
   traumatic cervical spinal cord injury: a subanalysis from the Surgical
   Timing in Acute Spinal Cord Injury Study}},
Journal = {{JOURNAL OF NEUROSURGERY-SPINE}},
Year = {{2012}},
Volume = {{17}},
Number = {{S}},
Pages = {{46-51}},
Month = {{SEP}},
Abstract = {{Object. While the majority of existing reports focus on complications
   sustained during the chronic stages after traumatic spinal cord injury
   (SCI), the objective in the current study was to characterize and
   quantify acute inpatient complications. In addition, the authors sought
   to create a prediction model using clinical variables documented at
   hospital admission to predict acute complication development.
   Methods. Analyses were based on data from the Surgical Timing in Acute
   Spinal Cord Injury Study (STASCIS) data registry, which contains
   prospective information on adult patients with cervical SCIs who were
   enrolled at 6 North American centers over a 7-year period. All patients
   who underwent a standardized American Spinal Injury Association (ASIA)
   neurological examination within 24 hours of injury and whose follow-up
   information was available at the acute hospital discharge were included
   in the study. For purposes of classification, complications were divided
   into 5 major categories: 1) cardiopulmonary, 2) surgical, 3) thrombotic,
   4) infectious, and 5) decubitus ulcer development. Univariate
   statistical analyses were performed to determine the relationship
   between complication occurrence and individual demographic, injury, and
   treatment variables. Multivariate logistic regression was subsequently
   performed to create a complication prediction model. Model
   discrimination was judged according to the area under the receiver
   operating characteristic curve.
   Results. Complete complication information was available for 411
   patients at the acute care discharge. One hundred sixty patients
   (38.9\%) experienced 240 complications. The mean age among those who
   experienced at least one complication was 45.9 years, as compared with
   43.5 years among those who did not have a complication (p = 0.18). In
   the univariate analysis, patients with complications were less likely to
   receive steroids at admission (p = 0.01), had a greater severity of
   neurological injury as indicated by the ASIA Impairment Scale (AIS)
   grade at presentation (p < 0.01), and a higher frequency of significant
   comorbidity (p = 0.04). In a multivariate logistic regression model, a
   severe initial AIS grade (p < 0.01), a high-energy injury mechanism (p =
   0.07), an older age (p = 0.05), the absence of steroid administration (p
   = 0.02), and the presence of comorbid illness (p = 0.02) were associated
   with a greater likelihood of complication development during the period
   of acute hospitalization. The area under the curve value for the full
   model was 0.75, indicating acceptable predictive discrimination.
   Conclusions. These results will help clinicians to identify patients
   with cervical SCIs at greatest risk for complication development and
   thus allowing for the institution of aggressive complication prevention
   measures. (http://thejns.org/doi/abs/10.3171/2012.4.AOSPINE1246)}},
DOI = {{10.3171/2012.4.AOSPINE1246}},
ISSN = {{1547-5654}},
Unique-ID = {{ISI:000307799400010}},
}

@article{ ISI:000296440100015,
Author = {As'habi, Atefeh and Tabibi, Hadi and Rad, Anahita Houshiar and Heshmati,
   Behnaz Nozary and Mahdavi-Mazdeh, Mitra and Hedayati, Mehdi},
Title = {{Dietary assessment of hemodialysis patients in Tehran, Iran}},
Journal = {{HEMODIALYSIS INTERNATIONAL}},
Year = {{2011}},
Volume = {{15}},
Number = {{4}},
Pages = {{530-537}},
Month = {{OCT}},
Abstract = {{Inadequate dietary intakes are a major determinant of malnutrition in
   hemodialysis (HD) patients. Considering the lack of information
   available on dietary intakes of HD patients in Iran, the present study
   was designed to assess the dietary intakes of HD patients in Tehran,
   Iran. For this cross-sectional study, from among adult HD patients of 50
   Tehran hemodialysis centers, 291 patients were randomly selected.
   Dietary intakes of these patients were assessed using a 4-day dietary
   recall. In addition, 4 mL of blood was obtained from each patient before
   dialysis to measure serum urea, creatinine, albumin, phosphorus,
   calcium, potassium, and high sensitive C-reactive protein levels.
   Dietary intakes of energy, protein and fiber were lower than recommended
   intakes in 88\%, 84.5\%, and 99\% of HD patients, respectively. There
   were significant associations between dietary energy intake with the
   patient's age (p < 0.05), and HD vintage (P < 0.001). In addition, a
   significant association was found between dietary protein intake and sex
   (P < 0.05). Intakes of vitamins B1, B2, B3, B6, B12, C, E, folic acid,
   and of the minerals calcium and zinc (from both the diet and
   supplements) were lower than recommended intakes in 13.5\%, 41.5\%,
   19\%, 66\%, 61\%, 78\%, 77\%, 24\%, 34\%, and 98.5\% of HD patients,
   respectively. Inadequate intakes of energy and various nutrients are
   prevalent in HD patients in Tehran, Iran, which may contribute to
   increased morbidity and mortality in these patients. Therefore,
   nutrition counseling and the administration of vitamin and mineral
   supplements are necessary in Iranian HD patients.}},
DOI = {{10.1111/j.1542-4758.2011.00582.x}},
ISSN = {{1492-7535}},
ORCID-Numbers = {{Mahdavi-Mazdeh, Mitra/0000-0002-9304-1877
   Hedayati, Mehdi/0000-0001-5816-775X}},
Unique-ID = {{ISI:000296440100015}},
}

@article{ ISI:000285135800025,
Author = {Hong, Chen-Jee and Tsai, Pei-Jane and Cheng, Chih-Ya and Chou, Chuan-Kai
   and Jheng, Huei-Fen and Chuang, You-Chung and Yang, Chia-Ning and Lin,
   Ya-Tzu and Hsu, Chih-Wei and Cheng, Irene H. and Chen, Shiow-Yi and
   Tsai, Shih-Jen and Liou, Ying-Jay and Tsai, Yau-Sheng},
Title = {{ENU Mutagenesis Identifies Mice with Morbid Obesity and Severe
   Hyperinsulinemia Caused by a Novel Mutation in Leptin}},
Journal = {{PLOS ONE}},
Year = {{2010}},
Volume = {{5}},
Number = {{12}},
Month = {{DEC 9}},
Abstract = {{Background: Obesity is a multifactorial disease that arises from complex
   interactions between genetic predisposition and environmental factors.
   Leptin is central to the regulation of energy metabolism and control of
   body weight in mammals.
   Methodology/Principal Findings: To better recapitulate the complexity of
   human obesity syndrome, we applied N-ethyl-N-nitrosourea (ENU)
   mutagenesis in combination with a set of metabolic assays in screening
   mice for obesity. Mapping revealed linkage to the chromosome 6 within a
   region containing mouse Leptin gene. Sequencing on the candidate genes
   identified a novel T-to-A mutation in the third exon of Leptin gene,
   which translates to a V145E amino acid exchange in the leptin
   propeptide. Homozygous Leptin(145E/145E) mutant mice exhibited morbid
   obesity, accompanied by adipose hypertrophy, energy imbalance, and liver
   steatosis. This was further associated with severe insulin resistance,
   hyperinsulinemia, dyslipidemia, and hyperleptinemia, characteristics of
   human obesity syndrome. Hypothalamic leptin actions in inhibition of
   orexigenic peptides NPY and AgRP and induction of SOCS1 and SOCS3 were
   attenuated in Leptin(145E/145E) mice. Administration of exogenous
   wild-type leptin attenuated hyperphagia and body weight increase in
   Leptin(145E/145E) mice. However, mutant V145E leptin
   coimmunoprecipitated with leptin receptor, suggesting that the V145E
   mutation does not affect the binding of leptin to its receptor.
   Molecular modeling predicted that the mutated residue would form
   hydrogen bond with the adjacent residues, potentially affecting the
   structure and formation of an active complex with leptin receptor within
   that region.
   Conclusions/Significance: Thus, our evolutionary, structural, and in
   vivo metabolic information suggests the residue 145 as of special
   function significance. The mouse model harboring leptin V145E mutation
   will provide new information on the current understanding of leptin
   biology and novel mouse model for the study of human obesity syndrome.}},
DOI = {{10.1371/journal.pone.0015333}},
Article-Number = {{e15333}},
ISSN = {{1932-6203}},
ResearcherID-Numbers = {{Tsai, Pei-Jane/G-3563-2011
   Tsai, Shih-Jen/}},
ORCID-Numbers = {{Tsai, Shih-Jen/0000-0002-9987-022X}},
Unique-ID = {{ISI:000285135800025}},
}

@article{ ISI:000264095500025,
Author = {Sornette, Didier and Woodard, Ryan and Zhou, Wei-Xing},
Title = {{The 2006-2008 oil bubble: Evidence of speculation, and prediction}},
Journal = {{PHYSICA A-STATISTICAL MECHANICS AND ITS APPLICATIONS}},
Year = {{2009}},
Volume = {{388}},
Number = {{8}},
Pages = {{1571-1576}},
Month = {{APR 15}},
Abstract = {{We present an analysis of oil prices in USD and in other major
   currencies that diagnoses unsustainable faster-than-exponential
   behavior. This supports the hypothesis that the recent oil price run-up
   was amplified by speculative behavior of the type found during a
   bubble-like expansion. We also attempt to unravel the information hidden
   in the oil supply-demand data reported by two leading agencies, the US
   Energy Information Administration (EIA) and the International Energy
   Agency (IEA). We suggest that the found increasing discrepancy between
   the EIA and IEA figures provides a measure of the estimation errors.
   Rattler than a clear transition to a supply restricted regime, we
   interpret the discrepancy between the IEA and EIA as a signature Of
   uncertainty, and there is no better fuel than uncertainty to promote
   speculation! Our post-crash analysis confirms that the oil peak in July
   2008 occurred within the expected 80\% confidence interval predicted
   with data available in our pre-crash analysis. (C) 2009 Elsevier B.V.
   All rights reserved.}},
DOI = {{10.1016/j.physa.2009.01.011}},
ISSN = {{0378-4371}},
ResearcherID-Numbers = {{Zhou, Wei-Xing/B-1250-2008}},
ORCID-Numbers = {{Zhou, Wei-Xing/0000-0002-8952-8228}},
Unique-ID = {{ISI:000264095500025}},
}

@inproceedings{ ISI:000290045002115,
Author = {Salciarini, D. and Tamagnini, C. and Conversini, P.},
Editor = {{Anderssen, RS and Braddock, RD and Newham, LTH}},
Title = {{Numerical approaches for rockfall analysis: a comparison}},
Booktitle = {{18TH WORLD IMACS CONGRESS AND MODSIM09 INTERNATIONAL CONGRESS ON
   MODELLING AND SIMULATION: INTERFACING MODELLING AND SIMULATION WITH
   MATHEMATICAL AND COMPUTATIONAL SCIENCES}},
Year = {{2009}},
Pages = {{2706-2712}},
Note = {{Combined IMACS World Congress/Modelling and Simulation
   Society-of-Australia-and-New-Zealand (MSSANZ)/18th Biennial Conference
   on Modelling and Simulation, Cairns, AUSTRALIA, JUL 13-17, 2009}},
Organization = {{IMACS; MSSANZ; CSIRO; Australian Math Sci Inst; Griffith Univ; eWater
   Cooperat Res Ctr; Dept Sustainabil \& Environm; HEMA Consulting;
   Hellenic European Res Comp Math \& Applicat; Int Council Ind Appl Math;
   Int Soc Grid Generat; Int Soc Photogrammetry \& Remote Sensing; Japan
   Soc Simulat Technol; Pacific Rim Math Assoc; Rutgers, State Univ New
   Jersey}},
Abstract = {{An important issue in the evaluation of potential hazard related to
   rockfalls is the quantitative prediction of the traveling distance of
   the falling blocks, which is necessary to identify the potentially
   endangered area. This information is also fundamental for the design of
   appropriate defensive works, which are intended to reduce the potential
   impact of the landslide on the population and facilities potentially at
   risk. The design of this type of protective measures typically requires,
   above all, the quantitative prediction of the final travel distance of
   the rock masses. Obtaining a reliable estimate of this quantity is
   complicated by the interaction of the rocks and the slope surface that
   can affect the behavior of the blocks at the impacts. Recently, several
   numerical techniques have been developed and applied to this purpose,
   based on the solution of the Newton's equations of motion for each
   block. The aim of this work is to compare the performance of two such
   approaches, namely the Colorado Rockfall Simulation Program (CRSP), and
   the Discrete Element Method (DEM). the CRSP method can describe the
   falling motion of blocks of cylindrical, spherical or discoidal shape,
   which translate and rotate in the vertical plane of motion. The motion
   of the block is determined by means of the parabolic equation of
   free-fall motion and the balance of total energy equation. The impact
   with the slope surface is modeled taking into account the block shape
   and size and the slope roughness. Upon impact with the slope surface,
   the normal and tangential components of the block velocity are reduced
   by means of suitable coefficients of restitution, K(n) and K(t), in the
   normal and tangential directions, respectively, to take into account the
   dissipation of energy due to inelastic deformations. The model is
   capable of considering the combination of free-fall, rebound, rolling
   and sliding motion that can occur for different slope roughness and
   block size. An alternative to the CRSP method, which appears
   particularly promising for its versatility, is represented by the DEM.
   In the DEM, the motion of the falling block under the action of gravity
   is computed by numerically solving Newton's equation of motion. In this
   work, the DEM code UDEC (Itasca, 1991) has been used to simulate the
   falling block and to model its fragmentation during rhe fall. In UDEC,
   each distinct element is a prismatic block that can be considered
   perfectly rigid or deformable. Each block in the model is subject to
   body forces (gravity) and contact forces exchanged at the contacts with
   other blocks or with rigid ``walls{''}. These two approaches have been
   used to simulate a real case study occurred in a rock slope located in
   central Italy where several rockfall events occurred and were recorded
   by in-situ surveys from the local administration. The results of the
   study indicate that when an appropriate calibration of the physical
   parameters is carried out the different approaches can correctly
   reproduce the observed phenomena. The performance of the different
   approaches to rockfall simulation - the CRSP method and the Discrete
   Element Method, in the particular implementation of the UDEC code - with
   reference to observations from a real rock slope lead to two main
   conclusions. As far as the falling of a single block is concerned, both
   methods give comparable results that are in line with the available
   observations.
   However, while in the CRSP method a single set of restitution
   coefficients is sufficient to characterize the block behavior upon
   impact, the local damping coeffcient introduced in UDEC to model the
   energy dissipation upon impact must be varied with block size, in order
   to model correctly the effect of block size on the observed traveling
   distance. On the other hand, a unique advantage of the DEM approach as
   compared to other methods derived from the lumped mass approach is the
   possibility of modeling the effects of rock fragmentation. The results
   of the simulations indicate that the position and the extension of the
   accumulation zone can be strongly affected by block fragmentation; in
   particular the traveling distance tends to decrease progressively with
   block fragmentation. Therefore, this particular aspect should be taken
   into proper consideration in the rockfall hazard evaluation whenever the
   possibility of block fragmentation is of concern.}},
ISBN = {{978-0-9758400-7-8}},
ResearcherID-Numbers = {{Tamagnini, Claudio/L-9350-2015
   Salciarini, Diana/}},
ORCID-Numbers = {{Tamagnini, Claudio/0000-0002-6565-1969
   Salciarini, Diana/0000-0002-0085-2639}},
Unique-ID = {{ISI:000290045002115}},
}

@inproceedings{ ISI:000272196300054,
Author = {Wu Qunli and Hao Ge and Cheng Xiaodong},
Editor = {{Zhou, QH}},
Title = {{Crude Oil Price Forecasting with an Improved Model Based on Wavelet
   Transform and RBF Neural Network}},
Booktitle = {{2009 INTERNATIONAL FORUM ON INFORMATION TECHNOLOGY AND APPLICATIONS, VOL
   1, PROCEEDINGS}},
Year = {{2009}},
Pages = {{231-234}},
Note = {{International Forum on Information Technology and Applications (IFITA
   2009), Chengdu, PEOPLES R CHINA, MAY 15-17, 2009}},
Abstract = {{The fluctuation of oil price decides the security of energy and
   economics. So the crude oil price forecasting performs importantly. In
   the paper, we apply the improved model based on Wavelet Transform and
   Radial Basis Function (RBF) neural network to forecast the future oil
   price. Wavelet Transform decomposes the original price which is used as
   the output layer of RBF neural network and the parts of the decomposed
   are used as the input layer of neural network The real data of Europe
   (UK) Brent Blend Spot Price FOB (Dollar per Barrel) showed by Energy
   Information Administration (Official Energy Statistics from the U.S.
   Government) is used as the word crude oil price, dating from January 199
   7 to October 2008. Finally, the model is proved acutely and feasibly.}},
DOI = {{10.1109/IFITA.2009.36}},
ISBN = {{978-0-7695-3600-2}},
Unique-ID = {{ISI:000272196300054}},
}

@article{ ISI:000262429500010,
Author = {Roche, John R. and Blache, Dominique and Kay, Jane K. and Miller, Dale
   R. and Sheahan, Angela J. and Miller, David W.},
Title = {{Neuroendocrine and physiological regulation of intake with particular
   reference to domesticated ruminant animals}},
Journal = {{NUTRITION RESEARCH REVIEWS}},
Year = {{2008}},
Volume = {{21}},
Number = {{2}},
Pages = {{207-234}},
Month = {{DEC}},
Abstract = {{The central nervous system undertakes the homeostatic role of sensing,
   nutrient intake and body reserves. integrating the information, and
   regulating energy intake and/or energy expenditure. Few tasks regulated
   by the brain hold greater survival value, particularly important in
   farmed ruminant species, where the demands of pregnancy, lactation
   and/or growth are not easily met by often bulky plant-based and
   sometimes nutrient-sparse diets. Information regarding metabolic state
   call be transmitted to the appetite control centres of the brain by a
   diverse array of signals, Such as stimulation of the vagus nerve, or
   metabolic `feedback' factors derived from the pituitary bland. adipose
   tissue, stomach/abomasum, intestine, pancreas and/or muscle. These
   signals act directly oil the neurons located in the arcuate nucleus of
   the medio-basal hypothalamus, a key integration. and hunger (orexigenic)
   and satiety (anorexigenic) control centre of the brain. Interest ill
   human obesity and associated disorders has fuelled considerable research
   effort ill this area. resulting ill increased understanding of chronic
   and acute factors influencing feed intake. In recent years, research has
   demonstrated that these results have relevance to animal production,
   with genetic selection for production found to affect orexigenic
   hormones, feeding found to reduce the concentration of acute controllers
   of orexigenic signals, and exogenous administration of orexigenic
   hormones (i.e. growth hormone or ghrelin) reportedly increasing DM
   intake in ruminant animals as well as single-stomached species. The
   Current state of knowledge oil factors influencing the hypothalamic
   orexigenic and anorexigenic control centres is reviewed. particularly as
   it relates to domesticated ruminant animals, and potential avenues for
   future research are identified.}},
DOI = {{10.1017/S0954422408138744}},
ISSN = {{0954-4224}},
ResearcherID-Numbers = {{Blache, Dominique/H-4991-2014}},
Unique-ID = {{ISI:000262429500010}},
}

@article{ ISI:000258338700002,
Author = {Kharecha, Pushker A. and Hansen, James E.},
Title = {{Implications of ``peak oil'' for atmospheric CO2 and climate}},
Journal = {{GLOBAL BIOGEOCHEMICAL CYCLES}},
Year = {{2008}},
Volume = {{22}},
Number = {{3}},
Month = {{AUG 5}},
Abstract = {{Unconstrained CO2 emission from fossil fuel burning has been the
   dominant cause of observed anthropogenic global warming. The amounts of
   ``proven'' and potential fossil fuel reserves are uncertain and debated.
   Regardless of the true values, society has flexibility in the degree to
   which it chooses to exploit these reserves, especially unconventional
   fossil fuels and those located in extreme or pristine environments. If
   conventional oil production peaks within the next few decades, it may
   have a large effect on future atmospheric CO2 and climate change,
   depending upon subsequent energy choices. Assuming that proven oil and
   gas reserves do not greatly exceed estimates of the Energy Information
   Administration, and recent trends are toward lower estimates, we show
   that it is feasible to keep atmospheric CO2 from exceeding about 450 ppm
   by 2100, provided that emissions from coal, unconventional fossil fuels,
   and land use are constrained. Coal-fired power plants without
   sequestration must be phased out before midcentury to achieve this CO2
   limit. It is also important to ``stretch'' conventional oil reserves via
   energy conservation and efficiency, thus averting strong pressures to
   extract liquid fuels from coal or unconventional fossil fuels while
   clean technologies are being developed for the era ``beyond fossil
   fuels''. We argue that a rising price on carbon emissions is needed to
   discourage conversion of the vast fossil resources into usable reserves,
   and to keep CO2 beneath the 450 ppm ceiling.}},
DOI = {{10.1029/2007GB003142}},
Article-Number = {{GB3012}},
ISSN = {{0886-6236}},
Unique-ID = {{ISI:000258338700002}},
}

@article{ ISI:000255775700095,
Author = {Ying, Weihai},
Title = {{NAD(+) and NADH in ischemic brain injury}},
Journal = {{FRONTIERS IN BIOSCIENCE-LANDMARK}},
Year = {{2008}},
Volume = {{13}},
Pages = {{1141-1151}},
Month = {{JAN 1}},
Abstract = {{NAD(+) and NADH have been emerging as the common mediators of energy
   metabolism, mitochondrial functions, calcium homeostasis, aging and cell
   death. NAD(+) and NADH can affect cell death by various mechanisms, such
   as influencing energy metabolism, mitochondrial permeability transition
   pores, and apoptosis-inducing factor. Because energy failure, calcium
   disregulation and cell death are the key components in the tissue
   damaging cascade initiated by cerebral ischemia, it is likely that
   NAD(+) and NADH play significant roles in ischemic brain damage. Many
   studies, including the findings that poly(ADP-ribose) polymerase-1
   mediates ischemic brain injury and that NAD(+) administration can
   decrease ischemic brain damage, have suggested significant roles of
   NAD(+) and NADH in the debilitating illness. However, there is still
   distinct insufficiency of the information regarding the roles of NAD(+)
   and NADH in ischemic brain injury. Because increasing evidence has
   indicated critical functions of NAD(+) and NADH in various biological
   processes, future studies on the roles of NAD(+) and NADH in cerebral
   ischemia may expose essential mechanisms underlying ischemic brain
   injury and suggest novel therapeutic strategies for the illness.}},
DOI = {{10.2741/2751}},
ISSN = {{1093-9946}},
Unique-ID = {{ISI:000255775700095}},
}

@article{ ISI:000247938900014,
Author = {Perello, Mario and Stuart, Ronald C. and Nillni, Eduardo A.},
Title = {{Differential effects of fasting and leptin on proopiomelanocortin
   peptides in the arcuate nucleus and in the nucleus of the solitary tract}},
Journal = {{AMERICAN JOURNAL OF PHYSIOLOGY-ENDOCRINOLOGY AND METABOLISM}},
Year = {{2007}},
Volume = {{292}},
Number = {{5}},
Pages = {{E1348-E1357}},
Month = {{MAY}},
Abstract = {{The alpha-melanocyte-stimulating hormone (alpha-MSH), derived from
   proopiomelanocortin (POMC), is generated by a posttranslational
   processing mechanism involving the prohormone convertases (PCs) PC1/3
   and PC2. In the brain, alpha-MSH is produced in the arcuate nucleus
   (ARC) of the hypothalamus and in the nucleus of the solitary tract (NTS)
   of the medulla. This peptide is key in controlling energy balance, as
   judged by changes observed at transcriptional level. However, little
   information is available regarding the biosynthesis of the precursor
   POMC and the production of its processed peptides during feeding,
   fasting, and fasting plus leptin in the ARC compared with the NTS in
   conjunction with the PC activity. In this study we found that, in the
   ARC, pomc mRNA, POMC-derived peptides, and PC1/3 all decreased during
   fasting, and administration of leptin reversed these effects. In
   contrast, in the NTS, where there is a large amount of a 28.1-kDa
   peptide similar in size to POMC, the 28.1-kDa peptide and other
   POMC-derived peptides, including alpha-MSH, were further accumulated in
   fasting conditions, whereas pomc mRNA decreased. These changes were not
   reversed by leptin. We also observed that, during fasting, PC2 levels
   decreased in the NTS. These data suggest that, in the NTS, fasting
   induced changes in POMC biosynthesis, and processing is independent of
   leptin. These observations indicate that changes in energy status affect
   POMC in the brain in a tissue-specific manner. This represents a novel
   aspect in the regulation of energy balance and may have implications in
   the pathophysiology of obesity.}},
DOI = {{10.1152/ajpendo.00466.2006}},
ISSN = {{0193-1849}},
Unique-ID = {{ISI:000247938900014}},
}

@inproceedings{ ISI:000256526300095,
Author = {Heimiller, Donna and Haymes, Steve and Schwartz, Marc and Musial, Walt},
Book-Group-Author = {{IEEE}},
Title = {{Offshore wind resource potential of the United States}},
Booktitle = {{2007 OCEANS, VOLS 1-5}},
Series = {{OCEANS-IEEE}},
Year = {{2007}},
Pages = {{675-682}},
Note = {{2007 OCEANS Conference, Vancouver, CANADA, SEP 29-OCT 04, 2007}},
Organization = {{MTS; IEEE; Canada; Oceanworks; ISE Grp Co; Sun Star Elect L P;
   KONGSBERG; IMAGENEX TECHNOL CORP; ONR; OPSI}},
Abstract = {{Offshore wind resources have the potential to be a significant domestic
   energy source. Many coastal areas have large electricity demand but have
   limited access to high-quality, land-based wind resource. The U.S.
   Department of Energy's National Renewable Energy Laboratory has
   developed a baseline offshore wind resource database that incorporates
   physical parameters that impact development. These characteristics
   include wind power class, water depth (U.S. Department of Commerce's
   National Oceanic and Atmospheric Administration's {[}NOAA] Coastal
   Relief Model), distance from shore (shoreline delineation by NOAA), and
   administrative jurisdiction (U.S. Department of the Interior's Minerals
   Management Service The database does not consider the impact of other
   factors on offshore wind resource, particularly environmental exclusions
   such as protected marine habitats, waterfowl breeding areas, and
   fisheries. The impact of these exclusions on offshore wind resource
   potential is explored using Geographic Information Systems techniques,
   which allow for spatial correlation of these locations. Future
   investigations of offshore wind resource exclusions may include high
   traffic seaways, underwater infrastructure, and other factors.}},
ISSN = {{0197-7385}},
ISBN = {{978-0-933957-37-4}},
Unique-ID = {{ISI:000256526300095}},
}

@article{ ISI:000244970400010,
Author = {Pietrafesa, L. J. and Kelleher, K. and Karl, T. and Davidson, M. and
   Peng, M. and Bao, S. and Dickey, D. and Xie, L. and Liu, H. and Xia, M.},
Title = {{A new architecture for coastal inundation and flood warning prediction}},
Journal = {{MARINE TECHNOLOGY SOCIETY JOURNAL}},
Year = {{2006}},
Volume = {{40}},
Number = {{4}},
Pages = {{71-77}},
Month = {{WIN}},
Abstract = {{The marine atmosphere, coastal ocean, estuary, harbor and river water
   systems constitute a physically coupled system. While these systems have
   always been heavily impacted by coastal storms, increases in population
   density, infrastructure, and personal and business merchandise have
   exacerbated the economic and personal impacts of these events over the
   past half century. As such there has been increased focus on the need
   for more timely and accurate forecasts of impending events.
   Traditionally model forecast architectures for coastal storm surge,
   flooding and inundation of coastal and inland areas have taken the
   approach of dealing with each system separately: rivers, estuaries,
   harbors and offshore facing areas. However, given advances in coupled
   modeling and the availability of real-time data, the ability to
   accurately predict and project coastal, estuary and inland flooding
   related to the passage of high energy and wet atmospheric events is
   rapidly emerging and requires a new paradigm in system architecture. No
   longer do monthly averaged winds or river discharge or water levels have
   to be invoked in developing hindcasts for planning purposes or for
   real-time forecasts. In 1999 a hurricane associated flood on the North
   Carolina coast took 56 lives and caused more than \$6 billion in
   economic impacts. None of the models existing at that time were able to
   properly forecast the massive flooding and clearly called for a new
   model paradigm.
   Here we propose a model system that couples atmospheric information to
   fully three dimensional, non-linear time dependent ocean basin, coastal
   and estuary hydrodynamic models coupled to interactive river models with
   input of real or modeled winds, observed or modeled precipitation,
   measured and modeled water levels, and streamflow. The river and
   estuarine components must both be capable of going into modes of storage
   or accelerated discharge. Spatial scales must downscale in the
   horizontal from thousands to tens meters and in the vertical from
   hundreds to several centimeters. Topography and elevation data should be
   of the highest resolution available, necessary for highly accurate
   predictions of the timing and location of the inundation and retreat of
   flood waters. Precipitation information must be derived from the optimal
   mix of direct radar, satellite and ground-based observations. Creating
   the capability described above will advance the modernization of
   hydrologic services provided by the National Oceanic \& Atmospheric
   Administration and provide more accurate and timely forecasts and
   climatologies of coastal and estuary flooding. The goal of these
   climatologies and improved forecasts is to provide better information to
   local and regional planners, emergency managers, highway patrols and to
   improve the capacity of coastal communities to mitigate against the
   impacts of coastal flooding.}},
ISSN = {{0025-3324}},
ResearcherID-Numbers = {{Kelleher, Kevin/L-6520-2015}},
Unique-ID = {{ISI:000244970400010}},
}

@inproceedings{ ISI:000225279900083,
Author = {Hill, RC},
Book-Group-Author = {{asme}},
Title = {{What powers the Chevrolet in 2030?}},
Booktitle = {{PROCEEDINGS OF 2004 ASME POWER}},
Year = {{2004}},
Pages = {{671-673}},
Note = {{ASME Power Conference 2004, Baltimore, MD, MAR 30-APR 01, 2004}},
Organization = {{Amer Soc Mech Engineers, Power Div; ASME, Fuels \& Combust Technologies
   Div}},
Abstract = {{``The Annual Energy Outlook 2003{''} from the Energy Information
   Administration indicates an annual petroleum consumption of 38.5 quads
   with 25.7 quads imported. The transportation sector uses 26 quads, or
   67\% of the total. No other sector (residential, commercial or
   industrial) of our society has this level of dependence on petroleum.
   Electric power generation, for example, has less than 5\% of its output
   dependent on petroleum. Recent energy policy has focused hydrogen as the
   next generation transportation fuel. Will this alternative stand
   technical scrutiny? What are the options? Do those of us laboring in the
   technology vineyard have a responsibility to speak out publicly on these
   options?}},
ISBN = {{0-7918-4162-6}},
Unique-ID = {{ISI:000225279900083}},
}

@article{ ISI:000186314900002,
Author = {Camina, JP and Carreira, MC and Micic, D and Pombo, M and Kelestimur, F
   and Dieguez, C and Casanueva, FF},
Title = {{Regulation of ghrelin secretion and action}},
Journal = {{ENDOCRINE}},
Year = {{2003}},
Volume = {{22}},
Number = {{1}},
Pages = {{5-12}},
Month = {{OCT}},
Abstract = {{The pulsatile release of growth hormone (GH) from anterior pituitary
   gland is regulated by the interplay of at least two hypothalamic
   hormones, GH-releasing hormone (GHRH) and somatostatin, via their
   engagement with specific cell surface receptors on the anterior
   pituitary somatotroph. Furthermore, release of GH in vivo may also be
   controlled by a third type of receptor, the growth hormone secretagogue
   receptor, a G-protein-coupled receptor, called GHS receptor type 1a
   (GHS-R1a), which was identified in the pituitary and the hypothalamus in
   humans using a nonpeptidyl growth hormone secretagogue (MK-0677).
   Ghrelin, the endogenous ligand for the GHS-R1a, is a 28-amino-acid
   peptide isolated from human stomach that is modified by a straight chain
   octanoyl group covalently linked to Sera, which is essential for its
   endocrine activity. This hormone, predominantly expressed and secreted
   by the stomach, has a dual action on GH secretion and food intake,
   showing interdependency between these actions. The finding that fasting
   and food intake, respectively, increase and decrease the secretion of
   ghrelin suggests that this hormone may be the bridge connecting somatic
   growth and body composition with energy metabolism, and appears to play
   a role in the alteration of energy homeostasis and body weight in
   pathophysiological states such as hypothyroidism and hyperthyroidism.
   Despite this, little is known about the intracellular signaling through
   which ghrelin exerts its regulatory actions. Activation of intracellular
   calcium mobilization is one of the earliest known cellular signals
   elicited by ghrelin. In HEK-293 cells expressing the GHS-R1a, ghrelin
   induces a biphasic cytosolic calcium elevation characterized by a spike
   phase of the response, which reflects Ins(1,4,5)P-3-dependent calcium
   mobilization of intracellular stores, and a sustained phase of the
   response, which is due to calcium influx across the plasma membrane
   triggered by aperture of capacitative calcium channels (store-operated
   calcium channels). Upon repeated administration, ghrelin showed a marked
   suppression of ghrelin-mediated elevations of intracellular calcium.
   This homologous desensitization represents an important physiological
   mechanism that modulates receptor responsiveness and acts as an
   information filter for intracellular signaling system. The discovery of
   ghrelin adds a new component to the complex machinery responsible for
   regulation of GH secretion in connection with the regulation of appetite
   and energy homeostasis.}},
DOI = {{10.1385/ENDO:22:1:5}},
ISSN = {{0969-711X}},
Unique-ID = {{ISI:000186314900002}},
}

@article{ ISI:000182452200003,
Author = {Feltz, WF and Smith, WL and Howell, HB and Knuteson, RO and Woolf, H and
   Revercomb, HE},
Title = {{Near-continuous profiling of temperature, moisture, and atmospheric
   stability using the atmospheric emitted radiance interferometer (AERI)}},
Journal = {{JOURNAL OF APPLIED METEOROLOGY}},
Year = {{2003}},
Volume = {{42}},
Number = {{5}},
Pages = {{584-597}},
Month = {{MAY}},
Abstract = {{The Department of Energy Atmospheric Radiation Measurement Program (ARM)
   has funded the development and installation of five ground-based
   atmospheric emitted radiance interferometer (AERI) systems at the
   Southern Great Plains (SGP) site. The purpose of this paper is to
   provide an overview of the AERI instrument, improvement of the AERI
   temperature and moisture retrieval technique, new profiling utility, and
   validation of high-temporal-resolution AERI-derived stability indices
   important for convective nowcasting. AERI systems have been built at the
   University of Wisconsin-Madison, Madison, Wisconsin, and deployed in the
   Oklahoma-Kansas area collocated with National Oceanic and Atmospheric
   Administration 404-MHz wind profilers at Lamont, Vici, Purcell, and
   Morris, Oklahoma, and Hillsboro, Kansas. The AERI systems produce
   absolutely calibrated atmospheric infrared emitted radiances at
   one-wavenumber resolution from 3 to 20 mum at less than 10-min temporal
   resolution. The instruments are robust, are automated in the field, and
   are monitored via the Internet in near-real time. The infrared radiances
   measured by the AERI systems contain meteorological information about
   the vertical structure of temperature and water vapor in the planetary
   boundary layer (PBL; 0-3 km). A mature temperature and water vapor
   retrieval algorithm has been developed over a 10-yr period that provides
   vertical profiles at less than 10-min temporal resolution to 3 km in the
   PBL. A statistical retrieval is combined with the hourly Geostationary
   Operational Environmental Satellite (GOES) sounder water vapor or Rapid
   Update Cycle, version 2, numerical weather prediction (NWP) model
   profiles to provide a nominal hybrid first guess of temperature and
   moisture to the AERI physical retrieval algorithm. The hourly satellite
   or NWP data provide a best estimate of the atmospheric state in the
   upper PBL; the AERI radiances provide the mesoscale temperature and
   moisture profile correction in the PBL to the large-scale GOES and NWP
   model profiles at high temporal resolution. The retrieval product has
   been named AERIplus because the first guess used for the mathematical
   physical inversion uses an optimal combination of statistical
   climatological, satellite, and numerical model data to provide a best
   estimate of the atmospheric state. The AERI physical retrieval algorithm
   adjusts the boundary layer temperature and moisture structure provided
   by the hybrid first guess to fit the observed AERI downwelling radiance
   measurement. This provides a calculated AERI temperature and moisture
   profile using AERI-observed radiances ``plus{''} the best-known
   atmospheric state above the boundary layer using NWP or satellite data.
   AERIplus retrieval accuracy for temperature has been determined to be
   better than 1 K, and water vapor retrieval accuracy is approximately 5\%
   in absolute water vapor when compared with well-calibrated radiosondes
   from the surface to an altitude of 3 km. Because AERI can monitor the
   thermodynamics where the atmosphere usually changes most rapidly,
   atmospheric stability tendency information is readily available from the
   system. High-temporal-resolution retrieval of convective available
   potential energy, convective inhibition, and PBL equivalent potential
   temperature theta(e) are provided in near-real time from all five AERI
   systems at the ARM SGP site, offering a unique look at the atmospheric
   state. This new source of meteorological data has shown excellent skill
   in detecting rapid synoptic and mesoscale meteorological changes within
   clear atmospheric conditions.
   This method has utility in nowcasting temperature inversion strength and
   destabilization caused by theta(e) advection. This
   high-temporal-resolution monitoring of rapid atmospheric destabilization
   is especially important for nowcasting severe convection.}},
DOI = {{10.1175/1520-0450(2003)042<0584:NPOTMA>2.0.CO;2}},
ISSN = {{0894-8763}},
Unique-ID = {{ISI:000182452200003}},
}

@inproceedings{ ISI:000185623400155,
Author = {Bhargava, A and Zoltowski, M},
Book-Group-Author = {{IEEE COMPUTER SOCIETY
   IEEE COMPUTER SOCIETY
   IEEE COMPUTER SOCIETY}},
Title = {{Sensors and wireless communication for medical care}},
Booktitle = {{14TH INTERNATIONAL WORKSHOP ON DATABASE AND EXPERT SYSTEMS APPLICATIONS,
   PROCEEDINGS}},
Year = {{2003}},
Pages = {{956-960}},
Note = {{14th International Workshop on Database and Expert Systems Applications
   (DEXA 2003), TECH UNIV PRAGUE, PRAGUE, CZECH REPUBLIC, SEP 01-05, 2003}},
Organization = {{DEXA Assoc; Austrian Comp Soc; Res Inst Appl Knowledge Proc, FAW; Appl
   Knowledge Proc Co, AWSoft GesmbH; Microsoft Res, Cambridge; Gerstner Lab}},
Abstract = {{Biological, chemical, and radiological agents can tamper with the
   activities of medical care providers, patient samples, and medicine
   administration. This results in a shut down of all medical care, leaving
   patients at a major risk. The technical challenge is to develop sensors
   to detect and monitor any violations in the medical care environment
   before threat to life occurs. Wireless devices must communicate
   multimedia data such as patient information, laboratory results,
   prescriptions, and Xray and EKG reports. The reliability, security, and
   accuracy of these sensors and wireless devices can affect the timeliness
   access to information for patient monitoring. In addition, data can be
   corrupted, computer information systems can fail, and communication
   networks may experience denial of service attacks leading to complete
   failure of proper patient care. In this paper, we discuss security and
   safety issues in medical environment, the technology, types, and
   characteristics of sensors, and research issues in smart antennas,
   denial of service, fault tolerant authentication, privacy issues, and
   energy considerations. A discussion of sensors in patient rooms,
   clinics/wards, hospitals, and measurements of safety and security is
   presented. The available devices for sensor and wireless communication
   are also briefly included.}},
DOI = {{10.1109/DEXA.2003.1232145}},
ISBN = {{0-7695-1993-8}},
Unique-ID = {{ISI:000185623400155}},
}

@inproceedings{ ISI:000188096400015,
Author = {Leiby, PN and Rubin, J},
Book-Group-Author = {{TRB
   TRB}},
Title = {{Transitions in light-duty vehicle transportation - Alternative-fuel and
   hybrid vehicles and learning}},
Booktitle = {{ENERGY, AIR QUALITY, AND FUELS 2003: ENERGY AND ENVIRONMENT}},
Series = {{TRANSPORTATION RESEARCH RECORD}},
Year = {{2003}},
Number = {{1842}},
Pages = {{127-134}},
Note = {{82nd Annual Meeting of the Transportation-Research-Board, WASHINGTON,
   D.C., JAN 12-16, 2003}},
Organization = {{Transportat Res Board; US Dept Transportat; Bur Transportat Stat; Fed
   Aviat Adm; Fed Highway Adm; Fed Motor Carrier Safety Adm; Fed Railroad
   Adm; Fed Transit Adm; Natl Highway Traff Safety Adm; Res \& Special
   Programs Adm; NASA; USA Corps Engineers; US Coast Guard; US DOE; US EPA}},
Abstract = {{New vehicle technologies and alternative fuels are believed to be key
   factors in increasing energy security, improving air quality, and
   reducing greenhouse gas emissions. Proposed legislation (Energy Policy
   Act of 2003) would extend significant tax credits to fuel-cell vehicles
   and promote hybrid vehicle use through credits toward other federal
   requirements (i.e., for alternative fuel use). Analyses using
   single-period equilibrium models and multiple-period scenario analyses
   are often used to demonstrate the feasibility of technology to attain
   policy goals. These analyses typically assume mature markets,
   large-scale vehicle production, and the widespread availability of
   alternative fuels at retail stations. These conditions are not currently
   attained and may or may not be realized in a market economy. The
   Transitional Alternative Fuels and Vehicles model is used to simulate
   market outcomes for the use and cost of alternative-fuel vehicles (AFVs)
   and hybrid electric vehicles (HEVs) over a 20-year period, considering
   possible transitional barriers related to infrastructure needs,
   production scale, and technological learning. Without subsidies, no
   substantial penetration by HEVs is projected, based on their prospective
   fuel efficiency gains and costs. Hybrid subsidies (on the order of
   \$2,000/vehicle) can induce substantial hybrid penetration and gasoline
   demand displacement under the U.S. Energy Information Administration's
   2001 oil price projections. This result is quantitatively different from
   that achieved for AFVs. Temporary HEV subsidies are effective at
   inducing hybrid vehicle penetration but do not have long-term effects
   once they are removed unless costs are reduced due to learning-by-doing.}},
ISSN = {{0361-1981}},
ISBN = {{0-309-08575-6}},
Unique-ID = {{ISI:000188096400015}},
}

@article{ ISI:000181020800001,
Author = {Bastiaanssen, WGM and Ahmad, MUD and Chemin, Y},
Title = {{Satellite surveillance of evaporative depletion across the Indus Basin}},
Journal = {{WATER RESOURCES RESEARCH}},
Year = {{2002}},
Volume = {{38}},
Number = {{12}},
Month = {{DEC 6}},
Abstract = {{{[}1] The irrigated Indus Basin in Pakistan has insufficient water
   resources to supply all its stakeholders. Information on evaporative
   depletion across the Basin is an important requirement if the water
   resources are to be managed efficiently. This paper presents the Surface
   Energy Balance Algorithm for Land (SEBAL) method used to compute actual
   evapotranspiration for large areas based on public domain National
   Oceanic and Atmospheric Administration (NOAA) satellite data.
   Computational procedures for retrieving actual evapotranspiration from
   satellites have been developed over the last 20 years. The current work
   is among the first applications used to estimate actual
   evapotranspiration on an annual scale across a vast river basin system
   with a minimum of ground data. Only sunshine duration and wind speed are
   required as input data for the remote sensing flux algorithm. The
   results were validated in the Indus Basin by comparing results from a
   field- scale transient moisture flow model, in situ Bowen ratio
   measurements, and residual water balance analyses for an area of 3
   million ha. The accuracy of assessing time- integrated actual annual
   evapotranspiration varied from 0\% to 10\% on a field scale to 5\% at
   the regional level. Spatiotemporal information on actual
   evapotranspiration helps to evaluate water distribution and water use
   between large irrigation project areas. Wide variations in evaporative
   depletion between project areas and crop types were found. Satellite-
   based measurements can provide such information and avoid the need to
   rely on field databases.}},
DOI = {{10.1029/2001WR000386}},
Article-Number = {{1273}},
ISSN = {{0043-1397}},
ResearcherID-Numbers = {{Ahmad, Mobin-ud-Din/A-1721-2012}},
ORCID-Numbers = {{Ahmad, Mobin-ud-Din/0000-0002-2905-5991}},
Unique-ID = {{ISI:000181020800001}},
}

@article{ ISI:000178793700008,
Author = {Farooqi, IS and Matarese, G and Lord, GM and Keogh, JM and Lawrence, E
   and Agwu, C and Sanna, V and Jebb, SA and Perna, F and Fontana, S and
   Lechler, RI and DePaoli, AM and O'Rahilly, S},
Title = {{Beneficial effects of leptin on obesity, T cell hyporesponsiveness, and
   neuroendocrine/metabolic dysfunction of human congenital leptin
   deficiency}},
Journal = {{JOURNAL OF CLINICAL INVESTIGATION}},
Year = {{2002}},
Volume = {{110}},
Number = {{8}},
Pages = {{1093-1103}},
Month = {{OCT}},
Abstract = {{The wide range of phenotypic abnormalities seen in the leptin-deficient
   ob/ob mouse and their reversibility by leptin administration provide
   compelling evidence for the existence,of multiple physiological
   functions of this hormone in rodents. In contrast, information regarding
   the roles of this hormone in humans is limited. Three morbidly obese
   children, who were congenitally deficient in leptin, were treated with
   daily subcutaneous injections of recombinant human leptin for up to 4
   years with sustained, beneficial effects on appetite, fat mass,
   hyperinsulinemia, and hyperlipidemia. Leptin therapy resulted in a rapid
   and sustained increase in plasma thyroid hormone levels and, through its
   age-dependent effects on gonadotropin secretion, facilitated
   appropriately timed pubertal development. Leptin deficiency was
   associated with reduced numbers of circulating CD4(+) T cells and
   impaired T cell proliferation and cytokine release, all of which were
   reversed by recombinant human leptin administration. The subcutaneous
   administration of recombinant human leptin has major and sustained
   beneficial effects on the multiple phenotypic abnormalities associated
   with congenital human leptin deficiency.}},
DOI = {{10.1172/JCI200215693}},
ISSN = {{0021-9738}},
ResearcherID-Numbers = {{Lord, Graham/B-3797-2011}},
Unique-ID = {{ISI:000178793700008}},
}

@article{ ISI:000178269900001,
Author = {Krause, F and Decanio, SJ and Hoerner, JA and Baer, P},
Title = {{Cutting carbon emissions at a profit (part I): Opportunities for the
   United States}},
Journal = {{CONTEMPORARY ECONOMIC POLICY}},
Year = {{2002}},
Volume = {{20}},
Number = {{4}},
Pages = {{339-365}},
Month = {{OCT}},
Abstract = {{This article identifies and corrects shortcomings in recent modeling
   studies on the economics of reducing greenhouse gas emissions in the
   United States. The major assessments of the Kyoto Protocol-by the U.S.
   Energy Information Administration, the Clinton White House Council of
   Economic Advisers, the U.S. Department Of Energy Interlaboratory Working
   Group, and the Stanford Energy Modeling Forum-are found to be seriously
   incomplete. Each study omits one or several of four major cost-reducing
   policy, options, resulting in cost estimates that are far too
   pessimistic.
   In the present study, these shortcomings are overcome through the
   integrated evaluation of all major cost-cutting policy options within a
   coherent least-cost framework. Three domestic policies-a national carbon
   cap and permit trading program, productivity-enhancing market reforms
   and technology programs, and recycling of permit auction revenues into
   economically advantageous tax cuts-are combined with international
   emissions allowance trading.
   This analysis shows that an integrated least-cost strategy for
   mitigating US. greenhouse gas emissions would produce an annual net
   output gain of roughly 0.4\% of GDP in 2010 and about 0.9\% of GDP in
   2020. On a cumulative net present value basis, the United States would
   gain \$250 billion by 2010 and \$600 billion by 2020. International
   flexibility, mechanisms (including emissions trading) are of only
   secondary significance in realizing these productivity, output, and
   welfare gains.}},
DOI = {{10.1093/cep/20.4.339}},
ISSN = {{1074-3529}},
Unique-ID = {{ISI:000178269900001}},
}

@article{ ISI:000171496500001,
Author = {Gately, D},
Title = {{How plausible is the consensus projection of oil below \$25 and Persian
   Gulf oil capacity and output doubling by 2020?}},
Journal = {{ENERGY JOURNAL}},
Year = {{2001}},
Volume = {{22}},
Number = {{4}},
Pages = {{1-27}},
Abstract = {{A two-part consensus in three recent long-term projections of the world
   oil market states: oil's price will stay below \$25 (1999 \$/barrel),
   and OPEC oil capacity and production will increase rapidly over the next
   two decades to unprecedented levels, more than doubling in the Persian
   Gulf by 2020. Such are the projections by the International Energy
   Agency (IEA), by the Energy Information Administration of the U.S.
   Department of Energy (DOE), and in The New Economy of Oil by John
   Mitchell and others. Yet such projections are not based on behavioral
   analysis of Gulf countries' decisions; they are merely the calculated
   residual demand for OPEC oil, the difference between projected world oil
   demand and non-OPEC supply, given some assumed price-path. Such
   projections by IEA and DOE are implausible because they rely on supply
   behavior by Gulf producers that is not in their own self-interest. The
   DOE projections of world oil prices could be reasonable, but only if
   world oil demand and/or non-OPEC supply are much more price-responsive
   than are represented in their numerical projections. Using an updated
   version of the model from Gately (1995), I show that the effect of
   greater price-responsiveness is to make faster output growth - not
   higher prices - the reliable path to higher OPEC revenue. I also
   demonstrate the effects of uncertainty about several key parameters
   (such as price and income elasticities) upon model results when
   parameter values are randomly sampled 500 times.}},
ISSN = {{0195-6574}},
Unique-ID = {{ISI:000171496500001}},
}

@article{ ISI:000087709000024,
Author = {Miller, SJ and Dunham, GE and Olson, ES and Brown, TD},
Title = {{Flue gas effects on a carbon-based mercury sorbent}},
Journal = {{FUEL PROCESSING TECHNOLOGY}},
Year = {{2000}},
Volume = {{65}},
Pages = {{343-363}},
Month = {{JUN}},
Note = {{Conference on Air Quality - Mercury, Trace Elements, and Particulate
   Matter, MCLEAN, VIRGINIA, DEC 01-04, 1998}},
Organization = {{Univ N Dakota, Energy \& Environm Res Ctr; EERC Ctr Air Toxic Metals; US
   EPA; Natl Ctr Environm Res \& Quality Assurance; US DOE, Natl Energy
   Technol Lab}},
Abstract = {{Coal is now the primary source of anthropogenic mercury emissions in the
   United States, accounting for 46\%, or 72 tons/year, of the total U.S.
   Environmental Protection Agency (EPA) estimated 158 tons/year {[}U.S.
   Environmental Protection Agency, Mercury Study Report to Congress,
   EPA/600/P-94/002Aa, External Review Draft, Jan. 1995.]. Development of
   cost-effective mercury control for coal-fired boilers is a primary
   research need identified in the EPA Mercury Study Report to Congress
   {[}U.S. Environmental Protection Agency, Mercury Study Report to
   Congress, EPA/600/P-94/002Aa, External Review Draft, Jan. 1995.]. During
   combustion of mercury-containing fuels such as coal, the mercury is
   completely volatilized and is not controlled by conventional particulate
   control devices unless the solid material effectively traps the mercury
   through sorption mechanisms. Typically, this does not occur naturally to
   a significant degree by the collected ash material. However, a promising
   approach for mercury control is the injection of an effective sorbent
   upstream of the particulate control device. Since the amount of mercury
   in the gas stream from coal combustion is usually in the range of 5 to
   10 mu g/m(3) (about 1 ppbv), only very small amounts of a sorbent may be
   necessary. A requirement is that the mercury be tightly bound in the
   sorbent, not desorbing upon exposure to ambient air or leaching under
   wet disposal conditions. On a worldwide basis, the projected increase in
   coal usage over the next two decades in China, India, and Indonesia will
   dwarf the current U.S. coal consumption of 1 billion tons/year
   {[}International Energy Outlook, U.S. Department of Energy, Energy
   Information Administration, Office of Integrated Analysis and
   Forecasting, Washington, DC, April 1998, DOE/EIA-0484(98).]. Therefore,
   in the United States, coal will be the dominant source of mercury
   emissions, and worldwide, coal may be the cause of significantly
   increased mercury emissions unless an effective control strategy is
   implemented. However, there is much uncertainty over the most
   technically sound and cost-effective approach for reducing mercury
   emissions from coal-fired boilers. (C) 2000 Elsevier Science B.V. All
   rights reserved.}},
DOI = {{10.1016/S0378-3820(99)00103-4}},
ISSN = {{0378-3820}},
Unique-ID = {{ISI:000087709000024}},
}

@article{ ISI:000086614900001,
Author = {Barnett, SB and Ter Haar, GR and Ziskin, MC and Rott, HD and Duck, FA
   and Maeda, K},
Title = {{International recommendations and guidelines for the safe use of
   diagnostic ultrasound in medicine}},
Journal = {{ULTRASOUND IN MEDICINE AND BIOLOGY}},
Year = {{2000}},
Volume = {{26}},
Number = {{3}},
Pages = {{355-366}},
Month = {{MAR}},
Abstract = {{Modern sophisticated ultrasonographic equipment is capable of delivering
   substantial levels of acoustic energy into the body when used at maximum
   outputs. The risk of producing bioeffects has been studied by
   international expert groups during symposia supported by the World
   Federation for Ultrasound in Medicine and Biology (WFUMB), These have
   resulted in the publication of internationally accepted conclusions and
   recommendations, National ultrasound safety committees have published
   guidelines as well. These recommendations and safety guidelines offer
   valuable information to help users apply diagnostic ultrasound in a safe
   and effective manner. Acoustic output from ultrasound medical devices is
   directly regulated only in the USA and this is done by the Food and Drug
   Administration (FDA), However, there is also a modern trend towards
   self-regulation which has implications for the worldwide use of
   diagnostic ultrasound. It has resulted in a move away from the
   relatively simple scheme of FDA-enforced, application-specific limits
   can acoustic output to a scheme whereby risk of adverse effects of
   ultrasound exposure is assessed from information provided by the
   equipment in the form of a real-time display of safety indices. Under
   this option, the FDA allows a relaxation of some intensity Limits,
   specifically approving the use of medical ultrasound devices that can
   expose the fetus or embryo to nearly eight times the intensity that was
   previously allowed. The shift of responsibility for risk assessment from
   a regulatory authority to the user creates an urgent need for awareness
   of risk and the development of knowledgeable and responsible attitudes
   to safety issues, To encourage this approach, it is encumbent on
   authorities, ultrasound societies and expert groups to provide relevant
   information on biological effects that might result from
   ultrasonographic procedures. It is obvious from the continued stream of
   enquiries received by ultrasound societies that effective dissemination
   of such knowledge requires sustained strenuous effort on the part of
   ultrasound safety committees. There is a strong need for continuing
   education to ensure that appropriate risk/benefit assessments are made
   by users based on an appropriate knowledge of the probability of
   biological effects occurring with each type of ultrasound procedure. The
   primary purpose of this paper is to draw attention to current safety
   guidelines and show the similarities and areas of general agreement with
   those issued by the parent ultrasound organisation, the WFUMB. It is
   equally important to identify gaps in our knowledge, where applicable.
   (C) 2000 World Federation for Ultrasound in Medicine \& Biology.}},
DOI = {{10.1016/S0301-5629(00)00204-0}},
ISSN = {{0301-5629}},
Unique-ID = {{ISI:000086614900001}},
}

@article{ ISI:000083584700006,
Author = {Brown, BW and Hollander, M},
Title = {{A conversation with Lincoln E. Moses}},
Journal = {{STATISTICAL SCIENCE}},
Year = {{1999}},
Volume = {{14}},
Number = {{3}},
Pages = {{338-354}},
Month = {{AUG}},
Abstract = {{Lincoln E. Moses was born on December 21, 1921 in Kansas City, Missouri.
   He attended San Bernardino Valley Junior College from 1937 to 1939 and
   earned an AA degree, earned an A.B. in Social Sciences from Stanford
   University in 1941 and a Ph.D. in Statistics from Stanford University in
   1950. He was Assistant Professor of Education at Teacher's College,
   Columbia University (1950-1952), Assistant Professor of Statistics in
   the Department of Statistics and the Department of Preventive Medicine,
   Stanford University (1952-1955), Associate professor in those
   departments from 1955 to 1959, and Professor of Statistics in the
   Department of Statistics and the Department of Research and Health
   Policy, Stanford University from 1959 until his retirement in 1992. He
   is now Professor Emeritus. He was Executive Head of the Department of
   Statistics at Stanford from 1964 to 1968. He served as Associate Dean,
   Humanities and Sciences, Stanford University (1965-1968 and 1985-1986)
   and Dean of Graduate Studies, Stanford University, 1969-1975. He was
   Administrator, Energy Information Administration, Department of Energy,
   1978-1980 after being appointed by President Carter in 1977. His many
   recognitions and honors include being Fellow, John Simon Guggenheim
   Memorial Foundation, 1960-1961, L. L. Thurstone Distinguished Fellow,
   University of North Carolina, 1968-1969, Fellow, Center for Advanced
   Study in the Behavioral Sciences, 1975-1976. He is a Fellow of the
   Institute of Mathematical Statistics, a Fellow of the American
   Statistical Association, an elected member of the International
   Statistical Institute, a Fellow of the American Association for the
   Advancement of Science, a Fellow of the American Academy of Arts and
   Sciences, a member of Phi Beta Kappa and a member of the Institute of
   Medicine. In 1980 he received the Distinguished Service Medal of the
   U.S. Department of Energy.}},
ISSN = {{0883-4237}},
Unique-ID = {{ISI:000083584700006}},
}

@article{ ISI:000083169400006,
Author = {Yamamura, N and Magata, Y and Yamashita, F and Hashida, M and Saji, H},
Title = {{Pharmacokinetic analysis of I-123-labeled medium chain fatty acid as a
   radiopharmaceutical for hepatic function based on beta-oxidation}},
Journal = {{ANNALS OF NUCLEAR MEDICINE}},
Year = {{1999}},
Volume = {{13}},
Number = {{4}},
Pages = {{235-239}},
Month = {{AUG}},
Abstract = {{Beta-oxidation is the most important pathway to provide energy for the
   liver. Our recent findings indicated that radiolabeled medium chain
   fatty acid analogs could be used as radiopharmaceuticals in the liver,
   allowing us to monitor alterations in energy metabolism on the cellular
   level. In the present study, pharmacokinetical analysis of a
   radioiodinated medium chain fatty acid analog,
   p-{[}I-123]iodophenylenanthic acid ({[}I-123]IPEA), was carried out in
   normal and hepatitis model rats to investigate the index for the
   measurement of beta-oxidation activity in hepatocytes. The rate constant
   for metabolism of {[}I-123]IPEA in the liver showed a strong correlation
   with the ATP level, which was determined as an indicator of
   beta-oxidation activity in hepatocytes. The radioactivity profile in the
   liver after {[}I-123]IPEA administration provided important information
   regarding hepatic viability, and the metabolic rate constant of
   {[}I-123]IPEA calculated by a pharmacokinetic method was a useful
   criterion for hepatic diagnosis based on hepatic cellular energy
   metabolism.}},
ISSN = {{0914-7187}},
Unique-ID = {{ISI:000083169400006}},
}

@article{ ISI:000077872100005,
Author = {Lyons, PC},
Title = {{The central and northern Appalachian Basin - a frontier region for
   coalbed methane development}},
Journal = {{INTERNATIONAL JOURNAL OF COAL GEOLOGY}},
Year = {{1998}},
Volume = {{38}},
Number = {{1-2}},
Pages = {{61-87}},
Month = {{DEC}},
Note = {{Symposium on Appalachian Coalbed Methane at the Joint Meeting of the
   American-Association-of-Petroleum-Geologists, Eastern
   Section/Society-of-Organic-Petrology, LEXINGTON, KENTUCKY, SEP 27-30,
   1997}},
Organization = {{Amer Assoc Petr Geologists, Eastern Sect; Soc Organ Petrol}},
Abstract = {{The Appalachian basin is the world's second largest coalbed-methane
   (CBM) producing basin. It has nearly 4000 wells with 1996 annual
   production at 147.8 billion cubic feet (Bcf). Cumulative CBM production
   is close to 0.9 trillion cubic feet (Tcf). The Black Warrior Basin of
   Alabama in the southern Appalachian basin (including a very minor amount
   from the Cahaba coal field) accounts for about 75\% of this annual
   production and about 75\% of the wells, and the remainder comes from the
   central and northern Appalachian basin. The Southwest Virginia coal
   field accounts for about 95\% of the production from the central and
   northern parts of the Appalachian basin. Production data and trends
   imply that several of the Appalachian basin states, except for Alabama
   and Virginia, are in their infancy with respect to CBM development.
   Total in-place CBM resources in the central and northern Appalachian
   basin have been variously estimated at 66 to 76 trillion cubic feet
   (Tcf), of which an estimated 14.55 Tcf (similar to 20\%) is technically
   recoverable according to a 1995 U.S. Geological Survey assessment. For
   comparison in the Black Warrior basin of the 20 Tcf in-place CBM
   resources, 2.30 Tcf (similar to 12\%) is technically recoverable.
   Because close to 0.9 Tcf of CBM has already been produced from the Black
   Warrior basin and the proved reserves are about 0.8 Tcf for 1996
   {[}Energy Information Administration (EIA), 1997]. U.S. Crude Oil,
   Natural Gas, and Natural Gas Liquids Reserves, 1996 Annual Report. U.S.
   Department of Energy DOE/EIA-0216(96), 145 pp.], these data imply that
   the central and northern Appalachian basin could become increasingly
   important in the Appalachian basin CBM picture as CBM resources are
   depleted in the southern Appalachian basin (Black Warrior Basin and
   Cahaba Coal Field). CBM development in the Appalachian states could
   decrease the eastern U.S.A.'s dependence on coal for electricity. CBM is
   expected to provide over the next few decades a virtually untapped
   source of unconventional fossil fuel in the Appalachian states, where
   the CBM resources are large and the demand for cleaner fossil-fuel
   energy is high. (C) 1998 Elsevier Science B.V. All rights reserved.}},
DOI = {{10.1016/S0166-5162(98)00033-0}},
ISSN = {{0166-5162}},
Unique-ID = {{ISI:000077872100005}},
}

@article{ ISI:000074045000023,
Author = {Gribbon, AP},
Title = {{Field test of nonintrusive traffic detection technologies}},
Journal = {{MATHEMATICAL AND COMPUTER MODELLING}},
Year = {{1998}},
Volume = {{27}},
Number = {{9-11}},
Pages = {{349-352}},
Month = {{MAY-JUN}},
Abstract = {{Accurate, low-cost methods of collecting historical traffic information
   are essential in making well-informed transportation planning decisions.
   In addition, detection of real-time traffic conditions is a key element
   in advanced traffic management and traveler information systems. Until
   the last decade,inductive loop detectors; pneumatic road tubes, and
   temporary manual counts were the primary methods for collecting both
   real-time and historical traffic data. However, technological
   innovations have given rise to design many different types of advanced
   traffic detectors. Recently developed traffic detectors use sonic,
   ultrasonic, microwave, or infrared energy. Most of these detectors can
   be mounted overhead or to the side of traffic lanes. Magnetic sensors
   are now being built in sizes small enough to be placed in conduits under
   the roadway. Artificial intelligence algorithms can process videotaped
   images of road scenes and output many useful traffic parameters.
   Even though nonintrusive technologies have been available for several
   years, there are still many uncertainties regarding their use. Traffic
   engineers lack a comprehensive comparison of the various types of
   traffic detection technology A study conducted by the Minnesota
   Department of Transportation (Mn/DOT) and SRF Consulting Group, Inc.
   (SRF) and sponsored by the Federal Highway Administration (FHWA) seeks
   to address this need.
   Mn/DOT and SRF undertook a two-year effort to test a wide variety of
   nonintrusive traffic detection technologies. The purpose of this
   evaluation was to collect practical information on the performance,
   installation requirements, long-term maintenance requirements, and costs
   of various types of nonintrusive traffic detection technologies. More
   than a dozen devices representing mag netic, sonic, ultrasonic,
   microwave, infrared, and video image processing technologies were
   evaluated during this project. Devices were evaluated for their
   performance in both freeway and urban intersection monitoring
   situations.
   Testing consisted of two phases. During Phase I, which ran from November
   1995 to January 1996, all participating devices measured traffic data on
   three lanes of Interstate 394 in Minneapolis at the Penn Avenue
   interchange. Phase Ii, which ran from February to November 1996,
   consisted of an all-season monitoring of the devices' performance and
   maintenance requirements and involved both freeway and intersection
   installations. The Minneapolis-St. Paul metropolitan area provided an
   excellent opportunity to evaluate the devices in many types of weather
   extremes, including very cold and very hot temperatures, rain, snow,
   fog, and high winds. (C) 1998 Elsevier Science Ltd. All rights reserved.}},
DOI = {{10.1016/S0895-7177(98)00069-7}},
ISSN = {{0895-7177}},
Unique-ID = {{ISI:000074045000023}},
}

@article{ ISI:A1997YJ55500012,
Author = {Straus, DM and Yang, QL},
Title = {{Vertical structure and dominant horizontal scales of baroclinic waves in
   the NASA DAO and NCEP reanalyses}},
Journal = {{MONTHLY WEATHER REVIEW}},
Year = {{1997}},
Volume = {{125}},
Number = {{12}},
Pages = {{3266-3278}},
Month = {{DEC}},
Abstract = {{The reanalyses of the Data Assimilation Office (DAO) of the National
   Aeronautics and Space Administration (NASA) are compared to those of the
   National Centers for Environmental Prediction (NCEP) with regard to the
   vertical structure and important horizontal scales of the baroclinic
   transients. Attention is focused on the eight Northern Hemisphere
   winters of 1985/86-1992/93 and on (bandpass) transients of timescales
   2-8 days.
   The local seasonal mean vertical shear (normalized by the square root of
   the static stability) is very similar between the two sets of analyses.
   The upper-level vorticity gradient (dominated by the meridional
   derivative) also shows little sensitivity to which reanalysis is used.
   The condition for barotropic instability (change of sign of total
   vorticity gradient) is satisfied.
   The vertical structure of bandpass kinetic energy, meridional sensible
   heat Bur, and variance of temperature gradient all show consistent
   differences between the NCEP and NASA reanalyses, with the NCEP signal
   significantly stronger at upper levels. The difference is modest for the
   kinetic energy (similar to 10\%) and is much stronger for the heat flux
   (similar to 100\%) and the variance of temperature gradient (similar to
   70\%). The NCEP reanalyses also have a stronger midlevel temperature
   gradient variance by about 20\%. The differences in this quantity
   reflect the treatment of the National Environmental Satellite, Data, and
   Information Service (NESDIS) operational retrievals used by both
   reanalyses, and these satellite data affect the NASA reanalyses more
   strongly.
   There are significant differences in the synoptic waves. The positive
   difference between the 300-hPa bandpass kinetic energy (NCEP minus NASA)
   as a function of the global wave number used to truncate the fields
   reaches nearly half (two-thirds) its total value by wavenumber 15 in the
   eastern Pacific (Atlantic). For the 200-hPa sensible heat flux the
   difference is a maximum at wavenumber 10 over the whole midlatitude
   belt.
   Differences in midlevel temperature gradient variance between the first
   three winters (using NESDIS statistical retrievals) and the last five
   winters (using NESDIS physically based retrievals) include (i) NASA
   deficit compared to NCEP is slightly greater in the latter period and
   (ii) NASA variance is nearly 20\% less in the latter period over the
   Pacific.}},
DOI = {{10.1175/1520-0493(1997)125<3266:VSADHS>2.0.CO;2}},
ISSN = {{0027-0644}},
Unique-ID = {{ISI:A1997YJ55500012}},
}

@inproceedings{ ISI:000072079000608,
Author = {Guerrero, J and Chorro, FJ and Martinez, M and Calpe, J and Soria, E and
   Espi, J},
Editor = {{Boom, H and Robinson, C and Rutten, W and Neuman, M and Wijkstra, H}},
Title = {{Spectral analysis of ventricular fibrillation: Validation of an
   experimental model.}},
Booktitle = {{PROCEEDINGS OF THE 18TH ANNUAL INTERNATIONAL CONFERENCE OF THE IEEE
   ENGINEERING IN MEDICINE AND BIOLOGY SOCIETY, VOL 18, PTS 1-5}},
Series = {{PROCEEDINGS OF THE ANNUAL INTERNATIONAL CONFERENCE OF THE IEEE
   ENGINEERING IN MEDICINE AND BIOLOGY SOCIETY}},
Year = {{1997}},
Volume = {{18}},
Pages = {{1258-1259}},
Note = {{18th Annual International Conference of IEEE
   Engineering-in-Medicine-amd-Biology-Society, AMSTERDAM, NETHERLANDS, OCT
   31-NOV 03, 1996}},
Organization = {{IEEE Engn Med \& Biol Soc}},
Abstract = {{The present study analyzes three aspects related to the Ventricular
   Fibrillation (VF): 1) Stability of the VF model using an isolated heart
   and maintaining perfusion; 2) Comparison among the information related
   to the spectral analysis of the VF signal given by different types and
   positioning of the electrodes during its stability; 3) Alterations in VF
   before its interruption provoked by administering ClK. The absolute
   (AAPM) and normalized (ANPM) amplitudes, the frequency for the maximum
   peak (FPM) and the energy contained in a band of +/-1 Hz around the FPM
   are analyzed for a group of 25 registers. The conclusions are: 1) VF
   stability in isolated heart; 2) similar information respect to the FPM
   and the energy is obtained for unipolar and bipolar, endo-and epicardial
   electrodes during stable VF; 3) Progressive reduction in the FPM is
   appreciated following the administration of ClK.}},
ISBN = {{0-7803-3812-X}},
ResearcherID-Numbers = {{GUERRERO, JUAN/L-9439-2014}},
ORCID-Numbers = {{GUERRERO, JUAN/0000-0001-6729-585X}},
Unique-ID = {{ISI:000072079000608}},
}

@article{ ISI:A1993KJ24700002,
Author = {PETERSON, FJ and PATTON, JE and MILLER, ME and GILLMAN, RA and WARWICK,
   WM and SANDUSKY, WF},
Title = {{END-USE LOAD AND CONSUMER ASSESSMENT PROGRAM - MOTIVATION AND OVERVIEW}},
Journal = {{ENERGY AND BUILDINGS}},
Year = {{1993}},
Volume = {{19}},
Number = {{3}},
Pages = {{159-166}},
Abstract = {{The End-Use Load and Consumer Assessment Program (ELCAP) was a major
   end-use data collection program undertaken by the Bonneville Power
   Administration from 1983 through 1990 to obtain specific information to
   support a variety of conservation and forecasting activities. The
   objectives of the program were to test key assumptions used in current
   engineering and forecasting models, provide insights regarding how
   various factors affect energy consumption, provide information to
   support load management conservation and marketing programs, and
   identify conservation resource potential from new demand-side
   technologies or programs. To accomplish this, a well-designed experiment
   was required that accounted for adequate representation of both existing
   and new buildings in the residential and commercial sector of the
   Pacific Northwest. This paper summarizes the motivations for obtaining
   the data, information regarding the sample, an overview of the analysis
   agenda, and specifics regarding the data set, both engineering and
   characteristics.}},
DOI = {{10.1016/0378-7788(93)90024-O}},
ISSN = {{0378-7788}},
Unique-ID = {{ISI:A1993KJ24700002}},
}

@article{ ISI:000314476300012,
Author = {Etzler, Frank M. and Uddin, Mohammad Nasir},
Title = {{Powder Technology and Pharmaceutical Development: Particle Size and
   Particle Adhesion}},
Journal = {{KONA POWDER AND PARTICLE JOURNAL}},
Year = {{2013}},
Number = {{30}},
Pages = {{125-143}},
Abstract = {{Both the FDA (U.S. Food and Drug Administration) and ICH (International
   Conference on Harmonisation) have urged the incorporation of Quality by
   Design (QbD)(1)) into the manufacture of pharmaceutical products(2)).
   The performance of many pharmaceutical manufacturing processes and the
   performance of some pharmaceutical products requires a knowledge of
   powder properties. Under the principles of QbD it is possible to adjust
   processes to account for variations in powder properties. These
   adjustments, in turn, require knowledge of the relation between powder
   properties and manufacturing performance. This relation between powder
   properties and performance is often not well understood; thus, the
   required information is not collected.
   In this paper, particle-particle and particle-surface interactions are
   considered to be a source of product variability. As particle size
   effects are intertwined with particle adhesion effects this topic is
   also considered. From the discussion below, it can be seen that the
   surface chemistry of particles can vary due to mechanical treatment,
   crystallization solvent, and surface contamination. Variations in
   surface chemistry affect interparticle adhesion and thus may lead to
   process or product performance changes. Issues concerning the role of
   interparticle adhesion that are related to tableting and dry powder
   inhalers are discussed in some detail.
   It is clear that a deeper understanding of the powder state and the
   establishment of appropriate analytical tools will be required to fully
   implement QbD. Improvements in particle sizing technologies,
   improvements powder sampling procedures and measurements of particle
   surface properties will be required. It is hoped that this paper will
   stimulate thought on this issue.}},
ISSN = {{0288-4534}},
Unique-ID = {{ISI:000314476300012}},
}

@article{ ISI:000306769700007,
Author = {Vlaardingerbroek, Hester and Veldhorst, Margriet A. B. and Spronk,
   Sandra and van den Akker, Chris H. P. and van Goudoever, Johannes B.},
Title = {{Parenteral lipid administration to very-low-birth-weight infants-early
   introduction of lipids and use of new lipid emulsions: a systematic
   review and meta-analysis}},
Journal = {{AMERICAN JOURNAL OF CLINICAL NUTRITION}},
Year = {{2012}},
Volume = {{96}},
Number = {{2}},
Pages = {{255-268}},
Month = {{AUG}},
Abstract = {{Background: The use of intravenous lipid emulsions in preterm infants
   has been limited by concerns regarding impaired lipid tolerance. As a
   result, the time of initiation of parenteral lipid infusion to
   very-low-birth-weight (VLBW) infants varies widely among different
   neonatal intensive care units. However, lipids provide energy for
   protein synthesis and supply essential fatty acids that are necessary
   for central nervous system development.
   Objective: The objective was to summarize the effects of initiation of
   lipids within the first 2 d of life and the effects of different lipid
   compositions on growth and morbidities in VLBW infants.
   Design: A systematic review and meta-analysis of publications identified
   in a search of PubMed, EMBASE, and Cochrane databases was undertaken.
   Randomized controlled studies were eligible if information on growth was
   available.
   Results: The search yielded 14 studies. No differences were observed in
   growth or morbidity with early lipid initiation. We found a weak
   favorable association of non-purely soybean-based emulsions with the
   incidence of sepsis (RR: 0.75; 95\% CI: 0.56, 1.00).
   Conclusions: The initiation of lipids within the first 2 d of life in
   VLBW infants appears to be safe and well tolerated; however, beneficial
   effects on growth could not be shown for this treatment nor for the type
   of lipid emulsion. Emulsions that are not purely soybean oil-based might
   be associated with a lower incidence of sepsis. Large-scale randomized
   controlled trials in preterm infants are warranted to determine whether
   early initiation of lipids and lipid emulsions that are not purely
   soybean oil-based results in improved long-term outcomes. Am J Clin Nutr
   2012;96:255-68.}},
DOI = {{10.3945/ajcn.112.040717}},
ISSN = {{0002-9165}},
EISSN = {{1938-3207}},
ORCID-Numbers = {{van den Akker, Chris/0000-0002-8907-2734}},
Unique-ID = {{ISI:000306769700007}},
}

@article{ ISI:000249231400020,
Author = {Tachibana, Tetsuya and Oikawa, Daichi and Adachi, Nami and Boswell, Tim
   and Furuse, Mitsuhiro},
Title = {{Central administration of alpha-melanocyte-stimulating hormone changes
   lipid metabolism in chicks}},
Journal = {{COMPARATIVE BIOCHEMISTRY AND PHYSIOLOGY A-MOLECULAR \& INTEGRATIVE
   PHYSIOLOGY}},
Year = {{2007}},
Volume = {{148}},
Number = {{2}},
Pages = {{408-412}},
Month = {{OCT}},
Abstract = {{Alpha-melanocyte-stimulating hormone (MSH) is well known as an
   anorexigenic peptide in the brain of mammals. In addition to this, brain
   alpha-MSH enhances heat production (HP), indicating that the peptide
   acts as a catabolic factor in the regulation of energy metabolism. The
   anorexigenic effect of alpha-MSH is also observed in chicks (Gallus
   gallus), but no information has been available for its effect on HP. The
   present study was performed to examine whether intracerebroventricular
   (ICV) injection of alpha-MSH increases HP in chicks. The injection of
   alpha-MSH (10 and 100 pmol) did not affect oxygen consumption, carbon
   dioxide production and HP during the I h post-injection period. This
   result was supported by another result that ICV injection of alpha-MSH
   did not affect locomotion activity in chicks. In contrast, the
   respiratory quotient was significantly lowered by the ICV injection of
   MSH. We also found that alpha-MSH significantly increased plasma
   non-esterified fatty acid concentrations. In summary, brain alpha-MSH
   appears to exert generally catabolic effects on lipid metabolism in the
   chick, but does not appear to be involved in the regulation of HP. (c)
   2007 Elsevier Inc. All rights reserved.}},
DOI = {{10.1016/j.cbpa.2007.05.023}},
ISSN = {{1095-6433}},
Unique-ID = {{ISI:000249231400020}},
}

@article{ ISI:000237839000017,
Author = {Matsuda, K and Shimakura, S and Maruyama, K and Miura, T and Uchiyama, M
   and Kawauchi, H and Shioda, S and Takahashi, A},
Title = {{Central administration of melanin-concentrating hormone (MCH) suppresses
   food intake, but not locomotor activity, in the goldfish, Carassius
   auratus}},
Journal = {{NEUROSCIENCE LETTERS}},
Year = {{2006}},
Volume = {{399}},
Number = {{3}},
Pages = {{259-263}},
Month = {{MAY 22}},
Abstract = {{Melanin-concentrating hormone (MCH) is a hypothalamo-pituitary peptide,
   which was first identified in the salmon pituitary as a hormone
   affecting body color. Recently, MCH has been implicated in the
   regulation of feeding behavior and energy homeostasis in mammals.
   Despite a growing body of knowledge concerning MCH in mammals, however,
   there is little information about the effect of MCH on appetite and
   behavior in fish. The aim of the present study was to investigate the
   action of MCH on feeding behavior and spontaneous loconnotor activity in
   the goldfish. We administered synthetic MCH by intracerebroventricular
   (ICV) injection and examined its effect on food intake and locomotor
   activity using an automatic monitoring system. Both types of synthetic
   MCH we employed, which are of fish and human origin, were effective in
   stimulating aggregation of melanin granules in the melanophores of
   goldfish scales. Cumulative food intake was significantly decreased by
   ICV injection of both MCHs in a dose-dependent manner. ICV injection of
   fish MCH at the same doses as those used for examination of food intake
   induced no marked changes in locomotor activity during the observation
   period. These results suggest that MCH influences feeding behavior, but
   not spontaneous locomotor activity, in the goldfish, and may exert an
   anorexigenic action in the goldfish brain, unlike its orexigenic action
   in mammals. (c) 2006 Elsevier Ireland Ltd. All rights reserved.}},
DOI = {{10.1016/j.neulet.2006.02.005}},
ISSN = {{0304-3940}},
Unique-ID = {{ISI:000237839000017}},
}

@article{ ISI:000359995500050,
Author = {Chiroma, Haruna and Abdul-kareem, Sameem and Khan, Abdullah and Nawi,
   Nazri Mohd and Gital, Abdulsalam Ya'u and Shuib, Liyana and Abubakar,
   Adamu I. and Rahman, Muhammad Zubair and Herawan, Tutut},
Title = {{Global Warming: Predicting OPEC Carbon Dioxide Emissions from Petroleum
   Consumption Using Neural Network and Hybrid Cuckoo Search Algorithm}},
Journal = {{PLOS ONE}},
Year = {{2015}},
Volume = {{10}},
Number = {{8}},
Month = {{AUG 25}},
Abstract = {{Background
   Global warming is attracting attention from policy makers due to its
   impacts such as floods, extreme weather, increases in temperature by 0.7
   degrees C, heat waves, storms, etc. These disasters result in loss of
   human life and billions of dollars in property. Global warming is
   believed to be caused by the emissions of greenhouse gases due to human
   activities including the emissions of carbon dioxide (CO2) from
   petroleum consumption. Limitations of the previous methods of predicting
   CO2 emissions and lack of work on the prediction of the Organization of
   the Petroleum Exporting Countries (OPEC) CO2 emissions from petroleum
   consumption have motivated this research.
   Methods/Findings
   The OPEC CO2 emissions data were collected from the Energy Information
   Administration. Artificial Neural Network (ANN) adaptability and
   performance motivated its choice for this study. To improve
   effectiveness of the ANN, the cuckoo search algorithm was hybridised
   with accelerated particle swarm optimisation for training the ANN to
   build a model for the prediction of OPEC CO2 emissions. The proposed
   model predicts OPEC CO2 emissions for 3, 6, 9, 12 and 16 years with an
   improved accuracy and speed over the state-of-the-art methods.
   Conclusion
   An accurate prediction of OPEC CO2 emissions can serve as a reference
   point for propagating the reorganisation of economic development in OPEC
   member countries with the view of reducing CO2 emissions to Kyoto
   benchmarks-hence, reducing global warming. The policy implications are
   discussed in the paper.}},
DOI = {{10.1371/journal.pone.0136140}},
Article-Number = {{e0136140}},
ISSN = {{1932-6203}},
ResearcherID-Numbers = {{Abdul Kareem, Sameem/B-2259-2009
   Chiroma, Haruna/}},
ORCID-Numbers = {{Abdul Kareem, Sameem/0000-0001-5177-8013
   Chiroma, Haruna/0000-0003-3446-4316}},
Unique-ID = {{ISI:000359995500050}},
}

@article{ ISI:000358557900005,
Author = {Gingerich, Daniel B. and Mauter, Meagan S.},
Title = {{Quantity, Quality, and Availability of Waste Heat from United States
   Thermal Power Generation}},
Journal = {{ENVIRONMENTAL SCIENCE \& TECHNOLOGY}},
Year = {{2015}},
Volume = {{49}},
Number = {{14}},
Pages = {{8297-8306}},
Month = {{JUL 21}},
Abstract = {{Secondary application of unconverted heat produced during electric power
   generation has the potential to improve the life-cycle fuel efficiency
   of the electric power industry and the sectors it serves. This work
   quantifies the residual heat (also known as waste heat) generated by
   U.S. thermal power plants and assesses the intermittency and transport
   issues that must be considered when planning to utilize this heat.
   Combining Energy Information Administration plant-level data with
   literature-reported process efficiency data, we develop estimates of the
   unconverted heat flux from individual U.S. thermal power plants in 2012.
   Together these power plants discharged an estimated 18.9 billion GJth of
   residual heat in 2012, 4\% of which was discharged at temperatures
   greater than 90 degrees C. We also characterize the temperature, spatial
   distribution, and temporal availability of this residual heat at the
   plant level and model the implications for the technical and economic
   feasibility of its end use. Increased implementation of flue gas
   desulfurization technologies at coal-fired facilities and the higher
   quality heat generated in the exhaust of natural gas fuel cycles are
   expected to increase the availability of residual heat generated by
   10.6\% in 2040.}},
DOI = {{10.1021/es5060989}},
ISSN = {{0013-936X}},
EISSN = {{1520-5851}},
ORCID-Numbers = {{Gingerich, Daniel/0000-0002-1406-6620
   Mauter, Meagan/0000-0002-4932-890X}},
Unique-ID = {{ISI:000358557900005}},
}

@article{ ISI:000356180600006,
Author = {Thompson, Frances E. and Dixit-Joshi, Sujata and Potischman, Nancy and
   Dodd, Kevin W. and Kirkpatrick, Sharon I. and Kushi, Lawrence H. and
   Alexander, Gwen L. and Coleman, Laura A. and Zimmerman, Thea P. and
   Sundaram, Maria E. and Clancy, Heather A. and Groesbeck, Michelle and
   Douglass, Deirdre and George, Stephanie M. and Schap, TusaRebecca E. and
   Subar, Amy F.},
Title = {{Comparison of Interviewer-Administered and Automated Self-Administered
   24-Hour Dietary Recalls in 3 Diverse Integrated Health Systems}},
Journal = {{AMERICAN JOURNAL OF EPIDEMIOLOGY}},
Year = {{2015}},
Volume = {{181}},
Number = {{12}},
Pages = {{970-978}},
Month = {{JUN 15}},
Abstract = {{Twenty-four-hour dietary recalls provide high-quality intake data but
   have been prohibitively expensive for large epidemiologic studies. This
   study's goal was to assess whether the web-based Automated
   Self-Administered 24-Hour Recall (ASA24) performs similarly enough to
   the standard interviewer-administered, Automated Multiple-Pass Method
   (AMPM) 24-hour dietary recall to be considered a viable alternative. In
   2010-2011, 1,081 adults from 3 integrated health systems in Detroit,
   Michigan; Marshfield, Wisconsin; and Kaiser-Permanente Northern
   California participated in a field trial. A quota design ensured a
   diverse sample by sex, age, and race/ethnicity. Each participant was
   asked to complete 2 recalls and was randomly assigned to 1 of 4
   protocols differing by type of recall and administration order. For
   energy, the mean intakes were 2,425 versus 2,374 kcal for men and 1,876
   versus 1,906 kcal for women by AMPM and ASA24, respectively. Of 20
   nutrients/food groups analyzed and controlling for false discovery rate,
   87\% were judged equivalent at the 20\% bound. ASA24 was preferred over
   AMPM by 70\% of the respondents. Attrition was lower in the ASA24/AMPM
   study group than in the AMPM/ASA24 group, and it was lower in the
   ASA24/ASA24 group than in the AMPM/AMPM group. ASA24 offers the
   potential to collect high-quality dietary intake information at low cost
   with less attrition.}},
DOI = {{10.1093/aje/kwu467}},
ISSN = {{0002-9262}},
EISSN = {{1476-6256}},
Unique-ID = {{ISI:000356180600006}},
}

@article{ ISI:000347362400007,
Author = {Lee, Sin Ji and Bose, Shambhunath and Seo, Jae-Gu and Chung, Won-Seok
   and Lim, Chi-Yeon and Kim, Hojun},
Title = {{The effects of co-administration of probiotics with herbal medicine on
   obesity, metabolic endotoxemia and dysbiosis: A randomized double-blind
   controlled clinical trial}},
Journal = {{CLINICAL NUTRITION}},
Year = {{2014}},
Volume = {{33}},
Number = {{6}},
Pages = {{973-981}},
Month = {{DEC}},
Abstract = {{Background \& aims: Probiotics help maintain balance in composition of
   the gut microbiota, and have been considered as a potential treatment
   for obesity. This study was conducted in order to assess the effects of
   probiotics when combined with herbal medicine in treatment of obesity.
   Probiotics were tested for the ability to modulate gut microbiota, gut
   permeability, and endotoxin level, which may have correlation with
   factors involved in obesity.
   Methods: A randomized, double-blind, placebo controlled study was
   conducted, in which patients with higher BMI (>25 kg/m(2)) and waist
   circumference (>85 cm) were enrolled and randomly assigned to receive
   Bofutsushosan with either probiotics or placebo capsules for a period of
   eight weeks. Assessment of body composition parameters, metabolic
   biomarkers, endotoxin level, gut permeability, and fecal bacteria in
   stool was performed at baseline and at week 8. The study was registered
   at the Clinical Research Information Service, approved by the Korea
   National Institute of Health (KCT0000386).
   Results: Although both groups showed a significant reduction in weight
   and waist circumference (p = 0.000), no significant differences in body
   composition and metabolic markers were observed. In correlation
   analysis, change in body composition showed positive correlation with
   endotoxin level (r = 0.441, p < 0.05 for BW; and r = 0.350, p < 0.05 for
   fat mass) and the population of gut Lactobacillus plantarum (r = 0.425,
   p < 0.05 for BW; and r = 0.407, p < 0.05 for BMI). The Gram negative
   bacterial population in gut also exhibited positive correlation with
   changes in body composition (WC) and total cholesterol level (r = 0.359,
   and 0.393, for the former and later parameters, respectively, p < 0.05
   for both). While, the profile of gut Bifidobacterium breve population
   showed negative correlation with endotoxin level (r = 0.350, p < 0.05).
   Conclusions: Correlations between gut microbiota and change in body
   composition indicate that probiotics may influence energy metabolism in
   obesity. Correlation between endotoxin level and weight reduction
   indicates that probiotics may play an important role in prevention of
   endotoxin production, which can lead to gut microbiota dysbiosis
   associated with obesity. (C) 2013 Elsevier Ltd and European Society for
   Clinical Nutrition and Metabolism. All rights reserved.}},
DOI = {{10.1016/j.clnu.2013.12.006}},
ISSN = {{0261-5614}},
EISSN = {{1532-1983}},
Unique-ID = {{ISI:000347362400007}},
}

@article{ ISI:000329325200057,
Author = {Dong, Jing and Xu, Huan and Xu, Huan and Wang, Peng-fei and Cai, Gui-ju
   and Song, Hai-feng and Wang, Chang-chen and Dong, Zhao-tong and Ju,
   Yan-jiao and Jiang, Zheng-yao},
Title = {{Nesfatin-1 Stimulates Fatty-Acid Oxidation by Activating AMP-Activated
   Protein Kinase in STZ-Induced Type 2 Diabetic Mice}},
Journal = {{PLOS ONE}},
Year = {{2013}},
Volume = {{8}},
Number = {{12}},
Month = {{DEC 31}},
Abstract = {{Nesfatin-1 is an anorexigenic peptide involved in energy homeostasis.
   Recently, nesfatin-1 was reported to decrease blood glucose level and
   improve insulin sensitivity in high-fat diet-fed rats. However, little
   information is known about the influence of nesfatin-1 on lipid
   metabolism either in physiological or diabetic condition. This study
   undertook whether nesfatin-1 was involved in the pathophysiology in
   Streptozotocin-induced type 2 diabetic mice (T2DM), which was induced by
   a combination of high-calorie diet and two low-doses Streptozotocin. We
   observed that plasma nesfatin-1 was significantly increased while
   expression of nesfatin-1 neurons were decreased in hypothalamus in
   diabetes group compared to only high-calorie diet control group;
   intravenous injection of nesfatin-1 decreased 0-1h, 0-2h, 0-3h
   cumulative food intake in T2DM, but 0-24h total food intake had no
   difference between groups. Body weight and plasma FFA were normalized
   after nesfatin-1(10 mu g/Kg) administration for 6 days. These results
   suggested that nesfatin-1 improved lipid disorder in T2DM. It was found
   that blood glucose and insulin resistance coefficient decreased with
   treatment of nesfatin-1 (both in 1 mu g/Kg and 10 mu g/Kg doses) in
   diabetes mice. For further understanding the role of nesfatin-1 on lipid
   metabolism, we detected p-AMPK and p-ACC of skeletal muscle in T2DM
   using western blotting. The expression of p-AMPK and p-ACC increased
   when nesfatin-1 was given with doses 1 mu g/Kg but not in doses 10 mu
   g/Kg. Taken together, nesfatin-1 participated in the development of T2DM
   and stimulated free fatty acid utilization via AMPK-ACC pathway in
   skeletal muscle in T2DM.}},
DOI = {{10.1371/journal.pone.0083397}},
Article-Number = {{e83397}},
ISSN = {{1932-6203}},
Unique-ID = {{ISI:000329325200057}},
}

@article{ ISI:000310397400003,
Author = {Vadivel, Vellingiri and Kunyanga, Catherine N. and Biesalski, Hans K.},
Title = {{Health benefits of nut consumption with special reference to body weight
   control}},
Journal = {{NUTRITION}},
Year = {{2012}},
Volume = {{28}},
Number = {{11-12}},
Pages = {{1089-1097}},
Month = {{NOV-DEC}},
Abstract = {{Nuts are an integral part of the Mediterranean food patterns, and their
   incorporation into the regular diets of human beings is believed to
   provide many health benefits. The recent recognition of nuts as
   ``heart-healthy{''} foods by the U.S. Food and Drug Administration has
   given a major boost to the positive image of nuts. Nut consumption has
   been associated with several health benefits, such as antioxidant,
   hypocholesterolemic, cardioprotective, anticancer, anti-inflammatory,
   and antidiabetic benefits, among other functional properties. However,
   although nuts possess these many health benefits, their consumption has
   been hampered by a lack of adequate information regarding those
   benefits. In addition, because nuts are energy-dense foods with high-fat
   content, there is a misconception among consumers that increased
   consumption may lead to unwanted gain in body weight with the risk of
   developing overweight/obesity. Nonetheless, available epidemiologic
   studies and short-term controlled feeding trials have supported the
   theory that the inclusion of nuts in the typical diet does not induce
   weight gain, despite an expected increase in total caloric intake. To
   address the misperception about nuts and body weight gain, the present
   review focuses mainly on the relation between nut consumption and body
   weight gain, in the context of the many health benefits of nuts. (C)
   2012 Elsevier Inc. All rights reserved.}},
DOI = {{10.1016/j.nut.2012.01.004}},
ISSN = {{0899-9007}},
Unique-ID = {{ISI:000310397400003}},
}

@article{ ISI:000306158000018,
Author = {Oshita, Yuko},
Title = {{Identifying critical supply chain paths that drive changes in CO2
   emissions}},
Journal = {{ENERGY ECONOMICS}},
Year = {{2012}},
Volume = {{34}},
Number = {{4}},
Pages = {{1041-1050}},
Month = {{JUL}},
Abstract = {{To address the problem of global warming, it is important to identify
   the supply chain paths that drive changes in life cycle CO2 emissions
   and provide both policy makers and decision makers with the information
   on the critical paths in order to efficiently reduce the CO2 emissions.
   In this article, I extract and analyze the factors and key supply chains
   involved in changes in CO2 emissions associated with Japan's overall
   demand from 1990 to 2000 using the Structural Path Decomposition (SPD)
   method applied to the 1990-1995-2000 linked Japanese environmental
   input-output tables at the four-digit commodity classification level.
   The results reveal that the volume of CO2 emissions increased as a
   result of changes in the input structure of the electricity of the
   services sector, such as ``electricity -> amusement and recreation
   facilities -> household demand{''}, ``electricity -> retail trade ->
   household demand{''} and ``electricity -> public administration (local)
   -> local government demand{''}, indicating increasing dependence of
   services on energy input. I also find that the final demand shift
   changed CO2 emissions, for example the rise in demand for integrated
   circuits in exports has contributed to increasing CO2 emissions
   generated from electricity, the fall in demand for frozen fish and
   shellfish in household demand has contributed to decreasing CO2
   emissions from marine fisheries. (C) 2011 Elsevier B.V. All rights
   reserved.}},
DOI = {{10.1016/j.eneco.2011.08.013}},
ISSN = {{0140-9883}},
Unique-ID = {{ISI:000306158000018}},
}

@article{ ISI:000296403200008,
Author = {Prvulovic, Slavica and Tolmac, Dragisa and Radovanovic, Ljiljana},
Title = {{Application of Promethee-Gaia Methodology in the Choice of Systems for
   Drying Paltry-Seeds and Powder Materials}},
Journal = {{STROJNISKI VESTNIK-JOURNAL OF MECHANICAL ENGINEERING}},
Year = {{2011}},
Volume = {{57}},
Number = {{10}},
Pages = {{778-784}},
Month = {{OCT}},
Abstract = {{This work deals with the application of Promethee-Gaia methodology and
   the choice of three systems for drying paltry-seeds and powder materials
   pneumatic driers, spiral driers and rotation driers with a drum with
   regard to five different criteria. The analysis is based on the
   Promethee I method, the Promethee II method and the Promethee-Gaia
   method, which withal shows a complex figure of the relation between
   alternatives and criteria in the Gala plane. In this work the
   application of Decision Lab program is shown, which was the basis in
   analysing results and ranking alternatives.
   The paper analyzes three different systems for drying. When choosing the
   system of drying the comparative analysis of five influential
   parameters, such as: the coefficient of heat transfer; price, drying
   energy, thermal usefulness, specific use of energy. Based on the
   analysis, the application of a pneumatic dryer is the cheapest, given
   the significant savings in cost, ie. investment cost and energy
   efficient. Next in order of the spiral dryer; and third in the rotation
   with a drum dryer, in terms of benefits administration. (C) 2011 Journal
   of Mechanical Engineering. All rights reserved.}},
DOI = {{10.5545/sv-jme.2008.068}},
ISSN = {{0039-2480}},
Unique-ID = {{ISI:000296403200008}},
}

@article{ ISI:000295674300040,
Author = {Bottino, Marcela and Cowett, Richard M. and Sinclair, John C.},
Title = {{Interventions for treatment of neonatal hyperglycemia in very low birth
   weight infants}},
Journal = {{COCHRANE DATABASE OF SYSTEMATIC REVIEWS}},
Year = {{2011}},
Number = {{10}},
Abstract = {{Background
   Early neonatal hyperglycemia is common among very lowbirthweight (VLBW)
   neonates. Increased risks for death and major morbidities have been
   observed among VLBW neonates who develop hyperglycemia. It is uncertain
   whether the hyperglycemia per se is a cause of adverse clinical outcomes
   or whether the incidence of adverse outcomes can be reduced by
   treatment.
   Objectives
   To assess the effects on clinical outcomes of interventions for treating
   neonatal hyperglycemia in the VLBW neonate receiving total or partial
   parenteral nutrition.
   Search strategy
   We searched The Cochrane Central Register of Controlled Trials (CENTRAL,
   The Cochrane Library, Issue 4 of 12, 2011), MEDLINE (1966 to April
   2011), EMBASE (1980 to April 2011) and CINAHL (1982 to July 2008). We
   searched for abstracts submitted for the annual meetings of Pediatric
   Academic Societies 2000 to 2011 and The European Society for Pediatric
   Research 2005 to 2010.
   Selection criteria
   Randomized or quasi-randomized trials of interventions for the treatment
   of hyperglycemia in hyperglycemic VLBW neonates were eligible for
   inclusion in this review.
   Data collection and analysis
   Two review authors independently selected studies for eligibility and
   extracted data on study design, methodology, clinical features, and
   treatment outcomes. Additional information on study design and outcomes
   was obtained from the lead investigator of each of the two included
   trials. The included trials were assessed for blinding of randomization,
   blinding of caretakers to the intervention, completeness of follow-up,
   and blinding of outcome measurement. The treatment effect measures for
   categorical outcomes were relative risk (RR) and risk difference (RD)
   with their 95\% confidence intervals (CI); for continuous outcomes the
   measure was mean difference and 95\% CI.
   Main results
   Only two eligible trials were found (Collins 1991; Meetze 1998). Both
   were randomized but of very small size (24 and 23 neonates randomized in
   each trial, respectively).
   No trial compared reduction versus no reduction of glucose infusion.
   Collins 1991 compared insulin infusion with standard care. Insulin
   infusion had no significant effect on death or bacterial sepsis; effects
   on other major morbidities were not assessed. Insulin infusion resulted
   in significant increases in non-protein energy intake, glucose intake,
   and short-term weight gain.
   Meetze 1998 compared insulin infusion with reduction of glucose
   infusion. Insulin infusion had no significant effects on death, severe
   intraventricular hemorrhage, retinopathy of prematurity, bacterial
   sepsis, fungal sepsis, or necrotizing enterocolitis; effects on other
   major morbidities were not assessed. Insulin infusion resulted in
   significant increases in glucose intake and total energy intake.
   Authors' conclusions
   Evidence from randomized trials in hyperglycemic VLBW neonates is
   insufficient to determine the effects of treatment on death or major
   morbidities. It remains uncertain whether the hyperglycemia per se is a
   cause of adverse clinical outcomes or how the hyperglycemia should be
   treated. Much larger randomized trials in hyperglycemic VLBW neonates
   that are powered on clinical outcomes are needed in order to determine
   whether, and how, the hyperglycemia should be treated.}},
DOI = {{10.1002/14651858.CD007453.pub3}},
Article-Number = {{CD007453}},
ISSN = {{1469-493X}},
Unique-ID = {{ISI:000295674300040}},
}

@article{ ISI:000275756500014,
Author = {Yellowlees, Peter M. and Chorba, Kathy and Parish, Michelle Burke and
   Wynn-Jones, Hannah and Nafiz, Najia},
Title = {{Telemedicine Can Make Healthcare Greener}},
Journal = {{TELEMEDICINE JOURNAL AND E-HEALTH}},
Year = {{2010}},
Volume = {{16}},
Number = {{2}},
Pages = {{230-233}},
Month = {{MAR}},
Abstract = {{The American healthcare industry is generally lacking environmentally
   sustainable practices. The environmental impact of healthcare practices
   in the country has been largely disregarded due to ambivalence,
   ignorance, and fears of additional costs and regulations. The current
   practices continue to pollute the environment by requiring large amounts
   of travel and paperwork by both the patient and the clinician.
   Telemedicine and health information technology help save time, energy,
   raw materials (such as paper and plastic), and fuel, thereby lowering
   the carbon footprint of the health industry. By implementing green
   practices, for instance, by engaging in carbon credit programs, the
   health industry could benefit financially as well as reduce its negative
   impact on the health of our planet. Companies that reduce their carbon
   emissions by implementing energy-saving practices can sell their carbon
   credits to companies that emit more carbon than permissible by their
   legally binding commitment. These carbon profits can then be used for
   healthcare research or to provide healthcare to the underserved.
   Alternatively, the savings could be used for green purchasing and to
   implement other carbon-reducing activities. This report reviews the
   numerous possible options for the American health industry to become
   greener and lower its carbon footprint while at the same time becoming
   more time-and cost efficient.}},
DOI = {{10.1089/tmj.2009.0105}},
ISSN = {{1530-5627}},
Unique-ID = {{ISI:000275756500014}},
}

@article{ ISI:000265503100003,
Author = {Mo, Qianxing and Lu, Shifang and Garippa, Carrie and Brownstein, Michael
   J. and Simon, Neal G.},
Title = {{Genome-wide analysis of DHEA- and DHT-induced gene expression in mouse
   hypothalamus and hippocampus}},
Journal = {{JOURNAL OF STEROID BIOCHEMISTRY AND MOLECULAR BIOLOGY}},
Year = {{2009}},
Volume = {{114}},
Number = {{3-5}},
Pages = {{135-143}},
Month = {{APR}},
Abstract = {{Dehydroepiandrosterone (DHEA) is the most abundant steroid in humans and
   a multi-functional neuroactive steroid that has been implicated in a
   variety of biological effects in both the periphery and central nervous
   system. Mechanistic studies of DHEA in the periphery have emphasized its
   role as a prohormone and those in the brain have focused on effects
   exerted at cell surface receptors. Recent results demonstrated that DHEA
   is intrinsically androgenic. It competes with DHT for binding to
   androgen receptor (AR), induces AR-regulated reporter gene expression in
   vitro, and exogenous DHEA administration regulates gene expression in
   peripheral androgen-dependent tissues and LnCAP prostate cancer cells,
   indicating genomic effects and adding a level of complexity to
   functional models. The absence of information about the effect of DHEA
   on gene expression in the CNS is a significant gap in light of
   continuing clinical interest in the compound as a hormone replacement
   therapy in older individuals, patients with adrenal insufficiency, and
   as a treatment that improves sense of well-being, increases libido,
   relieves depressive symptoms, and serves as a neuroprotective agent. In
   the present study, ovariectomized CF-1 female mice, an established model
   for assessing CNS effects of androgens, were treated with DHEA (1
   mg/day), dihydrotestosterone (DHT, a potent androgen used as a positive
   control; 0.1 mg/day) or vehicle (negative control) for 7 days. The
   effects of DHEA on gene expression were assessed in two regions of the
   CNS that are enriched in AR, hypothalamus and hippocampus, using DNA
   microarray, real-time RT-PCR, and immunohistochemistry. RIA of serum
   samples assessed treatment effects on circulating levels of major
   steroids. In hypothalamus, DHEA and DHT significantly up-regulated the
   gene expression of hypocretin (Hcrt; also called orexin),
   pro-melanin-concentrating hormone (Pmch), and protein kinase C delta
   (Prkcd), and down-regulated the expression of deleted in bladder cancer
   chromosome region candidate I (Dbccr1) and chitinase 3-like 3 (Chi313).
   Two-step real-time RT-PCR confirmed changes in the expression of three
   genes (Pmch, Hcrt and Prkcd) using the same RNA sample employed in the
   microarray experiment. Immunohistochemistry showed augmentation of
   prepto-hypocretin (pHcrt) neuropeptide protein expression by DHEA and
   DHT in hypothalamus, consistent with the localization of orexin neurons.
   In hippocampus, DHT down-regulated the expression of Prkcd, while DHEA
   did not have significant effects. RIA results supported the view that
   DHEA-induced effects were mediated through AR. The current study
   identified neurogenomic effects of DHEA treatment on a subset of genes
   directly implicated in the regulation of appetite, energy utilization,
   alertness, apoptosis, and cell survival. These changes in gene
   expression in the CNS represent a constellation of effects that may help
   explain the diverse benefits attributed to replacement therapy with
   DHEA. The data also provide a new level of detail regarding the genomic
   mechanism of action of DHEA in the CNS and strongly support a central
   role for the androgen receptor in the production of these effects. More
   broadly, the results may be clinically significant because they provide
   new insights into processes that appear to mediate the diverse CNS
   effects attributed to DHEA. (C) 2009 Elsevier Ltd. All rights reserved.}},
DOI = {{10.1016/j.jsbmb.2009.01.015}},
ISSN = {{0960-0760}},
Unique-ID = {{ISI:000265503100003}},
}

@article{ ISI:000253926600004,
Author = {Ito, Yuko and Ichikawa, Takafumi and Morohosh, Yasuo and Nakamura,
   Takeshi and Saegusa, Yoichi and Ishihara, Kazuhiko},
Title = {{Effect of tea catechins on body fat accumulation in rats fed a normal
   diet}},
Journal = {{BIOMEDICAL RESEARCH-TOKYO}},
Year = {{2008}},
Volume = {{29}},
Number = {{1}},
Pages = {{27-32}},
Month = {{FEB}},
Abstract = {{Although it is known that tea catechins exert potent effects in obese
   subjects, there is scant information concerning these effects on body
   weight gain and body fat accumulation in the non-obese. We studied
   normal rats fed a normal diet and water containing either 0.1\% or 0.5\%
   tea catechins to examine the effects on body fat content and serum
   cholesterol levels, as well as evaluating whether the effect is related
   to bile acids, which in recent years have emerged as an inducer of
   energy expenditure. The administration of 0.5\% catechins decreased the
   accumulation of body fat and the serum levels of cholesterol and bile
   acids. These results indicate that tea catechins modulate lipid
   metabolism not only in obese subjects, but also in the non-obese.}},
DOI = {{10.2220/biomedres.29.27}},
ISSN = {{0388-6107}},
Unique-ID = {{ISI:000253926600004}},
}

@inproceedings{ ISI:000258485200002,
Author = {Aizpurua, O. and Galan, R. and Jimenez, A.},
Book-Group-Author = {{IEEE}},
Title = {{A new cognitive-based massive alarm management system in electrical
   power administration}},
Booktitle = {{2008 7TH INTERNATIONAL CARIBBEAN CONFERENCE ON DEVICES, CIRCUITS AND
   SYSTEMS}},
Year = {{2008}},
Pages = {{6-11}},
Note = {{7th International Caribbean Conference on Devices, Circuits and Systems,
   Cancun, MEXICO, APR 28-30, 2008}},
Abstract = {{This paper presents a methodology that integrates several available
   techniques to manage the massive amount of alarm signals in electrical
   power dispatch control centres, as well as the contribution of each
   entity involved in the system. Artificial intelligence techniques that
   can be used in this problem are reviewed here based on the available
   information. The final objective is to rind the root cause of avalanches
   of alarms (failure tree) and to reduce their number through grouping or
   clustering techniques so that the EEMUA 191 standards are followed. Even
   though other contributions in this topic have been made before, the
   alarm management problem continues to be practically unsolved for many
   applications in industry. Here, the integration is developed using the
   ontology of each system domains, i.e., the ontology corresponding to the
   alarms, controls, events, energy flow and trigger sequence.
   Additionally, in this methodology, a rule based expert system is used to
   treat the alarms with a neural net based approach to treat the
   historical database of alarms and failures.}},
ISBN = {{978-1-4244-1956-2}},
Unique-ID = {{ISI:000258485200002}},
}

@article{ ISI:000232609400010,
Author = {Stellaard, F},
Title = {{Use of dual isotope tracers in biomedical research}},
Journal = {{ISOTOPES IN ENVIRONMENTAL AND HEALTH STUDIES}},
Year = {{2005}},
Volume = {{41}},
Number = {{3}},
Pages = {{275-286}},
Month = {{SEP}},
Note = {{Joint Meeting of the European-Stable-Isotope-Users-Group, Vienna,
   AUSTRIA, AUG 30-SEP 03, 2004}},
Organization = {{European Stable Isotope Users Grp}},
Abstract = {{Biomedical stable isotope studies involve administration of tracer and
   measurement of isotope enrichment in blood, urine, feces or breath. The
   aim of the studies is to gather quantitative information about a
   specific metabolic function. However, the measured isotope enrichment
   may be affected by other metabolic events than only this function. In
   this case, a correction is necessary. The best approach is to add a
   second tracer simultaneously which is known to be metabolised by all
   interfering metabolic events but not by the function of interest. This
   dual isotope approach also enables simultaneous measurement of two
   interrelated functions. A summary of selected applications involving
   dual isotope tracer studies is presented. The applications deal with
   energy expenditure ( doubly labelled water technique), cholesterol
   absorption, starch and lactose digestion, fat digestion, bile acid
   metabolism and the combination of stable and radioactive carbon isotopes
   in breath testing.}},
DOI = {{10.1080/10256010500230239}},
ISSN = {{1025-6016}},
Unique-ID = {{ISI:000232609400010}},
}

@article{ ISI:000173418300005,
Author = {Zhao, TXP and Stowe, LL and Smirnov, A and Crosby, D and Sapper, J and
   McClain, CR},
Title = {{Development of a global validation package for satellite oceanic aerosol
   optical thickness retrieval based on AERONET observations and its
   application to NOAA/NESDIS operational aerosol retrievals}},
Journal = {{JOURNAL OF THE ATMOSPHERIC SCIENCES}},
Year = {{2002}},
Volume = {{59}},
Number = {{3}},
Pages = {{294-312}},
Abstract = {{In this paper, a global validation package for satellite aerosol optical
   thickness retrieval using the Aerosol Robotic Network (AERONET)
   observations as ground truth is described. To standardize the validation
   procedure, the optimum time-space match-up window, the ensemble
   statistical analysis method, the best selection of AERONET channels, and
   the numerical scheme used to interpolate/extrapolate these observations
   to satellite channels have been identified through sensitivity studies.
   The package is shown to be a unique tool for more objective validation
   and intercomparison of satellite aerosol retrievals, helping to satisfy
   an increasingly important requirement of the satellite aerosol remote
   sensing community. Results of applying the package to the
   second-generation operational aerosol observational data (AEROBS) from
   the NOAA-14 Advanced Very High Resolution Radiometer (AVHRR) in 1998 and
   to the same year aerosol observation data {[}Clouds and the Earth's
   Radiant Energy System-Single Scanner Foodprint version 4 (CERES-SSF4)]
   from the Tropical Rainfall Measuring Mission (TRMM) Visible Infrared
   Scanner (VIRS) are presented as examples of global validation. The
   usefulness of the package for identifying improvements to the aerosol
   optical thickness tau retrieval algorithm is also demonstrated.
   The principal causes of systematic errors in the current National
   Oceanic and Atmospheric Administration (NOAA)/National Environmental
   Satellite, Data, and Information Service (NESDIS) operational aerosol
   optical thickness retrieval algorithm have been identified and can be
   reduced significantly, if the correction and adjustment suggested from
   the global validation are adopted. Random error in the tau retrieval is
   identified to be a major source of error on deriving the effective
   Angstromngstrom wavelength exponent alpha and may be associated with
   regional differences in aerosol particles, which are not accounted for
   in the current second-generation operational algorithm. Adjustments to
   the nonaerosol and aerosol radiative transfer model parameters that
   reduce systematic errors in tau retrievals are suggested for
   consideration in the next-generation algorithm. Basic features that
   should be included in the next-generation algorithm to reduce random
   error in tau retrievals and the resulting error in the effective
   Angstromngstrom wavelength exponent have also been discussed.
   Compared to the AERONET observation, the NOAA-14 AVHRR (AEROBS) tau
   values for mean conditions are biased high by 0.05 and 0.08, with random
   errors of 0.08 and 0.05, at 0.63 and 0.83 mum, respectively.
   Correspondingly, the TRMM VIRS (CERES-SSF4) values for mean conditions
   are biased high by 0.06 and 0.02, with random errors of 0.06 and 0.04 at
   0.63 and 1.61 mum, respectively. After corrections and adjustments to
   the retrieval algorithm, the biases in both channels of AVHRR and VIRS
   are reduced significantly to values close to zero, although random error
   is almost unchanged. The alpha exponent derived directly from the
   aerosol optical thicknesses (taus) has been shown to be poorly
   correlated both before and after adjustments, indicating that random
   error in the tau measurement (possibly related to aerosol model
   parameter variations or cloud-surface reflectance contamination) needs
   to be reduced.}},
DOI = {{10.1175/1520-0469(2002)059<0294:DOAGVP>2.0.CO;2}},
ISSN = {{0022-4928}},
ResearcherID-Numbers = {{Smirnov, Alexander/C-2121-2009}},
Unique-ID = {{ISI:000173418300005}},
}

@article{ ISI:000171415900002,
Author = {Tepper, SJ and Rapoport, A and Sheftell, F},
Title = {{The pathophysiology of migraine}},
Journal = {{NEUROLOGIST}},
Year = {{2001}},
Volume = {{7}},
Number = {{5}},
Pages = {{279-286}},
Month = {{SEP}},
Abstract = {{BACKGROUND- Migraine results from episodic changes in central nervous
   system physiologic function in hyperexcitable brain manifested by
   abnormal energy metabolism, lowered threshold for phosphene generation,
   and increased contingent negative variation. Human functional magnetic
   resonance imaging and magnetoencepholography data strongly suggest that
   aura is caused by cortical spreading depression.
   REVIEW SUMMARY- Brain hyperexcitability may be caused by low magnesium
   levels, mitochandrial abnormalities with abnormal phosphorylation of
   adenosine 5'-diphosphate, a dysfunction related to nitric oxide, or
   calcium channelopathy. Low magnesium can result in opening of calcium
   channels, increased intracellular calcium, glutamate release, and
   increased extracellular potassium, which may in turn trigger cortical
   spreading depression. Mitochondrial dysfunction has been suggested by a
   low phosphocreatine:Pi ratio and a possible response by migraine
   patients to riboflavin prophylaxis. Nitroglycerine administration
   results in a delayed migraine-like headache in migraine patients but not
   iii control patients; and a nonspecific nitric oxide synthase inhibitor
   aborted migraine at 2 hours in the majority of tested migraine patients
   compared to controls. Many patients with familial hemiplegic migraine
   have a missense mutation in the P/Q calcium channel, so that this form
   of migraine, at feast, is associated with a demonstrable calcium
   channelopathy.
   CONCLUSIONS- The generation of migraine occurs centrally in the brain
   stem, sometimes preceded by cortical spreading depression and aura.
   Activation of the trigeminovascular system stimulates perivascular
   trigeminal sensory afferent nerves with release of vasoactive
   neuropeptides, resulting in vasodilation and transduction of central
   nociceptive information. There is then a relay of pain impulses to
   central second- and third-order neurons and activation of brain stem
   autonomic nuclei to induce associated symptoms.}},
DOI = {{10.1097/00127893-200109000-00002}},
ISSN = {{1074-7931}},
Unique-ID = {{ISI:000171415900002}},
}

@article{ ISI:000362546900004,
Author = {Ljungberg, Michael and Gleisner, Katarina Sjogreen},
Title = {{Hybrid Imaging for Patient-Specific Dosimetry in Radionuclide Therapy}},
Journal = {{DIAGNOSTICS}},
Year = {{2015}},
Volume = {{5}},
Number = {{3}},
Pages = {{296-317}},
Month = {{SEP}},
Abstract = {{Radionuclide therapy aims to treat malignant diseases by systemic
   administration of radiopharmaceuticals, often using carrier molecules
   such as peptides and antibodies. The radionuclides used emit electrons
   or alpha particles as a consequence of radioactive decay, thus leading
   to local energy deposition. Administration to individual patients can be
   tailored with regards to the risk of toxicity in normal organs by using
   absorbed dose planning. The scintillation camera, employed in planar
   imaging or single-photon emission computed tomography (SPECT), generates
   images of the spatially and temporally varying activity distribution.
   Recent commercially available combined SPECT and computed tomography
   (CT) systems have dramatically increased the possibility of performing
   accurate dose planning by using the CT information in several steps of
   the dose-planning calculation chain. This paper discusses the dosimetry
   chain used for individual absorbed-dose planning and highlights the
   areas where hybrid imaging makes significant contributions.}},
DOI = {{10.3390/diagnostics5030296}},
ISSN = {{2075-4418}},
Unique-ID = {{ISI:000362546900004}},
}

@article{ ISI:000342801800005,
Author = {Peng, Zhangxiao and Wang, Yan and Gu, Xue and Guo, Xiaojie and Yan, Chao},
Title = {{Study on the pharmacokinetics and metabolism of costunolide and
   dehydrocostus lactone in rats by HPLC-UV and UPLC-Q-TOF/MS}},
Journal = {{BIOMEDICAL CHROMATOGRAPHY}},
Year = {{2014}},
Volume = {{28}},
Number = {{10}},
Pages = {{1325-1334}},
Month = {{OCT}},
Abstract = {{A method based on high-performance liquid chromatography coupled with
   ultraviolet detection was developed for studying the pharmacokinetics of
   costunolide (Cos) and dehydrocostus lactone (Dehy) in rats after
   intravenous (i.v.) administration. Following i.v. administration, the
   maximum plasma concentrations of Cos and Dehy were observed to be 12.29
   +/- 1.47 and 5.79 +/- 0.13 mu g/mL, respectively. The bioavailability of
   Cos was larger than that of Dehy; however, the clearance and the volume
   of distribution of Dehy were much larger than those of Cos. An
   ultraperformance liquid chromatography/quadrupole time-of-flight mass
   spectrometry system with automated MSE (E represents collision energy)
   data analysis software (MetaboLynx(TM)) was used to analyze and identify
   the metabolites of Cos and Dehy in vivo. Four metabolites of Cos and six
   metabolites of Dehy were discovered from the plasma, urine and feces of
   rats. The main metabolic pathway of Cos was phase II biotransformation,
   but the main metabolic pathways of Dehy was phase biotransformation. Two
   sequential desaturations and N-acetylcysteine conjugation were the
   common metabolic pathways of Cos and Dehy in rats. This information may
   be useful for the further development of the two drug candidates.
   Copyright (c) 2014 John Wiley \& Sons, Ltd.}},
DOI = {{10.1002/bmc.3167}},
ISSN = {{0269-3879}},
EISSN = {{1099-0801}},
Unique-ID = {{ISI:000342801800005}},
}

@article{ ISI:000342528700023,
Author = {Li, Tao and Trani, Antonio A.},
Title = {{A model to forecast airport-level General Aviation demand}},
Journal = {{JOURNAL OF AIR TRANSPORT MANAGEMENT}},
Year = {{2014}},
Volume = {{40}},
Pages = {{192-206}},
Month = {{AUG}},
Abstract = {{General Aviation (GA) demand forecast plays an important role in
   aviation management, planning and policy making. The objective of this
   paper is to develop an airport-level GA demand forecast model. The GA
   demand at an airport is modeled as a function of social-economic and
   demographic factors, the availability of supply factors, the competition
   from the commercial aviation, the number of based aircraft, and the
   presence of a flight school. Our models suggest that the relative fuel
   price - fuel price compared with personal income - is a significant
   determinant of airport level GA demand. The elasticity of itinerant and
   local GA demand with respect to the relative fuel price is -0.43 and
   -0.52, respectively. Our results are compared with those reported in
   other studies. Furthermore, we made projections of GA demand for the
   airports in the Terminal Area Forecast (TAP) using three fuel price
   scenarios from the Energy Information Administration. Our projections
   under the ``business-as-usual{''} fuel price scenario are close to those
   in the TAP. Our models could prove useful, for example, for the Federal
   Aviation Administration and airport planners to prepare airport-level GA
   demand forecast. (C) 2014 Elsevier Ltd. All rights reserved.}},
DOI = {{10.1016/j.jairtraman.2014.07.003}},
ISSN = {{0969-6997}},
EISSN = {{1873-2089}},
Unique-ID = {{ISI:000342528700023}},
}

@article{ ISI:000314146700010,
Author = {Ciriello, J. and Moreau, J. M.},
Title = {{SYSTEMIC ADMINISTRATION OF LEPTIN POTENTIATES THE RESPONSE OF NEURONS IN
   THE NUCLEUS OF THE SOLITARY TRACT TO CHEMORECEPTOR ACTIVATION IN THE RAT}},
Journal = {{NEUROSCIENCE}},
Year = {{2013}},
Volume = {{229}},
Pages = {{88-99}},
Month = {{JAN 15}},
Abstract = {{Leptin microinjections into the nucleus of the solitary tract (NTS) have
   been shown to elicit sympathoexcitatory responses, and potentiate the
   cardiovascular responses to activation of the chemoreflex. In this
   study, experiments were done in Sprague Dawley rats initially to provide
   a detailed mapping within the NTS complex of cells containing
   immunoreactivity to the long form of the leptin receptor (Ob-Rb). In a
   second series, this NTS region containing Ob-Rb immunoreactive cells was
   explored for single units antidromically activated by stimulation of
   pressor sites in the rostral ventrolateral medulla (RVLM). These
   antidromically identified neurons were then tested for their response to
   intra-carotid injections of leptin (50-100 ng/0.1ml), and to activation
   of peripheral chemoreceptors following an injection of potassium cyanide
   (KCN) (80 mu g/0.1ml) into the carotid artery. Cells containing
   Ob-Rb-like immunoreactivity were found predominantly in the caudal NTS:
   within the medial, commissural and gelatinous (sub-postremal area)
   subnuclei of the NTS complex. Of 73 single units tested in these NTS
   regions, 48 were antidromically activated by stimulation of RVLM pressor
   sites and 25 of these single units responded with an increase in
   discharge rate after intra-carotid injections of leptin. In addition, 17
   of these leptin responsive neurons were excited by the intra-carotid
   injections of KCN (80 mu/0.1 ml). Furthermore, the excitatory response
   of these single units to KCN was potentiated (59-83\%) immediately
   following the leptin injection. These data indicate that leptin
   responsive neurons in NTS mediate chemoreceptor afferent information to
   pressor sites in the RVLM, and suggest that leptin may act as a
   facilitator on neuronal circuits within the NTS that potentiates the
   sympathoexcitatory responses elicited during the reflex activation of
   arterial chemoreceptors. (C) 2012 IBRO. Published by Elsevier Ltd. All
   rights reserved.}},
DOI = {{10.1016/j.neuroscience.2012.10.065}},
ISSN = {{0306-4522}},
Unique-ID = {{ISI:000314146700010}},
}

@article{ ISI:000314191600089,
Author = {Asfaw, Abay and Mark, Christopher and Pana-Cryan, Regina},
Title = {{Profitability and occupational injuries in U.S. underground coal mines}},
Journal = {{ACCIDENT ANALYSIS AND PREVENTION}},
Year = {{2013}},
Volume = {{50}},
Pages = {{778-786}},
Month = {{JAN}},
Abstract = {{Background: Coal plays a crucial role in the U.S. economy yet
   underground coal mining continues to be one of the most dangerous
   occupations in the country. In addition, there are large variations in
   both profitability and the incidence of occupational injuries across
   mines.
   Objective: The objective of this study was to examine the association
   between profitability and the incidence rate of occupational injuries in
   U.S. underground coal mines between 1992 and 2008.
   Data and method: We used mine-specific data on annual hours worked,
   geographic location, and the number of occupational injuries suffered
   annually from the employment and accident/injury databases of the Mine
   Safety and Health Administration, and mine-specific data on annual
   revenue from coal sales, mine age, workforce union status, and mining
   method from the U.S. Energy Information Administration. A total of 5669
   mine-year observations (number of mines x number of years) were included
   in our analysis. We used a negative binomial random effects model that
   was appropriate for analyzing panel (combined time-series and
   cross-sectional) injury data that were non-negative and discrete. The
   dependent variable, occupational injury, was measured in three different
   and non-mutually exclusive ways: all reported fatal and nonfatal
   injuries, reported nonfatal injuries with lost workdays, and the `most
   serious' (i.e. sum of fatal and serious nonfatal) injuries reported. The
   total number of hours worked in each mine and year examined was used as
   an exposure variable. Profitability, the main explanatory variable, was
   approximated by revenue per hour worked. Our model included mine age,
   workforce union status, mining method, and geographic location as
   additional control variables.
   Results: After controlling for other variables, a 10\% increase in real
   total revenue per hour worked was associated with 0.9\%, 1.1\%. and
   1.6\% decrease, respectively, in the incidence rates of all reported
   injuries, reported injuries with lost workdays, and the most serious
   injuries reported.
   Conclusion: We found an inverse relationship between profitability and
   each of the three indicators of occupational injuries we used. These
   results might be partially due to factors that affect both profitability
   and safety, such as management or engineering practices, and partially
   due to lower investments in safety by less profitable mines, which could
   imply that some financially stressed mines might be so focused on
   survival that they forgo investing in safety. Published by Elsevier Ltd.}},
DOI = {{10.1016/j.aap.2012.07.002}},
ISSN = {{0001-4575}},
Unique-ID = {{ISI:000314191600089}},
}

@inproceedings{ ISI:000323598400008,
Author = {Wang, Yanwei and Tang, Helen and Yu, F. Richard and Huang, Minyi},
Editor = {{Agaian, SS and Jassim, SA and Du, EY}},
Title = {{Mean field game theoretic approach for security in mobile ad-hoc
   networks}},
Booktitle = {{MOBILE MULTIMEDIA/IMAGE PROCESSING, SECURITY, AND APPLICATIONS 2013}},
Series = {{Proceedings of SPIE}},
Year = {{2013}},
Volume = {{8755}},
Note = {{Conference on Mobile Multimedia/Image Processing, Security, and
   Applications, Baltimore, MD, APR 29-30, 2013}},
Organization = {{SPIE}},
Abstract = {{Game theory can provide a useful tool to study the security problem in
   mobile ad hoc networks (MANETs). Most existing work on applying game
   theories to security only considers two players in the security game
   model: an attacker and a defender. While this assumption is valid for a
   network with centralized administration, it may not be realistic in
   MANETs, where centralized administration is not available. Consequently,
   each individual node in a MANET should be treated separately in the
   security game model. In this paper, using recent advances in mean field
   game theory, we propose a novel game theoretic approach for security in
   MANETs. Mean field game theory provides a powerful mathematical tool for
   problems with a large number of players. Since security defence
   mechanisms consume precious system resources (e.g., energy), the
   proposed scheme considers not only the security requirement of MANETs
   but also the system resources. In addition, each node only needs to know
   its own state information and the aggregate effect of the other nodes in
   the MANET. Therefore, the proposed scheme is a fully distributed scheme.
   Simulation results are presented to illustrate the effectiveness of the
   proposed scheme.}},
DOI = {{10.1117/12.2015281}},
Article-Number = {{UNSP 875509}},
ISSN = {{0277-786X}},
ISBN = {{978-0-8194-9546-4}},
Unique-ID = {{ISI:000323598400008}},
}

@inproceedings{ ISI:000347240604069,
Author = {Zaldivar-Colado, A. and Aguilar Calderon, J. A. and Qui Orozco, S. O.
   and Nava Perez, L. and Garcia-Sanchez, O. V. and Bernal-Guadiana, R.},
Editor = {{Chova, LG and Martinez, AL and Torres, IC}},
Title = {{IMPLEMENTATION OF THE METHOD OF LINEAR REGRESSION FOR THE MODELING OF
   THE RELATIONSHIP BURNOUT - TEACHING PERFORMANCE}},
Booktitle = {{6TH INTERNATIONAL CONFERENCE OF EDUCATION, RESEARCH AND INNOVATION
   (ICERI 2013)}},
Year = {{2013}},
Pages = {{4374-4380}},
Note = {{6th International Conference on Education, Research and Innovation
   (ICERI), Seville, SPAIN, NOV 18-20, 2013}},
Abstract = {{Currently, investigations that looks for the variables that influence
   poor academic performance, high dropout rates, low completion rate and
   teacher performance are becoming more rational and meaningful. In this
   paper is shown, as a second phase of research to predict, with a high
   percentage of accuracy, the academic performance of the candidates to
   study a university career, a study that discovers other coefficients in
   a lot of the analyzed variables: teacher performance and the burnout
   syndrome
   The Burnout Syndrome describes physical and psychological states of the
   individual, characterized by decreased energy, focus and motivation,
   among others. This symptom is a major cause of absence from work and, in
   some cases, school dropout. It has also been considered as a variable
   that could cause poor teaching performance or poor academic
   accomplishment {[}1].
   The Burnout affects people who work with and for other people, for
   example teachers, students, doctors, nurses, psychologists, etc., no age
   or gender discrimination. Teachers and college students are constantly
   under situations that may cause the syndrome to manifest itself.
   Holding the hypothesis that burnout syndrome affects academic
   performance among the university professors by influencing teacher
   performance, in this investigation was determined, by the mathematical
   method of linear regression, the relationship between teachers burnout
   syndrome in the School of Computer Science in Mazatlan City (FIMAZ) of
   the Autonomous University of Sinaloa (UAS) and teacher performance, the
   result obtained on the assessment made by professors on the
   administration of the institutional administration and quantified as the
   percentage given by the students on various items such as class
   planning, content delivery, time management, assessment, etc..
   Information was collected using a specialized instrument to measure the
   presence of burnout syndrome (Maslash Scale) between teachers.
   Among the most relevant results stands out that teachers with a
   seniority of 15 years or more, have better rates of teacher performance
   (85\% or more) and low levels of exhaustion (burnout), while teachers
   with 14 years of teaching experience, obtained an approval of students
   less than 85\% and high levels of exhaustion (burnout).
   It is important to note that, overall, 20\% of the teachers surveyed
   presented high rates of burnout and 36\% average levels of the syndrome.
   It can be concluded that the burnout syndrome impacts on younger
   teachers with less seniority, thus affecting their teaching performance.
   But shouldn't be excluded other factors also involved in teaching and
   learning, such as knowledge of the discipline, dedication, personal and
   social situations.}},
ISBN = {{978-84-616-3847-5}},
Unique-ID = {{ISI:000347240604069}},
}

@article{ ISI:000303181600007,
Author = {Yahashi, Satowa and Kang, Ki Sung and Kaiya, Hiroyuki and Matsuda,
   Kouhei},
Title = {{GHRP-6 mimics ghrelin-induced stimulation of food intake and suppression
   of locomotor activity in goldfish}},
Journal = {{PEPTIDES}},
Year = {{2012}},
Volume = {{34}},
Number = {{2}},
Pages = {{324-328}},
Month = {{APR}},
Abstract = {{Ghrelin was first identified and characterized from rat stomach as an
   endogenous ligand for the growth hormone secretagogue (GHS) receptor
   (GHS-R). Ghrelin also acts as an orexigenic factor and regulates energy
   balance in rodents. In goldfish, native ghrelin consists of 11 molecular
   variants, the major form being a 17-residue peptide with n-octanoic acid
   modification (n-octanoyl ghrelin17), and intraperitoneal (IP)
   administration of n-octanoyl ghrelin17 induces central actions such as
   stimulation of food intake and suppression of locomotor activity through
   capsaicin-sensitive afferents. Four types of GHS-Rs (1a-1, 1a-2, 2a-1
   and 2a-2) have been identified in goldfish, and one GHS, GHRP-6, can
   activate only GHS-R2a-1 in vitro. However, there is no information about
   the effect of GHRP-6 on food intake and locomotor activity in goldfish
   in vivo. Therefore, in the present study, we examined whether
   IP-administered GHRP-6 would mimic the orexigenic action of n-octanoyl
   ghrelin17 and its suppression of locomotor activity. IP administration
   of GHRP-6 at 1 pmol/g body weight (SW) stimulated food intake, and was
   equipotent to the orexigenic action of n-octanoyl ghrelin17 at 10 pmol/g
   BW. IP-injected GHRP-6 at 1 pmol/g BW also induced a significant
   decrease of locomotor activity, as was the case for IP-injected
   n-octanoyl ghrelin17 at 10 pmol/g BW. The action of GHRP-6 was blocked
   by IP-preinjected capsaicin at 160 nmol/g BW. These results suggest that
   the central action of GHRP-6 might be mediated via the
   GHS-R2a-1-signaling pathway, and subsequently through
   capsaicin-sensitive afferents in goldfish. (C) 2012 Elsevier Inc. All
   rights reserved.}},
DOI = {{10.1016/j.peptides.2012.01.025}},
ISSN = {{0196-9781}},
Unique-ID = {{ISI:000303181600007}},
}

@article{ ISI:000297281500012,
Author = {Weissman, David E. and Bourassa, Mark A.},
Title = {{The Influence of Rainfall on Scatterometer Backscatter Within Tropical
   Cyclone Environments-Implications on Parameterization of Sea-Surface
   Stress}},
Journal = {{IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING}},
Year = {{2011}},
Volume = {{49}},
Number = {{12, 1, SI}},
Pages = {{4805-4814}},
Month = {{DEC}},
Note = {{30th IEEE International Geoscience and Remote Sensing Symposium (IGARSS)
   on Remote Sensing - Global Vision for Local Action, Honolulu, HI, JUN
   25-30, 2010}},
Organization = {{IEEE}},
Abstract = {{The use of satellite scatterometers to probe the winds in and near
   strong tropical cyclones (TCs) is a valuable tool for both numerical
   weather prediction and weather forecasters. The presence of widespread
   rain in these storms impedes the estimation of surface winds from the
   radar cross section measurements, when using a Ku-band radar. This paper
   seeks improvements in the methodology to infer surface winds and
   stresses from the satellite radar cross section data, by removing the
   effects of rain contamination at the ocean surface. The findings provide
   insights into improvements in the modeling efforts of TC intensity. This
   study demonstrates the use of high-resolution rain measurements obtained
   from a Next-Generation Radar collocated and simultaneous with the
   National Aeronautics and Space Administration Quick Scatterometer.
   Through the application of the National Oceanic and Atmospheric
   Administration/Atlantic Oceanographic and Meteorological
   Laboratory/Hurricane Research Division TC wind analysis (H{*}WIND), we
   are studying the dependence of a surface normalized radar cross section
   (NRCS), which is related to surface stress, on the TC wind speed and
   rain rate. One of our findings is that, in the three TCs we have
   studied, the highest winds are accompanied by significant rain. Another
   is that the wind-driven rain can act as a roughening effect as measured
   by the H-pol NRCS. We also offer reasons why this can be interpreted as
   an additional stress on the surface. This roughening affects both the
   estimation of surface winds by scatterometers and the air-sea energy
   exchanges. This information could lead to an improved understanding of
   the dependence of the drag coefficient on both wind and rain.}},
DOI = {{10.1109/TGRS.2011.2170842}},
ISSN = {{0196-2892}},
Unique-ID = {{ISI:000297281500012}},
}

@article{ ISI:000295781300001,
Author = {Yoon, R. S. and Hwang, J. S. and Beebe, K. S.},
Title = {{Long-term bisphosphonate usage and subtrochanteric insufficiency
   fractures A CAUSE FOR CONCERN?}},
Journal = {{JOURNAL OF BONE AND JOINT SURGERY-BRITISH VOLUME}},
Year = {{2011}},
Volume = {{93B}},
Number = {{10}},
Pages = {{1289-1295}},
Month = {{OCT}},
Abstract = {{For over a decade, bisphosphonate administration has evolved and become
   the cornerstone of the prevention and treatment of fragility fractures.
   Millions of post-menopausal women have relied on, and continue to depend
   on, the long-acting, bone density-maintaining pharmaceutical drug to
   prevent low-energy fractures. In return, we have seen the number of
   fragility fractures decrease, along with associated costs and emotional
   benefits. However, with any drug, there are often concerns with side
   effects and complications, and this unique drug class is seeing one such
   complication in atypical subtrochanteric femoral fracture,
   counterproductive to that which it was designed to prevent. This has
   created concern over long-term bisphosphonate administration and its
   potential link to these atypical fractures. There is controversial
   evidence surrounding such a definitive link, and no protocol for
   managing these fractures.
   This review offers the latest information regarding this rare but
   increasingly controversial adverse effect and its potential connection
   to one of the most successful forms of treatment that is available for
   the management of fragility fractures.}},
DOI = {{10.1302/0301-620X.93B10.26924}},
ISSN = {{0301-620X}},
ORCID-Numbers = {{Yoon, Richard/0000-0001-5240-6633}},
Unique-ID = {{ISI:000295781300001}},
}

@article{ ISI:000301811400012,
Author = {Gradosova, Iveta and Zivna, Helena and Svejkovska, Klara and Palicka,
   Vladimir and Tichy, Ales and Zivny, Pavel},
Title = {{Effects of amlodipine on bone metabolism in male albino Wistar rats}},
Journal = {{ACTA VETERINARIA BRNO}},
Year = {{2011}},
Volume = {{80}},
Number = {{4}},
Pages = {{391-396}},
Abstract = {{Amlodipine (dihydropyridine-type calcium channel blocker) is a widely
   used agent for the treatment of hypertension in human and veterinary
   medicine but detailed information about its effects on bone metabolism
   are missing. Therefore, the aim of our study was to investigate the
   effect of amlodipine on bone metabolism in male albino Wistar rats.
   Amlodipine (0.3 mg/100 g body weight; gavage) was administered to 8 rats
   for 8 weeks. Control group (n = 8) received aqua pro inj. (0.2 ml/100 g
   body weight; gavage). Bone marker concentrations of carboxy-terminal
   cross-linking telopeptide of type I collagen (CTX-I) and aminoterminal
   propeptide of procollagen type I in serum, and of bone alkaline
   phosphatase (BALP) in both serum and bone homogenate were measured by
   enzyme immunoassay. We investigated the expression of bone morphogenetic
   protein 2 (BMP-2) in proximal tibia using Western blotting, and bone
   mineral density was measured by Dual-energy X-ray Absorptiometry in
   lumbar and caudal vertebrae and in femoral areas. Mechanical properties
   of the femurs were measured by three-point bending of the shaft and
   compression testing of the femoral neck. After 8 weeks of amlodipine
   administration there was a significant decrease in serum concentrations
   of BALP (p = 0.0009) and CTX-I (p = 0.003), and the content of BALP in
   bone homogenate (p = 0.026) compared to the control. In addition,
   Western blot analysis indicated increased BMP-2 protein concentration
   after amlodipine administration. Our findings suggest that amlodipine
   has a retarding influence on bone metabolism in rats by decreasing bone
   turnover, which probably in consequence increases expression of BMP-2.}},
DOI = {{10.2754/avb201180040391}},
ISSN = {{0001-7213}},
Unique-ID = {{ISI:000301811400012}},
}

@incollection{ ISI:000300632500009,
Author = {Jungbluth, George and Fulton, Richard and Moodie, Linda and Seymour,
   Paul and Williams, Mike and Wolf, Lothar and Zhang, Jiashen},
Editor = {{Sinha, AK and Arctur, D and Jackson, I and Gundersen, LC}},
Title = {{GEONETCast: Global satellite data dissemination and the technical and
   social challenges}},
Booktitle = {{SOCIETAL CHALLENGES AND GEOINFORMATICS}},
Series = {{Geological Society of America Special Papers}},
Year = {{2011}},
Volume = {{482}},
Pages = {{77-85}},
Abstract = {{GEONETCast is a global, near-real-time, environmental data dissemination
   system in support of the Global Earth Observation System of Systems
   (GEOSS). The goal of the system is to enable enhanced dissemination,
   application, and exploitation of environmental data and products for the
   diverse societal benefits defined by the Group on Earth Observations
   (GEO), including agriculture, energy, health, climate, weather, disaster
   mitigation, biodiversity, water resources, and ecosystems. The system
   consists of three regional broadcasts: EUMETCast (operated by the
   European Organisation for the Exploitation of Meteorological Satellites
   {[}EUMETSAT], covering Europe, Africa, and parts of Asia and the
   Americas), CMACast (operated by the China Meteorological Administration
   {[}CMA], covering Asia and parts of the Pacific), and GEONETCast
   Americas (operated by the U. S. National Oceanic and Atmospheric
   Administration {[}NOAA], covering North, Central, and South America and
   the Caribbean). The GEONETCast system uses the Digital Video
   Broadcast-Satellite (DVB-S) or Digital Video
   Broadcasting-Satellite-Second Generation (DVB-S2) standard over
   commercial communications satellites and low-cost, off-the-shelf
   technology to widen the access of new user groups to Earth observation
   information.}},
DOI = {{10.1130/2011.2482(08)}},
ISSN = {{0072-1077}},
ISBN = {{978-0-8137-2482-9}},
Unique-ID = {{ISI:000300632500009}},
}

@article{ ISI:000266629000033,
Author = {Sovacool, Benjamin K. and Sovacool, Kelly E.},
Title = {{Identifying future electricity-water tradeoffs in the United States}},
Journal = {{ENERGY POLICY}},
Year = {{2009}},
Volume = {{37}},
Number = {{7}},
Pages = {{2763-2773}},
Month = {{JUL}},
Abstract = {{Researchers for the electricity industry, national laboratories, and
   state and federal agencies have begun to argue that the country could
   face water shortages resulting from the addition of thermoelectric power
   plants, but have not attempted to depict more precisely where or how
   severe those shortages will be. Using county-level data on rates of
   population growth collected from the US Census Bureau, utility estimates
   of future planned capacity additions in the contiguous United States
   reported to the US Energy Information Administration, and scientific
   estimates of anticipated water shortages provided from the US Geologic
   Survey and National Oceanic and Atmospheric Administration, this paper
   highlights the most likely locations of severe shortages in 22 counties
   brought about by thermoelectric capacity additions. Within these areas
   are some 20 major metropolitan regions where millions of people live.
   After exploring the electricity-water nexus and explaining the study's
   methodology, the article then focuses on four of these metropolitan
   areas - Houston, Texas; Atlanta, Georgia; Las Vegas, Nevada; New York,
   New York - to deepen an understanding of the water and electricity
   challenges they may soon be facing. It concludes by identifying an
   assortment of technologies and policies that could respond to these
   electricity-water tradeoffs. (C) 2009 Elsevier Ltd. All rights reserved.}},
DOI = {{10.1016/j.enpol.2009.03.012}},
ISSN = {{0301-4215}},
ORCID-Numbers = {{Sovacool, Benjamin/0000-0002-4794-9403}},
Unique-ID = {{ISI:000266629000033}},
}

@article{ ISI:000249391600007,
Author = {Ying, Weihai},
Title = {{NAD(+) and NADH in neuronal death}},
Journal = {{JOURNAL OF NEUROIMMUNE PHARMACOLOGY}},
Year = {{2007}},
Volume = {{2}},
Number = {{3}},
Pages = {{270-275}},
Month = {{SEP}},
Abstract = {{Neuronal death is a key pathological event in multiple neurological
   diseases. Increasing evidence has suggested that NAD+ and NADH mediate
   not only energy metabolism and mitochondrial functions, but also calcium
   homeostasis, aging, and cell death. This article is written to provide
   an overview about the information suggesting significant roles of NAD+
   and NADH in neuronal death in certain neurological diseases. Our latest
   studies have suggested that intranasal administration with NAD(+) can
   profoundly decrease ischemic brain damage. These observations suggest
   that NAD(+) administration may be a novel therapeutic strategy for some
   neurological diseases.}},
DOI = {{10.1007/s11481-007-9063-5}},
ISSN = {{1557-1890}},
Unique-ID = {{ISI:000249391600007}},
}

@article{ ISI:000243530100001,
Author = {Zhang, Yuanchong and Rossow, William B. and Stackhouse, Jr., Paul W.},
Title = {{Comparison of different global information sources used in surface
   radiative flux calculation: Radiative properties of the surface}},
Journal = {{JOURNAL OF GEOPHYSICAL RESEARCH-ATMOSPHERES}},
Year = {{2007}},
Volume = {{112}},
Number = {{D1}},
Month = {{JAN 10}},
Abstract = {{Direct estimates of surface radiative fluxes that resolve regional and
   weather-scale variability over the whole globe with reasonable accuracy
   have only become possible with the advent of extensive global, mostly
   satellite, data sets within the past couple of decades. The accuracy of
   these fluxes, estimated to be about 10-15 W/m(2), is largely limited by
   the accuracy of the input data sets. The leading uncertainties in the
   surface fluxes are no longer predominantly induced by clouds but are now
   as much associated with uncertainties in the surface and near-surface
   atmospheric properties. This study presents a fuller, more quantitative
   evaluation of the uncertainties for the surface albedo and emissivity
   and surface skin temperatures by comparing the main available global
   data sets from the Moderate-Resolution Imaging Spectroradiometer
   product, the NASA Global Energy and Water Cycle Experiment Surface
   Radiation Budget project, the European Centre for Medium-Range Weather
   Forecasts, the National Aeronautics and Space Administration, the
   National Centers for Environmental Prediction, the International
   Satellite Cloud Climatology Project (ISCCP), the Laboratoire de
   Meteorologie Dynamique, NOAA/NASA Pathfinder Advanced Very High
   Resolution Radiometer project, and the NOAA Optimum Interpolation Sea
   Surface Temperature Analysis and the Tropical Rainfall Measuring Mission
   (TRMM) Microwave Image project. The data sets are, in practice, treated
   as an ensemble of realizations of the actual climate such that their
   differences represent an estimate of the uncertainty in their
   measurements because we do not possess global ``truth'' data sets for
   these quantities. The results are globally representative and may be
   taken as a generalization of our previous ISCCP-based uncertainty
   estimates for the input data sets. Surface properties have the primary
   role in determining the surface upward shortwave (SW) and longwave (LW)
   flux. From this study the following conclusions are obtained. Although
   land surface albedos in the near-infrared remain poorly constrained
   (highly uncertain), they do not cause too much error in total surface SW
   fluxes; the more subtle regional and seasonal variations associated with
   vegetation and snow are still in doubt. The uncertainty of the broadband
   black-sky SW albedo for land surface from this study is about 7\%, which
   can easily induce 5-10 W/m(2) uncertainty in (upwelling) surface SW flux
   estimates. Even though available surface (broadband) LW emissivity data
   sets differ significantly (3-5\% uncertainty), this disagreement is
   confined to wavelengths > 20 mu m so that there is little practical
   effect (1-3 W/m(2)) on the surface upwelling LW fluxes. The surface skin
   temperature is one of two leading factors that cause problems with
   surface LW fluxes. Even though the differences among the various data
   sets are generally only 2-4 K, this can easily cause 10-15 W/m(2)
   uncertainty in calculated surface (upwelling) LW fluxes. Significant
   improvements could be obtained for surface LW flux calculations by
   improving the retrievals of (in order of decreasing importance): (1)
   surface skin temperature, (2) surface air and near-surface-layer
   temperature, (3) column precipitable water amount, and 4) broadband
   emissivity.
   In addition, for surface SW fluxes, improvements could be obtained
   (excluding improved cloud treatment) by improving the retrievals of (1)
   aerosols (from our sensitivity studies but not discussed in this work)
   and (2) surface (black-sky) albedo, of which the NIR part of the
   spectrum has mch larger uncertainty.}},
DOI = {{10.1029/2005JD007008}},
Article-Number = {{D01102}},
ISSN = {{2169-897X}},
EISSN = {{2169-8996}},
ResearcherID-Numbers = {{Rossow, William/F-3138-2015}},
Unique-ID = {{ISI:000243530100001}},
}
