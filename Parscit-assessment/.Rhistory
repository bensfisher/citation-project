rm(list=ls())
load('~/Desktop/Dissertation/First Article/tuned_models.RData')
nrow(valdat)
summary(valdat$MAonset.c)
128/4711
summary(data$MAonset)
sum(data$MAonset)
rm(list=ls())
library(dplyr)
setwd('~/citation-project/Parscit-assessment/')
matches = read.table('results/matches.txt', header=TRUE, sep=':', fill=TRUE)
cite.types = read.csv('RIACitations.csv')
View(cite.types)
View(matches)
colnames(matches) = c('Title','jac','jac_match','lev','lev_match','partial','partial_match',
'RIN','sor','sor_match','source')
cite.types = select(cite.types, Title, RIN, Type)
merged = merge(matches, cite.types, by=c('Title','RIN'), all.x=TRUE)
View(merged)
rm(list=ls())
library(dplyr)
setwd('~/citation-project/Parscit-assessment/')
matches = read.table('results/matches2.txt', header=TRUE, sep=':', fill=TRUE)
colnames(matches) = c('Title','jac','jac_match','lev','lev_match','partial','partial_match',
'RIN','sor','sor_match','source')
rm(list=ls())
library(dplyr)
setwd('~/citation-project/Parscit-assessment/')
matches = read.table('results/matches2.txt', header=TRUE, sep=':')
colnames(matches) = c('Title','jac','jac_match','lev','lev_match','partial','partial_match',
'RIN','sor','sor_match','source')
rm(list=ls())
library(dplyr)
setwd('~/citation-project/Parscit-assessment/')
matches = read.table('results/matches.txt', header=TRUE, sep=':')
View(matches)
rm(list=ls())
library(dplyr)
setwd('~/citation-project/Parscit-assessment/')
matches = read.table('results/matches.txt', header=TRUE, sep=':')
matches = filter(matches, cite !='NO PARSCIT CITATIONS')
matches = filter(matches, cite != 'nan')
matches$partial = as.numeric(as.character(matches$partial))
matches$jac = as.numeric(as.character(matches$jac))
matches$lev = as.numeric(as.character(matches$lev))
matches$sor = as.numeric(as.character(matches$sor))
matches = na.omit(matches)
gt = filter(matches, type=='gt')
pc = filter(matches, type=='pc')
rm(list=ls())
library(dplyr)
setwd('~/citation-project/Parscit-assessment/')
matches = read.table('results/matches.txt', header=TRUE, sep=':')
matches = filter(matches, cite !='NO PARSCIT CITATIONS')
matches = filter(matches, cite != 'nan')
matches$partial = as.numeric(as.character(matches$partial))
matches$jac = as.numeric(as.character(matches$jac))
matches$lev = as.numeric(as.character(matches$lev))
matches$sor = as.numeric(as.character(matches$sor))
matches = na.omit(matches)
gt = filter(matches, source=='gt')
pc = filter(matches, source=='pc')
gt.sample = gt[sample(nrow(gt), 250),]
############################
## ParsCit Assesment ######
## Last updated: 10/20/15 ##
############################
rm(list=ls())
library(dplyr)
setwd('~/citation-project/Parscit-assessment/')
matches = read.table('results/matches.txt', header=TRUE, sep=':')
matches = filter(matches, cite !='NO PARSCIT CITATIONS')
matches = filter(matches, cite != 'nan')
matches$partial = as.numeric(as.character(matches$partial))
matches$jac = as.numeric(as.character(matches$jac))
matches$lev = as.numeric(as.character(matches$lev))
matches$sor = as.numeric(as.character(matches$sor))
matches = na.omit(matches)
gt = filter(matches, source=='gt')
pc = filter(matches, source=='pc')
set.seed(1989)
gt.sample = gt[sample(nrow(gt), 250),]
pc.sample = pc[sample(nrow(pc), 250),]
?write.table
write.table(gt.sample, 'results/gtsample.txt', sep=":", row.names=FALSE)
write.csv(gt.sample, 'results/gtsample.txt', row.names=FALSE)
write.csv(gt.sample, 'results/gtsample.csv', row.names=FALSE)
gt.sample = read.csv('results/gtsample.csv')
View(gt.sample)
library(ROCR)
View(gt.sample)
matches = filter(jac_match != ' NO PARSCIT CITATIONS')
matches = filter(matches, jac_match != ' NO PARSCIT CITATIONS')
View(matches)
View(gt.sample)
jac.gt.pred = prediction((1-gt.sample$jac), gt.sample$jac_check)
jac.gt.auc = performance(jac.gt.pred, 'auc')
jac.gt.auc = performance(jac.gt.pred, measure='auc')
jac.gt.pred
gt.sample = na.omit(gt.sample)
jac.gt.pred = prediction((1-gt.sample$jac), gt.sample$jac_check)
jac.gt.auc = performance(jac.gt.pred, measure='auc')
jac.gt.auc
jac.gt.pr = performance(jac.gt.pred, 'prec', 'rec')
jac.gt.prec = jac.gt.pr@y.values[[1]]
jac.gt.prec[is.na(jac.gt.prec)] = 0
jac.gt.aupr = trapz(jac.gt.pr@x.values[[1]], jac.gt.prec)
library(caTools)
jac.gt.aupr = trapz(jac.gt.pr@x.values[[1]], jac.gt.prec)
sum(gt.sample$jac_check)
sum(gt.sample$lev_check)
sum(gt.sample$partial_check)
sum(gt.sample$sor_check)
write.csv(pc.sample, 'results/pcsample.csv', row.names=FALSE)
pc.sample = read.csv('results/pcsample.csv')
pc.sample = na.omit(pc.sample)
jac.gt.auc
sum(gt.sample$jac_check)
sum(gt.sample$jac_check)
sum(gt.sample$lev_check)
sum(gt.sample$sor_check)
sum(gt.sample$partial_check)
sum(pc.sample$jac_check)
sum(pc.sample$lev_check)
sum(pc.sample$sor_check)
sum(pc.sample$partial_check)
View(pc.sample)
sum(pc.sample$jac_check)
sum(pc.sample$lev_check)
sum(pc.sample$sor_chck)
sum(pc.sample$partial_check)
sum(gt.sample$jac_check)
sum(gt.sample$lev_check)
sum(gt.sample$sor_check)
sum(gt.sample$partial_check)
sum(pc.sample$jac_check)
sum(pc.sample$lev_check)
sum(pc.sample$sor_chck)
sum(pc.sample$partial_check)
gt.sample = read.csv('results/gtsample.csv')
pc.sample = read.csv('results/pcsample.csv')
gt.sample[is.na(gt.sample)] = 0
sum(gt.sample$partial_check)
library(reshape2)
types = select(gt.sample, partial_check, type)
types = melt(types, id.vars=c('type'))
types = dcast(types, type~variable, fun.aggregate=sum)
types
types = select(gt.sample, partial_check, type)
types = select(gt.sample, partial_check, type)
types$total = 1
types = melt(types, id.vars=c('type'))
types = dcast(types, type~variable, fun.aggregate=sum)
types
partial.gt.pred = prediction((1-gt.sample$partial), gt.sample$partial_check)
partial.gt.auc = performance(partial.gt.pred, measure='auc')
partial.gt.auc
partial.gt.roc = performance(partial.gt.pred, 'tpr', 'fpr')
cutoffs = data.frame(cut=partial.gt.roc@alpha.values[[1]], sens=partial.gt.roc@y.values[[1]],
spec=(1-partial.gt.roc@x.values[[1]]))
View(cutoffs)
cutoffs$sum = cutoffs$sens + cutoffs$spec
best = cutoffs[which(max(cutoffs$sum)),]
max(cutoffs$sum)
best = filter(cutoffs, max(sum))
cutoffs = arrange(cutoffs, desc(sum))
cutoffs[1,]
cutoffs[1,1]
best = 1 - cutoffs[1,1]
best
gt.matched = filter(gt, partial<=.15)
View(gt)
rm(gt.matched)
gt$check = 0
gt$check[gt$partial<=best] = 1
sum(gt$check)/len(gt$check)
sum(gt$check)/length(gt$check)
gt.types = select(gt, type, check)
gt.types$total = 1
gt.types = melt(gt.types, id.vars='type')
gt.types = dcast(gt.types, type~variable, fun.aggregate=sum)
View(gt.types)
sum(gt.check)
sum(gt$check)/length(gt$check)
ria.meta = read.csv('RIAMeta.csv')
colnames(ria.meta)
ria.meta = select(ria.meta, RIN, Bibliography)
head(ria)
head(ria.meta)
colnames(ria.meta) = c('ria','bibliography')
View(gt)
gt = merge(gt, ria.meta, by='ria',all.x=TRUE)
gt.bib = select(gt, bibliography, check)
gt.bib$total = 1
gt.bib = melt(gt.bib, id.vars='bibliography')
gt.bib = dcast(gt.bib, bibliography~variable, fun.aggregate=sum)
gt.bib
gt.bib = filter(gt, bibliography=='yes' | bibliography=='Yes' | bibliography == 'References Cited')
gt.bib = select(gt, type, check)
gt.bib$total = 1
gt.bib = melt(gt.bib, id.vars='type')
gt.bib = dcast(gt.bib, type~variable, fun.aggregate=sum)
gt.bib
gt.bib = dcast(gt.bib, type~variable, fun.aggregate=sum)
gt.bib = filter(gt, bibliography=='yes' | bibliography=='Yes' | bibliography == 'References Cited')
gt.bib = select(gt, type, check)
gt.bib$total = 1
gt.bib = melt(gt.bib, id.vars='type')
gt.bib = dcast(gt.bib, type~variable, fun.aggregate=sum)
gt.bib
View(gt.bib)
View(gt.types)
